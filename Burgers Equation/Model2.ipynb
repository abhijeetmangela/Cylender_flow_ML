{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e2e462d8b0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mu = torch.tensor(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepONet,self).__init__()\n",
    "        self.Branch_L1 = nn.Linear(100,100)\n",
    "        self.Branch_L2 = nn.Linear(100,100)\n",
    "        self.Branch_L3 = nn.Linear(100,100)\n",
    "        self.Branch_L4 = nn.Linear(100,100)\n",
    "        self.Branch_L5 = nn.Linear(100,100)\n",
    "        self.Branch_L6 = nn.Linear(100,100)\n",
    "        self.Branch_L7 = nn.Linear(100,100)\n",
    "\n",
    "        self.Trunk_L1 = nn.Linear(2,20)\n",
    "        self.Trunk_L2 = nn.Linear(20,20)\n",
    "        self.Trunk_L3 = nn.Linear(20,20)\n",
    "        self.Trunk_L4 = nn.Linear(20,20)\n",
    "        self.Trunk_L5 = nn.Linear(20,100)\n",
    "\n",
    "    def forward(self,y_0,x_loc_and_time):\n",
    "        # Branch\n",
    "        b = F.tanh(self.Branch_L1(y_0))\n",
    "        b = F.tanh(self.Branch_L2(b))\n",
    "        b = F.tanh(self.Branch_L3(b))\n",
    "        b = F.tanh(self.Branch_L4(b))\n",
    "        b = F.tanh(self.Branch_L5(b))\n",
    "        b = F.tanh(self.Branch_L6(b))\n",
    "        b = self.Branch_L7(b)\n",
    "\n",
    "        tr = F.tanh(self.Trunk_L1(x_loc_and_time))\n",
    "        tr = F.tanh(self.Trunk_L2(tr))\n",
    "        tr = F.tanh(self.Trunk_L3(tr))\n",
    "        tr = F.tanh(self.Trunk_L4(tr))\n",
    "        tr = self.Trunk_L5(tr)\n",
    "\n",
    "        #output = torch.matmul(b,tr.t()).sum(dim=0)\n",
    "        output = torch.sum(b * tr, dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = DeepONet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv('sin_pix.csv',index_col=0).dropna().to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 103)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,transform=None):\n",
    "        self.initial_conditions = torch.from_numpy(database[:,0:100])#.requires_grad_(True)\n",
    "        self.x_location = torch.from_numpy(database[:,[100]])#.requires_grad_(True)\n",
    "        self.time_vale = torch.from_numpy(database[:,[101]])#.requires_grad_(True)\n",
    "        self.true_y_value = torch.from_numpy(database[:,[102]])#.requires_grad_(True)\n",
    "        self.n_samples = database.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.initial_conditions[index] , self.x_location[index] , self.time_vale[index] , self.true_y_value[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,_,_,_ = dataset_data.__getitem__(1)\n",
    "#plt.plot(y)\n",
    "#plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6*dataset_data.__len__())\n",
    "test_size = dataset_data.__len__() - train_size\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "Burger_train_data , Burger_test_data = torch.utils.data.random_split(Data(),[train_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=Burger_train_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19800"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "data = data_iter.__next__()\n",
    "Init_val , x_loc, time, y_value = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 1\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1000\n",
    "total_samples = len(train_loader)\n",
    "n_iterations = math.ceil(total_samples/300)\n",
    "print(total_samples,n_iterations)\n",
    "learning_rate = 0.0000001\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "loss_rec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(outputs,inputs):\n",
    "    return torch.autograd.grad(outputs,inputs,grad_outputs=torch.ones_like(outputs),create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Physics_loss(init_conditions,time_input_physics):\n",
    "    for j in range(2):\n",
    "        x_locations = torch.linspace(0,1,300,dtype=torch.float32).requires_grad_(True)\n",
    "        time_input = time_input_physics*torch.ones_like(x_locations,dtype=torch.float32).requires_grad_(True)\n",
    "        input_1_physics = init_conditions.unsqueeze(0)\n",
    "        input2_physics = torch.cat((x_locations.unsqueeze(-1),time_input.unsqueeze(-1)),-1)\n",
    "        output_physics = model(input_1_physics,input2_physics)\n",
    "        du_dt = grad(output_physics,time_input)[0]\n",
    "        du_dx = grad(output_physics,x_locations)[0]\n",
    "        du2_dx2 = grad(du_dx,x_locations)[0]\n",
    "        return torch.mean(du_dt + output_physics*du_dx - mu*du2_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_locations = torch.linspace(0,1,300,dtype=torch.float32).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
      "        0.2000, 0.2000, 0.2000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "time_input_physics = torch.tensor(0.2)\n",
    "time_input = time_input_physics*torch.ones_like(x_locations,dtype=torch.float32).requires_grad_(True)\n",
    "print(time_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.2000],\n",
      "        [0.0033, 0.2000],\n",
      "        [0.0067, 0.2000],\n",
      "        [0.0100, 0.2000],\n",
      "        [0.0134, 0.2000],\n",
      "        [0.0167, 0.2000],\n",
      "        [0.0201, 0.2000],\n",
      "        [0.0234, 0.2000],\n",
      "        [0.0268, 0.2000],\n",
      "        [0.0301, 0.2000],\n",
      "        [0.0334, 0.2000],\n",
      "        [0.0368, 0.2000],\n",
      "        [0.0401, 0.2000],\n",
      "        [0.0435, 0.2000],\n",
      "        [0.0468, 0.2000],\n",
      "        [0.0502, 0.2000],\n",
      "        [0.0535, 0.2000],\n",
      "        [0.0569, 0.2000],\n",
      "        [0.0602, 0.2000],\n",
      "        [0.0635, 0.2000],\n",
      "        [0.0669, 0.2000],\n",
      "        [0.0702, 0.2000],\n",
      "        [0.0736, 0.2000],\n",
      "        [0.0769, 0.2000],\n",
      "        [0.0803, 0.2000],\n",
      "        [0.0836, 0.2000],\n",
      "        [0.0870, 0.2000],\n",
      "        [0.0903, 0.2000],\n",
      "        [0.0936, 0.2000],\n",
      "        [0.0970, 0.2000],\n",
      "        [0.1003, 0.2000],\n",
      "        [0.1037, 0.2000],\n",
      "        [0.1070, 0.2000],\n",
      "        [0.1104, 0.2000],\n",
      "        [0.1137, 0.2000],\n",
      "        [0.1171, 0.2000],\n",
      "        [0.1204, 0.2000],\n",
      "        [0.1237, 0.2000],\n",
      "        [0.1271, 0.2000],\n",
      "        [0.1304, 0.2000],\n",
      "        [0.1338, 0.2000],\n",
      "        [0.1371, 0.2000],\n",
      "        [0.1405, 0.2000],\n",
      "        [0.1438, 0.2000],\n",
      "        [0.1472, 0.2000],\n",
      "        [0.1505, 0.2000],\n",
      "        [0.1538, 0.2000],\n",
      "        [0.1572, 0.2000],\n",
      "        [0.1605, 0.2000],\n",
      "        [0.1639, 0.2000],\n",
      "        [0.1672, 0.2000],\n",
      "        [0.1706, 0.2000],\n",
      "        [0.1739, 0.2000],\n",
      "        [0.1773, 0.2000],\n",
      "        [0.1806, 0.2000],\n",
      "        [0.1839, 0.2000],\n",
      "        [0.1873, 0.2000],\n",
      "        [0.1906, 0.2000],\n",
      "        [0.1940, 0.2000],\n",
      "        [0.1973, 0.2000],\n",
      "        [0.2007, 0.2000],\n",
      "        [0.2040, 0.2000],\n",
      "        [0.2074, 0.2000],\n",
      "        [0.2107, 0.2000],\n",
      "        [0.2140, 0.2000],\n",
      "        [0.2174, 0.2000],\n",
      "        [0.2207, 0.2000],\n",
      "        [0.2241, 0.2000],\n",
      "        [0.2274, 0.2000],\n",
      "        [0.2308, 0.2000],\n",
      "        [0.2341, 0.2000],\n",
      "        [0.2375, 0.2000],\n",
      "        [0.2408, 0.2000],\n",
      "        [0.2441, 0.2000],\n",
      "        [0.2475, 0.2000],\n",
      "        [0.2508, 0.2000],\n",
      "        [0.2542, 0.2000],\n",
      "        [0.2575, 0.2000],\n",
      "        [0.2609, 0.2000],\n",
      "        [0.2642, 0.2000],\n",
      "        [0.2676, 0.2000],\n",
      "        [0.2709, 0.2000],\n",
      "        [0.2742, 0.2000],\n",
      "        [0.2776, 0.2000],\n",
      "        [0.2809, 0.2000],\n",
      "        [0.2843, 0.2000],\n",
      "        [0.2876, 0.2000],\n",
      "        [0.2910, 0.2000],\n",
      "        [0.2943, 0.2000],\n",
      "        [0.2977, 0.2000],\n",
      "        [0.3010, 0.2000],\n",
      "        [0.3043, 0.2000],\n",
      "        [0.3077, 0.2000],\n",
      "        [0.3110, 0.2000],\n",
      "        [0.3144, 0.2000],\n",
      "        [0.3177, 0.2000],\n",
      "        [0.3211, 0.2000],\n",
      "        [0.3244, 0.2000],\n",
      "        [0.3278, 0.2000],\n",
      "        [0.3311, 0.2000],\n",
      "        [0.3344, 0.2000],\n",
      "        [0.3378, 0.2000],\n",
      "        [0.3411, 0.2000],\n",
      "        [0.3445, 0.2000],\n",
      "        [0.3478, 0.2000],\n",
      "        [0.3512, 0.2000],\n",
      "        [0.3545, 0.2000],\n",
      "        [0.3579, 0.2000],\n",
      "        [0.3612, 0.2000],\n",
      "        [0.3645, 0.2000],\n",
      "        [0.3679, 0.2000],\n",
      "        [0.3712, 0.2000],\n",
      "        [0.3746, 0.2000],\n",
      "        [0.3779, 0.2000],\n",
      "        [0.3813, 0.2000],\n",
      "        [0.3846, 0.2000],\n",
      "        [0.3880, 0.2000],\n",
      "        [0.3913, 0.2000],\n",
      "        [0.3946, 0.2000],\n",
      "        [0.3980, 0.2000],\n",
      "        [0.4013, 0.2000],\n",
      "        [0.4047, 0.2000],\n",
      "        [0.4080, 0.2000],\n",
      "        [0.4114, 0.2000],\n",
      "        [0.4147, 0.2000],\n",
      "        [0.4181, 0.2000],\n",
      "        [0.4214, 0.2000],\n",
      "        [0.4247, 0.2000],\n",
      "        [0.4281, 0.2000],\n",
      "        [0.4314, 0.2000],\n",
      "        [0.4348, 0.2000],\n",
      "        [0.4381, 0.2000],\n",
      "        [0.4415, 0.2000],\n",
      "        [0.4448, 0.2000],\n",
      "        [0.4482, 0.2000],\n",
      "        [0.4515, 0.2000],\n",
      "        [0.4548, 0.2000],\n",
      "        [0.4582, 0.2000],\n",
      "        [0.4615, 0.2000],\n",
      "        [0.4649, 0.2000],\n",
      "        [0.4682, 0.2000],\n",
      "        [0.4716, 0.2000],\n",
      "        [0.4749, 0.2000],\n",
      "        [0.4783, 0.2000],\n",
      "        [0.4816, 0.2000],\n",
      "        [0.4849, 0.2000],\n",
      "        [0.4883, 0.2000],\n",
      "        [0.4916, 0.2000],\n",
      "        [0.4950, 0.2000],\n",
      "        [0.4983, 0.2000],\n",
      "        [0.5017, 0.2000],\n",
      "        [0.5050, 0.2000],\n",
      "        [0.5084, 0.2000],\n",
      "        [0.5117, 0.2000],\n",
      "        [0.5151, 0.2000],\n",
      "        [0.5184, 0.2000],\n",
      "        [0.5217, 0.2000],\n",
      "        [0.5251, 0.2000],\n",
      "        [0.5284, 0.2000],\n",
      "        [0.5318, 0.2000],\n",
      "        [0.5351, 0.2000],\n",
      "        [0.5385, 0.2000],\n",
      "        [0.5418, 0.2000],\n",
      "        [0.5452, 0.2000],\n",
      "        [0.5485, 0.2000],\n",
      "        [0.5518, 0.2000],\n",
      "        [0.5552, 0.2000],\n",
      "        [0.5585, 0.2000],\n",
      "        [0.5619, 0.2000],\n",
      "        [0.5652, 0.2000],\n",
      "        [0.5686, 0.2000],\n",
      "        [0.5719, 0.2000],\n",
      "        [0.5753, 0.2000],\n",
      "        [0.5786, 0.2000],\n",
      "        [0.5819, 0.2000],\n",
      "        [0.5853, 0.2000],\n",
      "        [0.5886, 0.2000],\n",
      "        [0.5920, 0.2000],\n",
      "        [0.5953, 0.2000],\n",
      "        [0.5987, 0.2000],\n",
      "        [0.6020, 0.2000],\n",
      "        [0.6054, 0.2000],\n",
      "        [0.6087, 0.2000],\n",
      "        [0.6120, 0.2000],\n",
      "        [0.6154, 0.2000],\n",
      "        [0.6187, 0.2000],\n",
      "        [0.6221, 0.2000],\n",
      "        [0.6254, 0.2000],\n",
      "        [0.6288, 0.2000],\n",
      "        [0.6321, 0.2000],\n",
      "        [0.6355, 0.2000],\n",
      "        [0.6388, 0.2000],\n",
      "        [0.6421, 0.2000],\n",
      "        [0.6455, 0.2000],\n",
      "        [0.6488, 0.2000],\n",
      "        [0.6522, 0.2000],\n",
      "        [0.6555, 0.2000],\n",
      "        [0.6589, 0.2000],\n",
      "        [0.6622, 0.2000],\n",
      "        [0.6656, 0.2000],\n",
      "        [0.6689, 0.2000],\n",
      "        [0.6722, 0.2000],\n",
      "        [0.6756, 0.2000],\n",
      "        [0.6789, 0.2000],\n",
      "        [0.6823, 0.2000],\n",
      "        [0.6856, 0.2000],\n",
      "        [0.6890, 0.2000],\n",
      "        [0.6923, 0.2000],\n",
      "        [0.6957, 0.2000],\n",
      "        [0.6990, 0.2000],\n",
      "        [0.7023, 0.2000],\n",
      "        [0.7057, 0.2000],\n",
      "        [0.7090, 0.2000],\n",
      "        [0.7124, 0.2000],\n",
      "        [0.7157, 0.2000],\n",
      "        [0.7191, 0.2000],\n",
      "        [0.7224, 0.2000],\n",
      "        [0.7258, 0.2000],\n",
      "        [0.7291, 0.2000],\n",
      "        [0.7324, 0.2000],\n",
      "        [0.7358, 0.2000],\n",
      "        [0.7391, 0.2000],\n",
      "        [0.7425, 0.2000],\n",
      "        [0.7458, 0.2000],\n",
      "        [0.7492, 0.2000],\n",
      "        [0.7525, 0.2000],\n",
      "        [0.7559, 0.2000],\n",
      "        [0.7592, 0.2000],\n",
      "        [0.7625, 0.2000],\n",
      "        [0.7659, 0.2000],\n",
      "        [0.7692, 0.2000],\n",
      "        [0.7726, 0.2000],\n",
      "        [0.7759, 0.2000],\n",
      "        [0.7793, 0.2000],\n",
      "        [0.7826, 0.2000],\n",
      "        [0.7860, 0.2000],\n",
      "        [0.7893, 0.2000],\n",
      "        [0.7926, 0.2000],\n",
      "        [0.7960, 0.2000],\n",
      "        [0.7993, 0.2000],\n",
      "        [0.8027, 0.2000],\n",
      "        [0.8060, 0.2000],\n",
      "        [0.8094, 0.2000],\n",
      "        [0.8127, 0.2000],\n",
      "        [0.8161, 0.2000],\n",
      "        [0.8194, 0.2000],\n",
      "        [0.8227, 0.2000],\n",
      "        [0.8261, 0.2000],\n",
      "        [0.8294, 0.2000],\n",
      "        [0.8328, 0.2000],\n",
      "        [0.8361, 0.2000],\n",
      "        [0.8395, 0.2000],\n",
      "        [0.8428, 0.2000],\n",
      "        [0.8462, 0.2000],\n",
      "        [0.8495, 0.2000],\n",
      "        [0.8528, 0.2000],\n",
      "        [0.8562, 0.2000],\n",
      "        [0.8595, 0.2000],\n",
      "        [0.8629, 0.2000],\n",
      "        [0.8662, 0.2000],\n",
      "        [0.8696, 0.2000],\n",
      "        [0.8729, 0.2000],\n",
      "        [0.8763, 0.2000],\n",
      "        [0.8796, 0.2000],\n",
      "        [0.8829, 0.2000],\n",
      "        [0.8863, 0.2000],\n",
      "        [0.8896, 0.2000],\n",
      "        [0.8930, 0.2000],\n",
      "        [0.8963, 0.2000],\n",
      "        [0.8997, 0.2000],\n",
      "        [0.9030, 0.2000],\n",
      "        [0.9064, 0.2000],\n",
      "        [0.9097, 0.2000],\n",
      "        [0.9130, 0.2000],\n",
      "        [0.9164, 0.2000],\n",
      "        [0.9197, 0.2000],\n",
      "        [0.9231, 0.2000],\n",
      "        [0.9264, 0.2000],\n",
      "        [0.9298, 0.2000],\n",
      "        [0.9331, 0.2000],\n",
      "        [0.9365, 0.2000],\n",
      "        [0.9398, 0.2000],\n",
      "        [0.9431, 0.2000],\n",
      "        [0.9465, 0.2000],\n",
      "        [0.9498, 0.2000],\n",
      "        [0.9532, 0.2000],\n",
      "        [0.9565, 0.2000],\n",
      "        [0.9599, 0.2000],\n",
      "        [0.9632, 0.2000],\n",
      "        [0.9666, 0.2000],\n",
      "        [0.9699, 0.2000],\n",
      "        [0.9732, 0.2000],\n",
      "        [0.9766, 0.2000],\n",
      "        [0.9799, 0.2000],\n",
      "        [0.9833, 0.2000],\n",
      "        [0.9866, 0.2000],\n",
      "        [0.9900, 0.2000],\n",
      "        [0.9933, 0.2000],\n",
      "        [0.9967, 0.2000],\n",
      "        [1.0000, 0.2000]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input2_physics = torch.cat((x_locations.unsqueeze(-1),time_input.unsqueeze(-1)),-1)\n",
    "print(input2_physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_1_physics = input1[1,:].unsqueeze(0)\n",
    "#input_1_physics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_physics = model(input_1_physics,input2_physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#du_dt = grad(output_physics,time_input)[0]\n",
    "#du_dx = grad(output_physics,x_locations)[0]\n",
    "#du2_dx2 = grad(du_dx,x_locations)[0]\n",
    "#loss_physics_burgers = torch.mean(du_dt + x_locations*du_dx - mu*du2_dx2)\n",
    "#loss_physics_burgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physics_loss_rec = Physics_loss(input1,input_time[3])\n",
    "#Physics_loss_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] , Step [10/40] , Loss: 56.5995941162109375\n",
      "Epoch [1/1000] , Step [20/40] , Loss: 38.4516410827636719\n",
      "Epoch [1/1000] , Step [30/40] , Loss: 24.6633071899414062\n",
      "Epoch [1/1000] , Step [40/40] , Loss: 14.8686094284057617\n",
      "Epoch [2/1000] , Step [10/40] , Loss: 8.4469442367553711\n",
      "Epoch [2/1000] , Step [20/40] , Loss: 4.6344499588012695\n",
      "Epoch [2/1000] , Step [30/40] , Loss: 2.6424450874328613\n",
      "Epoch [2/1000] , Step [40/40] , Loss: 1.7520772218704224\n",
      "Epoch [3/1000] , Step [10/40] , Loss: 1.4442034959793091\n",
      "Epoch [3/1000] , Step [20/40] , Loss: 1.3289878368377686\n",
      "Epoch [3/1000] , Step [30/40] , Loss: 1.2765829563140869\n",
      "Epoch [3/1000] , Step [40/40] , Loss: 1.2403537034988403\n",
      "Epoch [4/1000] , Step [10/40] , Loss: 1.2312407493591309\n",
      "Epoch [4/1000] , Step [20/40] , Loss: 1.1999136209487915\n",
      "Epoch [4/1000] , Step [30/40] , Loss: 1.1652846336364746\n",
      "Epoch [4/1000] , Step [40/40] , Loss: 1.1314847469329834\n",
      "Epoch [5/1000] , Step [10/40] , Loss: 1.0968023538589478\n",
      "Epoch [5/1000] , Step [20/40] , Loss: 1.0495258569717407\n",
      "Epoch [5/1000] , Step [30/40] , Loss: 1.0460441112518311\n",
      "Epoch [5/1000] , Step [40/40] , Loss: 1.0284531116485596\n",
      "Epoch [6/1000] , Step [10/40] , Loss: 1.0141267776489258\n",
      "Epoch [6/1000] , Step [20/40] , Loss: 0.9355283379554749\n",
      "Epoch [6/1000] , Step [30/40] , Loss: 0.9644770622253418\n",
      "Epoch [6/1000] , Step [40/40] , Loss: 0.8732951879501343\n",
      "Epoch [7/1000] , Step [10/40] , Loss: 0.8801741003990173\n",
      "Epoch [7/1000] , Step [20/40] , Loss: 0.8841461539268494\n",
      "Epoch [7/1000] , Step [30/40] , Loss: 0.8516273498535156\n",
      "Epoch [7/1000] , Step [40/40] , Loss: 0.7976798415184021\n",
      "Epoch [8/1000] , Step [10/40] , Loss: 0.8055675625801086\n",
      "Epoch [8/1000] , Step [20/40] , Loss: 0.7749507427215576\n",
      "Epoch [8/1000] , Step [30/40] , Loss: 0.7905685901641846\n",
      "Epoch [8/1000] , Step [40/40] , Loss: 0.7824102640151978\n",
      "Epoch [9/1000] , Step [10/40] , Loss: 0.7465019822120667\n",
      "Epoch [9/1000] , Step [20/40] , Loss: 0.7099558115005493\n",
      "Epoch [9/1000] , Step [30/40] , Loss: 0.7026260495185852\n",
      "Epoch [9/1000] , Step [40/40] , Loss: 0.7052236795425415\n",
      "Epoch [10/1000] , Step [10/40] , Loss: 0.6857437491416931\n",
      "Epoch [10/1000] , Step [20/40] , Loss: 0.6974358558654785\n",
      "Epoch [10/1000] , Step [30/40] , Loss: 0.6718220710754395\n",
      "Epoch [10/1000] , Step [40/40] , Loss: 0.6421055793762207\n",
      "Epoch [11/1000] , Step [10/40] , Loss: 0.6344926357269287\n",
      "Epoch [11/1000] , Step [20/40] , Loss: 0.6289358139038086\n",
      "Epoch [11/1000] , Step [30/40] , Loss: 0.6262183189392090\n",
      "Epoch [11/1000] , Step [40/40] , Loss: 0.5820799469947815\n",
      "Epoch [12/1000] , Step [10/40] , Loss: 0.5728124380111694\n",
      "Epoch [12/1000] , Step [20/40] , Loss: 0.6025111675262451\n",
      "Epoch [12/1000] , Step [30/40] , Loss: 0.5743704438209534\n",
      "Epoch [12/1000] , Step [40/40] , Loss: 0.5479961633682251\n",
      "Epoch [13/1000] , Step [10/40] , Loss: 0.5790805220603943\n",
      "Epoch [13/1000] , Step [20/40] , Loss: 0.5718317031860352\n",
      "Epoch [13/1000] , Step [30/40] , Loss: 0.5264802575111389\n",
      "Epoch [13/1000] , Step [40/40] , Loss: 0.5583498477935791\n",
      "Epoch [14/1000] , Step [10/40] , Loss: 0.5398998856544495\n",
      "Epoch [14/1000] , Step [20/40] , Loss: 0.5540719628334045\n",
      "Epoch [14/1000] , Step [30/40] , Loss: 0.5501059293746948\n",
      "Epoch [14/1000] , Step [40/40] , Loss: 0.5272628664970398\n",
      "Epoch [15/1000] , Step [10/40] , Loss: 0.5312578678131104\n",
      "Epoch [15/1000] , Step [20/40] , Loss: 0.5069759488105774\n",
      "Epoch [15/1000] , Step [30/40] , Loss: 0.5111147165298462\n",
      "Epoch [15/1000] , Step [40/40] , Loss: 0.5071589350700378\n",
      "Epoch [16/1000] , Step [10/40] , Loss: 0.5026391148567200\n",
      "Epoch [16/1000] , Step [20/40] , Loss: 0.4893202781677246\n",
      "Epoch [16/1000] , Step [30/40] , Loss: 0.5010582804679871\n",
      "Epoch [16/1000] , Step [40/40] , Loss: 0.5265481472015381\n",
      "Epoch [17/1000] , Step [10/40] , Loss: 0.5085859894752502\n",
      "Epoch [17/1000] , Step [20/40] , Loss: 0.4930419921875000\n",
      "Epoch [17/1000] , Step [30/40] , Loss: 0.5115281939506531\n",
      "Epoch [17/1000] , Step [40/40] , Loss: 0.5173029303550720\n",
      "Epoch [18/1000] , Step [10/40] , Loss: 0.4671270549297333\n",
      "Epoch [18/1000] , Step [20/40] , Loss: 0.4944009780883789\n",
      "Epoch [18/1000] , Step [30/40] , Loss: 0.4943928122520447\n",
      "Epoch [18/1000] , Step [40/40] , Loss: 0.4767679870128632\n",
      "Epoch [19/1000] , Step [10/40] , Loss: 0.5063994526863098\n",
      "Epoch [19/1000] , Step [20/40] , Loss: 0.4884881973266602\n",
      "Epoch [19/1000] , Step [30/40] , Loss: 0.4778077602386475\n",
      "Epoch [19/1000] , Step [40/40] , Loss: 0.4483466744422913\n",
      "Epoch [20/1000] , Step [10/40] , Loss: 0.4770646691322327\n",
      "Epoch [20/1000] , Step [20/40] , Loss: 0.4711838066577911\n",
      "Epoch [20/1000] , Step [30/40] , Loss: 0.4551692306995392\n",
      "Epoch [20/1000] , Step [40/40] , Loss: 0.4652387201786041\n",
      "Epoch [21/1000] , Step [10/40] , Loss: 0.4583254456520081\n",
      "Epoch [21/1000] , Step [20/40] , Loss: 0.4958311319351196\n",
      "Epoch [21/1000] , Step [30/40] , Loss: 0.4954432547092438\n",
      "Epoch [21/1000] , Step [40/40] , Loss: 0.4543979167938232\n",
      "Epoch [22/1000] , Step [10/40] , Loss: 0.4718075692653656\n",
      "Epoch [22/1000] , Step [20/40] , Loss: 0.4943692684173584\n",
      "Epoch [22/1000] , Step [30/40] , Loss: 0.4869239330291748\n",
      "Epoch [22/1000] , Step [40/40] , Loss: 0.4855093657970428\n",
      "Epoch [23/1000] , Step [10/40] , Loss: 0.4599524140357971\n",
      "Epoch [23/1000] , Step [20/40] , Loss: 0.4638971984386444\n",
      "Epoch [23/1000] , Step [30/40] , Loss: 0.4959532022476196\n",
      "Epoch [23/1000] , Step [40/40] , Loss: 0.4900419116020203\n",
      "Epoch [24/1000] , Step [10/40] , Loss: 0.4753491282463074\n",
      "Epoch [24/1000] , Step [20/40] , Loss: 0.4819608330726624\n",
      "Epoch [24/1000] , Step [30/40] , Loss: 0.4502105116844177\n",
      "Epoch [24/1000] , Step [40/40] , Loss: 0.4782664775848389\n",
      "Epoch [25/1000] , Step [10/40] , Loss: 0.4753907918930054\n",
      "Epoch [25/1000] , Step [20/40] , Loss: 0.5011374950408936\n",
      "Epoch [25/1000] , Step [30/40] , Loss: 0.4829149246215820\n",
      "Epoch [25/1000] , Step [40/40] , Loss: 0.4629007875919342\n",
      "Epoch [26/1000] , Step [10/40] , Loss: 0.4965465068817139\n",
      "Epoch [26/1000] , Step [20/40] , Loss: 0.4632909595966339\n",
      "Epoch [26/1000] , Step [30/40] , Loss: 0.4854701161384583\n",
      "Epoch [26/1000] , Step [40/40] , Loss: 0.4592365026473999\n",
      "Epoch [27/1000] , Step [10/40] , Loss: 0.4833673834800720\n",
      "Epoch [27/1000] , Step [20/40] , Loss: 0.4574660360813141\n",
      "Epoch [27/1000] , Step [30/40] , Loss: 0.4883196353912354\n",
      "Epoch [27/1000] , Step [40/40] , Loss: 0.4617516994476318\n",
      "Epoch [28/1000] , Step [10/40] , Loss: 0.4747468531131744\n",
      "Epoch [28/1000] , Step [20/40] , Loss: 0.4857220351696014\n",
      "Epoch [28/1000] , Step [30/40] , Loss: 0.4947802126407623\n",
      "Epoch [28/1000] , Step [40/40] , Loss: 0.4836756885051727\n",
      "Epoch [29/1000] , Step [10/40] , Loss: 0.4912799298763275\n",
      "Epoch [29/1000] , Step [20/40] , Loss: 0.4608491659164429\n",
      "Epoch [29/1000] , Step [30/40] , Loss: 0.4539653062820435\n",
      "Epoch [29/1000] , Step [40/40] , Loss: 0.4829303026199341\n",
      "Epoch [30/1000] , Step [10/40] , Loss: 0.5080980658531189\n",
      "Epoch [30/1000] , Step [20/40] , Loss: 0.5102273225784302\n",
      "Epoch [30/1000] , Step [30/40] , Loss: 0.4690560996532440\n",
      "Epoch [30/1000] , Step [40/40] , Loss: 0.4830792844295502\n",
      "Epoch [31/1000] , Step [10/40] , Loss: 0.4948962926864624\n",
      "Epoch [31/1000] , Step [20/40] , Loss: 0.4533112049102783\n",
      "Epoch [31/1000] , Step [30/40] , Loss: 0.4786476194858551\n",
      "Epoch [31/1000] , Step [40/40] , Loss: 0.4766131639480591\n",
      "Epoch [32/1000] , Step [10/40] , Loss: 0.4974223673343658\n",
      "Epoch [32/1000] , Step [20/40] , Loss: 0.4816423058509827\n",
      "Epoch [32/1000] , Step [30/40] , Loss: 0.4793708622455597\n",
      "Epoch [32/1000] , Step [40/40] , Loss: 0.4937627315521240\n",
      "Epoch [33/1000] , Step [10/40] , Loss: 0.5115748643875122\n",
      "Epoch [33/1000] , Step [20/40] , Loss: 0.4765167534351349\n",
      "Epoch [33/1000] , Step [30/40] , Loss: 0.4680380225181580\n",
      "Epoch [33/1000] , Step [40/40] , Loss: 0.4794281423091888\n",
      "Epoch [34/1000] , Step [10/40] , Loss: 0.4871425032615662\n",
      "Epoch [34/1000] , Step [20/40] , Loss: 0.4706188738346100\n",
      "Epoch [34/1000] , Step [30/40] , Loss: 0.4940423071384430\n",
      "Epoch [34/1000] , Step [40/40] , Loss: 0.5115363001823425\n",
      "Epoch [35/1000] , Step [10/40] , Loss: 0.4979994595050812\n",
      "Epoch [35/1000] , Step [20/40] , Loss: 0.4710412025451660\n",
      "Epoch [35/1000] , Step [30/40] , Loss: 0.4823998510837555\n",
      "Epoch [35/1000] , Step [40/40] , Loss: 0.4784651398658752\n",
      "Epoch [36/1000] , Step [10/40] , Loss: 0.4768038392066956\n",
      "Epoch [36/1000] , Step [20/40] , Loss: 0.4753997027873993\n",
      "Epoch [36/1000] , Step [30/40] , Loss: 0.5027296543121338\n",
      "Epoch [36/1000] , Step [40/40] , Loss: 0.4898675680160522\n",
      "Epoch [37/1000] , Step [10/40] , Loss: 0.5129610896110535\n",
      "Epoch [37/1000] , Step [20/40] , Loss: 0.5005341768264771\n",
      "Epoch [37/1000] , Step [30/40] , Loss: 0.4794552326202393\n",
      "Epoch [37/1000] , Step [40/40] , Loss: 0.4425846636295319\n",
      "Epoch [38/1000] , Step [10/40] , Loss: 0.4663357436656952\n",
      "Epoch [38/1000] , Step [20/40] , Loss: 0.4827780723571777\n",
      "Epoch [38/1000] , Step [30/40] , Loss: 0.4703819751739502\n",
      "Epoch [38/1000] , Step [40/40] , Loss: 0.4643327891826630\n",
      "Epoch [39/1000] , Step [10/40] , Loss: 0.4594104886054993\n",
      "Epoch [39/1000] , Step [20/40] , Loss: 0.4647032618522644\n",
      "Epoch [39/1000] , Step [30/40] , Loss: 0.4927127361297607\n",
      "Epoch [39/1000] , Step [40/40] , Loss: 0.4681233763694763\n",
      "Epoch [40/1000] , Step [10/40] , Loss: 0.4928367137908936\n",
      "Epoch [40/1000] , Step [20/40] , Loss: 0.5005014538764954\n",
      "Epoch [40/1000] , Step [30/40] , Loss: 0.4693689346313477\n",
      "Epoch [40/1000] , Step [40/40] , Loss: 0.4857008457183838\n",
      "Epoch [41/1000] , Step [10/40] , Loss: 0.4810986816883087\n",
      "Epoch [41/1000] , Step [20/40] , Loss: 0.4721200764179230\n",
      "Epoch [41/1000] , Step [30/40] , Loss: 0.4862411916255951\n",
      "Epoch [41/1000] , Step [40/40] , Loss: 0.4525106251239777\n",
      "Epoch [42/1000] , Step [10/40] , Loss: 0.4686578810214996\n",
      "Epoch [42/1000] , Step [20/40] , Loss: 0.4914971590042114\n",
      "Epoch [42/1000] , Step [30/40] , Loss: 0.4994506537914276\n",
      "Epoch [42/1000] , Step [40/40] , Loss: 0.5229683518409729\n",
      "Epoch [43/1000] , Step [10/40] , Loss: 0.4764426052570343\n",
      "Epoch [43/1000] , Step [20/40] , Loss: 0.4937633275985718\n",
      "Epoch [43/1000] , Step [30/40] , Loss: 0.4884886741638184\n",
      "Epoch [43/1000] , Step [40/40] , Loss: 0.4902152121067047\n",
      "Epoch [44/1000] , Step [10/40] , Loss: 0.4988543391227722\n",
      "Epoch [44/1000] , Step [20/40] , Loss: 0.4608230888843536\n",
      "Epoch [44/1000] , Step [30/40] , Loss: 0.4710524082183838\n",
      "Epoch [44/1000] , Step [40/40] , Loss: 0.4926419258117676\n",
      "Epoch [45/1000] , Step [10/40] , Loss: 0.5058760643005371\n",
      "Epoch [45/1000] , Step [20/40] , Loss: 0.4860238432884216\n",
      "Epoch [45/1000] , Step [30/40] , Loss: 0.4663277268409729\n",
      "Epoch [45/1000] , Step [40/40] , Loss: 0.4770637154579163\n",
      "Epoch [46/1000] , Step [10/40] , Loss: 0.4725903868675232\n",
      "Epoch [46/1000] , Step [20/40] , Loss: 0.4870551526546478\n",
      "Epoch [46/1000] , Step [30/40] , Loss: 0.4616758525371552\n",
      "Epoch [46/1000] , Step [40/40] , Loss: 0.4733396768569946\n",
      "Epoch [47/1000] , Step [10/40] , Loss: 0.4850988984107971\n",
      "Epoch [47/1000] , Step [20/40] , Loss: 0.4884681999683380\n",
      "Epoch [47/1000] , Step [30/40] , Loss: 0.4863209724426270\n",
      "Epoch [47/1000] , Step [40/40] , Loss: 0.4647010862827301\n",
      "Epoch [48/1000] , Step [10/40] , Loss: 0.4732332825660706\n",
      "Epoch [48/1000] , Step [20/40] , Loss: 0.4655609130859375\n",
      "Epoch [48/1000] , Step [30/40] , Loss: 0.4650353491306305\n",
      "Epoch [48/1000] , Step [40/40] , Loss: 0.4509238302707672\n",
      "Epoch [49/1000] , Step [10/40] , Loss: 0.5010150671005249\n",
      "Epoch [49/1000] , Step [20/40] , Loss: 0.4664084315299988\n",
      "Epoch [49/1000] , Step [30/40] , Loss: 0.4739896655082703\n",
      "Epoch [49/1000] , Step [40/40] , Loss: 0.4822966754436493\n",
      "Epoch [50/1000] , Step [10/40] , Loss: 0.4805097579956055\n",
      "Epoch [50/1000] , Step [20/40] , Loss: 0.4801540970802307\n",
      "Epoch [50/1000] , Step [30/40] , Loss: 0.4981449544429779\n",
      "Epoch [50/1000] , Step [40/40] , Loss: 0.4889392554759979\n",
      "Epoch [51/1000] , Step [10/40] , Loss: 0.4553034007549286\n",
      "Epoch [51/1000] , Step [20/40] , Loss: 0.4770269393920898\n",
      "Epoch [51/1000] , Step [30/40] , Loss: 0.5128414034843445\n",
      "Epoch [51/1000] , Step [40/40] , Loss: 0.4983269870281219\n",
      "Epoch [52/1000] , Step [10/40] , Loss: 0.4998706877231598\n",
      "Epoch [52/1000] , Step [20/40] , Loss: 0.4952060580253601\n",
      "Epoch [52/1000] , Step [30/40] , Loss: 0.4855625331401825\n",
      "Epoch [52/1000] , Step [40/40] , Loss: 0.4886360168457031\n",
      "Epoch [53/1000] , Step [10/40] , Loss: 0.4686769843101501\n",
      "Epoch [53/1000] , Step [20/40] , Loss: 0.4764894843101501\n",
      "Epoch [53/1000] , Step [30/40] , Loss: 0.4882552027702332\n",
      "Epoch [53/1000] , Step [40/40] , Loss: 0.4434091448783875\n",
      "Epoch [54/1000] , Step [10/40] , Loss: 0.4582188725471497\n",
      "Epoch [54/1000] , Step [20/40] , Loss: 0.4509482681751251\n",
      "Epoch [54/1000] , Step [30/40] , Loss: 0.5070753097534180\n",
      "Epoch [54/1000] , Step [40/40] , Loss: 0.4695378839969635\n",
      "Epoch [55/1000] , Step [10/40] , Loss: 0.4680209159851074\n",
      "Epoch [55/1000] , Step [20/40] , Loss: 0.5022338032722473\n",
      "Epoch [55/1000] , Step [30/40] , Loss: 0.4895913004875183\n",
      "Epoch [55/1000] , Step [40/40] , Loss: 0.4867354631423950\n",
      "Epoch [56/1000] , Step [10/40] , Loss: 0.4874961078166962\n",
      "Epoch [56/1000] , Step [20/40] , Loss: 0.4945155382156372\n",
      "Epoch [56/1000] , Step [30/40] , Loss: 0.4950823485851288\n",
      "Epoch [56/1000] , Step [40/40] , Loss: 0.4825038313865662\n",
      "Epoch [57/1000] , Step [10/40] , Loss: 0.4683153331279755\n",
      "Epoch [57/1000] , Step [20/40] , Loss: 0.4716371297836304\n",
      "Epoch [57/1000] , Step [30/40] , Loss: 0.4860310256481171\n",
      "Epoch [57/1000] , Step [40/40] , Loss: 0.4931542575359344\n",
      "Epoch [58/1000] , Step [10/40] , Loss: 0.4824404120445251\n",
      "Epoch [58/1000] , Step [20/40] , Loss: 0.4981938302516937\n",
      "Epoch [58/1000] , Step [30/40] , Loss: 0.4691211581230164\n",
      "Epoch [58/1000] , Step [40/40] , Loss: 0.4413967132568359\n",
      "Epoch [59/1000] , Step [10/40] , Loss: 0.5052265524864197\n",
      "Epoch [59/1000] , Step [20/40] , Loss: 0.4345499873161316\n",
      "Epoch [59/1000] , Step [30/40] , Loss: 0.4823200404644012\n",
      "Epoch [59/1000] , Step [40/40] , Loss: 0.4642425179481506\n",
      "Epoch [60/1000] , Step [10/40] , Loss: 0.4558736681938171\n",
      "Epoch [60/1000] , Step [20/40] , Loss: 0.4804639816284180\n",
      "Epoch [60/1000] , Step [30/40] , Loss: 0.4846785366535187\n",
      "Epoch [60/1000] , Step [40/40] , Loss: 0.4796704351902008\n",
      "Epoch [61/1000] , Step [10/40] , Loss: 0.4653010666370392\n",
      "Epoch [61/1000] , Step [20/40] , Loss: 0.4797708988189697\n",
      "Epoch [61/1000] , Step [30/40] , Loss: 0.4840918481349945\n",
      "Epoch [61/1000] , Step [40/40] , Loss: 0.4618284404277802\n",
      "Epoch [62/1000] , Step [10/40] , Loss: 0.5038145184516907\n",
      "Epoch [62/1000] , Step [20/40] , Loss: 0.4629374146461487\n",
      "Epoch [62/1000] , Step [30/40] , Loss: 0.4582559168338776\n",
      "Epoch [62/1000] , Step [40/40] , Loss: 0.5049652457237244\n",
      "Epoch [63/1000] , Step [10/40] , Loss: 0.4631913602352142\n",
      "Epoch [63/1000] , Step [20/40] , Loss: 0.4699624776840210\n",
      "Epoch [63/1000] , Step [30/40] , Loss: 0.4601086080074310\n",
      "Epoch [63/1000] , Step [40/40] , Loss: 0.4624747633934021\n",
      "Epoch [64/1000] , Step [10/40] , Loss: 0.4884004592895508\n",
      "Epoch [64/1000] , Step [20/40] , Loss: 0.4752495288848877\n",
      "Epoch [64/1000] , Step [30/40] , Loss: 0.4813851416110992\n",
      "Epoch [64/1000] , Step [40/40] , Loss: 0.4723655879497528\n",
      "Epoch [65/1000] , Step [10/40] , Loss: 0.4629317224025726\n",
      "Epoch [65/1000] , Step [20/40] , Loss: 0.4816435873508453\n",
      "Epoch [65/1000] , Step [30/40] , Loss: 0.4780646860599518\n",
      "Epoch [65/1000] , Step [40/40] , Loss: 0.4322520792484283\n",
      "Epoch [66/1000] , Step [10/40] , Loss: 0.4867748022079468\n",
      "Epoch [66/1000] , Step [20/40] , Loss: 0.4718512296676636\n",
      "Epoch [66/1000] , Step [30/40] , Loss: 0.4720763564109802\n",
      "Epoch [66/1000] , Step [40/40] , Loss: 0.4686628580093384\n",
      "Epoch [67/1000] , Step [10/40] , Loss: 0.4796647429466248\n",
      "Epoch [67/1000] , Step [20/40] , Loss: 0.4823752939701080\n",
      "Epoch [67/1000] , Step [30/40] , Loss: 0.4600044786930084\n",
      "Epoch [67/1000] , Step [40/40] , Loss: 0.4734576344490051\n",
      "Epoch [68/1000] , Step [10/40] , Loss: 0.4888917803764343\n",
      "Epoch [68/1000] , Step [20/40] , Loss: 0.4962454140186310\n",
      "Epoch [68/1000] , Step [30/40] , Loss: 0.4794992804527283\n",
      "Epoch [68/1000] , Step [40/40] , Loss: 0.4621531963348389\n",
      "Epoch [69/1000] , Step [10/40] , Loss: 0.4657251536846161\n",
      "Epoch [69/1000] , Step [20/40] , Loss: 0.4853433966636658\n",
      "Epoch [69/1000] , Step [30/40] , Loss: 0.4907323420047760\n",
      "Epoch [69/1000] , Step [40/40] , Loss: 0.4990815818309784\n",
      "Epoch [70/1000] , Step [10/40] , Loss: 0.4831336140632629\n",
      "Epoch [70/1000] , Step [20/40] , Loss: 0.4506189227104187\n",
      "Epoch [70/1000] , Step [30/40] , Loss: 0.4770025610923767\n",
      "Epoch [70/1000] , Step [40/40] , Loss: 0.4623796641826630\n",
      "Epoch [71/1000] , Step [10/40] , Loss: 0.4828588962554932\n",
      "Epoch [71/1000] , Step [20/40] , Loss: 0.5134024620056152\n",
      "Epoch [71/1000] , Step [30/40] , Loss: 0.4954928159713745\n",
      "Epoch [71/1000] , Step [40/40] , Loss: 0.4634619355201721\n",
      "Epoch [72/1000] , Step [10/40] , Loss: 0.4864295423030853\n",
      "Epoch [72/1000] , Step [20/40] , Loss: 0.4951542615890503\n",
      "Epoch [72/1000] , Step [30/40] , Loss: 0.4949727356433868\n",
      "Epoch [72/1000] , Step [40/40] , Loss: 0.5287284255027771\n",
      "Epoch [73/1000] , Step [10/40] , Loss: 0.4801855385303497\n",
      "Epoch [73/1000] , Step [20/40] , Loss: 0.4893050789833069\n",
      "Epoch [73/1000] , Step [30/40] , Loss: 0.4938409626483917\n",
      "Epoch [73/1000] , Step [40/40] , Loss: 0.4469831287860870\n",
      "Epoch [74/1000] , Step [10/40] , Loss: 0.5010275840759277\n",
      "Epoch [74/1000] , Step [20/40] , Loss: 0.4796890914440155\n",
      "Epoch [74/1000] , Step [30/40] , Loss: 0.4784857034683228\n",
      "Epoch [74/1000] , Step [40/40] , Loss: 0.5078139901161194\n",
      "Epoch [75/1000] , Step [10/40] , Loss: 0.4958710968494415\n",
      "Epoch [75/1000] , Step [20/40] , Loss: 0.4767630398273468\n",
      "Epoch [75/1000] , Step [30/40] , Loss: 0.4916079044342041\n",
      "Epoch [75/1000] , Step [40/40] , Loss: 0.4483168125152588\n",
      "Epoch [76/1000] , Step [10/40] , Loss: 0.4868319332599640\n",
      "Epoch [76/1000] , Step [20/40] , Loss: 0.4788093864917755\n",
      "Epoch [76/1000] , Step [30/40] , Loss: 0.4665471017360687\n",
      "Epoch [76/1000] , Step [40/40] , Loss: 0.4721558988094330\n",
      "Epoch [77/1000] , Step [10/40] , Loss: 0.4791623950004578\n",
      "Epoch [77/1000] , Step [20/40] , Loss: 0.4771902263164520\n",
      "Epoch [77/1000] , Step [30/40] , Loss: 0.4694715440273285\n",
      "Epoch [77/1000] , Step [40/40] , Loss: 0.4638272821903229\n",
      "Epoch [78/1000] , Step [10/40] , Loss: 0.4884888529777527\n",
      "Epoch [78/1000] , Step [20/40] , Loss: 0.4753027856349945\n",
      "Epoch [78/1000] , Step [30/40] , Loss: 0.4747881889343262\n",
      "Epoch [78/1000] , Step [40/40] , Loss: 0.4872102439403534\n",
      "Epoch [79/1000] , Step [10/40] , Loss: 0.4658655524253845\n",
      "Epoch [79/1000] , Step [20/40] , Loss: 0.4840694069862366\n",
      "Epoch [79/1000] , Step [30/40] , Loss: 0.5027674436569214\n",
      "Epoch [79/1000] , Step [40/40] , Loss: 0.4430280029773712\n",
      "Epoch [80/1000] , Step [10/40] , Loss: 0.4892454445362091\n",
      "Epoch [80/1000] , Step [20/40] , Loss: 0.4839293360710144\n",
      "Epoch [80/1000] , Step [30/40] , Loss: 0.4929863512516022\n",
      "Epoch [80/1000] , Step [40/40] , Loss: 0.4860198497772217\n",
      "Epoch [81/1000] , Step [10/40] , Loss: 0.4801046848297119\n",
      "Epoch [81/1000] , Step [20/40] , Loss: 0.4722799658775330\n",
      "Epoch [81/1000] , Step [30/40] , Loss: 0.4970674216747284\n",
      "Epoch [81/1000] , Step [40/40] , Loss: 0.4528951644897461\n",
      "Epoch [82/1000] , Step [10/40] , Loss: 0.4861280322074890\n",
      "Epoch [82/1000] , Step [20/40] , Loss: 0.4906028509140015\n",
      "Epoch [82/1000] , Step [30/40] , Loss: 0.4661317169666290\n",
      "Epoch [82/1000] , Step [40/40] , Loss: 0.4651527702808380\n",
      "Epoch [83/1000] , Step [10/40] , Loss: 0.4826279282569885\n",
      "Epoch [83/1000] , Step [20/40] , Loss: 0.5291246771812439\n",
      "Epoch [83/1000] , Step [30/40] , Loss: 0.4889466464519501\n",
      "Epoch [83/1000] , Step [40/40] , Loss: 0.4554372131824493\n",
      "Epoch [84/1000] , Step [10/40] , Loss: 0.5091875791549683\n",
      "Epoch [84/1000] , Step [20/40] , Loss: 0.5025573968887329\n",
      "Epoch [84/1000] , Step [30/40] , Loss: 0.4644120335578918\n",
      "Epoch [84/1000] , Step [40/40] , Loss: 0.4918678402900696\n",
      "Epoch [85/1000] , Step [10/40] , Loss: 0.4578850865364075\n",
      "Epoch [85/1000] , Step [20/40] , Loss: 0.4738541841506958\n",
      "Epoch [85/1000] , Step [30/40] , Loss: 0.4620665907859802\n",
      "Epoch [85/1000] , Step [40/40] , Loss: 0.5059181451797485\n",
      "Epoch [86/1000] , Step [10/40] , Loss: 0.4795806109905243\n",
      "Epoch [86/1000] , Step [20/40] , Loss: 0.4691975116729736\n",
      "Epoch [86/1000] , Step [30/40] , Loss: 0.4980313181877136\n",
      "Epoch [86/1000] , Step [40/40] , Loss: 0.4772741794586182\n",
      "Epoch [87/1000] , Step [10/40] , Loss: 0.4468130171298981\n",
      "Epoch [87/1000] , Step [20/40] , Loss: 0.4661679565906525\n",
      "Epoch [87/1000] , Step [30/40] , Loss: 0.4958882629871368\n",
      "Epoch [87/1000] , Step [40/40] , Loss: 0.4753133952617645\n",
      "Epoch [88/1000] , Step [10/40] , Loss: 0.4743584692478180\n",
      "Epoch [88/1000] , Step [20/40] , Loss: 0.4748531579971313\n",
      "Epoch [88/1000] , Step [30/40] , Loss: 0.4764926135540009\n",
      "Epoch [88/1000] , Step [40/40] , Loss: 0.4878910183906555\n",
      "Epoch [89/1000] , Step [10/40] , Loss: 0.4955620765686035\n",
      "Epoch [89/1000] , Step [20/40] , Loss: 0.4756106138229370\n",
      "Epoch [89/1000] , Step [30/40] , Loss: 0.4590138196945190\n",
      "Epoch [89/1000] , Step [40/40] , Loss: 0.4966700673103333\n",
      "Epoch [90/1000] , Step [10/40] , Loss: 0.4975412786006927\n",
      "Epoch [90/1000] , Step [20/40] , Loss: 0.4599275290966034\n",
      "Epoch [90/1000] , Step [30/40] , Loss: 0.5338499546051025\n",
      "Epoch [90/1000] , Step [40/40] , Loss: 0.4745516479015350\n",
      "Epoch [91/1000] , Step [10/40] , Loss: 0.4903260469436646\n",
      "Epoch [91/1000] , Step [20/40] , Loss: 0.4787973463535309\n",
      "Epoch [91/1000] , Step [30/40] , Loss: 0.4565359950065613\n",
      "Epoch [91/1000] , Step [40/40] , Loss: 0.4982098639011383\n",
      "Epoch [92/1000] , Step [10/40] , Loss: 0.5101455450057983\n",
      "Epoch [92/1000] , Step [20/40] , Loss: 0.4908538758754730\n",
      "Epoch [92/1000] , Step [30/40] , Loss: 0.5089052319526672\n",
      "Epoch [92/1000] , Step [40/40] , Loss: 0.4831281304359436\n",
      "Epoch [93/1000] , Step [10/40] , Loss: 0.4798415303230286\n",
      "Epoch [93/1000] , Step [20/40] , Loss: 0.4924338161945343\n",
      "Epoch [93/1000] , Step [30/40] , Loss: 0.4644091725349426\n",
      "Epoch [93/1000] , Step [40/40] , Loss: 0.4712919890880585\n",
      "Epoch [94/1000] , Step [10/40] , Loss: 0.4901882112026215\n",
      "Epoch [94/1000] , Step [20/40] , Loss: 0.4780486822128296\n",
      "Epoch [94/1000] , Step [30/40] , Loss: 0.4462996423244476\n",
      "Epoch [94/1000] , Step [40/40] , Loss: 0.4977253675460815\n",
      "Epoch [95/1000] , Step [10/40] , Loss: 0.4700458049774170\n",
      "Epoch [95/1000] , Step [20/40] , Loss: 0.4756079018115997\n",
      "Epoch [95/1000] , Step [30/40] , Loss: 0.4702063202857971\n",
      "Epoch [95/1000] , Step [40/40] , Loss: 0.5015171170234680\n",
      "Epoch [96/1000] , Step [10/40] , Loss: 0.4466134905815125\n",
      "Epoch [96/1000] , Step [20/40] , Loss: 0.5059328079223633\n",
      "Epoch [96/1000] , Step [30/40] , Loss: 0.4850730597972870\n",
      "Epoch [96/1000] , Step [40/40] , Loss: 0.4800796508789062\n",
      "Epoch [97/1000] , Step [10/40] , Loss: 0.4696459472179413\n",
      "Epoch [97/1000] , Step [20/40] , Loss: 0.4958185851573944\n",
      "Epoch [97/1000] , Step [30/40] , Loss: 0.4884090125560760\n",
      "Epoch [97/1000] , Step [40/40] , Loss: 0.4853448271751404\n",
      "Epoch [98/1000] , Step [10/40] , Loss: 0.4852793514728546\n",
      "Epoch [98/1000] , Step [20/40] , Loss: 0.4749294519424438\n",
      "Epoch [98/1000] , Step [30/40] , Loss: 0.5007480978965759\n",
      "Epoch [98/1000] , Step [40/40] , Loss: 0.4673285186290741\n",
      "Epoch [99/1000] , Step [10/40] , Loss: 0.4907732903957367\n",
      "Epoch [99/1000] , Step [20/40] , Loss: 0.4767537117004395\n",
      "Epoch [99/1000] , Step [30/40] , Loss: 0.4949689507484436\n",
      "Epoch [99/1000] , Step [40/40] , Loss: 0.4582037627696991\n",
      "Epoch [100/1000] , Step [10/40] , Loss: 0.4588103890419006\n",
      "Epoch [100/1000] , Step [20/40] , Loss: 0.4642940163612366\n",
      "Epoch [100/1000] , Step [30/40] , Loss: 0.4757685959339142\n",
      "Epoch [100/1000] , Step [40/40] , Loss: 0.5036215782165527\n",
      "Epoch [101/1000] , Step [10/40] , Loss: 0.4521487355232239\n",
      "Epoch [101/1000] , Step [20/40] , Loss: 0.4489068090915680\n",
      "Epoch [101/1000] , Step [30/40] , Loss: 0.4723136425018311\n",
      "Epoch [101/1000] , Step [40/40] , Loss: 0.4884545803070068\n",
      "Epoch [102/1000] , Step [10/40] , Loss: 0.4597074687480927\n",
      "Epoch [102/1000] , Step [20/40] , Loss: 0.5003902912139893\n",
      "Epoch [102/1000] , Step [30/40] , Loss: 0.4911811649799347\n",
      "Epoch [102/1000] , Step [40/40] , Loss: 0.4698039591312408\n",
      "Epoch [103/1000] , Step [10/40] , Loss: 0.4808129966259003\n",
      "Epoch [103/1000] , Step [20/40] , Loss: 0.5070475935935974\n",
      "Epoch [103/1000] , Step [30/40] , Loss: 0.4839571118354797\n",
      "Epoch [103/1000] , Step [40/40] , Loss: 0.5109949111938477\n",
      "Epoch [104/1000] , Step [10/40] , Loss: 0.5152419209480286\n",
      "Epoch [104/1000] , Step [20/40] , Loss: 0.4737820625305176\n",
      "Epoch [104/1000] , Step [30/40] , Loss: 0.4591840803623199\n",
      "Epoch [104/1000] , Step [40/40] , Loss: 0.5041362047195435\n",
      "Epoch [105/1000] , Step [10/40] , Loss: 0.4943942427635193\n",
      "Epoch [105/1000] , Step [20/40] , Loss: 0.4625127315521240\n",
      "Epoch [105/1000] , Step [30/40] , Loss: 0.4739659428596497\n",
      "Epoch [105/1000] , Step [40/40] , Loss: 0.4756839871406555\n",
      "Epoch [106/1000] , Step [10/40] , Loss: 0.4738577902317047\n",
      "Epoch [106/1000] , Step [20/40] , Loss: 0.4892948269844055\n",
      "Epoch [106/1000] , Step [30/40] , Loss: 0.4717166721820831\n",
      "Epoch [106/1000] , Step [40/40] , Loss: 0.5103766322135925\n",
      "Epoch [107/1000] , Step [10/40] , Loss: 0.4796479344367981\n",
      "Epoch [107/1000] , Step [20/40] , Loss: 0.4710698425769806\n",
      "Epoch [107/1000] , Step [30/40] , Loss: 0.4800388514995575\n",
      "Epoch [107/1000] , Step [40/40] , Loss: 0.4810183048248291\n",
      "Epoch [108/1000] , Step [10/40] , Loss: 0.4687416255474091\n",
      "Epoch [108/1000] , Step [20/40] , Loss: 0.4787819981575012\n",
      "Epoch [108/1000] , Step [30/40] , Loss: 0.4842813313007355\n",
      "Epoch [108/1000] , Step [40/40] , Loss: 0.4612703025341034\n",
      "Epoch [109/1000] , Step [10/40] , Loss: 0.4647843539714813\n",
      "Epoch [109/1000] , Step [20/40] , Loss: 0.4932784438133240\n",
      "Epoch [109/1000] , Step [30/40] , Loss: 0.4799329936504364\n",
      "Epoch [109/1000] , Step [40/40] , Loss: 0.4667603969573975\n",
      "Epoch [110/1000] , Step [10/40] , Loss: 0.4653036296367645\n",
      "Epoch [110/1000] , Step [20/40] , Loss: 0.4710645079612732\n",
      "Epoch [110/1000] , Step [30/40] , Loss: 0.4843259453773499\n",
      "Epoch [110/1000] , Step [40/40] , Loss: 0.4589912593364716\n",
      "Epoch [111/1000] , Step [10/40] , Loss: 0.4636411964893341\n",
      "Epoch [111/1000] , Step [20/40] , Loss: 0.4946455955505371\n",
      "Epoch [111/1000] , Step [30/40] , Loss: 0.4687753617763519\n",
      "Epoch [111/1000] , Step [40/40] , Loss: 0.4424011409282684\n",
      "Epoch [112/1000] , Step [10/40] , Loss: 0.5020280480384827\n",
      "Epoch [112/1000] , Step [20/40] , Loss: 0.4740293323993683\n",
      "Epoch [112/1000] , Step [30/40] , Loss: 0.5017372965812683\n",
      "Epoch [112/1000] , Step [40/40] , Loss: 0.4648918807506561\n",
      "Epoch [113/1000] , Step [10/40] , Loss: 0.4760660529136658\n",
      "Epoch [113/1000] , Step [20/40] , Loss: 0.4514130353927612\n",
      "Epoch [113/1000] , Step [30/40] , Loss: 0.4757386445999146\n",
      "Epoch [113/1000] , Step [40/40] , Loss: 0.4886232912540436\n",
      "Epoch [114/1000] , Step [10/40] , Loss: 0.4580973982810974\n",
      "Epoch [114/1000] , Step [20/40] , Loss: 0.4802897870540619\n",
      "Epoch [114/1000] , Step [30/40] , Loss: 0.4576335847377777\n",
      "Epoch [114/1000] , Step [40/40] , Loss: 0.5249217748641968\n",
      "Epoch [115/1000] , Step [10/40] , Loss: 0.4884104132652283\n",
      "Epoch [115/1000] , Step [20/40] , Loss: 0.4972268939018250\n",
      "Epoch [115/1000] , Step [30/40] , Loss: 0.4814901947975159\n",
      "Epoch [115/1000] , Step [40/40] , Loss: 0.4627848863601685\n",
      "Epoch [116/1000] , Step [10/40] , Loss: 0.4554640054702759\n",
      "Epoch [116/1000] , Step [20/40] , Loss: 0.4815901815891266\n",
      "Epoch [116/1000] , Step [30/40] , Loss: 0.4643686413764954\n",
      "Epoch [116/1000] , Step [40/40] , Loss: 0.5064092278480530\n",
      "Epoch [117/1000] , Step [10/40] , Loss: 0.4669893682003021\n",
      "Epoch [117/1000] , Step [20/40] , Loss: 0.4988510906696320\n",
      "Epoch [117/1000] , Step [30/40] , Loss: 0.4623786211013794\n",
      "Epoch [117/1000] , Step [40/40] , Loss: 0.4789826571941376\n",
      "Epoch [118/1000] , Step [10/40] , Loss: 0.4708413481712341\n",
      "Epoch [118/1000] , Step [20/40] , Loss: 0.4845333099365234\n",
      "Epoch [118/1000] , Step [30/40] , Loss: 0.4732690155506134\n",
      "Epoch [118/1000] , Step [40/40] , Loss: 0.4808937907218933\n",
      "Epoch [119/1000] , Step [10/40] , Loss: 0.4771098792552948\n",
      "Epoch [119/1000] , Step [20/40] , Loss: 0.4405766129493713\n",
      "Epoch [119/1000] , Step [30/40] , Loss: 0.4760409593582153\n",
      "Epoch [119/1000] , Step [40/40] , Loss: 0.5023162364959717\n",
      "Epoch [120/1000] , Step [10/40] , Loss: 0.4642908871173859\n",
      "Epoch [120/1000] , Step [20/40] , Loss: 0.4684375822544098\n",
      "Epoch [120/1000] , Step [30/40] , Loss: 0.4651499986648560\n",
      "Epoch [120/1000] , Step [40/40] , Loss: 0.4967073798179626\n",
      "Epoch [121/1000] , Step [10/40] , Loss: 0.4851452410221100\n",
      "Epoch [121/1000] , Step [20/40] , Loss: 0.4795833528041840\n",
      "Epoch [121/1000] , Step [30/40] , Loss: 0.4658563137054443\n",
      "Epoch [121/1000] , Step [40/40] , Loss: 0.4615184068679810\n",
      "Epoch [122/1000] , Step [10/40] , Loss: 0.4762967228889465\n",
      "Epoch [122/1000] , Step [20/40] , Loss: 0.4904767572879791\n",
      "Epoch [122/1000] , Step [30/40] , Loss: 0.4926249980926514\n",
      "Epoch [122/1000] , Step [40/40] , Loss: 0.4821888208389282\n",
      "Epoch [123/1000] , Step [10/40] , Loss: 0.5016189217567444\n",
      "Epoch [123/1000] , Step [20/40] , Loss: 0.4691917896270752\n",
      "Epoch [123/1000] , Step [30/40] , Loss: 0.4630373120307922\n",
      "Epoch [123/1000] , Step [40/40] , Loss: 0.4602693021297455\n",
      "Epoch [124/1000] , Step [10/40] , Loss: 0.4862025678157806\n",
      "Epoch [124/1000] , Step [20/40] , Loss: 0.4671858847141266\n",
      "Epoch [124/1000] , Step [30/40] , Loss: 0.4657772779464722\n",
      "Epoch [124/1000] , Step [40/40] , Loss: 0.4962949752807617\n",
      "Epoch [125/1000] , Step [10/40] , Loss: 0.4523985385894775\n",
      "Epoch [125/1000] , Step [20/40] , Loss: 0.4537405371665955\n",
      "Epoch [125/1000] , Step [30/40] , Loss: 0.4939465522766113\n",
      "Epoch [125/1000] , Step [40/40] , Loss: 0.5052806735038757\n",
      "Epoch [126/1000] , Step [10/40] , Loss: 0.4801390171051025\n",
      "Epoch [126/1000] , Step [20/40] , Loss: 0.4770329296588898\n",
      "Epoch [126/1000] , Step [30/40] , Loss: 0.4659708142280579\n",
      "Epoch [126/1000] , Step [40/40] , Loss: 0.4847241342067719\n",
      "Epoch [127/1000] , Step [10/40] , Loss: 0.4496560692787170\n",
      "Epoch [127/1000] , Step [20/40] , Loss: 0.4793625473976135\n",
      "Epoch [127/1000] , Step [30/40] , Loss: 0.4722727537155151\n",
      "Epoch [127/1000] , Step [40/40] , Loss: 0.4660521745681763\n",
      "Epoch [128/1000] , Step [10/40] , Loss: 0.4594759345054626\n",
      "Epoch [128/1000] , Step [20/40] , Loss: 0.4659405052661896\n",
      "Epoch [128/1000] , Step [30/40] , Loss: 0.4968169331550598\n",
      "Epoch [128/1000] , Step [40/40] , Loss: 0.5030839443206787\n",
      "Epoch [129/1000] , Step [10/40] , Loss: 0.4869093894958496\n",
      "Epoch [129/1000] , Step [20/40] , Loss: 0.4523548483848572\n",
      "Epoch [129/1000] , Step [30/40] , Loss: 0.4921895265579224\n",
      "Epoch [129/1000] , Step [40/40] , Loss: 0.4498924612998962\n",
      "Epoch [130/1000] , Step [10/40] , Loss: 0.4851963520050049\n",
      "Epoch [130/1000] , Step [20/40] , Loss: 0.4874757826328278\n",
      "Epoch [130/1000] , Step [30/40] , Loss: 0.4868233203887939\n",
      "Epoch [130/1000] , Step [40/40] , Loss: 0.4742590785026550\n",
      "Epoch [131/1000] , Step [10/40] , Loss: 0.4902981817722321\n",
      "Epoch [131/1000] , Step [20/40] , Loss: 0.4646861851215363\n",
      "Epoch [131/1000] , Step [30/40] , Loss: 0.4843391776084900\n",
      "Epoch [131/1000] , Step [40/40] , Loss: 0.4774868190288544\n",
      "Epoch [132/1000] , Step [10/40] , Loss: 0.4665704369544983\n",
      "Epoch [132/1000] , Step [20/40] , Loss: 0.4831049740314484\n",
      "Epoch [132/1000] , Step [30/40] , Loss: 0.4768702685832977\n",
      "Epoch [132/1000] , Step [40/40] , Loss: 0.4959659278392792\n",
      "Epoch [133/1000] , Step [10/40] , Loss: 0.4857247769832611\n",
      "Epoch [133/1000] , Step [20/40] , Loss: 0.4770514667034149\n",
      "Epoch [133/1000] , Step [30/40] , Loss: 0.4863542020320892\n",
      "Epoch [133/1000] , Step [40/40] , Loss: 0.4604060947895050\n",
      "Epoch [134/1000] , Step [10/40] , Loss: 0.4846190214157104\n",
      "Epoch [134/1000] , Step [20/40] , Loss: 0.4691587984561920\n",
      "Epoch [134/1000] , Step [30/40] , Loss: 0.4837565124034882\n",
      "Epoch [134/1000] , Step [40/40] , Loss: 0.4580201506614685\n",
      "Epoch [135/1000] , Step [10/40] , Loss: 0.4656432569026947\n",
      "Epoch [135/1000] , Step [20/40] , Loss: 0.4964440762996674\n",
      "Epoch [135/1000] , Step [30/40] , Loss: 0.4610300660133362\n",
      "Epoch [135/1000] , Step [40/40] , Loss: 0.4881514608860016\n",
      "Epoch [136/1000] , Step [10/40] , Loss: 0.4936775267124176\n",
      "Epoch [136/1000] , Step [20/40] , Loss: 0.5050296783447266\n",
      "Epoch [136/1000] , Step [30/40] , Loss: 0.4962050914764404\n",
      "Epoch [136/1000] , Step [40/40] , Loss: 0.4569101035594940\n",
      "Epoch [137/1000] , Step [10/40] , Loss: 0.4667949676513672\n",
      "Epoch [137/1000] , Step [20/40] , Loss: 0.4577209055423737\n",
      "Epoch [137/1000] , Step [30/40] , Loss: 0.4744158089160919\n",
      "Epoch [137/1000] , Step [40/40] , Loss: 0.4873486459255219\n",
      "Epoch [138/1000] , Step [10/40] , Loss: 0.4856450855731964\n",
      "Epoch [138/1000] , Step [20/40] , Loss: 0.4811266660690308\n",
      "Epoch [138/1000] , Step [30/40] , Loss: 0.4878835678100586\n",
      "Epoch [138/1000] , Step [40/40] , Loss: 0.4910514056682587\n",
      "Epoch [139/1000] , Step [10/40] , Loss: 0.4805188775062561\n",
      "Epoch [139/1000] , Step [20/40] , Loss: 0.4560011625289917\n",
      "Epoch [139/1000] , Step [30/40] , Loss: 0.4671838879585266\n",
      "Epoch [139/1000] , Step [40/40] , Loss: 0.5063796043395996\n",
      "Epoch [140/1000] , Step [10/40] , Loss: 0.4860756099224091\n",
      "Epoch [140/1000] , Step [20/40] , Loss: 0.4818043708801270\n",
      "Epoch [140/1000] , Step [30/40] , Loss: 0.4786517918109894\n",
      "Epoch [140/1000] , Step [40/40] , Loss: 0.4775161147117615\n",
      "Epoch [141/1000] , Step [10/40] , Loss: 0.4717015027999878\n",
      "Epoch [141/1000] , Step [20/40] , Loss: 0.4674552679061890\n",
      "Epoch [141/1000] , Step [30/40] , Loss: 0.4732446968555450\n",
      "Epoch [141/1000] , Step [40/40] , Loss: 0.4666677117347717\n",
      "Epoch [142/1000] , Step [10/40] , Loss: 0.4729673564434052\n",
      "Epoch [142/1000] , Step [20/40] , Loss: 0.4589064121246338\n",
      "Epoch [142/1000] , Step [30/40] , Loss: 0.4699176549911499\n",
      "Epoch [142/1000] , Step [40/40] , Loss: 0.4473545551300049\n",
      "Epoch [143/1000] , Step [10/40] , Loss: 0.4678147733211517\n",
      "Epoch [143/1000] , Step [20/40] , Loss: 0.4316192269325256\n",
      "Epoch [143/1000] , Step [30/40] , Loss: 0.4825749695301056\n",
      "Epoch [143/1000] , Step [40/40] , Loss: 0.4894455969333649\n",
      "Epoch [144/1000] , Step [10/40] , Loss: 0.4557009935379028\n",
      "Epoch [144/1000] , Step [20/40] , Loss: 0.4714320600032806\n",
      "Epoch [144/1000] , Step [30/40] , Loss: 0.4763373136520386\n",
      "Epoch [144/1000] , Step [40/40] , Loss: 0.4841425716876984\n",
      "Epoch [145/1000] , Step [10/40] , Loss: 0.4620922803878784\n",
      "Epoch [145/1000] , Step [20/40] , Loss: 0.4861292243003845\n",
      "Epoch [145/1000] , Step [30/40] , Loss: 0.5024216771125793\n",
      "Epoch [145/1000] , Step [40/40] , Loss: 0.4762330949306488\n",
      "Epoch [146/1000] , Step [10/40] , Loss: 0.4649474024772644\n",
      "Epoch [146/1000] , Step [20/40] , Loss: 0.4560585618019104\n",
      "Epoch [146/1000] , Step [30/40] , Loss: 0.4834678173065186\n",
      "Epoch [146/1000] , Step [40/40] , Loss: 0.4753524065017700\n",
      "Epoch [147/1000] , Step [10/40] , Loss: 0.4724680185317993\n",
      "Epoch [147/1000] , Step [20/40] , Loss: 0.4780149161815643\n",
      "Epoch [147/1000] , Step [30/40] , Loss: 0.4726834595203400\n",
      "Epoch [147/1000] , Step [40/40] , Loss: 0.4759719967842102\n",
      "Epoch [148/1000] , Step [10/40] , Loss: 0.4900159835815430\n",
      "Epoch [148/1000] , Step [20/40] , Loss: 0.4490570127964020\n",
      "Epoch [148/1000] , Step [30/40] , Loss: 0.4681811630725861\n",
      "Epoch [148/1000] , Step [40/40] , Loss: 0.4694278538227081\n",
      "Epoch [149/1000] , Step [10/40] , Loss: 0.4828576743602753\n",
      "Epoch [149/1000] , Step [20/40] , Loss: 0.4691672325134277\n",
      "Epoch [149/1000] , Step [30/40] , Loss: 0.4760584533214569\n",
      "Epoch [149/1000] , Step [40/40] , Loss: 0.4802587032318115\n",
      "Epoch [150/1000] , Step [10/40] , Loss: 0.4715219140052795\n",
      "Epoch [150/1000] , Step [20/40] , Loss: 0.4725168049335480\n",
      "Epoch [150/1000] , Step [30/40] , Loss: 0.4760961234569550\n",
      "Epoch [150/1000] , Step [40/40] , Loss: 0.5084386467933655\n",
      "Epoch [151/1000] , Step [10/40] , Loss: 0.4724490046501160\n",
      "Epoch [151/1000] , Step [20/40] , Loss: 0.4601138532161713\n",
      "Epoch [151/1000] , Step [30/40] , Loss: 0.4698215723037720\n",
      "Epoch [151/1000] , Step [40/40] , Loss: 0.4792765080928802\n",
      "Epoch [152/1000] , Step [10/40] , Loss: 0.4840767085552216\n",
      "Epoch [152/1000] , Step [20/40] , Loss: 0.4577381312847137\n",
      "Epoch [152/1000] , Step [30/40] , Loss: 0.4799709320068359\n",
      "Epoch [152/1000] , Step [40/40] , Loss: 0.5021992921829224\n",
      "Epoch [153/1000] , Step [10/40] , Loss: 0.4837037622928619\n",
      "Epoch [153/1000] , Step [20/40] , Loss: 0.5026416182518005\n",
      "Epoch [153/1000] , Step [30/40] , Loss: 0.4403564333915710\n",
      "Epoch [153/1000] , Step [40/40] , Loss: 0.4784149229526520\n",
      "Epoch [154/1000] , Step [10/40] , Loss: 0.4749245643615723\n",
      "Epoch [154/1000] , Step [20/40] , Loss: 0.4870999753475189\n",
      "Epoch [154/1000] , Step [30/40] , Loss: 0.4731591939926147\n",
      "Epoch [154/1000] , Step [40/40] , Loss: 0.4496812522411346\n",
      "Epoch [155/1000] , Step [10/40] , Loss: 0.4875479638576508\n",
      "Epoch [155/1000] , Step [20/40] , Loss: 0.4507087767124176\n",
      "Epoch [155/1000] , Step [30/40] , Loss: 0.4666567146778107\n",
      "Epoch [155/1000] , Step [40/40] , Loss: 0.4754661917686462\n",
      "Epoch [156/1000] , Step [10/40] , Loss: 0.4651640653610229\n",
      "Epoch [156/1000] , Step [20/40] , Loss: 0.4906678199768066\n",
      "Epoch [156/1000] , Step [30/40] , Loss: 0.5085238218307495\n",
      "Epoch [156/1000] , Step [40/40] , Loss: 0.4639770090579987\n",
      "Epoch [157/1000] , Step [10/40] , Loss: 0.4586978554725647\n",
      "Epoch [157/1000] , Step [20/40] , Loss: 0.4626331031322479\n",
      "Epoch [157/1000] , Step [30/40] , Loss: 0.4737307429313660\n",
      "Epoch [157/1000] , Step [40/40] , Loss: 0.4804005026817322\n",
      "Epoch [158/1000] , Step [10/40] , Loss: 0.4778047502040863\n",
      "Epoch [158/1000] , Step [20/40] , Loss: 0.4685207903385162\n",
      "Epoch [158/1000] , Step [30/40] , Loss: 0.4820764362812042\n",
      "Epoch [158/1000] , Step [40/40] , Loss: 0.4532372951507568\n",
      "Epoch [159/1000] , Step [10/40] , Loss: 0.4810752272605896\n",
      "Epoch [159/1000] , Step [20/40] , Loss: 0.4679602682590485\n",
      "Epoch [159/1000] , Step [30/40] , Loss: 0.4635894298553467\n",
      "Epoch [159/1000] , Step [40/40] , Loss: 0.4653402566909790\n",
      "Epoch [160/1000] , Step [10/40] , Loss: 0.4533331394195557\n",
      "Epoch [160/1000] , Step [20/40] , Loss: 0.4627874791622162\n",
      "Epoch [160/1000] , Step [30/40] , Loss: 0.4807256460189819\n",
      "Epoch [160/1000] , Step [40/40] , Loss: 0.4724664092063904\n",
      "Epoch [161/1000] , Step [10/40] , Loss: 0.4609321951866150\n",
      "Epoch [161/1000] , Step [20/40] , Loss: 0.4878483712673187\n",
      "Epoch [161/1000] , Step [30/40] , Loss: 0.4832099676132202\n",
      "Epoch [161/1000] , Step [40/40] , Loss: 0.4563335478305817\n",
      "Epoch [162/1000] , Step [10/40] , Loss: 0.4607625901699066\n",
      "Epoch [162/1000] , Step [20/40] , Loss: 0.4655326306819916\n",
      "Epoch [162/1000] , Step [30/40] , Loss: 0.4641219377517700\n",
      "Epoch [162/1000] , Step [40/40] , Loss: 0.4581166207790375\n",
      "Epoch [163/1000] , Step [10/40] , Loss: 0.4439736306667328\n",
      "Epoch [163/1000] , Step [20/40] , Loss: 0.4492016732692719\n",
      "Epoch [163/1000] , Step [30/40] , Loss: 0.4467507302761078\n",
      "Epoch [163/1000] , Step [40/40] , Loss: 0.4818774163722992\n",
      "Epoch [164/1000] , Step [10/40] , Loss: 0.4868331849575043\n",
      "Epoch [164/1000] , Step [20/40] , Loss: 0.4726581275463104\n",
      "Epoch [164/1000] , Step [30/40] , Loss: 0.4857321679592133\n",
      "Epoch [164/1000] , Step [40/40] , Loss: 0.4704346954822540\n",
      "Epoch [165/1000] , Step [10/40] , Loss: 0.4769231677055359\n",
      "Epoch [165/1000] , Step [20/40] , Loss: 0.4704930484294891\n",
      "Epoch [165/1000] , Step [30/40] , Loss: 0.4715637564659119\n",
      "Epoch [165/1000] , Step [40/40] , Loss: 0.4354254007339478\n",
      "Epoch [166/1000] , Step [10/40] , Loss: 0.4748242199420929\n",
      "Epoch [166/1000] , Step [20/40] , Loss: 0.5020714402198792\n",
      "Epoch [166/1000] , Step [30/40] , Loss: 0.4861406087875366\n",
      "Epoch [166/1000] , Step [40/40] , Loss: 0.4768793284893036\n",
      "Epoch [167/1000] , Step [10/40] , Loss: 0.4415989220142365\n",
      "Epoch [167/1000] , Step [20/40] , Loss: 0.4812543094158173\n",
      "Epoch [167/1000] , Step [30/40] , Loss: 0.4497840404510498\n",
      "Epoch [167/1000] , Step [40/40] , Loss: 0.4777289927005768\n",
      "Epoch [168/1000] , Step [10/40] , Loss: 0.4782736897468567\n",
      "Epoch [168/1000] , Step [20/40] , Loss: 0.4747932553291321\n",
      "Epoch [168/1000] , Step [30/40] , Loss: 0.4556432366371155\n",
      "Epoch [168/1000] , Step [40/40] , Loss: 0.4611282050609589\n",
      "Epoch [169/1000] , Step [10/40] , Loss: 0.4618275463581085\n",
      "Epoch [169/1000] , Step [20/40] , Loss: 0.4647805392742157\n",
      "Epoch [169/1000] , Step [30/40] , Loss: 0.4515219330787659\n",
      "Epoch [169/1000] , Step [40/40] , Loss: 0.4940417706966400\n",
      "Epoch [170/1000] , Step [10/40] , Loss: 0.4534742236137390\n",
      "Epoch [170/1000] , Step [20/40] , Loss: 0.4605638682842255\n",
      "Epoch [170/1000] , Step [30/40] , Loss: 0.4738225638866425\n",
      "Epoch [170/1000] , Step [40/40] , Loss: 0.4698238074779510\n",
      "Epoch [171/1000] , Step [10/40] , Loss: 0.4538554847240448\n",
      "Epoch [171/1000] , Step [20/40] , Loss: 0.4696404635906219\n",
      "Epoch [171/1000] , Step [30/40] , Loss: 0.4735212624073029\n",
      "Epoch [171/1000] , Step [40/40] , Loss: 0.4538629353046417\n",
      "Epoch [172/1000] , Step [10/40] , Loss: 0.4779652953147888\n",
      "Epoch [172/1000] , Step [20/40] , Loss: 0.4885365962982178\n",
      "Epoch [172/1000] , Step [30/40] , Loss: 0.4891950190067291\n",
      "Epoch [172/1000] , Step [40/40] , Loss: 0.4626820683479309\n",
      "Epoch [173/1000] , Step [10/40] , Loss: 0.4631161689758301\n",
      "Epoch [173/1000] , Step [20/40] , Loss: 0.4657185673713684\n",
      "Epoch [173/1000] , Step [30/40] , Loss: 0.4631004333496094\n",
      "Epoch [173/1000] , Step [40/40] , Loss: 0.4926183819770813\n",
      "Epoch [174/1000] , Step [10/40] , Loss: 0.4847216308116913\n",
      "Epoch [174/1000] , Step [20/40] , Loss: 0.4623552858829498\n",
      "Epoch [174/1000] , Step [30/40] , Loss: 0.4724597036838531\n",
      "Epoch [174/1000] , Step [40/40] , Loss: 0.4823953211307526\n",
      "Epoch [175/1000] , Step [10/40] , Loss: 0.4774629771709442\n",
      "Epoch [175/1000] , Step [20/40] , Loss: 0.4884235858917236\n",
      "Epoch [175/1000] , Step [30/40] , Loss: 0.4713076353073120\n",
      "Epoch [175/1000] , Step [40/40] , Loss: 0.4806331098079681\n",
      "Epoch [176/1000] , Step [10/40] , Loss: 0.4856564104557037\n",
      "Epoch [176/1000] , Step [20/40] , Loss: 0.4778474867343903\n",
      "Epoch [176/1000] , Step [30/40] , Loss: 0.5015174746513367\n",
      "Epoch [176/1000] , Step [40/40] , Loss: 0.4474548697471619\n",
      "Epoch [177/1000] , Step [10/40] , Loss: 0.4547971189022064\n",
      "Epoch [177/1000] , Step [20/40] , Loss: 0.4875688254833221\n",
      "Epoch [177/1000] , Step [30/40] , Loss: 0.4559338092803955\n",
      "Epoch [177/1000] , Step [40/40] , Loss: 0.4655151069164276\n",
      "Epoch [178/1000] , Step [10/40] , Loss: 0.4501428008079529\n",
      "Epoch [178/1000] , Step [20/40] , Loss: 0.4639644622802734\n",
      "Epoch [178/1000] , Step [30/40] , Loss: 0.4806775152683258\n",
      "Epoch [178/1000] , Step [40/40] , Loss: 0.4886272251605988\n",
      "Epoch [179/1000] , Step [10/40] , Loss: 0.4851866364479065\n",
      "Epoch [179/1000] , Step [20/40] , Loss: 0.4574311673641205\n",
      "Epoch [179/1000] , Step [30/40] , Loss: 0.4562045633792877\n",
      "Epoch [179/1000] , Step [40/40] , Loss: 0.4391893446445465\n",
      "Epoch [180/1000] , Step [10/40] , Loss: 0.4627608954906464\n",
      "Epoch [180/1000] , Step [20/40] , Loss: 0.4539194703102112\n",
      "Epoch [180/1000] , Step [30/40] , Loss: 0.4859364628791809\n",
      "Epoch [180/1000] , Step [40/40] , Loss: 0.5093176364898682\n",
      "Epoch [181/1000] , Step [10/40] , Loss: 0.5135515928268433\n",
      "Epoch [181/1000] , Step [20/40] , Loss: 0.4667445421218872\n",
      "Epoch [181/1000] , Step [30/40] , Loss: 0.4445872902870178\n",
      "Epoch [181/1000] , Step [40/40] , Loss: 0.4907201826572418\n",
      "Epoch [182/1000] , Step [10/40] , Loss: 0.4624799191951752\n",
      "Epoch [182/1000] , Step [20/40] , Loss: 0.4627837538719177\n",
      "Epoch [182/1000] , Step [30/40] , Loss: 0.4873374998569489\n",
      "Epoch [182/1000] , Step [40/40] , Loss: 0.4711593389511108\n",
      "Epoch [183/1000] , Step [10/40] , Loss: 0.4800506830215454\n",
      "Epoch [183/1000] , Step [20/40] , Loss: 0.4638499617576599\n",
      "Epoch [183/1000] , Step [30/40] , Loss: 0.4563590288162231\n",
      "Epoch [183/1000] , Step [40/40] , Loss: 0.4563244581222534\n",
      "Epoch [184/1000] , Step [10/40] , Loss: 0.4887708425521851\n",
      "Epoch [184/1000] , Step [20/40] , Loss: 0.4533516466617584\n",
      "Epoch [184/1000] , Step [30/40] , Loss: 0.4421923160552979\n",
      "Epoch [184/1000] , Step [40/40] , Loss: 0.4592554867267609\n",
      "Epoch [185/1000] , Step [10/40] , Loss: 0.4456203281879425\n",
      "Epoch [185/1000] , Step [20/40] , Loss: 0.4715028703212738\n",
      "Epoch [185/1000] , Step [30/40] , Loss: 0.4627681970596313\n",
      "Epoch [185/1000] , Step [40/40] , Loss: 0.4385603368282318\n",
      "Epoch [186/1000] , Step [10/40] , Loss: 0.4664077162742615\n",
      "Epoch [186/1000] , Step [20/40] , Loss: 0.4754284918308258\n",
      "Epoch [186/1000] , Step [30/40] , Loss: 0.4497773945331573\n",
      "Epoch [186/1000] , Step [40/40] , Loss: 0.4420156180858612\n",
      "Epoch [187/1000] , Step [10/40] , Loss: 0.4550940096378326\n",
      "Epoch [187/1000] , Step [20/40] , Loss: 0.4716700613498688\n",
      "Epoch [187/1000] , Step [30/40] , Loss: 0.4683777987957001\n",
      "Epoch [187/1000] , Step [40/40] , Loss: 0.4602963328361511\n",
      "Epoch [188/1000] , Step [10/40] , Loss: 0.4724850654602051\n",
      "Epoch [188/1000] , Step [20/40] , Loss: 0.4845834672451019\n",
      "Epoch [188/1000] , Step [30/40] , Loss: 0.4432847499847412\n",
      "Epoch [188/1000] , Step [40/40] , Loss: 0.4385440349578857\n",
      "Epoch [189/1000] , Step [10/40] , Loss: 0.4697808325290680\n",
      "Epoch [189/1000] , Step [20/40] , Loss: 0.4725730419158936\n",
      "Epoch [189/1000] , Step [30/40] , Loss: 0.4906702339649200\n",
      "Epoch [189/1000] , Step [40/40] , Loss: 0.4507425725460052\n",
      "Epoch [190/1000] , Step [10/40] , Loss: 0.4591661691665649\n",
      "Epoch [190/1000] , Step [20/40] , Loss: 0.4457928836345673\n",
      "Epoch [190/1000] , Step [30/40] , Loss: 0.4447998404502869\n",
      "Epoch [190/1000] , Step [40/40] , Loss: 0.4549928307533264\n",
      "Epoch [191/1000] , Step [10/40] , Loss: 0.4828082621097565\n",
      "Epoch [191/1000] , Step [20/40] , Loss: 0.4656898677349091\n",
      "Epoch [191/1000] , Step [30/40] , Loss: 0.4475561678409576\n",
      "Epoch [191/1000] , Step [40/40] , Loss: 0.4447597265243530\n",
      "Epoch [192/1000] , Step [10/40] , Loss: 0.4406519532203674\n",
      "Epoch [192/1000] , Step [20/40] , Loss: 0.4589530825614929\n",
      "Epoch [192/1000] , Step [30/40] , Loss: 0.4314046800136566\n",
      "Epoch [192/1000] , Step [40/40] , Loss: 0.4308976829051971\n",
      "Epoch [193/1000] , Step [10/40] , Loss: 0.4711268842220306\n",
      "Epoch [193/1000] , Step [20/40] , Loss: 0.4324302971363068\n",
      "Epoch [193/1000] , Step [30/40] , Loss: 0.4837788641452789\n",
      "Epoch [193/1000] , Step [40/40] , Loss: 0.4477487802505493\n",
      "Epoch [194/1000] , Step [10/40] , Loss: 0.4670847654342651\n",
      "Epoch [194/1000] , Step [20/40] , Loss: 0.4642397463321686\n",
      "Epoch [194/1000] , Step [30/40] , Loss: 0.4800772964954376\n",
      "Epoch [194/1000] , Step [40/40] , Loss: 0.4594045281410217\n",
      "Epoch [195/1000] , Step [10/40] , Loss: 0.4485259056091309\n",
      "Epoch [195/1000] , Step [20/40] , Loss: 0.4788946211338043\n",
      "Epoch [195/1000] , Step [30/40] , Loss: 0.4495703279972076\n",
      "Epoch [195/1000] , Step [40/40] , Loss: 0.4749675989151001\n",
      "Epoch [196/1000] , Step [10/40] , Loss: 0.4426575601100922\n",
      "Epoch [196/1000] , Step [20/40] , Loss: 0.4756570160388947\n",
      "Epoch [196/1000] , Step [30/40] , Loss: 0.4379567801952362\n",
      "Epoch [196/1000] , Step [40/40] , Loss: 0.4571565091609955\n",
      "Epoch [197/1000] , Step [10/40] , Loss: 0.4711852371692657\n",
      "Epoch [197/1000] , Step [20/40] , Loss: 0.4548803269863129\n",
      "Epoch [197/1000] , Step [30/40] , Loss: 0.4570190012454987\n",
      "Epoch [197/1000] , Step [40/40] , Loss: 0.4733538031578064\n",
      "Epoch [198/1000] , Step [10/40] , Loss: 0.4379103779792786\n",
      "Epoch [198/1000] , Step [20/40] , Loss: 0.4563491940498352\n",
      "Epoch [198/1000] , Step [30/40] , Loss: 0.4478785395622253\n",
      "Epoch [198/1000] , Step [40/40] , Loss: 0.4593609869480133\n",
      "Epoch [199/1000] , Step [10/40] , Loss: 0.4449512958526611\n",
      "Epoch [199/1000] , Step [20/40] , Loss: 0.4629733562469482\n",
      "Epoch [199/1000] , Step [30/40] , Loss: 0.4743566513061523\n",
      "Epoch [199/1000] , Step [40/40] , Loss: 0.4349911808967590\n",
      "Epoch [200/1000] , Step [10/40] , Loss: 0.4752506613731384\n",
      "Epoch [200/1000] , Step [20/40] , Loss: 0.4454966485500336\n",
      "Epoch [200/1000] , Step [30/40] , Loss: 0.4528450071811676\n",
      "Epoch [200/1000] , Step [40/40] , Loss: 0.4492107033729553\n",
      "Epoch [201/1000] , Step [10/40] , Loss: 0.4554654359817505\n",
      "Epoch [201/1000] , Step [20/40] , Loss: 0.4459171593189240\n",
      "Epoch [201/1000] , Step [30/40] , Loss: 0.4445044398307800\n",
      "Epoch [201/1000] , Step [40/40] , Loss: 0.4045418798923492\n",
      "Epoch [202/1000] , Step [10/40] , Loss: 0.4495205879211426\n",
      "Epoch [202/1000] , Step [20/40] , Loss: 0.4388835132122040\n",
      "Epoch [202/1000] , Step [30/40] , Loss: 0.4444360435009003\n",
      "Epoch [202/1000] , Step [40/40] , Loss: 0.4533700346946716\n",
      "Epoch [203/1000] , Step [10/40] , Loss: 0.4585709273815155\n",
      "Epoch [203/1000] , Step [20/40] , Loss: 0.4505441486835480\n",
      "Epoch [203/1000] , Step [30/40] , Loss: 0.4589207470417023\n",
      "Epoch [203/1000] , Step [40/40] , Loss: 0.4567433595657349\n",
      "Epoch [204/1000] , Step [10/40] , Loss: 0.4507382512092590\n",
      "Epoch [204/1000] , Step [20/40] , Loss: 0.4292176067829132\n",
      "Epoch [204/1000] , Step [30/40] , Loss: 0.4740346968173981\n",
      "Epoch [204/1000] , Step [40/40] , Loss: 0.4412153363227844\n",
      "Epoch [205/1000] , Step [10/40] , Loss: 0.4482111334800720\n",
      "Epoch [205/1000] , Step [20/40] , Loss: 0.4403286278247833\n",
      "Epoch [205/1000] , Step [30/40] , Loss: 0.4379955828189850\n",
      "Epoch [205/1000] , Step [40/40] , Loss: 0.4537058472633362\n",
      "Epoch [206/1000] , Step [10/40] , Loss: 0.4458886086940765\n",
      "Epoch [206/1000] , Step [20/40] , Loss: 0.4387915432453156\n",
      "Epoch [206/1000] , Step [30/40] , Loss: 0.4439908266067505\n",
      "Epoch [206/1000] , Step [40/40] , Loss: 0.4623069763183594\n",
      "Epoch [207/1000] , Step [10/40] , Loss: 0.4445557892322540\n",
      "Epoch [207/1000] , Step [20/40] , Loss: 0.4220458269119263\n",
      "Epoch [207/1000] , Step [30/40] , Loss: 0.4127051532268524\n",
      "Epoch [207/1000] , Step [40/40] , Loss: 0.4097140729427338\n",
      "Epoch [208/1000] , Step [10/40] , Loss: 0.4328154027462006\n",
      "Epoch [208/1000] , Step [20/40] , Loss: 0.4360911250114441\n",
      "Epoch [208/1000] , Step [30/40] , Loss: 0.4494030773639679\n",
      "Epoch [208/1000] , Step [40/40] , Loss: 0.4111747145652771\n",
      "Epoch [209/1000] , Step [10/40] , Loss: 0.4320671558380127\n",
      "Epoch [209/1000] , Step [20/40] , Loss: 0.4451820850372314\n",
      "Epoch [209/1000] , Step [30/40] , Loss: 0.4170192480087280\n",
      "Epoch [209/1000] , Step [40/40] , Loss: 0.4462938904762268\n",
      "Epoch [210/1000] , Step [10/40] , Loss: 0.4327062070369720\n",
      "Epoch [210/1000] , Step [20/40] , Loss: 0.4358668625354767\n",
      "Epoch [210/1000] , Step [30/40] , Loss: 0.4132083356380463\n",
      "Epoch [210/1000] , Step [40/40] , Loss: 0.4385130107402802\n",
      "Epoch [211/1000] , Step [10/40] , Loss: 0.4468310177326202\n",
      "Epoch [211/1000] , Step [20/40] , Loss: 0.4428237676620483\n",
      "Epoch [211/1000] , Step [30/40] , Loss: 0.4226838052272797\n",
      "Epoch [211/1000] , Step [40/40] , Loss: 0.3965361118316650\n",
      "Epoch [212/1000] , Step [10/40] , Loss: 0.4165139794349670\n",
      "Epoch [212/1000] , Step [20/40] , Loss: 0.4245534837245941\n",
      "Epoch [212/1000] , Step [30/40] , Loss: 0.4352806508541107\n",
      "Epoch [212/1000] , Step [40/40] , Loss: 0.4087544083595276\n",
      "Epoch [213/1000] , Step [10/40] , Loss: 0.4225701093673706\n",
      "Epoch [213/1000] , Step [20/40] , Loss: 0.4355715513229370\n",
      "Epoch [213/1000] , Step [30/40] , Loss: 0.4169928133487701\n",
      "Epoch [213/1000] , Step [40/40] , Loss: 0.4287081062793732\n",
      "Epoch [214/1000] , Step [10/40] , Loss: 0.3956497311592102\n",
      "Epoch [214/1000] , Step [20/40] , Loss: 0.4338975846767426\n",
      "Epoch [214/1000] , Step [30/40] , Loss: 0.4283599257469177\n",
      "Epoch [214/1000] , Step [40/40] , Loss: 0.3877874016761780\n",
      "Epoch [215/1000] , Step [10/40] , Loss: 0.4077865481376648\n",
      "Epoch [215/1000] , Step [20/40] , Loss: 0.4209454357624054\n",
      "Epoch [215/1000] , Step [30/40] , Loss: 0.4106045365333557\n",
      "Epoch [215/1000] , Step [40/40] , Loss: 0.4049312770366669\n",
      "Epoch [216/1000] , Step [10/40] , Loss: 0.4070151150226593\n",
      "Epoch [216/1000] , Step [20/40] , Loss: 0.4155569970607758\n",
      "Epoch [216/1000] , Step [30/40] , Loss: 0.4182983934879303\n",
      "Epoch [216/1000] , Step [40/40] , Loss: 0.4148232638835907\n",
      "Epoch [217/1000] , Step [10/40] , Loss: 0.4062201082706451\n",
      "Epoch [217/1000] , Step [20/40] , Loss: 0.3849784731864929\n",
      "Epoch [217/1000] , Step [30/40] , Loss: 0.4029374122619629\n",
      "Epoch [217/1000] , Step [40/40] , Loss: 0.4209785461425781\n",
      "Epoch [218/1000] , Step [10/40] , Loss: 0.4112037718296051\n",
      "Epoch [218/1000] , Step [20/40] , Loss: 0.3835594952106476\n",
      "Epoch [218/1000] , Step [30/40] , Loss: 0.4025970101356506\n",
      "Epoch [218/1000] , Step [40/40] , Loss: 0.3802213072776794\n",
      "Epoch [219/1000] , Step [10/40] , Loss: 0.4065814912319183\n",
      "Epoch [219/1000] , Step [20/40] , Loss: 0.3962807357311249\n",
      "Epoch [219/1000] , Step [30/40] , Loss: 0.3905290365219116\n",
      "Epoch [219/1000] , Step [40/40] , Loss: 0.4022669792175293\n",
      "Epoch [220/1000] , Step [10/40] , Loss: 0.4014467000961304\n",
      "Epoch [220/1000] , Step [20/40] , Loss: 0.3863778710365295\n",
      "Epoch [220/1000] , Step [30/40] , Loss: 0.4048630893230438\n",
      "Epoch [220/1000] , Step [40/40] , Loss: 0.3660015463829041\n",
      "Epoch [221/1000] , Step [10/40] , Loss: 0.3952239751815796\n",
      "Epoch [221/1000] , Step [20/40] , Loss: 0.3727184236049652\n",
      "Epoch [221/1000] , Step [30/40] , Loss: 0.3782146573066711\n",
      "Epoch [221/1000] , Step [40/40] , Loss: 0.3863200247287750\n",
      "Epoch [222/1000] , Step [10/40] , Loss: 0.3758896291255951\n",
      "Epoch [222/1000] , Step [20/40] , Loss: 0.3712738752365112\n",
      "Epoch [222/1000] , Step [30/40] , Loss: 0.3709785640239716\n",
      "Epoch [222/1000] , Step [40/40] , Loss: 0.3711212277412415\n",
      "Epoch [223/1000] , Step [10/40] , Loss: 0.3624163568019867\n",
      "Epoch [223/1000] , Step [20/40] , Loss: 0.3818933963775635\n",
      "Epoch [223/1000] , Step [30/40] , Loss: 0.3839797377586365\n",
      "Epoch [223/1000] , Step [40/40] , Loss: 0.3848258554935455\n",
      "Epoch [224/1000] , Step [10/40] , Loss: 0.3656050264835358\n",
      "Epoch [224/1000] , Step [20/40] , Loss: 0.3942856788635254\n",
      "Epoch [224/1000] , Step [30/40] , Loss: 0.3695896267890930\n",
      "Epoch [224/1000] , Step [40/40] , Loss: 0.3563560247421265\n",
      "Epoch [225/1000] , Step [10/40] , Loss: 0.3562625050544739\n",
      "Epoch [225/1000] , Step [20/40] , Loss: 0.3661696910858154\n",
      "Epoch [225/1000] , Step [30/40] , Loss: 0.3511016070842743\n",
      "Epoch [225/1000] , Step [40/40] , Loss: 0.3664006292819977\n",
      "Epoch [226/1000] , Step [10/40] , Loss: 0.3724852502346039\n",
      "Epoch [226/1000] , Step [20/40] , Loss: 0.3781116008758545\n",
      "Epoch [226/1000] , Step [30/40] , Loss: 0.3582549095153809\n",
      "Epoch [226/1000] , Step [40/40] , Loss: 0.3769970834255219\n",
      "Epoch [227/1000] , Step [10/40] , Loss: 0.3551870286464691\n",
      "Epoch [227/1000] , Step [20/40] , Loss: 0.3318908512592316\n",
      "Epoch [227/1000] , Step [30/40] , Loss: 0.3649582564830780\n",
      "Epoch [227/1000] , Step [40/40] , Loss: 0.3473702669143677\n",
      "Epoch [228/1000] , Step [10/40] , Loss: 0.3464315831661224\n",
      "Epoch [228/1000] , Step [20/40] , Loss: 0.3555564880371094\n",
      "Epoch [228/1000] , Step [30/40] , Loss: 0.3248580992221832\n",
      "Epoch [228/1000] , Step [40/40] , Loss: 0.3417772054672241\n",
      "Epoch [229/1000] , Step [10/40] , Loss: 0.3317209482192993\n",
      "Epoch [229/1000] , Step [20/40] , Loss: 0.3482421040534973\n",
      "Epoch [229/1000] , Step [30/40] , Loss: 0.3422178626060486\n",
      "Epoch [229/1000] , Step [40/40] , Loss: 0.3131173551082611\n",
      "Epoch [230/1000] , Step [10/40] , Loss: 0.3275329768657684\n",
      "Epoch [230/1000] , Step [20/40] , Loss: 0.3441103994846344\n",
      "Epoch [230/1000] , Step [30/40] , Loss: 0.3262959718704224\n",
      "Epoch [230/1000] , Step [40/40] , Loss: 0.3395569920539856\n",
      "Epoch [231/1000] , Step [10/40] , Loss: 0.3236594200134277\n",
      "Epoch [231/1000] , Step [20/40] , Loss: 0.3012271523475647\n",
      "Epoch [231/1000] , Step [30/40] , Loss: 0.3408208489418030\n",
      "Epoch [231/1000] , Step [40/40] , Loss: 0.3431340157985687\n",
      "Epoch [232/1000] , Step [10/40] , Loss: 0.3385791182518005\n",
      "Epoch [232/1000] , Step [20/40] , Loss: 0.3222474753856659\n",
      "Epoch [232/1000] , Step [30/40] , Loss: 0.3224189281463623\n",
      "Epoch [232/1000] , Step [40/40] , Loss: 0.3133743405342102\n",
      "Epoch [233/1000] , Step [10/40] , Loss: 0.3224897384643555\n",
      "Epoch [233/1000] , Step [20/40] , Loss: 0.3295229971408844\n",
      "Epoch [233/1000] , Step [30/40] , Loss: 0.3100413382053375\n",
      "Epoch [233/1000] , Step [40/40] , Loss: 0.3420770168304443\n",
      "Epoch [234/1000] , Step [10/40] , Loss: 0.3092782795429230\n",
      "Epoch [234/1000] , Step [20/40] , Loss: 0.3183706700801849\n",
      "Epoch [234/1000] , Step [30/40] , Loss: 0.3210757076740265\n",
      "Epoch [234/1000] , Step [40/40] , Loss: 0.2979238331317902\n",
      "Epoch [235/1000] , Step [10/40] , Loss: 0.2937053143978119\n",
      "Epoch [235/1000] , Step [20/40] , Loss: 0.3297574222087860\n",
      "Epoch [235/1000] , Step [30/40] , Loss: 0.3024148344993591\n",
      "Epoch [235/1000] , Step [40/40] , Loss: 0.3166669309139252\n",
      "Epoch [236/1000] , Step [10/40] , Loss: 0.3134889602661133\n",
      "Epoch [236/1000] , Step [20/40] , Loss: 0.3044283390045166\n",
      "Epoch [236/1000] , Step [30/40] , Loss: 0.3380969762802124\n",
      "Epoch [236/1000] , Step [40/40] , Loss: 0.3152089416980743\n",
      "Epoch [237/1000] , Step [10/40] , Loss: 0.3069561421871185\n",
      "Epoch [237/1000] , Step [20/40] , Loss: 0.3041063845157623\n",
      "Epoch [237/1000] , Step [30/40] , Loss: 0.3068861067295074\n",
      "Epoch [237/1000] , Step [40/40] , Loss: 0.3060838580131531\n",
      "Epoch [238/1000] , Step [10/40] , Loss: 0.3096118569374084\n",
      "Epoch [238/1000] , Step [20/40] , Loss: 0.3081879317760468\n",
      "Epoch [238/1000] , Step [30/40] , Loss: 0.2901152074337006\n",
      "Epoch [238/1000] , Step [40/40] , Loss: 0.2969585061073303\n",
      "Epoch [239/1000] , Step [10/40] , Loss: 0.2931785881519318\n",
      "Epoch [239/1000] , Step [20/40] , Loss: 0.2807325422763824\n",
      "Epoch [239/1000] , Step [30/40] , Loss: 0.2914617955684662\n",
      "Epoch [239/1000] , Step [40/40] , Loss: 0.2871816456317902\n",
      "Epoch [240/1000] , Step [10/40] , Loss: 0.3153291046619415\n",
      "Epoch [240/1000] , Step [20/40] , Loss: 0.3015658855438232\n",
      "Epoch [240/1000] , Step [30/40] , Loss: 0.3026327490806580\n",
      "Epoch [240/1000] , Step [40/40] , Loss: 0.3273360729217529\n",
      "Epoch [241/1000] , Step [10/40] , Loss: 0.3016165792942047\n",
      "Epoch [241/1000] , Step [20/40] , Loss: 0.3233176767826080\n",
      "Epoch [241/1000] , Step [30/40] , Loss: 0.2951482832431793\n",
      "Epoch [241/1000] , Step [40/40] , Loss: 0.2872823774814606\n",
      "Epoch [242/1000] , Step [10/40] , Loss: 0.2970726788043976\n",
      "Epoch [242/1000] , Step [20/40] , Loss: 0.3203381896018982\n",
      "Epoch [242/1000] , Step [30/40] , Loss: 0.2945019602775574\n",
      "Epoch [242/1000] , Step [40/40] , Loss: 0.2859037816524506\n",
      "Epoch [243/1000] , Step [10/40] , Loss: 0.2755594551563263\n",
      "Epoch [243/1000] , Step [20/40] , Loss: 0.2877743244171143\n",
      "Epoch [243/1000] , Step [30/40] , Loss: 0.2957128286361694\n",
      "Epoch [243/1000] , Step [40/40] , Loss: 0.2996240854263306\n",
      "Epoch [244/1000] , Step [10/40] , Loss: 0.2902935147285461\n",
      "Epoch [244/1000] , Step [20/40] , Loss: 0.2855435311794281\n",
      "Epoch [244/1000] , Step [30/40] , Loss: 0.2845732271671295\n",
      "Epoch [244/1000] , Step [40/40] , Loss: 0.2984938323497772\n",
      "Epoch [245/1000] , Step [10/40] , Loss: 0.2813526988029480\n",
      "Epoch [245/1000] , Step [20/40] , Loss: 0.2743424177169800\n",
      "Epoch [245/1000] , Step [30/40] , Loss: 0.2930997610092163\n",
      "Epoch [245/1000] , Step [40/40] , Loss: 0.2852391898632050\n",
      "Epoch [246/1000] , Step [10/40] , Loss: 0.2811823487281799\n",
      "Epoch [246/1000] , Step [20/40] , Loss: 0.2966347932815552\n",
      "Epoch [246/1000] , Step [30/40] , Loss: 0.2838690280914307\n",
      "Epoch [246/1000] , Step [40/40] , Loss: 0.2621488869190216\n",
      "Epoch [247/1000] , Step [10/40] , Loss: 0.2800091803073883\n",
      "Epoch [247/1000] , Step [20/40] , Loss: 0.2652474939823151\n",
      "Epoch [247/1000] , Step [30/40] , Loss: 0.2657840251922607\n",
      "Epoch [247/1000] , Step [40/40] , Loss: 0.2572815716266632\n",
      "Epoch [248/1000] , Step [10/40] , Loss: 0.2703437805175781\n",
      "Epoch [248/1000] , Step [20/40] , Loss: 0.2829093337059021\n",
      "Epoch [248/1000] , Step [30/40] , Loss: 0.2728009819984436\n",
      "Epoch [248/1000] , Step [40/40] , Loss: 0.3127566874027252\n",
      "Epoch [249/1000] , Step [10/40] , Loss: 0.2713538706302643\n",
      "Epoch [249/1000] , Step [20/40] , Loss: 0.2701531052589417\n",
      "Epoch [249/1000] , Step [30/40] , Loss: 0.2878616154193878\n",
      "Epoch [249/1000] , Step [40/40] , Loss: 0.2624467909336090\n",
      "Epoch [250/1000] , Step [10/40] , Loss: 0.2770842611789703\n",
      "Epoch [250/1000] , Step [20/40] , Loss: 0.2807975709438324\n",
      "Epoch [250/1000] , Step [30/40] , Loss: 0.2768490314483643\n",
      "Epoch [250/1000] , Step [40/40] , Loss: 0.2794516384601593\n",
      "Epoch [251/1000] , Step [10/40] , Loss: 0.2949414253234863\n",
      "Epoch [251/1000] , Step [20/40] , Loss: 0.2778219282627106\n",
      "Epoch [251/1000] , Step [30/40] , Loss: 0.2920341789722443\n",
      "Epoch [251/1000] , Step [40/40] , Loss: 0.2738797664642334\n",
      "Epoch [252/1000] , Step [10/40] , Loss: 0.2617441713809967\n",
      "Epoch [252/1000] , Step [20/40] , Loss: 0.2829239666461945\n",
      "Epoch [252/1000] , Step [30/40] , Loss: 0.2476182878017426\n",
      "Epoch [252/1000] , Step [40/40] , Loss: 0.2915182113647461\n",
      "Epoch [253/1000] , Step [10/40] , Loss: 0.2691709697246552\n",
      "Epoch [253/1000] , Step [20/40] , Loss: 0.2590042650699615\n",
      "Epoch [253/1000] , Step [30/40] , Loss: 0.2718484401702881\n",
      "Epoch [253/1000] , Step [40/40] , Loss: 0.2760333716869354\n",
      "Epoch [254/1000] , Step [10/40] , Loss: 0.2765342295169830\n",
      "Epoch [254/1000] , Step [20/40] , Loss: 0.2713753879070282\n",
      "Epoch [254/1000] , Step [30/40] , Loss: 0.2603619992733002\n",
      "Epoch [254/1000] , Step [40/40] , Loss: 0.2781774699687958\n",
      "Epoch [255/1000] , Step [10/40] , Loss: 0.2617295980453491\n",
      "Epoch [255/1000] , Step [20/40] , Loss: 0.2620571851730347\n",
      "Epoch [255/1000] , Step [30/40] , Loss: 0.2800422906875610\n",
      "Epoch [255/1000] , Step [40/40] , Loss: 0.2531662881374359\n",
      "Epoch [256/1000] , Step [10/40] , Loss: 0.2802298367023468\n",
      "Epoch [256/1000] , Step [20/40] , Loss: 0.2843497693538666\n",
      "Epoch [256/1000] , Step [30/40] , Loss: 0.2728757262229919\n",
      "Epoch [256/1000] , Step [40/40] , Loss: 0.2676753997802734\n",
      "Epoch [257/1000] , Step [10/40] , Loss: 0.2775101363658905\n",
      "Epoch [257/1000] , Step [20/40] , Loss: 0.2650008797645569\n",
      "Epoch [257/1000] , Step [30/40] , Loss: 0.2611135840415955\n",
      "Epoch [257/1000] , Step [40/40] , Loss: 0.2757157385349274\n",
      "Epoch [258/1000] , Step [10/40] , Loss: 0.2634898424148560\n",
      "Epoch [258/1000] , Step [20/40] , Loss: 0.2833443284034729\n",
      "Epoch [258/1000] , Step [30/40] , Loss: 0.2771909534931183\n",
      "Epoch [258/1000] , Step [40/40] , Loss: 0.2689320743083954\n",
      "Epoch [259/1000] , Step [10/40] , Loss: 0.2749152779579163\n",
      "Epoch [259/1000] , Step [20/40] , Loss: 0.2675479948520660\n",
      "Epoch [259/1000] , Step [30/40] , Loss: 0.2548853754997253\n",
      "Epoch [259/1000] , Step [40/40] , Loss: 0.2720011174678802\n",
      "Epoch [260/1000] , Step [10/40] , Loss: 0.2487934678792953\n",
      "Epoch [260/1000] , Step [20/40] , Loss: 0.2650381922721863\n",
      "Epoch [260/1000] , Step [30/40] , Loss: 0.2463781684637070\n",
      "Epoch [260/1000] , Step [40/40] , Loss: 0.2588411271572113\n",
      "Epoch [261/1000] , Step [10/40] , Loss: 0.2717028558254242\n",
      "Epoch [261/1000] , Step [20/40] , Loss: 0.2609146535396576\n",
      "Epoch [261/1000] , Step [30/40] , Loss: 0.2678760290145874\n",
      "Epoch [261/1000] , Step [40/40] , Loss: 0.2698580026626587\n",
      "Epoch [262/1000] , Step [10/40] , Loss: 0.2629252076148987\n",
      "Epoch [262/1000] , Step [20/40] , Loss: 0.2578669786453247\n",
      "Epoch [262/1000] , Step [30/40] , Loss: 0.2452663183212280\n",
      "Epoch [262/1000] , Step [40/40] , Loss: 0.2652987837791443\n",
      "Epoch [263/1000] , Step [10/40] , Loss: 0.2621145248413086\n",
      "Epoch [263/1000] , Step [20/40] , Loss: 0.2506977319717407\n",
      "Epoch [263/1000] , Step [30/40] , Loss: 0.2508143186569214\n",
      "Epoch [263/1000] , Step [40/40] , Loss: 0.2561138570308685\n",
      "Epoch [264/1000] , Step [10/40] , Loss: 0.2620987892150879\n",
      "Epoch [264/1000] , Step [20/40] , Loss: 0.2631125748157501\n",
      "Epoch [264/1000] , Step [30/40] , Loss: 0.2679901719093323\n",
      "Epoch [264/1000] , Step [40/40] , Loss: 0.2576658427715302\n",
      "Epoch [265/1000] , Step [10/40] , Loss: 0.2533692121505737\n",
      "Epoch [265/1000] , Step [20/40] , Loss: 0.2564019858837128\n",
      "Epoch [265/1000] , Step [30/40] , Loss: 0.2598325610160828\n",
      "Epoch [265/1000] , Step [40/40] , Loss: 0.2781653106212616\n",
      "Epoch [266/1000] , Step [10/40] , Loss: 0.2297998368740082\n",
      "Epoch [266/1000] , Step [20/40] , Loss: 0.2627099156379700\n",
      "Epoch [266/1000] , Step [30/40] , Loss: 0.2729513347148895\n",
      "Epoch [266/1000] , Step [40/40] , Loss: 0.2743020057678223\n",
      "Epoch [267/1000] , Step [10/40] , Loss: 0.2731737792491913\n",
      "Epoch [267/1000] , Step [20/40] , Loss: 0.2794708907604218\n",
      "Epoch [267/1000] , Step [30/40] , Loss: 0.2749640941619873\n",
      "Epoch [267/1000] , Step [40/40] , Loss: 0.2757079005241394\n",
      "Epoch [268/1000] , Step [10/40] , Loss: 0.2754189372062683\n",
      "Epoch [268/1000] , Step [20/40] , Loss: 0.2768819630146027\n",
      "Epoch [268/1000] , Step [30/40] , Loss: 0.2679783701896667\n",
      "Epoch [268/1000] , Step [40/40] , Loss: 0.2609665095806122\n",
      "Epoch [269/1000] , Step [10/40] , Loss: 0.2581083476543427\n",
      "Epoch [269/1000] , Step [20/40] , Loss: 0.2501374185085297\n",
      "Epoch [269/1000] , Step [30/40] , Loss: 0.2470539212226868\n",
      "Epoch [269/1000] , Step [40/40] , Loss: 0.2725795805454254\n",
      "Epoch [270/1000] , Step [10/40] , Loss: 0.2669220268726349\n",
      "Epoch [270/1000] , Step [20/40] , Loss: 0.2632864415645599\n",
      "Epoch [270/1000] , Step [30/40] , Loss: 0.2470057606697083\n",
      "Epoch [270/1000] , Step [40/40] , Loss: 0.2784850001335144\n",
      "Epoch [271/1000] , Step [10/40] , Loss: 0.2547967731952667\n",
      "Epoch [271/1000] , Step [20/40] , Loss: 0.2651507258415222\n",
      "Epoch [271/1000] , Step [30/40] , Loss: 0.2550081610679626\n",
      "Epoch [271/1000] , Step [40/40] , Loss: 0.2436253577470779\n",
      "Epoch [272/1000] , Step [10/40] , Loss: 0.2747638523578644\n",
      "Epoch [272/1000] , Step [20/40] , Loss: 0.2683036327362061\n",
      "Epoch [272/1000] , Step [30/40] , Loss: 0.2518532574176788\n",
      "Epoch [272/1000] , Step [40/40] , Loss: 0.2632105350494385\n",
      "Epoch [273/1000] , Step [10/40] , Loss: 0.2798928022384644\n",
      "Epoch [273/1000] , Step [20/40] , Loss: 0.2555527687072754\n",
      "Epoch [273/1000] , Step [30/40] , Loss: 0.2569785118103027\n",
      "Epoch [273/1000] , Step [40/40] , Loss: 0.2494072169065475\n",
      "Epoch [274/1000] , Step [10/40] , Loss: 0.2851207852363586\n",
      "Epoch [274/1000] , Step [20/40] , Loss: 0.2782292366027832\n",
      "Epoch [274/1000] , Step [30/40] , Loss: 0.2527051866054535\n",
      "Epoch [274/1000] , Step [40/40] , Loss: 0.2439989149570465\n",
      "Epoch [275/1000] , Step [10/40] , Loss: 0.2735258936882019\n",
      "Epoch [275/1000] , Step [20/40] , Loss: 0.2536106705665588\n",
      "Epoch [275/1000] , Step [30/40] , Loss: 0.2550888359546661\n",
      "Epoch [275/1000] , Step [40/40] , Loss: 0.2502452433109283\n",
      "Epoch [276/1000] , Step [10/40] , Loss: 0.2631743550300598\n",
      "Epoch [276/1000] , Step [20/40] , Loss: 0.2496559768915176\n",
      "Epoch [276/1000] , Step [30/40] , Loss: 0.2349808365106583\n",
      "Epoch [276/1000] , Step [40/40] , Loss: 0.2270494103431702\n",
      "Epoch [277/1000] , Step [10/40] , Loss: 0.2567603588104248\n",
      "Epoch [277/1000] , Step [20/40] , Loss: 0.2482155263423920\n",
      "Epoch [277/1000] , Step [30/40] , Loss: 0.2593325972557068\n",
      "Epoch [277/1000] , Step [40/40] , Loss: 0.2475446760654449\n",
      "Epoch [278/1000] , Step [10/40] , Loss: 0.2490897476673126\n",
      "Epoch [278/1000] , Step [20/40] , Loss: 0.2669768929481506\n",
      "Epoch [278/1000] , Step [30/40] , Loss: 0.2493001520633698\n",
      "Epoch [278/1000] , Step [40/40] , Loss: 0.2393540292978287\n",
      "Epoch [279/1000] , Step [10/40] , Loss: 0.2662101089954376\n",
      "Epoch [279/1000] , Step [20/40] , Loss: 0.2515980601310730\n",
      "Epoch [279/1000] , Step [30/40] , Loss: 0.2483206540346146\n",
      "Epoch [279/1000] , Step [40/40] , Loss: 0.2579276859760284\n",
      "Epoch [280/1000] , Step [10/40] , Loss: 0.2601080536842346\n",
      "Epoch [280/1000] , Step [20/40] , Loss: 0.2571144104003906\n",
      "Epoch [280/1000] , Step [30/40] , Loss: 0.2513578534126282\n",
      "Epoch [280/1000] , Step [40/40] , Loss: 0.2531295120716095\n",
      "Epoch [281/1000] , Step [10/40] , Loss: 0.2473994046449661\n",
      "Epoch [281/1000] , Step [20/40] , Loss: 0.2544376552104950\n",
      "Epoch [281/1000] , Step [30/40] , Loss: 0.2438503950834274\n",
      "Epoch [281/1000] , Step [40/40] , Loss: 0.2601636946201324\n",
      "Epoch [282/1000] , Step [10/40] , Loss: 0.2745685577392578\n",
      "Epoch [282/1000] , Step [20/40] , Loss: 0.2727061808109283\n",
      "Epoch [282/1000] , Step [30/40] , Loss: 0.2501735389232635\n",
      "Epoch [282/1000] , Step [40/40] , Loss: 0.2586969733238220\n",
      "Epoch [283/1000] , Step [10/40] , Loss: 0.2650627493858337\n",
      "Epoch [283/1000] , Step [20/40] , Loss: 0.2599593997001648\n",
      "Epoch [283/1000] , Step [30/40] , Loss: 0.2394325435161591\n",
      "Epoch [283/1000] , Step [40/40] , Loss: 0.2726787626743317\n",
      "Epoch [284/1000] , Step [10/40] , Loss: 0.2559812068939209\n",
      "Epoch [284/1000] , Step [20/40] , Loss: 0.2541137933731079\n",
      "Epoch [284/1000] , Step [30/40] , Loss: 0.2516190111637115\n",
      "Epoch [284/1000] , Step [40/40] , Loss: 0.2408141940832138\n",
      "Epoch [285/1000] , Step [10/40] , Loss: 0.2509469985961914\n",
      "Epoch [285/1000] , Step [20/40] , Loss: 0.2550523877143860\n",
      "Epoch [285/1000] , Step [30/40] , Loss: 0.2640725970268250\n",
      "Epoch [285/1000] , Step [40/40] , Loss: 0.2531875669956207\n",
      "Epoch [286/1000] , Step [10/40] , Loss: 0.2472825348377228\n",
      "Epoch [286/1000] , Step [20/40] , Loss: 0.2554735541343689\n",
      "Epoch [286/1000] , Step [30/40] , Loss: 0.2489604800939560\n",
      "Epoch [286/1000] , Step [40/40] , Loss: 0.2505019605159760\n",
      "Epoch [287/1000] , Step [10/40] , Loss: 0.2515275478363037\n",
      "Epoch [287/1000] , Step [20/40] , Loss: 0.2479022443294525\n",
      "Epoch [287/1000] , Step [30/40] , Loss: 0.2647635340690613\n",
      "Epoch [287/1000] , Step [40/40] , Loss: 0.2456303238868713\n",
      "Epoch [288/1000] , Step [10/40] , Loss: 0.2511147856712341\n",
      "Epoch [288/1000] , Step [20/40] , Loss: 0.2641418874263763\n",
      "Epoch [288/1000] , Step [30/40] , Loss: 0.2544400990009308\n",
      "Epoch [288/1000] , Step [40/40] , Loss: 0.2625296115875244\n",
      "Epoch [289/1000] , Step [10/40] , Loss: 0.2568894624710083\n",
      "Epoch [289/1000] , Step [20/40] , Loss: 0.2382012605667114\n",
      "Epoch [289/1000] , Step [30/40] , Loss: 0.2605111896991730\n",
      "Epoch [289/1000] , Step [40/40] , Loss: 0.2532828450202942\n",
      "Epoch [290/1000] , Step [10/40] , Loss: 0.2653031051158905\n",
      "Epoch [290/1000] , Step [20/40] , Loss: 0.2518926262855530\n",
      "Epoch [290/1000] , Step [30/40] , Loss: 0.2423884868621826\n",
      "Epoch [290/1000] , Step [40/40] , Loss: 0.2750679254531860\n",
      "Epoch [291/1000] , Step [10/40] , Loss: 0.2491182386875153\n",
      "Epoch [291/1000] , Step [20/40] , Loss: 0.2477501332759857\n",
      "Epoch [291/1000] , Step [30/40] , Loss: 0.2358657270669937\n",
      "Epoch [291/1000] , Step [40/40] , Loss: 0.2128330320119858\n",
      "Epoch [292/1000] , Step [10/40] , Loss: 0.2549770176410675\n",
      "Epoch [292/1000] , Step [20/40] , Loss: 0.2695979475975037\n",
      "Epoch [292/1000] , Step [30/40] , Loss: 0.2545058727264404\n",
      "Epoch [292/1000] , Step [40/40] , Loss: 0.2668823003768921\n",
      "Epoch [293/1000] , Step [10/40] , Loss: 0.2534430921077728\n",
      "Epoch [293/1000] , Step [20/40] , Loss: 0.2787050306797028\n",
      "Epoch [293/1000] , Step [30/40] , Loss: 0.2460347861051559\n",
      "Epoch [293/1000] , Step [40/40] , Loss: 0.2573299407958984\n",
      "Epoch [294/1000] , Step [10/40] , Loss: 0.2436873316764832\n",
      "Epoch [294/1000] , Step [20/40] , Loss: 0.2565430998802185\n",
      "Epoch [294/1000] , Step [30/40] , Loss: 0.2466787993907928\n",
      "Epoch [294/1000] , Step [40/40] , Loss: 0.2636426687240601\n",
      "Epoch [295/1000] , Step [10/40] , Loss: 0.2448201775550842\n",
      "Epoch [295/1000] , Step [20/40] , Loss: 0.2488424628973007\n",
      "Epoch [295/1000] , Step [30/40] , Loss: 0.2481560558080673\n",
      "Epoch [295/1000] , Step [40/40] , Loss: 0.2444570809602737\n",
      "Epoch [296/1000] , Step [10/40] , Loss: 0.2436215877532959\n",
      "Epoch [296/1000] , Step [20/40] , Loss: 0.2612707614898682\n",
      "Epoch [296/1000] , Step [30/40] , Loss: 0.2417097091674805\n",
      "Epoch [296/1000] , Step [40/40] , Loss: 0.2586559653282166\n",
      "Epoch [297/1000] , Step [10/40] , Loss: 0.2454486042261124\n",
      "Epoch [297/1000] , Step [20/40] , Loss: 0.2451837360858917\n",
      "Epoch [297/1000] , Step [30/40] , Loss: 0.2441582679748535\n",
      "Epoch [297/1000] , Step [40/40] , Loss: 0.2572672665119171\n",
      "Epoch [298/1000] , Step [10/40] , Loss: 0.2560394406318665\n",
      "Epoch [298/1000] , Step [20/40] , Loss: 0.2341874837875366\n",
      "Epoch [298/1000] , Step [30/40] , Loss: 0.2491241246461868\n",
      "Epoch [298/1000] , Step [40/40] , Loss: 0.2792631089687347\n",
      "Epoch [299/1000] , Step [10/40] , Loss: 0.2607342302799225\n",
      "Epoch [299/1000] , Step [20/40] , Loss: 0.2770467698574066\n",
      "Epoch [299/1000] , Step [30/40] , Loss: 0.2527165114879608\n",
      "Epoch [299/1000] , Step [40/40] , Loss: 0.2350865006446838\n",
      "Epoch [300/1000] , Step [10/40] , Loss: 0.2332026660442352\n",
      "Epoch [300/1000] , Step [20/40] , Loss: 0.2459782361984253\n",
      "Epoch [300/1000] , Step [30/40] , Loss: 0.2632900774478912\n",
      "Epoch [300/1000] , Step [40/40] , Loss: 0.2404418289661407\n",
      "Epoch [301/1000] , Step [10/40] , Loss: 0.2461170852184296\n",
      "Epoch [301/1000] , Step [20/40] , Loss: 0.2598709464073181\n",
      "Epoch [301/1000] , Step [30/40] , Loss: 0.2551933825016022\n",
      "Epoch [301/1000] , Step [40/40] , Loss: 0.2565100193023682\n",
      "Epoch [302/1000] , Step [10/40] , Loss: 0.2559958696365356\n",
      "Epoch [302/1000] , Step [20/40] , Loss: 0.2490508258342743\n",
      "Epoch [302/1000] , Step [30/40] , Loss: 0.2415992468595505\n",
      "Epoch [302/1000] , Step [40/40] , Loss: 0.2751241922378540\n",
      "Epoch [303/1000] , Step [10/40] , Loss: 0.2567880153656006\n",
      "Epoch [303/1000] , Step [20/40] , Loss: 0.2509995996952057\n",
      "Epoch [303/1000] , Step [30/40] , Loss: 0.2764473557472229\n",
      "Epoch [303/1000] , Step [40/40] , Loss: 0.2775018811225891\n",
      "Epoch [304/1000] , Step [10/40] , Loss: 0.2438707500696182\n",
      "Epoch [304/1000] , Step [20/40] , Loss: 0.2638377845287323\n",
      "Epoch [304/1000] , Step [30/40] , Loss: 0.2564812004566193\n",
      "Epoch [304/1000] , Step [40/40] , Loss: 0.2776739895343781\n",
      "Epoch [305/1000] , Step [10/40] , Loss: 0.2259770184755325\n",
      "Epoch [305/1000] , Step [20/40] , Loss: 0.2716999948024750\n",
      "Epoch [305/1000] , Step [30/40] , Loss: 0.2649949789047241\n",
      "Epoch [305/1000] , Step [40/40] , Loss: 0.2759107351303101\n",
      "Epoch [306/1000] , Step [10/40] , Loss: 0.2562806904315948\n",
      "Epoch [306/1000] , Step [20/40] , Loss: 0.2557945549488068\n",
      "Epoch [306/1000] , Step [30/40] , Loss: 0.2360956221818924\n",
      "Epoch [306/1000] , Step [40/40] , Loss: 0.2659316360950470\n",
      "Epoch [307/1000] , Step [10/40] , Loss: 0.2567341625690460\n",
      "Epoch [307/1000] , Step [20/40] , Loss: 0.2464721202850342\n",
      "Epoch [307/1000] , Step [30/40] , Loss: 0.2635634839534760\n",
      "Epoch [307/1000] , Step [40/40] , Loss: 0.2595863044261932\n",
      "Epoch [308/1000] , Step [10/40] , Loss: 0.2561769783496857\n",
      "Epoch [308/1000] , Step [20/40] , Loss: 0.2256066799163818\n",
      "Epoch [308/1000] , Step [30/40] , Loss: 0.2715332210063934\n",
      "Epoch [308/1000] , Step [40/40] , Loss: 0.2385570704936981\n",
      "Epoch [309/1000] , Step [10/40] , Loss: 0.2347376197576523\n",
      "Epoch [309/1000] , Step [20/40] , Loss: 0.2441165298223495\n",
      "Epoch [309/1000] , Step [30/40] , Loss: 0.2527555227279663\n",
      "Epoch [309/1000] , Step [40/40] , Loss: 0.2369325459003448\n",
      "Epoch [310/1000] , Step [10/40] , Loss: 0.2664952874183655\n",
      "Epoch [310/1000] , Step [20/40] , Loss: 0.2666955590248108\n",
      "Epoch [310/1000] , Step [30/40] , Loss: 0.2414033710956573\n",
      "Epoch [310/1000] , Step [40/40] , Loss: 0.2351845204830170\n",
      "Epoch [311/1000] , Step [10/40] , Loss: 0.2459539175033569\n",
      "Epoch [311/1000] , Step [20/40] , Loss: 0.2498651742935181\n",
      "Epoch [311/1000] , Step [30/40] , Loss: 0.2420476078987122\n",
      "Epoch [311/1000] , Step [40/40] , Loss: 0.2527072429656982\n",
      "Epoch [312/1000] , Step [10/40] , Loss: 0.2636058330535889\n",
      "Epoch [312/1000] , Step [20/40] , Loss: 0.2447362095117569\n",
      "Epoch [312/1000] , Step [30/40] , Loss: 0.2574831247329712\n",
      "Epoch [312/1000] , Step [40/40] , Loss: 0.2567182779312134\n",
      "Epoch [313/1000] , Step [10/40] , Loss: 0.2586199641227722\n",
      "Epoch [313/1000] , Step [20/40] , Loss: 0.2483099997043610\n",
      "Epoch [313/1000] , Step [30/40] , Loss: 0.2638643980026245\n",
      "Epoch [313/1000] , Step [40/40] , Loss: 0.2506572604179382\n",
      "Epoch [314/1000] , Step [10/40] , Loss: 0.2559581995010376\n",
      "Epoch [314/1000] , Step [20/40] , Loss: 0.2330052107572556\n",
      "Epoch [314/1000] , Step [30/40] , Loss: 0.2499922215938568\n",
      "Epoch [314/1000] , Step [40/40] , Loss: 0.2954436838626862\n",
      "Epoch [315/1000] , Step [10/40] , Loss: 0.2397323697805405\n",
      "Epoch [315/1000] , Step [20/40] , Loss: 0.2350185811519623\n",
      "Epoch [315/1000] , Step [30/40] , Loss: 0.2629096508026123\n",
      "Epoch [315/1000] , Step [40/40] , Loss: 0.2356023341417313\n",
      "Epoch [316/1000] , Step [10/40] , Loss: 0.2488429248332977\n",
      "Epoch [316/1000] , Step [20/40] , Loss: 0.2567041218280792\n",
      "Epoch [316/1000] , Step [30/40] , Loss: 0.2344371676445007\n",
      "Epoch [316/1000] , Step [40/40] , Loss: 0.2420235425233841\n",
      "Epoch [317/1000] , Step [10/40] , Loss: 0.2636134326457977\n",
      "Epoch [317/1000] , Step [20/40] , Loss: 0.2374586760997772\n",
      "Epoch [317/1000] , Step [30/40] , Loss: 0.2578183710575104\n",
      "Epoch [317/1000] , Step [40/40] , Loss: 0.2563202083110809\n",
      "Epoch [318/1000] , Step [10/40] , Loss: 0.2582918405532837\n",
      "Epoch [318/1000] , Step [20/40] , Loss: 0.2495029717683792\n",
      "Epoch [318/1000] , Step [30/40] , Loss: 0.2597227096557617\n",
      "Epoch [318/1000] , Step [40/40] , Loss: 0.2506464421749115\n",
      "Epoch [319/1000] , Step [10/40] , Loss: 0.2629673779010773\n",
      "Epoch [319/1000] , Step [20/40] , Loss: 0.2486109882593155\n",
      "Epoch [319/1000] , Step [30/40] , Loss: 0.2867106497287750\n",
      "Epoch [319/1000] , Step [40/40] , Loss: 0.2332956939935684\n",
      "Epoch [320/1000] , Step [10/40] , Loss: 0.2515498995780945\n",
      "Epoch [320/1000] , Step [20/40] , Loss: 0.2635215520858765\n",
      "Epoch [320/1000] , Step [30/40] , Loss: 0.2661096453666687\n",
      "Epoch [320/1000] , Step [40/40] , Loss: 0.2371493130922318\n",
      "Epoch [321/1000] , Step [10/40] , Loss: 0.2686549425125122\n",
      "Epoch [321/1000] , Step [20/40] , Loss: 0.2641736567020416\n",
      "Epoch [321/1000] , Step [30/40] , Loss: 0.2435942292213440\n",
      "Epoch [321/1000] , Step [40/40] , Loss: 0.2255440652370453\n",
      "Epoch [322/1000] , Step [10/40] , Loss: 0.2341558784246445\n",
      "Epoch [322/1000] , Step [20/40] , Loss: 0.2525381743907928\n",
      "Epoch [322/1000] , Step [30/40] , Loss: 0.2624728381633759\n",
      "Epoch [322/1000] , Step [40/40] , Loss: 0.2471963167190552\n",
      "Epoch [323/1000] , Step [10/40] , Loss: 0.2543949484825134\n",
      "Epoch [323/1000] , Step [20/40] , Loss: 0.2382061034440994\n",
      "Epoch [323/1000] , Step [30/40] , Loss: 0.2746693789958954\n",
      "Epoch [323/1000] , Step [40/40] , Loss: 0.2302385121583939\n",
      "Epoch [324/1000] , Step [10/40] , Loss: 0.2262647002935410\n",
      "Epoch [324/1000] , Step [20/40] , Loss: 0.2696683704853058\n",
      "Epoch [324/1000] , Step [30/40] , Loss: 0.2497316449880600\n",
      "Epoch [324/1000] , Step [40/40] , Loss: 0.2327757328748703\n",
      "Epoch [325/1000] , Step [10/40] , Loss: 0.2504230439662933\n",
      "Epoch [325/1000] , Step [20/40] , Loss: 0.2376584112644196\n",
      "Epoch [325/1000] , Step [30/40] , Loss: 0.2602781653404236\n",
      "Epoch [325/1000] , Step [40/40] , Loss: 0.2492762207984924\n",
      "Epoch [326/1000] , Step [10/40] , Loss: 0.2416591644287109\n",
      "Epoch [326/1000] , Step [20/40] , Loss: 0.2450731992721558\n",
      "Epoch [326/1000] , Step [30/40] , Loss: 0.2497504949569702\n",
      "Epoch [326/1000] , Step [40/40] , Loss: 0.2202990949153900\n",
      "Epoch [327/1000] , Step [10/40] , Loss: 0.2606672942638397\n",
      "Epoch [327/1000] , Step [20/40] , Loss: 0.2274577170610428\n",
      "Epoch [327/1000] , Step [30/40] , Loss: 0.2465932220220566\n",
      "Epoch [327/1000] , Step [40/40] , Loss: 0.2422189861536026\n",
      "Epoch [328/1000] , Step [10/40] , Loss: 0.2433151006698608\n",
      "Epoch [328/1000] , Step [20/40] , Loss: 0.2486330419778824\n",
      "Epoch [328/1000] , Step [30/40] , Loss: 0.2525421679019928\n",
      "Epoch [328/1000] , Step [40/40] , Loss: 0.2821158468723297\n",
      "Epoch [329/1000] , Step [10/40] , Loss: 0.2616441845893860\n",
      "Epoch [329/1000] , Step [20/40] , Loss: 0.2452875375747681\n",
      "Epoch [329/1000] , Step [30/40] , Loss: 0.2572380602359772\n",
      "Epoch [329/1000] , Step [40/40] , Loss: 0.2560121715068817\n",
      "Epoch [330/1000] , Step [10/40] , Loss: 0.2376739531755447\n",
      "Epoch [330/1000] , Step [20/40] , Loss: 0.2489078491926193\n",
      "Epoch [330/1000] , Step [30/40] , Loss: 0.2405496388673782\n",
      "Epoch [330/1000] , Step [40/40] , Loss: 0.2253856658935547\n",
      "Epoch [331/1000] , Step [10/40] , Loss: 0.2418179064989090\n",
      "Epoch [331/1000] , Step [20/40] , Loss: 0.2458122819662094\n",
      "Epoch [331/1000] , Step [30/40] , Loss: 0.2554111480712891\n",
      "Epoch [331/1000] , Step [40/40] , Loss: 0.2931739985942841\n",
      "Epoch [332/1000] , Step [10/40] , Loss: 0.2340492904186249\n",
      "Epoch [332/1000] , Step [20/40] , Loss: 0.2627672553062439\n",
      "Epoch [332/1000] , Step [30/40] , Loss: 0.2530899047851562\n",
      "Epoch [332/1000] , Step [40/40] , Loss: 0.2349250316619873\n",
      "Epoch [333/1000] , Step [10/40] , Loss: 0.2407365888357162\n",
      "Epoch [333/1000] , Step [20/40] , Loss: 0.2350791990756989\n",
      "Epoch [333/1000] , Step [30/40] , Loss: 0.2643996179103851\n",
      "Epoch [333/1000] , Step [40/40] , Loss: 0.3094713389873505\n",
      "Epoch [334/1000] , Step [10/40] , Loss: 0.2477188706398010\n",
      "Epoch [334/1000] , Step [20/40] , Loss: 0.2677246034145355\n",
      "Epoch [334/1000] , Step [30/40] , Loss: 0.2621890008449554\n",
      "Epoch [334/1000] , Step [40/40] , Loss: 0.2449815273284912\n",
      "Epoch [335/1000] , Step [10/40] , Loss: 0.2552876472473145\n",
      "Epoch [335/1000] , Step [20/40] , Loss: 0.2611075341701508\n",
      "Epoch [335/1000] , Step [30/40] , Loss: 0.2629523277282715\n",
      "Epoch [335/1000] , Step [40/40] , Loss: 0.2458600699901581\n",
      "Epoch [336/1000] , Step [10/40] , Loss: 0.2543275654315948\n",
      "Epoch [336/1000] , Step [20/40] , Loss: 0.2582798898220062\n",
      "Epoch [336/1000] , Step [30/40] , Loss: 0.2441501021385193\n",
      "Epoch [336/1000] , Step [40/40] , Loss: 0.2432415932416916\n",
      "Epoch [337/1000] , Step [10/40] , Loss: 0.2462709546089172\n",
      "Epoch [337/1000] , Step [20/40] , Loss: 0.2613957822322845\n",
      "Epoch [337/1000] , Step [30/40] , Loss: 0.2642599344253540\n",
      "Epoch [337/1000] , Step [40/40] , Loss: 0.2473120987415314\n",
      "Epoch [338/1000] , Step [10/40] , Loss: 0.2654794156551361\n",
      "Epoch [338/1000] , Step [20/40] , Loss: 0.2567271590232849\n",
      "Epoch [338/1000] , Step [30/40] , Loss: 0.2483077943325043\n",
      "Epoch [338/1000] , Step [40/40] , Loss: 0.2522172033786774\n",
      "Epoch [339/1000] , Step [10/40] , Loss: 0.2514878213405609\n",
      "Epoch [339/1000] , Step [20/40] , Loss: 0.2555057704448700\n",
      "Epoch [339/1000] , Step [30/40] , Loss: 0.2649618387222290\n",
      "Epoch [339/1000] , Step [40/40] , Loss: 0.2558405697345734\n",
      "Epoch [340/1000] , Step [10/40] , Loss: 0.2747046053409576\n",
      "Epoch [340/1000] , Step [20/40] , Loss: 0.2443754822015762\n",
      "Epoch [340/1000] , Step [30/40] , Loss: 0.2557505369186401\n",
      "Epoch [340/1000] , Step [40/40] , Loss: 0.2414409369230270\n",
      "Epoch [341/1000] , Step [10/40] , Loss: 0.2541583478450775\n",
      "Epoch [341/1000] , Step [20/40] , Loss: 0.2589922249317169\n",
      "Epoch [341/1000] , Step [30/40] , Loss: 0.2574994862079620\n",
      "Epoch [341/1000] , Step [40/40] , Loss: 0.2436394095420837\n",
      "Epoch [342/1000] , Step [10/40] , Loss: 0.2259072661399841\n",
      "Epoch [342/1000] , Step [20/40] , Loss: 0.2593820393085480\n",
      "Epoch [342/1000] , Step [30/40] , Loss: 0.2713695168495178\n",
      "Epoch [342/1000] , Step [40/40] , Loss: 0.2446168214082718\n",
      "Epoch [343/1000] , Step [10/40] , Loss: 0.2503525614738464\n",
      "Epoch [343/1000] , Step [20/40] , Loss: 0.2473613619804382\n",
      "Epoch [343/1000] , Step [30/40] , Loss: 0.2626880705356598\n",
      "Epoch [343/1000] , Step [40/40] , Loss: 0.2487725317478180\n",
      "Epoch [344/1000] , Step [10/40] , Loss: 0.2728428244590759\n",
      "Epoch [344/1000] , Step [20/40] , Loss: 0.2354246079921722\n",
      "Epoch [344/1000] , Step [30/40] , Loss: 0.2506703138351440\n",
      "Epoch [344/1000] , Step [40/40] , Loss: 0.2329803109169006\n",
      "Epoch [345/1000] , Step [10/40] , Loss: 0.2589898109436035\n",
      "Epoch [345/1000] , Step [20/40] , Loss: 0.2480450123548508\n",
      "Epoch [345/1000] , Step [30/40] , Loss: 0.2391290366649628\n",
      "Epoch [345/1000] , Step [40/40] , Loss: 0.2784891426563263\n",
      "Epoch [346/1000] , Step [10/40] , Loss: 0.2499613016843796\n",
      "Epoch [346/1000] , Step [20/40] , Loss: 0.2465776056051254\n",
      "Epoch [346/1000] , Step [30/40] , Loss: 0.2358423024415970\n",
      "Epoch [346/1000] , Step [40/40] , Loss: 0.2403656989336014\n",
      "Epoch [347/1000] , Step [10/40] , Loss: 0.2425993382930756\n",
      "Epoch [347/1000] , Step [20/40] , Loss: 0.2451266944408417\n",
      "Epoch [347/1000] , Step [30/40] , Loss: 0.2520757913589478\n",
      "Epoch [347/1000] , Step [40/40] , Loss: 0.2352546602487564\n",
      "Epoch [348/1000] , Step [10/40] , Loss: 0.2440046966075897\n",
      "Epoch [348/1000] , Step [20/40] , Loss: 0.2471006810665131\n",
      "Epoch [348/1000] , Step [30/40] , Loss: 0.2567681372165680\n",
      "Epoch [348/1000] , Step [40/40] , Loss: 0.2508179247379303\n",
      "Epoch [349/1000] , Step [10/40] , Loss: 0.2476228326559067\n",
      "Epoch [349/1000] , Step [20/40] , Loss: 0.2577838003635406\n",
      "Epoch [349/1000] , Step [30/40] , Loss: 0.2486692667007446\n",
      "Epoch [349/1000] , Step [40/40] , Loss: 0.2507960796356201\n",
      "Epoch [350/1000] , Step [10/40] , Loss: 0.2381798028945923\n",
      "Epoch [350/1000] , Step [20/40] , Loss: 0.2303804159164429\n",
      "Epoch [350/1000] , Step [30/40] , Loss: 0.2631121873855591\n",
      "Epoch [350/1000] , Step [40/40] , Loss: 0.2476102560758591\n",
      "Epoch [351/1000] , Step [10/40] , Loss: 0.2627348303794861\n",
      "Epoch [351/1000] , Step [20/40] , Loss: 0.2409755438566208\n",
      "Epoch [351/1000] , Step [30/40] , Loss: 0.2471899986267090\n",
      "Epoch [351/1000] , Step [40/40] , Loss: 0.2461066693067551\n",
      "Epoch [352/1000] , Step [10/40] , Loss: 0.2650842368602753\n",
      "Epoch [352/1000] , Step [20/40] , Loss: 0.2390498965978622\n",
      "Epoch [352/1000] , Step [30/40] , Loss: 0.2506071627140045\n",
      "Epoch [352/1000] , Step [40/40] , Loss: 0.2323877215385437\n",
      "Epoch [353/1000] , Step [10/40] , Loss: 0.2318627685308456\n",
      "Epoch [353/1000] , Step [20/40] , Loss: 0.2590072453022003\n",
      "Epoch [353/1000] , Step [30/40] , Loss: 0.2461821138858795\n",
      "Epoch [353/1000] , Step [40/40] , Loss: 0.2555343210697174\n",
      "Epoch [354/1000] , Step [10/40] , Loss: 0.2576456367969513\n",
      "Epoch [354/1000] , Step [20/40] , Loss: 0.2721512317657471\n",
      "Epoch [354/1000] , Step [30/40] , Loss: 0.2380374521017075\n",
      "Epoch [354/1000] , Step [40/40] , Loss: 0.2318832576274872\n",
      "Epoch [355/1000] , Step [10/40] , Loss: 0.2462180852890015\n",
      "Epoch [355/1000] , Step [20/40] , Loss: 0.2362035065889359\n",
      "Epoch [355/1000] , Step [30/40] , Loss: 0.2429554909467697\n",
      "Epoch [355/1000] , Step [40/40] , Loss: 0.2704737782478333\n",
      "Epoch [356/1000] , Step [10/40] , Loss: 0.2539938688278198\n",
      "Epoch [356/1000] , Step [20/40] , Loss: 0.2203686535358429\n",
      "Epoch [356/1000] , Step [30/40] , Loss: 0.2549908459186554\n",
      "Epoch [356/1000] , Step [40/40] , Loss: 0.2904707193374634\n",
      "Epoch [357/1000] , Step [10/40] , Loss: 0.2639163136482239\n",
      "Epoch [357/1000] , Step [20/40] , Loss: 0.2444388717412949\n",
      "Epoch [357/1000] , Step [30/40] , Loss: 0.2404912561178207\n",
      "Epoch [357/1000] , Step [40/40] , Loss: 0.2512495815753937\n",
      "Epoch [358/1000] , Step [10/40] , Loss: 0.2552244961261749\n",
      "Epoch [358/1000] , Step [20/40] , Loss: 0.2376957684755325\n",
      "Epoch [358/1000] , Step [30/40] , Loss: 0.2502282261848450\n",
      "Epoch [358/1000] , Step [40/40] , Loss: 0.2346980124711990\n",
      "Epoch [359/1000] , Step [10/40] , Loss: 0.2446005344390869\n",
      "Epoch [359/1000] , Step [20/40] , Loss: 0.2343656867742538\n",
      "Epoch [359/1000] , Step [30/40] , Loss: 0.2630214989185333\n",
      "Epoch [359/1000] , Step [40/40] , Loss: 0.2370369732379913\n",
      "Epoch [360/1000] , Step [10/40] , Loss: 0.2354514747858047\n",
      "Epoch [360/1000] , Step [20/40] , Loss: 0.2578730583190918\n",
      "Epoch [360/1000] , Step [30/40] , Loss: 0.2630268335342407\n",
      "Epoch [360/1000] , Step [40/40] , Loss: 0.2622312903404236\n",
      "Epoch [361/1000] , Step [10/40] , Loss: 0.2426836937665939\n",
      "Epoch [361/1000] , Step [20/40] , Loss: 0.2471766471862793\n",
      "Epoch [361/1000] , Step [30/40] , Loss: 0.2444611191749573\n",
      "Epoch [361/1000] , Step [40/40] , Loss: 0.2597604691982269\n",
      "Epoch [362/1000] , Step [10/40] , Loss: 0.2412685602903366\n",
      "Epoch [362/1000] , Step [20/40] , Loss: 0.2435170859098434\n",
      "Epoch [362/1000] , Step [30/40] , Loss: 0.2682677209377289\n",
      "Epoch [362/1000] , Step [40/40] , Loss: 0.2269387692213058\n",
      "Epoch [363/1000] , Step [10/40] , Loss: 0.2429696172475815\n",
      "Epoch [363/1000] , Step [20/40] , Loss: 0.2424585819244385\n",
      "Epoch [363/1000] , Step [30/40] , Loss: 0.2331534922122955\n",
      "Epoch [363/1000] , Step [40/40] , Loss: 0.2544089853763580\n",
      "Epoch [364/1000] , Step [10/40] , Loss: 0.2591587901115417\n",
      "Epoch [364/1000] , Step [20/40] , Loss: 0.2405377924442291\n",
      "Epoch [364/1000] , Step [30/40] , Loss: 0.2552036046981812\n",
      "Epoch [364/1000] , Step [40/40] , Loss: 0.2399984896183014\n",
      "Epoch [365/1000] , Step [10/40] , Loss: 0.2561168670654297\n",
      "Epoch [365/1000] , Step [20/40] , Loss: 0.2482372820377350\n",
      "Epoch [365/1000] , Step [30/40] , Loss: 0.2684755027294159\n",
      "Epoch [365/1000] , Step [40/40] , Loss: 0.2268899530172348\n",
      "Epoch [366/1000] , Step [10/40] , Loss: 0.2357660830020905\n",
      "Epoch [366/1000] , Step [20/40] , Loss: 0.2456777840852737\n",
      "Epoch [366/1000] , Step [30/40] , Loss: 0.2539373338222504\n",
      "Epoch [366/1000] , Step [40/40] , Loss: 0.2495331913232803\n",
      "Epoch [367/1000] , Step [10/40] , Loss: 0.2505334913730621\n",
      "Epoch [367/1000] , Step [20/40] , Loss: 0.2403020411729813\n",
      "Epoch [367/1000] , Step [30/40] , Loss: 0.2336262762546539\n",
      "Epoch [367/1000] , Step [40/40] , Loss: 0.2552445232868195\n",
      "Epoch [368/1000] , Step [10/40] , Loss: 0.2553428411483765\n",
      "Epoch [368/1000] , Step [20/40] , Loss: 0.2391642481088638\n",
      "Epoch [368/1000] , Step [30/40] , Loss: 0.2361394912004471\n",
      "Epoch [368/1000] , Step [40/40] , Loss: 0.2273570746183395\n",
      "Epoch [369/1000] , Step [10/40] , Loss: 0.2317845821380615\n",
      "Epoch [369/1000] , Step [20/40] , Loss: 0.2644591629505157\n",
      "Epoch [369/1000] , Step [30/40] , Loss: 0.2496578693389893\n",
      "Epoch [369/1000] , Step [40/40] , Loss: 0.2733959257602692\n",
      "Epoch [370/1000] , Step [10/40] , Loss: 0.2509370744228363\n",
      "Epoch [370/1000] , Step [20/40] , Loss: 0.2425313889980316\n",
      "Epoch [370/1000] , Step [30/40] , Loss: 0.2392929494380951\n",
      "Epoch [370/1000] , Step [40/40] , Loss: 0.2621794939041138\n",
      "Epoch [371/1000] , Step [10/40] , Loss: 0.2433691024780273\n",
      "Epoch [371/1000] , Step [20/40] , Loss: 0.2484733462333679\n",
      "Epoch [371/1000] , Step [30/40] , Loss: 0.2276497036218643\n",
      "Epoch [371/1000] , Step [40/40] , Loss: 0.2699232697486877\n",
      "Epoch [372/1000] , Step [10/40] , Loss: 0.2442268580198288\n",
      "Epoch [372/1000] , Step [20/40] , Loss: 0.2535144686698914\n",
      "Epoch [372/1000] , Step [30/40] , Loss: 0.2530013918876648\n",
      "Epoch [372/1000] , Step [40/40] , Loss: 0.2405574619770050\n",
      "Epoch [373/1000] , Step [10/40] , Loss: 0.2598521113395691\n",
      "Epoch [373/1000] , Step [20/40] , Loss: 0.2775096595287323\n",
      "Epoch [373/1000] , Step [30/40] , Loss: 0.2481333911418915\n",
      "Epoch [373/1000] , Step [40/40] , Loss: 0.2671490907669067\n",
      "Epoch [374/1000] , Step [10/40] , Loss: 0.2392118871212006\n",
      "Epoch [374/1000] , Step [20/40] , Loss: 0.2409880310297012\n",
      "Epoch [374/1000] , Step [30/40] , Loss: 0.2723332643508911\n",
      "Epoch [374/1000] , Step [40/40] , Loss: 0.2538431286811829\n",
      "Epoch [375/1000] , Step [10/40] , Loss: 0.2470075190067291\n",
      "Epoch [375/1000] , Step [20/40] , Loss: 0.2398130744695663\n",
      "Epoch [375/1000] , Step [30/40] , Loss: 0.2479730993509293\n",
      "Epoch [375/1000] , Step [40/40] , Loss: 0.2666235864162445\n",
      "Epoch [376/1000] , Step [10/40] , Loss: 0.2498542666435242\n",
      "Epoch [376/1000] , Step [20/40] , Loss: 0.2289945036172867\n",
      "Epoch [376/1000] , Step [30/40] , Loss: 0.2643389701843262\n",
      "Epoch [376/1000] , Step [40/40] , Loss: 0.2518832087516785\n",
      "Epoch [377/1000] , Step [10/40] , Loss: 0.2567636370658875\n",
      "Epoch [377/1000] , Step [20/40] , Loss: 0.2418425679206848\n",
      "Epoch [377/1000] , Step [30/40] , Loss: 0.2469066977500916\n",
      "Epoch [377/1000] , Step [40/40] , Loss: 0.2237689942121506\n",
      "Epoch [378/1000] , Step [10/40] , Loss: 0.2305000722408295\n",
      "Epoch [378/1000] , Step [20/40] , Loss: 0.2358550429344177\n",
      "Epoch [378/1000] , Step [30/40] , Loss: 0.2624836564064026\n",
      "Epoch [378/1000] , Step [40/40] , Loss: 0.2606326341629028\n",
      "Epoch [379/1000] , Step [10/40] , Loss: 0.2380748242139816\n",
      "Epoch [379/1000] , Step [20/40] , Loss: 0.2645238041877747\n",
      "Epoch [379/1000] , Step [30/40] , Loss: 0.2474962174892426\n",
      "Epoch [379/1000] , Step [40/40] , Loss: 0.2669462859630585\n",
      "Epoch [380/1000] , Step [10/40] , Loss: 0.2605815827846527\n",
      "Epoch [380/1000] , Step [20/40] , Loss: 0.2452349960803986\n",
      "Epoch [380/1000] , Step [30/40] , Loss: 0.2400598824024200\n",
      "Epoch [380/1000] , Step [40/40] , Loss: 0.2471358776092529\n",
      "Epoch [381/1000] , Step [10/40] , Loss: 0.2311251908540726\n",
      "Epoch [381/1000] , Step [20/40] , Loss: 0.2500239014625549\n",
      "Epoch [381/1000] , Step [30/40] , Loss: 0.2686068415641785\n",
      "Epoch [381/1000] , Step [40/40] , Loss: 0.2241318821907043\n",
      "Epoch [382/1000] , Step [10/40] , Loss: 0.2504567503929138\n",
      "Epoch [382/1000] , Step [20/40] , Loss: 0.2455452978610992\n",
      "Epoch [382/1000] , Step [30/40] , Loss: 0.2342127263545990\n",
      "Epoch [382/1000] , Step [40/40] , Loss: 0.2669214904308319\n",
      "Epoch [383/1000] , Step [10/40] , Loss: 0.2311115711927414\n",
      "Epoch [383/1000] , Step [20/40] , Loss: 0.2300811558961868\n",
      "Epoch [383/1000] , Step [30/40] , Loss: 0.2670772969722748\n",
      "Epoch [383/1000] , Step [40/40] , Loss: 0.2186182886362076\n",
      "Epoch [384/1000] , Step [10/40] , Loss: 0.2549890279769897\n",
      "Epoch [384/1000] , Step [20/40] , Loss: 0.2585020065307617\n",
      "Epoch [384/1000] , Step [30/40] , Loss: 0.2350039482116699\n",
      "Epoch [384/1000] , Step [40/40] , Loss: 0.2754225730895996\n",
      "Epoch [385/1000] , Step [10/40] , Loss: 0.2421601712703705\n",
      "Epoch [385/1000] , Step [20/40] , Loss: 0.2341785132884979\n",
      "Epoch [385/1000] , Step [30/40] , Loss: 0.2473450750112534\n",
      "Epoch [385/1000] , Step [40/40] , Loss: 0.2308451086282730\n",
      "Epoch [386/1000] , Step [10/40] , Loss: 0.2736262381076813\n",
      "Epoch [386/1000] , Step [20/40] , Loss: 0.2323500663042068\n",
      "Epoch [386/1000] , Step [30/40] , Loss: 0.2470261454582214\n",
      "Epoch [386/1000] , Step [40/40] , Loss: 0.2637556493282318\n",
      "Epoch [387/1000] , Step [10/40] , Loss: 0.2378445118665695\n",
      "Epoch [387/1000] , Step [20/40] , Loss: 0.2453811615705490\n",
      "Epoch [387/1000] , Step [30/40] , Loss: 0.2576118707656860\n",
      "Epoch [387/1000] , Step [40/40] , Loss: 0.2533771395683289\n",
      "Epoch [388/1000] , Step [10/40] , Loss: 0.2412113398313522\n",
      "Epoch [388/1000] , Step [20/40] , Loss: 0.2166544944047928\n",
      "Epoch [388/1000] , Step [30/40] , Loss: 0.2383499741554260\n",
      "Epoch [388/1000] , Step [40/40] , Loss: 0.2292912155389786\n",
      "Epoch [389/1000] , Step [10/40] , Loss: 0.2376807481050491\n",
      "Epoch [389/1000] , Step [20/40] , Loss: 0.2508245110511780\n",
      "Epoch [389/1000] , Step [30/40] , Loss: 0.2343287467956543\n",
      "Epoch [389/1000] , Step [40/40] , Loss: 0.2478205114603043\n",
      "Epoch [390/1000] , Step [10/40] , Loss: 0.2434228956699371\n",
      "Epoch [390/1000] , Step [20/40] , Loss: 0.2405629158020020\n",
      "Epoch [390/1000] , Step [30/40] , Loss: 0.2631556093692780\n",
      "Epoch [390/1000] , Step [40/40] , Loss: 0.2436285912990570\n",
      "Epoch [391/1000] , Step [10/40] , Loss: 0.2379803508520126\n",
      "Epoch [391/1000] , Step [20/40] , Loss: 0.2889463305473328\n",
      "Epoch [391/1000] , Step [30/40] , Loss: 0.2503481805324554\n",
      "Epoch [391/1000] , Step [40/40] , Loss: 0.2205083370208740\n",
      "Epoch [392/1000] , Step [10/40] , Loss: 0.2465277165174484\n",
      "Epoch [392/1000] , Step [20/40] , Loss: 0.2576357126235962\n",
      "Epoch [392/1000] , Step [30/40] , Loss: 0.2496287673711777\n",
      "Epoch [392/1000] , Step [40/40] , Loss: 0.2370151877403259\n",
      "Epoch [393/1000] , Step [10/40] , Loss: 0.2416726052761078\n",
      "Epoch [393/1000] , Step [20/40] , Loss: 0.2523791193962097\n",
      "Epoch [393/1000] , Step [30/40] , Loss: 0.2460209429264069\n",
      "Epoch [393/1000] , Step [40/40] , Loss: 0.2547993957996368\n",
      "Epoch [394/1000] , Step [10/40] , Loss: 0.2396438419818878\n",
      "Epoch [394/1000] , Step [20/40] , Loss: 0.2417079955339432\n",
      "Epoch [394/1000] , Step [30/40] , Loss: 0.2512570321559906\n",
      "Epoch [394/1000] , Step [40/40] , Loss: 0.2612355053424835\n",
      "Epoch [395/1000] , Step [10/40] , Loss: 0.2287288606166840\n",
      "Epoch [395/1000] , Step [20/40] , Loss: 0.2618185877799988\n",
      "Epoch [395/1000] , Step [30/40] , Loss: 0.2603407800197601\n",
      "Epoch [395/1000] , Step [40/40] , Loss: 0.2373690605163574\n",
      "Epoch [396/1000] , Step [10/40] , Loss: 0.2414650619029999\n",
      "Epoch [396/1000] , Step [20/40] , Loss: 0.2684836983680725\n",
      "Epoch [396/1000] , Step [30/40] , Loss: 0.2493751496076584\n",
      "Epoch [396/1000] , Step [40/40] , Loss: 0.2653532326221466\n",
      "Epoch [397/1000] , Step [10/40] , Loss: 0.2472924292087555\n",
      "Epoch [397/1000] , Step [20/40] , Loss: 0.2342748641967773\n",
      "Epoch [397/1000] , Step [30/40] , Loss: 0.2357667833566666\n",
      "Epoch [397/1000] , Step [40/40] , Loss: 0.2461672425270081\n",
      "Epoch [398/1000] , Step [10/40] , Loss: 0.2658778727054596\n",
      "Epoch [398/1000] , Step [20/40] , Loss: 0.2404984831809998\n",
      "Epoch [398/1000] , Step [30/40] , Loss: 0.2476531565189362\n",
      "Epoch [398/1000] , Step [40/40] , Loss: 0.2629340589046478\n",
      "Epoch [399/1000] , Step [10/40] , Loss: 0.2539416551589966\n",
      "Epoch [399/1000] , Step [20/40] , Loss: 0.2369780689477921\n",
      "Epoch [399/1000] , Step [30/40] , Loss: 0.2532272040843964\n",
      "Epoch [399/1000] , Step [40/40] , Loss: 0.2576714754104614\n",
      "Epoch [400/1000] , Step [10/40] , Loss: 0.2384313642978668\n",
      "Epoch [400/1000] , Step [20/40] , Loss: 0.2357925623655319\n",
      "Epoch [400/1000] , Step [30/40] , Loss: 0.2443015277385712\n",
      "Epoch [400/1000] , Step [40/40] , Loss: 0.2201348543167114\n",
      "Epoch [401/1000] , Step [10/40] , Loss: 0.2797709405422211\n",
      "Epoch [401/1000] , Step [20/40] , Loss: 0.2593641281127930\n",
      "Epoch [401/1000] , Step [30/40] , Loss: 0.2706124484539032\n",
      "Epoch [401/1000] , Step [40/40] , Loss: 0.2738566398620605\n",
      "Epoch [402/1000] , Step [10/40] , Loss: 0.2381209284067154\n",
      "Epoch [402/1000] , Step [20/40] , Loss: 0.2292354255914688\n",
      "Epoch [402/1000] , Step [30/40] , Loss: 0.2157787084579468\n",
      "Epoch [402/1000] , Step [40/40] , Loss: 0.2383184283971786\n",
      "Epoch [403/1000] , Step [10/40] , Loss: 0.2358457744121552\n",
      "Epoch [403/1000] , Step [20/40] , Loss: 0.2737094759941101\n",
      "Epoch [403/1000] , Step [30/40] , Loss: 0.2429063320159912\n",
      "Epoch [403/1000] , Step [40/40] , Loss: 0.2507539987564087\n",
      "Epoch [404/1000] , Step [10/40] , Loss: 0.2631123960018158\n",
      "Epoch [404/1000] , Step [20/40] , Loss: 0.2411022633314133\n",
      "Epoch [404/1000] , Step [30/40] , Loss: 0.2267632931470871\n",
      "Epoch [404/1000] , Step [40/40] , Loss: 0.2512769997119904\n",
      "Epoch [405/1000] , Step [10/40] , Loss: 0.2339391559362411\n",
      "Epoch [405/1000] , Step [20/40] , Loss: 0.2519231140613556\n",
      "Epoch [405/1000] , Step [30/40] , Loss: 0.2388184815645218\n",
      "Epoch [405/1000] , Step [40/40] , Loss: 0.2595218122005463\n",
      "Epoch [406/1000] , Step [10/40] , Loss: 0.2689881026744843\n",
      "Epoch [406/1000] , Step [20/40] , Loss: 0.2496713697910309\n",
      "Epoch [406/1000] , Step [30/40] , Loss: 0.2448630928993225\n",
      "Epoch [406/1000] , Step [40/40] , Loss: 0.2545989453792572\n",
      "Epoch [407/1000] , Step [10/40] , Loss: 0.2486407905817032\n",
      "Epoch [407/1000] , Step [20/40] , Loss: 0.2501324713230133\n",
      "Epoch [407/1000] , Step [30/40] , Loss: 0.2352131009101868\n",
      "Epoch [407/1000] , Step [40/40] , Loss: 0.2518426179885864\n",
      "Epoch [408/1000] , Step [10/40] , Loss: 0.2426514625549316\n",
      "Epoch [408/1000] , Step [20/40] , Loss: 0.2531132996082306\n",
      "Epoch [408/1000] , Step [30/40] , Loss: 0.2472255975008011\n",
      "Epoch [408/1000] , Step [40/40] , Loss: 0.2278005182743073\n",
      "Epoch [409/1000] , Step [10/40] , Loss: 0.2818845808506012\n",
      "Epoch [409/1000] , Step [20/40] , Loss: 0.2402598112821579\n",
      "Epoch [409/1000] , Step [30/40] , Loss: 0.2508119344711304\n",
      "Epoch [409/1000] , Step [40/40] , Loss: 0.2746080160140991\n",
      "Epoch [410/1000] , Step [10/40] , Loss: 0.2412568330764771\n",
      "Epoch [410/1000] , Step [20/40] , Loss: 0.2760703563690186\n",
      "Epoch [410/1000] , Step [30/40] , Loss: 0.2493053525686264\n",
      "Epoch [410/1000] , Step [40/40] , Loss: 0.2470458745956421\n",
      "Epoch [411/1000] , Step [10/40] , Loss: 0.2551323771476746\n",
      "Epoch [411/1000] , Step [20/40] , Loss: 0.2298072576522827\n",
      "Epoch [411/1000] , Step [30/40] , Loss: 0.2694488465785980\n",
      "Epoch [411/1000] , Step [40/40] , Loss: 0.2688964307308197\n",
      "Epoch [412/1000] , Step [10/40] , Loss: 0.2511097788810730\n",
      "Epoch [412/1000] , Step [20/40] , Loss: 0.2368145883083344\n",
      "Epoch [412/1000] , Step [30/40] , Loss: 0.2535047531127930\n",
      "Epoch [412/1000] , Step [40/40] , Loss: 0.2301008701324463\n",
      "Epoch [413/1000] , Step [10/40] , Loss: 0.2301125228404999\n",
      "Epoch [413/1000] , Step [20/40] , Loss: 0.2348590493202209\n",
      "Epoch [413/1000] , Step [30/40] , Loss: 0.2569397985935211\n",
      "Epoch [413/1000] , Step [40/40] , Loss: 0.2479991614818573\n",
      "Epoch [414/1000] , Step [10/40] , Loss: 0.2665564119815826\n",
      "Epoch [414/1000] , Step [20/40] , Loss: 0.2506664097309113\n",
      "Epoch [414/1000] , Step [30/40] , Loss: 0.2372089177370071\n",
      "Epoch [414/1000] , Step [40/40] , Loss: 0.2374702692031860\n",
      "Epoch [415/1000] , Step [10/40] , Loss: 0.2525267302989960\n",
      "Epoch [415/1000] , Step [20/40] , Loss: 0.2494317442178726\n",
      "Epoch [415/1000] , Step [30/40] , Loss: 0.2120940387248993\n",
      "Epoch [415/1000] , Step [40/40] , Loss: 0.2590986788272858\n",
      "Epoch [416/1000] , Step [10/40] , Loss: 0.2430922240018845\n",
      "Epoch [416/1000] , Step [20/40] , Loss: 0.2644241452217102\n",
      "Epoch [416/1000] , Step [30/40] , Loss: 0.2655481994152069\n",
      "Epoch [416/1000] , Step [40/40] , Loss: 0.2336757779121399\n",
      "Epoch [417/1000] , Step [10/40] , Loss: 0.2535200417041779\n",
      "Epoch [417/1000] , Step [20/40] , Loss: 0.2451375126838684\n",
      "Epoch [417/1000] , Step [30/40] , Loss: 0.2681994140148163\n",
      "Epoch [417/1000] , Step [40/40] , Loss: 0.2592483758926392\n",
      "Epoch [418/1000] , Step [10/40] , Loss: 0.2399991899728775\n",
      "Epoch [418/1000] , Step [20/40] , Loss: 0.2642511725425720\n",
      "Epoch [418/1000] , Step [30/40] , Loss: 0.2381580322980881\n",
      "Epoch [418/1000] , Step [40/40] , Loss: 0.2372116744518280\n",
      "Epoch [419/1000] , Step [10/40] , Loss: 0.2539435923099518\n",
      "Epoch [419/1000] , Step [20/40] , Loss: 0.2328936159610748\n",
      "Epoch [419/1000] , Step [30/40] , Loss: 0.2393510192632675\n",
      "Epoch [419/1000] , Step [40/40] , Loss: 0.2530113160610199\n",
      "Epoch [420/1000] , Step [10/40] , Loss: 0.2471571117639542\n",
      "Epoch [420/1000] , Step [20/40] , Loss: 0.2345168739557266\n",
      "Epoch [420/1000] , Step [30/40] , Loss: 0.2646366655826569\n",
      "Epoch [420/1000] , Step [40/40] , Loss: 0.2339842468500137\n",
      "Epoch [421/1000] , Step [10/40] , Loss: 0.2495149970054626\n",
      "Epoch [421/1000] , Step [20/40] , Loss: 0.2588588595390320\n",
      "Epoch [421/1000] , Step [30/40] , Loss: 0.2475759685039520\n",
      "Epoch [421/1000] , Step [40/40] , Loss: 0.2406909167766571\n",
      "Epoch [422/1000] , Step [10/40] , Loss: 0.2561157345771790\n",
      "Epoch [422/1000] , Step [20/40] , Loss: 0.2424498498439789\n",
      "Epoch [422/1000] , Step [30/40] , Loss: 0.2557603716850281\n",
      "Epoch [422/1000] , Step [40/40] , Loss: 0.2518583238124847\n",
      "Epoch [423/1000] , Step [10/40] , Loss: 0.2699109017848969\n",
      "Epoch [423/1000] , Step [20/40] , Loss: 0.2319874316453934\n",
      "Epoch [423/1000] , Step [30/40] , Loss: 0.2353883832693100\n",
      "Epoch [423/1000] , Step [40/40] , Loss: 0.2444120794534683\n",
      "Epoch [424/1000] , Step [10/40] , Loss: 0.2514314353466034\n",
      "Epoch [424/1000] , Step [20/40] , Loss: 0.2468801289796829\n",
      "Epoch [424/1000] , Step [30/40] , Loss: 0.2456495314836502\n",
      "Epoch [424/1000] , Step [40/40] , Loss: 0.2545526027679443\n",
      "Epoch [425/1000] , Step [10/40] , Loss: 0.2442418932914734\n",
      "Epoch [425/1000] , Step [20/40] , Loss: 0.2512857913970947\n",
      "Epoch [425/1000] , Step [30/40] , Loss: 0.2251486033201218\n",
      "Epoch [425/1000] , Step [40/40] , Loss: 0.2746286094188690\n",
      "Epoch [426/1000] , Step [10/40] , Loss: 0.2499771118164062\n",
      "Epoch [426/1000] , Step [20/40] , Loss: 0.2599258422851562\n",
      "Epoch [426/1000] , Step [30/40] , Loss: 0.2486368119716644\n",
      "Epoch [426/1000] , Step [40/40] , Loss: 0.2212055772542953\n",
      "Epoch [427/1000] , Step [10/40] , Loss: 0.2418474704027176\n",
      "Epoch [427/1000] , Step [20/40] , Loss: 0.2442573308944702\n",
      "Epoch [427/1000] , Step [30/40] , Loss: 0.2621190249919891\n",
      "Epoch [427/1000] , Step [40/40] , Loss: 0.2566533386707306\n",
      "Epoch [428/1000] , Step [10/40] , Loss: 0.2684201300144196\n",
      "Epoch [428/1000] , Step [20/40] , Loss: 0.2342444807291031\n",
      "Epoch [428/1000] , Step [30/40] , Loss: 0.2272789478302002\n",
      "Epoch [428/1000] , Step [40/40] , Loss: 0.2033325582742691\n",
      "Epoch [429/1000] , Step [10/40] , Loss: 0.2243017852306366\n",
      "Epoch [429/1000] , Step [20/40] , Loss: 0.2462116628885269\n",
      "Epoch [429/1000] , Step [30/40] , Loss: 0.2310304790735245\n",
      "Epoch [429/1000] , Step [40/40] , Loss: 0.2406315058469772\n",
      "Epoch [430/1000] , Step [10/40] , Loss: 0.2416385561227798\n",
      "Epoch [430/1000] , Step [20/40] , Loss: 0.2596925199031830\n",
      "Epoch [430/1000] , Step [30/40] , Loss: 0.2345538437366486\n",
      "Epoch [430/1000] , Step [40/40] , Loss: 0.2418181151151657\n",
      "Epoch [431/1000] , Step [10/40] , Loss: 0.2315281927585602\n",
      "Epoch [431/1000] , Step [20/40] , Loss: 0.2561480104923248\n",
      "Epoch [431/1000] , Step [30/40] , Loss: 0.2595569193363190\n",
      "Epoch [431/1000] , Step [40/40] , Loss: 0.2382362186908722\n",
      "Epoch [432/1000] , Step [10/40] , Loss: 0.2353145778179169\n",
      "Epoch [432/1000] , Step [20/40] , Loss: 0.2491039037704468\n",
      "Epoch [432/1000] , Step [30/40] , Loss: 0.2377207726240158\n",
      "Epoch [432/1000] , Step [40/40] , Loss: 0.2686792016029358\n",
      "Epoch [433/1000] , Step [10/40] , Loss: 0.2726733088493347\n",
      "Epoch [433/1000] , Step [20/40] , Loss: 0.2537391483783722\n",
      "Epoch [433/1000] , Step [30/40] , Loss: 0.2668839395046234\n",
      "Epoch [433/1000] , Step [40/40] , Loss: 0.2239461541175842\n",
      "Epoch [434/1000] , Step [10/40] , Loss: 0.2542562484741211\n",
      "Epoch [434/1000] , Step [20/40] , Loss: 0.2496128380298615\n",
      "Epoch [434/1000] , Step [30/40] , Loss: 0.2450093179941177\n",
      "Epoch [434/1000] , Step [40/40] , Loss: 0.2758601903915405\n",
      "Epoch [435/1000] , Step [10/40] , Loss: 0.2246736288070679\n",
      "Epoch [435/1000] , Step [20/40] , Loss: 0.2546557486057281\n",
      "Epoch [435/1000] , Step [30/40] , Loss: 0.2633056342601776\n",
      "Epoch [435/1000] , Step [40/40] , Loss: 0.2446558028459549\n",
      "Epoch [436/1000] , Step [10/40] , Loss: 0.2469757646322250\n",
      "Epoch [436/1000] , Step [20/40] , Loss: 0.2545693516731262\n",
      "Epoch [436/1000] , Step [30/40] , Loss: 0.2165738940238953\n",
      "Epoch [436/1000] , Step [40/40] , Loss: 0.2190387994050980\n",
      "Epoch [437/1000] , Step [10/40] , Loss: 0.2249883264303207\n",
      "Epoch [437/1000] , Step [20/40] , Loss: 0.2409624606370926\n",
      "Epoch [437/1000] , Step [30/40] , Loss: 0.2394450306892395\n",
      "Epoch [437/1000] , Step [40/40] , Loss: 0.2273431569337845\n",
      "Epoch [438/1000] , Step [10/40] , Loss: 0.2355550527572632\n",
      "Epoch [438/1000] , Step [20/40] , Loss: 0.2466257661581039\n",
      "Epoch [438/1000] , Step [30/40] , Loss: 0.2356188446283340\n",
      "Epoch [438/1000] , Step [40/40] , Loss: 0.2302366346120834\n",
      "Epoch [439/1000] , Step [10/40] , Loss: 0.2414138615131378\n",
      "Epoch [439/1000] , Step [20/40] , Loss: 0.2345950454473495\n",
      "Epoch [439/1000] , Step [30/40] , Loss: 0.2447112053632736\n",
      "Epoch [439/1000] , Step [40/40] , Loss: 0.2451637387275696\n",
      "Epoch [440/1000] , Step [10/40] , Loss: 0.2499817162752151\n",
      "Epoch [440/1000] , Step [20/40] , Loss: 0.2510881721973419\n",
      "Epoch [440/1000] , Step [30/40] , Loss: 0.2312785983085632\n",
      "Epoch [440/1000] , Step [40/40] , Loss: 0.2694172263145447\n",
      "Epoch [441/1000] , Step [10/40] , Loss: 0.2336771935224533\n",
      "Epoch [441/1000] , Step [20/40] , Loss: 0.2533495128154755\n",
      "Epoch [441/1000] , Step [30/40] , Loss: 0.2442539036273956\n",
      "Epoch [441/1000] , Step [40/40] , Loss: 0.2379798442125320\n",
      "Epoch [442/1000] , Step [10/40] , Loss: 0.2416951507329941\n",
      "Epoch [442/1000] , Step [20/40] , Loss: 0.2529035210609436\n",
      "Epoch [442/1000] , Step [30/40] , Loss: 0.2396689504384995\n",
      "Epoch [442/1000] , Step [40/40] , Loss: 0.2745119035243988\n",
      "Epoch [443/1000] , Step [10/40] , Loss: 0.2328121215105057\n",
      "Epoch [443/1000] , Step [20/40] , Loss: 0.2278783470392227\n",
      "Epoch [443/1000] , Step [30/40] , Loss: 0.2861777842044830\n",
      "Epoch [443/1000] , Step [40/40] , Loss: 0.2380163967609406\n",
      "Epoch [444/1000] , Step [10/40] , Loss: 0.2494496554136276\n",
      "Epoch [444/1000] , Step [20/40] , Loss: 0.2249291241168976\n",
      "Epoch [444/1000] , Step [30/40] , Loss: 0.2689482569694519\n",
      "Epoch [444/1000] , Step [40/40] , Loss: 0.2638074457645416\n",
      "Epoch [445/1000] , Step [10/40] , Loss: 0.2541612088680267\n",
      "Epoch [445/1000] , Step [20/40] , Loss: 0.2660017013549805\n",
      "Epoch [445/1000] , Step [30/40] , Loss: 0.2215391099452972\n",
      "Epoch [445/1000] , Step [40/40] , Loss: 0.2425119876861572\n",
      "Epoch [446/1000] , Step [10/40] , Loss: 0.2171636521816254\n",
      "Epoch [446/1000] , Step [20/40] , Loss: 0.2191176563501358\n",
      "Epoch [446/1000] , Step [30/40] , Loss: 0.2298172563314438\n",
      "Epoch [446/1000] , Step [40/40] , Loss: 0.2117673158645630\n",
      "Epoch [447/1000] , Step [10/40] , Loss: 0.2501742839813232\n",
      "Epoch [447/1000] , Step [20/40] , Loss: 0.2517742514610291\n",
      "Epoch [447/1000] , Step [30/40] , Loss: 0.2448281794786453\n",
      "Epoch [447/1000] , Step [40/40] , Loss: 0.2251648902893066\n",
      "Epoch [448/1000] , Step [10/40] , Loss: 0.2683196663856506\n",
      "Epoch [448/1000] , Step [20/40] , Loss: 0.2459815144538879\n",
      "Epoch [448/1000] , Step [30/40] , Loss: 0.2459352463483810\n",
      "Epoch [448/1000] , Step [40/40] , Loss: 0.2499437034130096\n",
      "Epoch [449/1000] , Step [10/40] , Loss: 0.2549967765808105\n",
      "Epoch [449/1000] , Step [20/40] , Loss: 0.2363844215869904\n",
      "Epoch [449/1000] , Step [30/40] , Loss: 0.2394938617944717\n",
      "Epoch [449/1000] , Step [40/40] , Loss: 0.2302547693252563\n",
      "Epoch [450/1000] , Step [10/40] , Loss: 0.2420963048934937\n",
      "Epoch [450/1000] , Step [20/40] , Loss: 0.2789582610130310\n",
      "Epoch [450/1000] , Step [30/40] , Loss: 0.2289399504661560\n",
      "Epoch [450/1000] , Step [40/40] , Loss: 0.2265434712171555\n",
      "Epoch [451/1000] , Step [10/40] , Loss: 0.2410904914140701\n",
      "Epoch [451/1000] , Step [20/40] , Loss: 0.2419823706150055\n",
      "Epoch [451/1000] , Step [30/40] , Loss: 0.2440451234579086\n",
      "Epoch [451/1000] , Step [40/40] , Loss: 0.2354360669851303\n",
      "Epoch [452/1000] , Step [10/40] , Loss: 0.2409860193729401\n",
      "Epoch [452/1000] , Step [20/40] , Loss: 0.2270534932613373\n",
      "Epoch [452/1000] , Step [30/40] , Loss: 0.2348063290119171\n",
      "Epoch [452/1000] , Step [40/40] , Loss: 0.2263025343418121\n",
      "Epoch [453/1000] , Step [10/40] , Loss: 0.2333997786045074\n",
      "Epoch [453/1000] , Step [20/40] , Loss: 0.2572490572929382\n",
      "Epoch [453/1000] , Step [30/40] , Loss: 0.2426179647445679\n",
      "Epoch [453/1000] , Step [40/40] , Loss: 0.2413124442100525\n",
      "Epoch [454/1000] , Step [10/40] , Loss: 0.2423640489578247\n",
      "Epoch [454/1000] , Step [20/40] , Loss: 0.2244073599576950\n",
      "Epoch [454/1000] , Step [30/40] , Loss: 0.2330360561609268\n",
      "Epoch [454/1000] , Step [40/40] , Loss: 0.2546611726284027\n",
      "Epoch [455/1000] , Step [10/40] , Loss: 0.2494540959596634\n",
      "Epoch [455/1000] , Step [20/40] , Loss: 0.2523596882820129\n",
      "Epoch [455/1000] , Step [30/40] , Loss: 0.2639926075935364\n",
      "Epoch [455/1000] , Step [40/40] , Loss: 0.2532815933227539\n",
      "Epoch [456/1000] , Step [10/40] , Loss: 0.2453234493732452\n",
      "Epoch [456/1000] , Step [20/40] , Loss: 0.2337984293699265\n",
      "Epoch [456/1000] , Step [30/40] , Loss: 0.2432399094104767\n",
      "Epoch [456/1000] , Step [40/40] , Loss: 0.2133276313543320\n",
      "Epoch [457/1000] , Step [10/40] , Loss: 0.2417256832122803\n",
      "Epoch [457/1000] , Step [20/40] , Loss: 0.2470380365848541\n",
      "Epoch [457/1000] , Step [30/40] , Loss: 0.2330330014228821\n",
      "Epoch [457/1000] , Step [40/40] , Loss: 0.2462026327848434\n",
      "Epoch [458/1000] , Step [10/40] , Loss: 0.2550486326217651\n",
      "Epoch [458/1000] , Step [20/40] , Loss: 0.2214284539222717\n",
      "Epoch [458/1000] , Step [30/40] , Loss: 0.2373406887054443\n",
      "Epoch [458/1000] , Step [40/40] , Loss: 0.2234063744544983\n",
      "Epoch [459/1000] , Step [10/40] , Loss: 0.2317450195550919\n",
      "Epoch [459/1000] , Step [20/40] , Loss: 0.2368835210800171\n",
      "Epoch [459/1000] , Step [30/40] , Loss: 0.2221289277076721\n",
      "Epoch [459/1000] , Step [40/40] , Loss: 0.2333064228296280\n",
      "Epoch [460/1000] , Step [10/40] , Loss: 0.2454197257757187\n",
      "Epoch [460/1000] , Step [20/40] , Loss: 0.2388008832931519\n",
      "Epoch [460/1000] , Step [30/40] , Loss: 0.2389822453260422\n",
      "Epoch [460/1000] , Step [40/40] , Loss: 0.2371045053005219\n",
      "Epoch [461/1000] , Step [10/40] , Loss: 0.2561449110507965\n",
      "Epoch [461/1000] , Step [20/40] , Loss: 0.2447703778743744\n",
      "Epoch [461/1000] , Step [30/40] , Loss: 0.2392403632402420\n",
      "Epoch [461/1000] , Step [40/40] , Loss: 0.2668384313583374\n",
      "Epoch [462/1000] , Step [10/40] , Loss: 0.2458568811416626\n",
      "Epoch [462/1000] , Step [20/40] , Loss: 0.2550080418586731\n",
      "Epoch [462/1000] , Step [30/40] , Loss: 0.2335339039564133\n",
      "Epoch [462/1000] , Step [40/40] , Loss: 0.2312069237232208\n",
      "Epoch [463/1000] , Step [10/40] , Loss: 0.2509542107582092\n",
      "Epoch [463/1000] , Step [20/40] , Loss: 0.2411150038242340\n",
      "Epoch [463/1000] , Step [30/40] , Loss: 0.2297629565000534\n",
      "Epoch [463/1000] , Step [40/40] , Loss: 0.2625779211521149\n",
      "Epoch [464/1000] , Step [10/40] , Loss: 0.2673184275627136\n",
      "Epoch [464/1000] , Step [20/40] , Loss: 0.2461841702461243\n",
      "Epoch [464/1000] , Step [30/40] , Loss: 0.2384893894195557\n",
      "Epoch [464/1000] , Step [40/40] , Loss: 0.2624548673629761\n",
      "Epoch [465/1000] , Step [10/40] , Loss: 0.2469548135995865\n",
      "Epoch [465/1000] , Step [20/40] , Loss: 0.2345167398452759\n",
      "Epoch [465/1000] , Step [30/40] , Loss: 0.2121257036924362\n",
      "Epoch [465/1000] , Step [40/40] , Loss: 0.2416490763425827\n",
      "Epoch [466/1000] , Step [10/40] , Loss: 0.2427845448255539\n",
      "Epoch [466/1000] , Step [20/40] , Loss: 0.2197755277156830\n",
      "Epoch [466/1000] , Step [30/40] , Loss: 0.2371352761983871\n",
      "Epoch [466/1000] , Step [40/40] , Loss: 0.2497554421424866\n",
      "Epoch [467/1000] , Step [10/40] , Loss: 0.2522358298301697\n",
      "Epoch [467/1000] , Step [20/40] , Loss: 0.2325815260410309\n",
      "Epoch [467/1000] , Step [30/40] , Loss: 0.2478598505258560\n",
      "Epoch [467/1000] , Step [40/40] , Loss: 0.2216275781393051\n",
      "Epoch [468/1000] , Step [10/40] , Loss: 0.2263951152563095\n",
      "Epoch [468/1000] , Step [20/40] , Loss: 0.2624317407608032\n",
      "Epoch [468/1000] , Step [30/40] , Loss: 0.2534163892269135\n",
      "Epoch [468/1000] , Step [40/40] , Loss: 0.2426569759845734\n",
      "Epoch [469/1000] , Step [10/40] , Loss: 0.2407727837562561\n",
      "Epoch [469/1000] , Step [20/40] , Loss: 0.2531760334968567\n",
      "Epoch [469/1000] , Step [30/40] , Loss: 0.2491426169872284\n",
      "Epoch [469/1000] , Step [40/40] , Loss: 0.2689118087291718\n",
      "Epoch [470/1000] , Step [10/40] , Loss: 0.2452691048383713\n",
      "Epoch [470/1000] , Step [20/40] , Loss: 0.2417495548725128\n",
      "Epoch [470/1000] , Step [30/40] , Loss: 0.2233717590570450\n",
      "Epoch [470/1000] , Step [40/40] , Loss: 0.2447178512811661\n",
      "Epoch [471/1000] , Step [10/40] , Loss: 0.2304589152336121\n",
      "Epoch [471/1000] , Step [20/40] , Loss: 0.2315888851881027\n",
      "Epoch [471/1000] , Step [30/40] , Loss: 0.2393240630626678\n",
      "Epoch [471/1000] , Step [40/40] , Loss: 0.2390942424535751\n",
      "Epoch [472/1000] , Step [10/40] , Loss: 0.2391155064105988\n",
      "Epoch [472/1000] , Step [20/40] , Loss: 0.2422783821821213\n",
      "Epoch [472/1000] , Step [30/40] , Loss: 0.2326982319355011\n",
      "Epoch [472/1000] , Step [40/40] , Loss: 0.2074419707059860\n",
      "Epoch [473/1000] , Step [10/40] , Loss: 0.2301966845989227\n",
      "Epoch [473/1000] , Step [20/40] , Loss: 0.2270451486110687\n",
      "Epoch [473/1000] , Step [30/40] , Loss: 0.2575234174728394\n",
      "Epoch [473/1000] , Step [40/40] , Loss: 0.2254055440425873\n",
      "Epoch [474/1000] , Step [10/40] , Loss: 0.2473537921905518\n",
      "Epoch [474/1000] , Step [20/40] , Loss: 0.2470747828483582\n",
      "Epoch [474/1000] , Step [30/40] , Loss: 0.2499006092548370\n",
      "Epoch [474/1000] , Step [40/40] , Loss: 0.2312145978212357\n",
      "Epoch [475/1000] , Step [10/40] , Loss: 0.2391275763511658\n",
      "Epoch [475/1000] , Step [20/40] , Loss: 0.2204938232898712\n",
      "Epoch [475/1000] , Step [30/40] , Loss: 0.2394158542156219\n",
      "Epoch [475/1000] , Step [40/40] , Loss: 0.2562713027000427\n",
      "Epoch [476/1000] , Step [10/40] , Loss: 0.2420364022254944\n",
      "Epoch [476/1000] , Step [20/40] , Loss: 0.2440033704042435\n",
      "Epoch [476/1000] , Step [30/40] , Loss: 0.2528162896633148\n",
      "Epoch [476/1000] , Step [40/40] , Loss: 0.2347221523523331\n",
      "Epoch [477/1000] , Step [10/40] , Loss: 0.2448370754718781\n",
      "Epoch [477/1000] , Step [20/40] , Loss: 0.2279220074415207\n",
      "Epoch [477/1000] , Step [30/40] , Loss: 0.2440062463283539\n",
      "Epoch [477/1000] , Step [40/40] , Loss: 0.2355522662401199\n",
      "Epoch [478/1000] , Step [10/40] , Loss: 0.2100276052951813\n",
      "Epoch [478/1000] , Step [20/40] , Loss: 0.2115910351276398\n",
      "Epoch [478/1000] , Step [30/40] , Loss: 0.2320971637964249\n",
      "Epoch [478/1000] , Step [40/40] , Loss: 0.2651855349540710\n",
      "Epoch [479/1000] , Step [10/40] , Loss: 0.2177489846944809\n",
      "Epoch [479/1000] , Step [20/40] , Loss: 0.2498570233583450\n",
      "Epoch [479/1000] , Step [30/40] , Loss: 0.2475889772176743\n",
      "Epoch [479/1000] , Step [40/40] , Loss: 0.2522355020046234\n",
      "Epoch [480/1000] , Step [10/40] , Loss: 0.2520074248313904\n",
      "Epoch [480/1000] , Step [20/40] , Loss: 0.2354282736778259\n",
      "Epoch [480/1000] , Step [30/40] , Loss: 0.2430104017257690\n",
      "Epoch [480/1000] , Step [40/40] , Loss: 0.2471502870321274\n",
      "Epoch [481/1000] , Step [10/40] , Loss: 0.2334146052598953\n",
      "Epoch [481/1000] , Step [20/40] , Loss: 0.2192083448171616\n",
      "Epoch [481/1000] , Step [30/40] , Loss: 0.2531183660030365\n",
      "Epoch [481/1000] , Step [40/40] , Loss: 0.2245909273624420\n",
      "Epoch [482/1000] , Step [10/40] , Loss: 0.2364602982997894\n",
      "Epoch [482/1000] , Step [20/40] , Loss: 0.2590193450450897\n",
      "Epoch [482/1000] , Step [30/40] , Loss: 0.2270559072494507\n",
      "Epoch [482/1000] , Step [40/40] , Loss: 0.2150177359580994\n",
      "Epoch [483/1000] , Step [10/40] , Loss: 0.2593878805637360\n",
      "Epoch [483/1000] , Step [20/40] , Loss: 0.2426927685737610\n",
      "Epoch [483/1000] , Step [30/40] , Loss: 0.2604804337024689\n",
      "Epoch [483/1000] , Step [40/40] , Loss: 0.2329891622066498\n",
      "Epoch [484/1000] , Step [10/40] , Loss: 0.2344867736101151\n",
      "Epoch [484/1000] , Step [20/40] , Loss: 0.2269831746816635\n",
      "Epoch [484/1000] , Step [30/40] , Loss: 0.2407330572605133\n",
      "Epoch [484/1000] , Step [40/40] , Loss: 0.2363044321537018\n",
      "Epoch [485/1000] , Step [10/40] , Loss: 0.2345040440559387\n",
      "Epoch [485/1000] , Step [20/40] , Loss: 0.2254099696874619\n",
      "Epoch [485/1000] , Step [30/40] , Loss: 0.2302442640066147\n",
      "Epoch [485/1000] , Step [40/40] , Loss: 0.2424483895301819\n",
      "Epoch [486/1000] , Step [10/40] , Loss: 0.2332446873188019\n",
      "Epoch [486/1000] , Step [20/40] , Loss: 0.2418507188558578\n",
      "Epoch [486/1000] , Step [30/40] , Loss: 0.2335497438907623\n",
      "Epoch [486/1000] , Step [40/40] , Loss: 0.2298533469438553\n",
      "Epoch [487/1000] , Step [10/40] , Loss: 0.2301300615072250\n",
      "Epoch [487/1000] , Step [20/40] , Loss: 0.2531155347824097\n",
      "Epoch [487/1000] , Step [30/40] , Loss: 0.2268957197666168\n",
      "Epoch [487/1000] , Step [40/40] , Loss: 0.2276545464992523\n",
      "Epoch [488/1000] , Step [10/40] , Loss: 0.2146918177604675\n",
      "Epoch [488/1000] , Step [20/40] , Loss: 0.2347959727048874\n",
      "Epoch [488/1000] , Step [30/40] , Loss: 0.2700355648994446\n",
      "Epoch [488/1000] , Step [40/40] , Loss: 0.2453020811080933\n",
      "Epoch [489/1000] , Step [10/40] , Loss: 0.2242171764373779\n",
      "Epoch [489/1000] , Step [20/40] , Loss: 0.2349137812852859\n",
      "Epoch [489/1000] , Step [30/40] , Loss: 0.2498563677072525\n",
      "Epoch [489/1000] , Step [40/40] , Loss: 0.2627125382423401\n",
      "Epoch [490/1000] , Step [10/40] , Loss: 0.2380871176719666\n",
      "Epoch [490/1000] , Step [20/40] , Loss: 0.2240031808614731\n",
      "Epoch [490/1000] , Step [30/40] , Loss: 0.2192432582378387\n",
      "Epoch [490/1000] , Step [40/40] , Loss: 0.2318118214607239\n",
      "Epoch [491/1000] , Step [10/40] , Loss: 0.2201562970876694\n",
      "Epoch [491/1000] , Step [20/40] , Loss: 0.2505868673324585\n",
      "Epoch [491/1000] , Step [30/40] , Loss: 0.2239427566528320\n",
      "Epoch [491/1000] , Step [40/40] , Loss: 0.2346789985895157\n",
      "Epoch [492/1000] , Step [10/40] , Loss: 0.2398448288440704\n",
      "Epoch [492/1000] , Step [20/40] , Loss: 0.2415702342987061\n",
      "Epoch [492/1000] , Step [30/40] , Loss: 0.2429177910089493\n",
      "Epoch [492/1000] , Step [40/40] , Loss: 0.2400604188442230\n",
      "Epoch [493/1000] , Step [10/40] , Loss: 0.2379155009984970\n",
      "Epoch [493/1000] , Step [20/40] , Loss: 0.2472764402627945\n",
      "Epoch [493/1000] , Step [30/40] , Loss: 0.2507438361644745\n",
      "Epoch [493/1000] , Step [40/40] , Loss: 0.2249077260494232\n",
      "Epoch [494/1000] , Step [10/40] , Loss: 0.2262790054082870\n",
      "Epoch [494/1000] , Step [20/40] , Loss: 0.2342079877853394\n",
      "Epoch [494/1000] , Step [30/40] , Loss: 0.2609375119209290\n",
      "Epoch [494/1000] , Step [40/40] , Loss: 0.2507050931453705\n",
      "Epoch [495/1000] , Step [10/40] , Loss: 0.2593551278114319\n",
      "Epoch [495/1000] , Step [20/40] , Loss: 0.2569651603698730\n",
      "Epoch [495/1000] , Step [30/40] , Loss: 0.2195706814527512\n",
      "Epoch [495/1000] , Step [40/40] , Loss: 0.2315734028816223\n",
      "Epoch [496/1000] , Step [10/40] , Loss: 0.2542178034782410\n",
      "Epoch [496/1000] , Step [20/40] , Loss: 0.2185633778572083\n",
      "Epoch [496/1000] , Step [30/40] , Loss: 0.2323620319366455\n",
      "Epoch [496/1000] , Step [40/40] , Loss: 0.2563774585723877\n",
      "Epoch [497/1000] , Step [10/40] , Loss: 0.2357863485813141\n",
      "Epoch [497/1000] , Step [20/40] , Loss: 0.2509125769138336\n",
      "Epoch [497/1000] , Step [30/40] , Loss: 0.2253109663724899\n",
      "Epoch [497/1000] , Step [40/40] , Loss: 0.1957574188709259\n",
      "Epoch [498/1000] , Step [10/40] , Loss: 0.2511996328830719\n",
      "Epoch [498/1000] , Step [20/40] , Loss: 0.2240375429391861\n",
      "Epoch [498/1000] , Step [30/40] , Loss: 0.2319061905145645\n",
      "Epoch [498/1000] , Step [40/40] , Loss: 0.2582691609859467\n",
      "Epoch [499/1000] , Step [10/40] , Loss: 0.2426031678915024\n",
      "Epoch [499/1000] , Step [20/40] , Loss: 0.2472321540117264\n",
      "Epoch [499/1000] , Step [30/40] , Loss: 0.2391419708728790\n",
      "Epoch [499/1000] , Step [40/40] , Loss: 0.2399600297212601\n",
      "Epoch [500/1000] , Step [10/40] , Loss: 0.2432515621185303\n",
      "Epoch [500/1000] , Step [20/40] , Loss: 0.2418213784694672\n",
      "Epoch [500/1000] , Step [30/40] , Loss: 0.2424282133579254\n",
      "Epoch [500/1000] , Step [40/40] , Loss: 0.2318874001502991\n",
      "Epoch [501/1000] , Step [10/40] , Loss: 0.2383497655391693\n",
      "Epoch [501/1000] , Step [20/40] , Loss: 0.2624514997005463\n",
      "Epoch [501/1000] , Step [30/40] , Loss: 0.2459111511707306\n",
      "Epoch [501/1000] , Step [40/40] , Loss: 0.2694793939590454\n",
      "Epoch [502/1000] , Step [10/40] , Loss: 0.2268463075160980\n",
      "Epoch [502/1000] , Step [20/40] , Loss: 0.2558299899101257\n",
      "Epoch [502/1000] , Step [30/40] , Loss: 0.2309855818748474\n",
      "Epoch [502/1000] , Step [40/40] , Loss: 0.2378413528203964\n",
      "Epoch [503/1000] , Step [10/40] , Loss: 0.2241192758083344\n",
      "Epoch [503/1000] , Step [20/40] , Loss: 0.2405254244804382\n",
      "Epoch [503/1000] , Step [30/40] , Loss: 0.2419670224189758\n",
      "Epoch [503/1000] , Step [40/40] , Loss: 0.2305096387863159\n",
      "Epoch [504/1000] , Step [10/40] , Loss: 0.2430497556924820\n",
      "Epoch [504/1000] , Step [20/40] , Loss: 0.2451272606849670\n",
      "Epoch [504/1000] , Step [30/40] , Loss: 0.2234141081571579\n",
      "Epoch [504/1000] , Step [40/40] , Loss: 0.2408785372972488\n",
      "Epoch [505/1000] , Step [10/40] , Loss: 0.2232942581176758\n",
      "Epoch [505/1000] , Step [20/40] , Loss: 0.2444710433483124\n",
      "Epoch [505/1000] , Step [30/40] , Loss: 0.2415872365236282\n",
      "Epoch [505/1000] , Step [40/40] , Loss: 0.2559855878353119\n",
      "Epoch [506/1000] , Step [10/40] , Loss: 0.2673406898975372\n",
      "Epoch [506/1000] , Step [20/40] , Loss: 0.2437325567007065\n",
      "Epoch [506/1000] , Step [30/40] , Loss: 0.2506652772426605\n",
      "Epoch [506/1000] , Step [40/40] , Loss: 0.2660385072231293\n",
      "Epoch [507/1000] , Step [10/40] , Loss: 0.2238998413085938\n",
      "Epoch [507/1000] , Step [20/40] , Loss: 0.2288801670074463\n",
      "Epoch [507/1000] , Step [30/40] , Loss: 0.2451048642396927\n",
      "Epoch [507/1000] , Step [40/40] , Loss: 0.2496123611927032\n",
      "Epoch [508/1000] , Step [10/40] , Loss: 0.2234774529933929\n",
      "Epoch [508/1000] , Step [20/40] , Loss: 0.2491229027509689\n",
      "Epoch [508/1000] , Step [30/40] , Loss: 0.2341897189617157\n",
      "Epoch [508/1000] , Step [40/40] , Loss: 0.2568639516830444\n",
      "Epoch [509/1000] , Step [10/40] , Loss: 0.2599093616008759\n",
      "Epoch [509/1000] , Step [20/40] , Loss: 0.2607344686985016\n",
      "Epoch [509/1000] , Step [30/40] , Loss: 0.2238475978374481\n",
      "Epoch [509/1000] , Step [40/40] , Loss: 0.2345062941312790\n",
      "Epoch [510/1000] , Step [10/40] , Loss: 0.2380762100219727\n",
      "Epoch [510/1000] , Step [20/40] , Loss: 0.2523268461227417\n",
      "Epoch [510/1000] , Step [30/40] , Loss: 0.2432459145784378\n",
      "Epoch [510/1000] , Step [40/40] , Loss: 0.2656952142715454\n",
      "Epoch [511/1000] , Step [10/40] , Loss: 0.2186734229326248\n",
      "Epoch [511/1000] , Step [20/40] , Loss: 0.2512055337429047\n",
      "Epoch [511/1000] , Step [30/40] , Loss: 0.2383812069892883\n",
      "Epoch [511/1000] , Step [40/40] , Loss: 0.2398437261581421\n",
      "Epoch [512/1000] , Step [10/40] , Loss: 0.2601680755615234\n",
      "Epoch [512/1000] , Step [20/40] , Loss: 0.2516141235828400\n",
      "Epoch [512/1000] , Step [30/40] , Loss: 0.2395168989896774\n",
      "Epoch [512/1000] , Step [40/40] , Loss: 0.2485163211822510\n",
      "Epoch [513/1000] , Step [10/40] , Loss: 0.2462000250816345\n",
      "Epoch [513/1000] , Step [20/40] , Loss: 0.2445000708103180\n",
      "Epoch [513/1000] , Step [30/40] , Loss: 0.2191829979419708\n",
      "Epoch [513/1000] , Step [40/40] , Loss: 0.2534365653991699\n",
      "Epoch [514/1000] , Step [10/40] , Loss: 0.2281867563724518\n",
      "Epoch [514/1000] , Step [20/40] , Loss: 0.2435581386089325\n",
      "Epoch [514/1000] , Step [30/40] , Loss: 0.2226110249757767\n",
      "Epoch [514/1000] , Step [40/40] , Loss: 0.2400306165218353\n",
      "Epoch [515/1000] , Step [10/40] , Loss: 0.2253499478101730\n",
      "Epoch [515/1000] , Step [20/40] , Loss: 0.2494578957557678\n",
      "Epoch [515/1000] , Step [30/40] , Loss: 0.2334522753953934\n",
      "Epoch [515/1000] , Step [40/40] , Loss: 0.2556945681571960\n",
      "Epoch [516/1000] , Step [10/40] , Loss: 0.2449693977832794\n",
      "Epoch [516/1000] , Step [20/40] , Loss: 0.2282409220933914\n",
      "Epoch [516/1000] , Step [30/40] , Loss: 0.2482391148805618\n",
      "Epoch [516/1000] , Step [40/40] , Loss: 0.2388732284307480\n",
      "Epoch [517/1000] , Step [10/40] , Loss: 0.2302880287170410\n",
      "Epoch [517/1000] , Step [20/40] , Loss: 0.2281210124492645\n",
      "Epoch [517/1000] , Step [30/40] , Loss: 0.2496733665466309\n",
      "Epoch [517/1000] , Step [40/40] , Loss: 0.2605198919773102\n",
      "Epoch [518/1000] , Step [10/40] , Loss: 0.2350067645311356\n",
      "Epoch [518/1000] , Step [20/40] , Loss: 0.2256568819284439\n",
      "Epoch [518/1000] , Step [30/40] , Loss: 0.2426777929067612\n",
      "Epoch [518/1000] , Step [40/40] , Loss: 0.2410523742437363\n",
      "Epoch [519/1000] , Step [10/40] , Loss: 0.2299849241971970\n",
      "Epoch [519/1000] , Step [20/40] , Loss: 0.2476004213094711\n",
      "Epoch [519/1000] , Step [30/40] , Loss: 0.2281435430049896\n",
      "Epoch [519/1000] , Step [40/40] , Loss: 0.2639734745025635\n",
      "Epoch [520/1000] , Step [10/40] , Loss: 0.2195608168840408\n",
      "Epoch [520/1000] , Step [20/40] , Loss: 0.2332895696163177\n",
      "Epoch [520/1000] , Step [30/40] , Loss: 0.2381177991628647\n",
      "Epoch [520/1000] , Step [40/40] , Loss: 0.2529834806919098\n",
      "Epoch [521/1000] , Step [10/40] , Loss: 0.2409964203834534\n",
      "Epoch [521/1000] , Step [20/40] , Loss: 0.2252682596445084\n",
      "Epoch [521/1000] , Step [30/40] , Loss: 0.2496442943811417\n",
      "Epoch [521/1000] , Step [40/40] , Loss: 0.2394442856311798\n",
      "Epoch [522/1000] , Step [10/40] , Loss: 0.2451400160789490\n",
      "Epoch [522/1000] , Step [20/40] , Loss: 0.2110907584428787\n",
      "Epoch [522/1000] , Step [30/40] , Loss: 0.2510641217231750\n",
      "Epoch [522/1000] , Step [40/40] , Loss: 0.2250503152608871\n",
      "Epoch [523/1000] , Step [10/40] , Loss: 0.2333313524723053\n",
      "Epoch [523/1000] , Step [20/40] , Loss: 0.2323111295700073\n",
      "Epoch [523/1000] , Step [30/40] , Loss: 0.2449631392955780\n",
      "Epoch [523/1000] , Step [40/40] , Loss: 0.2475541085004807\n",
      "Epoch [524/1000] , Step [10/40] , Loss: 0.2335558086633682\n",
      "Epoch [524/1000] , Step [20/40] , Loss: 0.2398525625467300\n",
      "Epoch [524/1000] , Step [30/40] , Loss: 0.2447561770677567\n",
      "Epoch [524/1000] , Step [40/40] , Loss: 0.2386526018381119\n",
      "Epoch [525/1000] , Step [10/40] , Loss: 0.2367648184299469\n",
      "Epoch [525/1000] , Step [20/40] , Loss: 0.2461625635623932\n",
      "Epoch [525/1000] , Step [30/40] , Loss: 0.2468900531530380\n",
      "Epoch [525/1000] , Step [40/40] , Loss: 0.2442476749420166\n",
      "Epoch [526/1000] , Step [10/40] , Loss: 0.2469359338283539\n",
      "Epoch [526/1000] , Step [20/40] , Loss: 0.2364114820957184\n",
      "Epoch [526/1000] , Step [30/40] , Loss: 0.2466804087162018\n",
      "Epoch [526/1000] , Step [40/40] , Loss: 0.2439845055341721\n",
      "Epoch [527/1000] , Step [10/40] , Loss: 0.2296760976314545\n",
      "Epoch [527/1000] , Step [20/40] , Loss: 0.2528560459613800\n",
      "Epoch [527/1000] , Step [30/40] , Loss: 0.2566953897476196\n",
      "Epoch [527/1000] , Step [40/40] , Loss: 0.2699221372604370\n",
      "Epoch [528/1000] , Step [10/40] , Loss: 0.2215312123298645\n",
      "Epoch [528/1000] , Step [20/40] , Loss: 0.2265669703483582\n",
      "Epoch [528/1000] , Step [30/40] , Loss: 0.2519382238388062\n",
      "Epoch [528/1000] , Step [40/40] , Loss: 0.2224970757961273\n",
      "Epoch [529/1000] , Step [10/40] , Loss: 0.2287577092647552\n",
      "Epoch [529/1000] , Step [20/40] , Loss: 0.2238451242446899\n",
      "Epoch [529/1000] , Step [30/40] , Loss: 0.2510864138603210\n",
      "Epoch [529/1000] , Step [40/40] , Loss: 0.2232914417982101\n",
      "Epoch [530/1000] , Step [10/40] , Loss: 0.2605468928813934\n",
      "Epoch [530/1000] , Step [20/40] , Loss: 0.2208784669637680\n",
      "Epoch [530/1000] , Step [30/40] , Loss: 0.2297936826944351\n",
      "Epoch [530/1000] , Step [40/40] , Loss: 0.2368003576993942\n",
      "Epoch [531/1000] , Step [10/40] , Loss: 0.2568604350090027\n",
      "Epoch [531/1000] , Step [20/40] , Loss: 0.2480064630508423\n",
      "Epoch [531/1000] , Step [30/40] , Loss: 0.2397012412548065\n",
      "Epoch [531/1000] , Step [40/40] , Loss: 0.2499570697546005\n",
      "Epoch [532/1000] , Step [10/40] , Loss: 0.2231017053127289\n",
      "Epoch [532/1000] , Step [20/40] , Loss: 0.2182132899761200\n",
      "Epoch [532/1000] , Step [30/40] , Loss: 0.2309353202581406\n",
      "Epoch [532/1000] , Step [40/40] , Loss: 0.2430118620395660\n",
      "Epoch [533/1000] , Step [10/40] , Loss: 0.2356700599193573\n",
      "Epoch [533/1000] , Step [20/40] , Loss: 0.2388572394847870\n",
      "Epoch [533/1000] , Step [30/40] , Loss: 0.2394141405820847\n",
      "Epoch [533/1000] , Step [40/40] , Loss: 0.2299347817897797\n",
      "Epoch [534/1000] , Step [10/40] , Loss: 0.2328365445137024\n",
      "Epoch [534/1000] , Step [20/40] , Loss: 0.2116554677486420\n",
      "Epoch [534/1000] , Step [30/40] , Loss: 0.2268740981817245\n",
      "Epoch [534/1000] , Step [40/40] , Loss: 0.2380541115999222\n",
      "Epoch [535/1000] , Step [10/40] , Loss: 0.2522809207439423\n",
      "Epoch [535/1000] , Step [20/40] , Loss: 0.2385004460811615\n",
      "Epoch [535/1000] , Step [30/40] , Loss: 0.2385504692792892\n",
      "Epoch [535/1000] , Step [40/40] , Loss: 0.2481962144374847\n",
      "Epoch [536/1000] , Step [10/40] , Loss: 0.2358391880989075\n",
      "Epoch [536/1000] , Step [20/40] , Loss: 0.2204791754484177\n",
      "Epoch [536/1000] , Step [30/40] , Loss: 0.2369377762079239\n",
      "Epoch [536/1000] , Step [40/40] , Loss: 0.2635252177715302\n",
      "Epoch [537/1000] , Step [10/40] , Loss: 0.2334324717521667\n",
      "Epoch [537/1000] , Step [20/40] , Loss: 0.2204185277223587\n",
      "Epoch [537/1000] , Step [30/40] , Loss: 0.2423331886529922\n",
      "Epoch [537/1000] , Step [40/40] , Loss: 0.2431822270154953\n",
      "Epoch [538/1000] , Step [10/40] , Loss: 0.2376281917095184\n",
      "Epoch [538/1000] , Step [20/40] , Loss: 0.2422287166118622\n",
      "Epoch [538/1000] , Step [30/40] , Loss: 0.2453417181968689\n",
      "Epoch [538/1000] , Step [40/40] , Loss: 0.2441839128732681\n",
      "Epoch [539/1000] , Step [10/40] , Loss: 0.2409512549638748\n",
      "Epoch [539/1000] , Step [20/40] , Loss: 0.2491453886032104\n",
      "Epoch [539/1000] , Step [30/40] , Loss: 0.2200733870267868\n",
      "Epoch [539/1000] , Step [40/40] , Loss: 0.2474431097507477\n",
      "Epoch [540/1000] , Step [10/40] , Loss: 0.2223127633333206\n",
      "Epoch [540/1000] , Step [20/40] , Loss: 0.2153463959693909\n",
      "Epoch [540/1000] , Step [30/40] , Loss: 0.2299976646900177\n",
      "Epoch [540/1000] , Step [40/40] , Loss: 0.2264060676097870\n",
      "Epoch [541/1000] , Step [10/40] , Loss: 0.2505757212638855\n",
      "Epoch [541/1000] , Step [20/40] , Loss: 0.2403837740421295\n",
      "Epoch [541/1000] , Step [30/40] , Loss: 0.2250845134258270\n",
      "Epoch [541/1000] , Step [40/40] , Loss: 0.2416443824768066\n",
      "Epoch [542/1000] , Step [10/40] , Loss: 0.2292257994413376\n",
      "Epoch [542/1000] , Step [20/40] , Loss: 0.2447181195020676\n",
      "Epoch [542/1000] , Step [30/40] , Loss: 0.2384516894817352\n",
      "Epoch [542/1000] , Step [40/40] , Loss: 0.2209876626729965\n",
      "Epoch [543/1000] , Step [10/40] , Loss: 0.2347770035266876\n",
      "Epoch [543/1000] , Step [20/40] , Loss: 0.2272523045539856\n",
      "Epoch [543/1000] , Step [30/40] , Loss: 0.2433523684740067\n",
      "Epoch [543/1000] , Step [40/40] , Loss: 0.2231301069259644\n",
      "Epoch [544/1000] , Step [10/40] , Loss: 0.2243490666151047\n",
      "Epoch [544/1000] , Step [20/40] , Loss: 0.2147867977619171\n",
      "Epoch [544/1000] , Step [30/40] , Loss: 0.2345047593116760\n",
      "Epoch [544/1000] , Step [40/40] , Loss: 0.2391281276941299\n",
      "Epoch [545/1000] , Step [10/40] , Loss: 0.2315772920846939\n",
      "Epoch [545/1000] , Step [20/40] , Loss: 0.2451634854078293\n",
      "Epoch [545/1000] , Step [30/40] , Loss: 0.2217312753200531\n",
      "Epoch [545/1000] , Step [40/40] , Loss: 0.2651227414608002\n",
      "Epoch [546/1000] , Step [10/40] , Loss: 0.2429443895816803\n",
      "Epoch [546/1000] , Step [20/40] , Loss: 0.2318062484264374\n",
      "Epoch [546/1000] , Step [30/40] , Loss: 0.2255170643329620\n",
      "Epoch [546/1000] , Step [40/40] , Loss: 0.2407118529081345\n",
      "Epoch [547/1000] , Step [10/40] , Loss: 0.2278232574462891\n",
      "Epoch [547/1000] , Step [20/40] , Loss: 0.2318153083324432\n",
      "Epoch [547/1000] , Step [30/40] , Loss: 0.2250061631202698\n",
      "Epoch [547/1000] , Step [40/40] , Loss: 0.2185767143964767\n",
      "Epoch [548/1000] , Step [10/40] , Loss: 0.2337403744459152\n",
      "Epoch [548/1000] , Step [20/40] , Loss: 0.2358093261718750\n",
      "Epoch [548/1000] , Step [30/40] , Loss: 0.2442952245473862\n",
      "Epoch [548/1000] , Step [40/40] , Loss: 0.2275082170963287\n",
      "Epoch [549/1000] , Step [10/40] , Loss: 0.2456162869930267\n",
      "Epoch [549/1000] , Step [20/40] , Loss: 0.2464595884084702\n",
      "Epoch [549/1000] , Step [30/40] , Loss: 0.2302938848733902\n",
      "Epoch [549/1000] , Step [40/40] , Loss: 0.2327732741832733\n",
      "Epoch [550/1000] , Step [10/40] , Loss: 0.2239966690540314\n",
      "Epoch [550/1000] , Step [20/40] , Loss: 0.2251103669404984\n",
      "Epoch [550/1000] , Step [30/40] , Loss: 0.2173105329275131\n",
      "Epoch [550/1000] , Step [40/40] , Loss: 0.2334771007299423\n",
      "Epoch [551/1000] , Step [10/40] , Loss: 0.2337393462657928\n",
      "Epoch [551/1000] , Step [20/40] , Loss: 0.2271285653114319\n",
      "Epoch [551/1000] , Step [30/40] , Loss: 0.2446789294481277\n",
      "Epoch [551/1000] , Step [40/40] , Loss: 0.2490949779748917\n",
      "Epoch [552/1000] , Step [10/40] , Loss: 0.2248371690511703\n",
      "Epoch [552/1000] , Step [20/40] , Loss: 0.2244019508361816\n",
      "Epoch [552/1000] , Step [30/40] , Loss: 0.2384249567985535\n",
      "Epoch [552/1000] , Step [40/40] , Loss: 0.2341589182615280\n",
      "Epoch [553/1000] , Step [10/40] , Loss: 0.2279561758041382\n",
      "Epoch [553/1000] , Step [20/40] , Loss: 0.2231066673994064\n",
      "Epoch [553/1000] , Step [30/40] , Loss: 0.2594788372516632\n",
      "Epoch [553/1000] , Step [40/40] , Loss: 0.2148406952619553\n",
      "Epoch [554/1000] , Step [10/40] , Loss: 0.2199242115020752\n",
      "Epoch [554/1000] , Step [20/40] , Loss: 0.2386867702007294\n",
      "Epoch [554/1000] , Step [30/40] , Loss: 0.2349706441164017\n",
      "Epoch [554/1000] , Step [40/40] , Loss: 0.2365313619375229\n",
      "Epoch [555/1000] , Step [10/40] , Loss: 0.2458822578191757\n",
      "Epoch [555/1000] , Step [20/40] , Loss: 0.2283358275890350\n",
      "Epoch [555/1000] , Step [30/40] , Loss: 0.2414213269948959\n",
      "Epoch [555/1000] , Step [40/40] , Loss: 0.2138265073299408\n",
      "Epoch [556/1000] , Step [10/40] , Loss: 0.2409244924783707\n",
      "Epoch [556/1000] , Step [20/40] , Loss: 0.2368937432765961\n",
      "Epoch [556/1000] , Step [30/40] , Loss: 0.2304381132125854\n",
      "Epoch [556/1000] , Step [40/40] , Loss: 0.2194121479988098\n",
      "Epoch [557/1000] , Step [10/40] , Loss: 0.2212181240320206\n",
      "Epoch [557/1000] , Step [20/40] , Loss: 0.2330503612756729\n",
      "Epoch [557/1000] , Step [30/40] , Loss: 0.2281405478715897\n",
      "Epoch [557/1000] , Step [40/40] , Loss: 0.2271197289228439\n",
      "Epoch [558/1000] , Step [10/40] , Loss: 0.2440667599439621\n",
      "Epoch [558/1000] , Step [20/40] , Loss: 0.2281583696603775\n",
      "Epoch [558/1000] , Step [30/40] , Loss: 0.2182709425687790\n",
      "Epoch [558/1000] , Step [40/40] , Loss: 0.2280148863792419\n",
      "Epoch [559/1000] , Step [10/40] , Loss: 0.2323231399059296\n",
      "Epoch [559/1000] , Step [20/40] , Loss: 0.2388433068990707\n",
      "Epoch [559/1000] , Step [30/40] , Loss: 0.2358812391757965\n",
      "Epoch [559/1000] , Step [40/40] , Loss: 0.2104424089193344\n",
      "Epoch [560/1000] , Step [10/40] , Loss: 0.2352576255798340\n",
      "Epoch [560/1000] , Step [20/40] , Loss: 0.2326888889074326\n",
      "Epoch [560/1000] , Step [30/40] , Loss: 0.2372847199440002\n",
      "Epoch [560/1000] , Step [40/40] , Loss: 0.2351931035518646\n",
      "Epoch [561/1000] , Step [10/40] , Loss: 0.2636606395244598\n",
      "Epoch [561/1000] , Step [20/40] , Loss: 0.2283612936735153\n",
      "Epoch [561/1000] , Step [30/40] , Loss: 0.2286862879991531\n",
      "Epoch [561/1000] , Step [40/40] , Loss: 0.2250663340091705\n",
      "Epoch [562/1000] , Step [10/40] , Loss: 0.2321113497018814\n",
      "Epoch [562/1000] , Step [20/40] , Loss: 0.2314848750829697\n",
      "Epoch [562/1000] , Step [30/40] , Loss: 0.2646882832050323\n",
      "Epoch [562/1000] , Step [40/40] , Loss: 0.2131577283143997\n",
      "Epoch [563/1000] , Step [10/40] , Loss: 0.2475984841585159\n",
      "Epoch [563/1000] , Step [20/40] , Loss: 0.2206556499004364\n",
      "Epoch [563/1000] , Step [30/40] , Loss: 0.2320990115404129\n",
      "Epoch [563/1000] , Step [40/40] , Loss: 0.2192841172218323\n",
      "Epoch [564/1000] , Step [10/40] , Loss: 0.2401608973741531\n",
      "Epoch [564/1000] , Step [20/40] , Loss: 0.2265170514583588\n",
      "Epoch [564/1000] , Step [30/40] , Loss: 0.2383547425270081\n",
      "Epoch [564/1000] , Step [40/40] , Loss: 0.2244901806116104\n",
      "Epoch [565/1000] , Step [10/40] , Loss: 0.2331187129020691\n",
      "Epoch [565/1000] , Step [20/40] , Loss: 0.2440642416477203\n",
      "Epoch [565/1000] , Step [30/40] , Loss: 0.2166229933500290\n",
      "Epoch [565/1000] , Step [40/40] , Loss: 0.2168602049350739\n",
      "Epoch [566/1000] , Step [10/40] , Loss: 0.2398558259010315\n",
      "Epoch [566/1000] , Step [20/40] , Loss: 0.2306441515684128\n",
      "Epoch [566/1000] , Step [30/40] , Loss: 0.2358864247798920\n",
      "Epoch [566/1000] , Step [40/40] , Loss: 0.2528754174709320\n",
      "Epoch [567/1000] , Step [10/40] , Loss: 0.2332917302846909\n",
      "Epoch [567/1000] , Step [20/40] , Loss: 0.2485805451869965\n",
      "Epoch [567/1000] , Step [30/40] , Loss: 0.2501026690006256\n",
      "Epoch [567/1000] , Step [40/40] , Loss: 0.2275599688291550\n",
      "Epoch [568/1000] , Step [10/40] , Loss: 0.2552934587001801\n",
      "Epoch [568/1000] , Step [20/40] , Loss: 0.2356355488300323\n",
      "Epoch [568/1000] , Step [30/40] , Loss: 0.2260144352912903\n",
      "Epoch [568/1000] , Step [40/40] , Loss: 0.2342459857463837\n",
      "Epoch [569/1000] , Step [10/40] , Loss: 0.2307484447956085\n",
      "Epoch [569/1000] , Step [20/40] , Loss: 0.2336376607418060\n",
      "Epoch [569/1000] , Step [30/40] , Loss: 0.2421018928289413\n",
      "Epoch [569/1000] , Step [40/40] , Loss: 0.2323659807443619\n",
      "Epoch [570/1000] , Step [10/40] , Loss: 0.2283489853143692\n",
      "Epoch [570/1000] , Step [20/40] , Loss: 0.2243111282587051\n",
      "Epoch [570/1000] , Step [30/40] , Loss: 0.2519520521163940\n",
      "Epoch [570/1000] , Step [40/40] , Loss: 0.2501020729541779\n",
      "Epoch [571/1000] , Step [10/40] , Loss: 0.2193759381771088\n",
      "Epoch [571/1000] , Step [20/40] , Loss: 0.2431231439113617\n",
      "Epoch [571/1000] , Step [30/40] , Loss: 0.2355444580316544\n",
      "Epoch [571/1000] , Step [40/40] , Loss: 0.2531798183917999\n",
      "Epoch [572/1000] , Step [10/40] , Loss: 0.2464678734540939\n",
      "Epoch [572/1000] , Step [20/40] , Loss: 0.2345707416534424\n",
      "Epoch [572/1000] , Step [30/40] , Loss: 0.2236954271793365\n",
      "Epoch [572/1000] , Step [40/40] , Loss: 0.2115986347198486\n",
      "Epoch [573/1000] , Step [10/40] , Loss: 0.2388511598110199\n",
      "Epoch [573/1000] , Step [20/40] , Loss: 0.2461590170860291\n",
      "Epoch [573/1000] , Step [30/40] , Loss: 0.2546283602714539\n",
      "Epoch [573/1000] , Step [40/40] , Loss: 0.2061773687601089\n",
      "Epoch [574/1000] , Step [10/40] , Loss: 0.2394277602434158\n",
      "Epoch [574/1000] , Step [20/40] , Loss: 0.2394687384366989\n",
      "Epoch [574/1000] , Step [30/40] , Loss: 0.2238432615995407\n",
      "Epoch [574/1000] , Step [40/40] , Loss: 0.2330638468265533\n",
      "Epoch [575/1000] , Step [10/40] , Loss: 0.2424678057432175\n",
      "Epoch [575/1000] , Step [20/40] , Loss: 0.2335374206304550\n",
      "Epoch [575/1000] , Step [30/40] , Loss: 0.2290166318416595\n",
      "Epoch [575/1000] , Step [40/40] , Loss: 0.2375240772962570\n",
      "Epoch [576/1000] , Step [10/40] , Loss: 0.2472172826528549\n",
      "Epoch [576/1000] , Step [20/40] , Loss: 0.2216715216636658\n",
      "Epoch [576/1000] , Step [30/40] , Loss: 0.2361147254705429\n",
      "Epoch [576/1000] , Step [40/40] , Loss: 0.2368310987949371\n",
      "Epoch [577/1000] , Step [10/40] , Loss: 0.2509499192237854\n",
      "Epoch [577/1000] , Step [20/40] , Loss: 0.2375439852476120\n",
      "Epoch [577/1000] , Step [30/40] , Loss: 0.2369288504123688\n",
      "Epoch [577/1000] , Step [40/40] , Loss: 0.2476893514394760\n",
      "Epoch [578/1000] , Step [10/40] , Loss: 0.2388821840286255\n",
      "Epoch [578/1000] , Step [20/40] , Loss: 0.2155344784259796\n",
      "Epoch [578/1000] , Step [30/40] , Loss: 0.2198780626058578\n",
      "Epoch [578/1000] , Step [40/40] , Loss: 0.2462320029735565\n",
      "Epoch [579/1000] , Step [10/40] , Loss: 0.2226313203573227\n",
      "Epoch [579/1000] , Step [20/40] , Loss: 0.2399102002382278\n",
      "Epoch [579/1000] , Step [30/40] , Loss: 0.2295023947954178\n",
      "Epoch [579/1000] , Step [40/40] , Loss: 0.2347926348447800\n",
      "Epoch [580/1000] , Step [10/40] , Loss: 0.2330159842967987\n",
      "Epoch [580/1000] , Step [20/40] , Loss: 0.2170531153678894\n",
      "Epoch [580/1000] , Step [30/40] , Loss: 0.2220583260059357\n",
      "Epoch [580/1000] , Step [40/40] , Loss: 0.2550436258316040\n",
      "Epoch [581/1000] , Step [10/40] , Loss: 0.2611694633960724\n",
      "Epoch [581/1000] , Step [20/40] , Loss: 0.2392712980508804\n",
      "Epoch [581/1000] , Step [30/40] , Loss: 0.2384856045246124\n",
      "Epoch [581/1000] , Step [40/40] , Loss: 0.2371562123298645\n",
      "Epoch [582/1000] , Step [10/40] , Loss: 0.2289042174816132\n",
      "Epoch [582/1000] , Step [20/40] , Loss: 0.2376579046249390\n",
      "Epoch [582/1000] , Step [30/40] , Loss: 0.2413161098957062\n",
      "Epoch [582/1000] , Step [40/40] , Loss: 0.2081343233585358\n",
      "Epoch [583/1000] , Step [10/40] , Loss: 0.2246036380529404\n",
      "Epoch [583/1000] , Step [20/40] , Loss: 0.2382804006338120\n",
      "Epoch [583/1000] , Step [30/40] , Loss: 0.2281038612127304\n",
      "Epoch [583/1000] , Step [40/40] , Loss: 0.2399910539388657\n",
      "Epoch [584/1000] , Step [10/40] , Loss: 0.2306867092847824\n",
      "Epoch [584/1000] , Step [20/40] , Loss: 0.2261935621500015\n",
      "Epoch [584/1000] , Step [30/40] , Loss: 0.2518266141414642\n",
      "Epoch [584/1000] , Step [40/40] , Loss: 0.2439140081405640\n",
      "Epoch [585/1000] , Step [10/40] , Loss: 0.2381831109523773\n",
      "Epoch [585/1000] , Step [20/40] , Loss: 0.2127741277217865\n",
      "Epoch [585/1000] , Step [30/40] , Loss: 0.2306872010231018\n",
      "Epoch [585/1000] , Step [40/40] , Loss: 0.2125494629144669\n",
      "Epoch [586/1000] , Step [10/40] , Loss: 0.2322823256254196\n",
      "Epoch [586/1000] , Step [20/40] , Loss: 0.2381889075040817\n",
      "Epoch [586/1000] , Step [30/40] , Loss: 0.2239986360073090\n",
      "Epoch [586/1000] , Step [40/40] , Loss: 0.2582184970378876\n",
      "Epoch [587/1000] , Step [10/40] , Loss: 0.2232259809970856\n",
      "Epoch [587/1000] , Step [20/40] , Loss: 0.2325102090835571\n",
      "Epoch [587/1000] , Step [30/40] , Loss: 0.2347323149442673\n",
      "Epoch [587/1000] , Step [40/40] , Loss: 0.2405654788017273\n",
      "Epoch [588/1000] , Step [10/40] , Loss: 0.2232061922550201\n",
      "Epoch [588/1000] , Step [20/40] , Loss: 0.2191604077816010\n",
      "Epoch [588/1000] , Step [30/40] , Loss: 0.2318508327007294\n",
      "Epoch [588/1000] , Step [40/40] , Loss: 0.2149921655654907\n",
      "Epoch [589/1000] , Step [10/40] , Loss: 0.2146602272987366\n",
      "Epoch [589/1000] , Step [20/40] , Loss: 0.2096910774707794\n",
      "Epoch [589/1000] , Step [30/40] , Loss: 0.2252824306488037\n",
      "Epoch [589/1000] , Step [40/40] , Loss: 0.1983588188886642\n",
      "Epoch [590/1000] , Step [10/40] , Loss: 0.2369115799665451\n",
      "Epoch [590/1000] , Step [20/40] , Loss: 0.2425661385059357\n",
      "Epoch [590/1000] , Step [30/40] , Loss: 0.2114353924989700\n",
      "Epoch [590/1000] , Step [40/40] , Loss: 0.2232101708650589\n",
      "Epoch [591/1000] , Step [10/40] , Loss: 0.2361759096384048\n",
      "Epoch [591/1000] , Step [20/40] , Loss: 0.2459079772233963\n",
      "Epoch [591/1000] , Step [30/40] , Loss: 0.2462508380413055\n",
      "Epoch [591/1000] , Step [40/40] , Loss: 0.2489633113145828\n",
      "Epoch [592/1000] , Step [10/40] , Loss: 0.2455804198980331\n",
      "Epoch [592/1000] , Step [20/40] , Loss: 0.2372507452964783\n",
      "Epoch [592/1000] , Step [30/40] , Loss: 0.2269860208034515\n",
      "Epoch [592/1000] , Step [40/40] , Loss: 0.2158435881137848\n",
      "Epoch [593/1000] , Step [10/40] , Loss: 0.2222003191709518\n",
      "Epoch [593/1000] , Step [20/40] , Loss: 0.2229705899953842\n",
      "Epoch [593/1000] , Step [30/40] , Loss: 0.2283678650856018\n",
      "Epoch [593/1000] , Step [40/40] , Loss: 0.2306887954473495\n",
      "Epoch [594/1000] , Step [10/40] , Loss: 0.2187596112489700\n",
      "Epoch [594/1000] , Step [20/40] , Loss: 0.2262160181999207\n",
      "Epoch [594/1000] , Step [30/40] , Loss: 0.2235705554485321\n",
      "Epoch [594/1000] , Step [40/40] , Loss: 0.2479199022054672\n",
      "Epoch [595/1000] , Step [10/40] , Loss: 0.2339012473821640\n",
      "Epoch [595/1000] , Step [20/40] , Loss: 0.2227598428726196\n",
      "Epoch [595/1000] , Step [30/40] , Loss: 0.2314173877239227\n",
      "Epoch [595/1000] , Step [40/40] , Loss: 0.2251320332288742\n",
      "Epoch [596/1000] , Step [10/40] , Loss: 0.2202631682157516\n",
      "Epoch [596/1000] , Step [20/40] , Loss: 0.2206142991781235\n",
      "Epoch [596/1000] , Step [30/40] , Loss: 0.2280984669923782\n",
      "Epoch [596/1000] , Step [40/40] , Loss: 0.2461492568254471\n",
      "Epoch [597/1000] , Step [10/40] , Loss: 0.2408670634031296\n",
      "Epoch [597/1000] , Step [20/40] , Loss: 0.2145051658153534\n",
      "Epoch [597/1000] , Step [30/40] , Loss: 0.2197051644325256\n",
      "Epoch [597/1000] , Step [40/40] , Loss: 0.2444485723972321\n",
      "Epoch [598/1000] , Step [10/40] , Loss: 0.2195599526166916\n",
      "Epoch [598/1000] , Step [20/40] , Loss: 0.2186736762523651\n",
      "Epoch [598/1000] , Step [30/40] , Loss: 0.2131800651550293\n",
      "Epoch [598/1000] , Step [40/40] , Loss: 0.2374942302703857\n",
      "Epoch [599/1000] , Step [10/40] , Loss: 0.2240835279226303\n",
      "Epoch [599/1000] , Step [20/40] , Loss: 0.2439317703247070\n",
      "Epoch [599/1000] , Step [30/40] , Loss: 0.2326312661170959\n",
      "Epoch [599/1000] , Step [40/40] , Loss: 0.2209665477275848\n",
      "Epoch [600/1000] , Step [10/40] , Loss: 0.2328173965215683\n",
      "Epoch [600/1000] , Step [20/40] , Loss: 0.2309101521968842\n",
      "Epoch [600/1000] , Step [30/40] , Loss: 0.2154293060302734\n",
      "Epoch [600/1000] , Step [40/40] , Loss: 0.2380946576595306\n",
      "Epoch [601/1000] , Step [10/40] , Loss: 0.2246843129396439\n",
      "Epoch [601/1000] , Step [20/40] , Loss: 0.2137606739997864\n",
      "Epoch [601/1000] , Step [30/40] , Loss: 0.2397779673337936\n",
      "Epoch [601/1000] , Step [40/40] , Loss: 0.2369522303342819\n",
      "Epoch [602/1000] , Step [10/40] , Loss: 0.2518672347068787\n",
      "Epoch [602/1000] , Step [20/40] , Loss: 0.2315663993358612\n",
      "Epoch [602/1000] , Step [30/40] , Loss: 0.2486463785171509\n",
      "Epoch [602/1000] , Step [40/40] , Loss: 0.2131247818470001\n",
      "Epoch [603/1000] , Step [10/40] , Loss: 0.2463012039661407\n",
      "Epoch [603/1000] , Step [20/40] , Loss: 0.2125854343175888\n",
      "Epoch [603/1000] , Step [30/40] , Loss: 0.2376674264669418\n",
      "Epoch [603/1000] , Step [40/40] , Loss: 0.2347630262374878\n",
      "Epoch [604/1000] , Step [10/40] , Loss: 0.2217618674039841\n",
      "Epoch [604/1000] , Step [20/40] , Loss: 0.2206541895866394\n",
      "Epoch [604/1000] , Step [30/40] , Loss: 0.2363154590129852\n",
      "Epoch [604/1000] , Step [40/40] , Loss: 0.2564608156681061\n",
      "Epoch [605/1000] , Step [10/40] , Loss: 0.2279973179101944\n",
      "Epoch [605/1000] , Step [20/40] , Loss: 0.2299218475818634\n",
      "Epoch [605/1000] , Step [30/40] , Loss: 0.2167887687683105\n",
      "Epoch [605/1000] , Step [40/40] , Loss: 0.2220822125673294\n",
      "Epoch [606/1000] , Step [10/40] , Loss: 0.2433982938528061\n",
      "Epoch [606/1000] , Step [20/40] , Loss: 0.2389983683824539\n",
      "Epoch [606/1000] , Step [30/40] , Loss: 0.2473335415124893\n",
      "Epoch [606/1000] , Step [40/40] , Loss: 0.2308132946491241\n",
      "Epoch [607/1000] , Step [10/40] , Loss: 0.2181604802608490\n",
      "Epoch [607/1000] , Step [20/40] , Loss: 0.2295107692480087\n",
      "Epoch [607/1000] , Step [30/40] , Loss: 0.2253287285566330\n",
      "Epoch [607/1000] , Step [40/40] , Loss: 0.2322602719068527\n",
      "Epoch [608/1000] , Step [10/40] , Loss: 0.2550201117992401\n",
      "Epoch [608/1000] , Step [20/40] , Loss: 0.2213146835565567\n",
      "Epoch [608/1000] , Step [30/40] , Loss: 0.2162473648786545\n",
      "Epoch [608/1000] , Step [40/40] , Loss: 0.2244627624750137\n",
      "Epoch [609/1000] , Step [10/40] , Loss: 0.2287828922271729\n",
      "Epoch [609/1000] , Step [20/40] , Loss: 0.2337462007999420\n",
      "Epoch [609/1000] , Step [30/40] , Loss: 0.2468422949314117\n",
      "Epoch [609/1000] , Step [40/40] , Loss: 0.2506929039955139\n",
      "Epoch [610/1000] , Step [10/40] , Loss: 0.2160743474960327\n",
      "Epoch [610/1000] , Step [20/40] , Loss: 0.2233551591634750\n",
      "Epoch [610/1000] , Step [30/40] , Loss: 0.2308507710695267\n",
      "Epoch [610/1000] , Step [40/40] , Loss: 0.2483133524656296\n",
      "Epoch [611/1000] , Step [10/40] , Loss: 0.2274390757083893\n",
      "Epoch [611/1000] , Step [20/40] , Loss: 0.2337669581174850\n",
      "Epoch [611/1000] , Step [30/40] , Loss: 0.2332865446805954\n",
      "Epoch [611/1000] , Step [40/40] , Loss: 0.2370583564043045\n",
      "Epoch [612/1000] , Step [10/40] , Loss: 0.2130950242280960\n",
      "Epoch [612/1000] , Step [20/40] , Loss: 0.2152008712291718\n",
      "Epoch [612/1000] , Step [30/40] , Loss: 0.2170965522527695\n",
      "Epoch [612/1000] , Step [40/40] , Loss: 0.2526564300060272\n",
      "Epoch [613/1000] , Step [10/40] , Loss: 0.2077655345201492\n",
      "Epoch [613/1000] , Step [20/40] , Loss: 0.2279708832502365\n",
      "Epoch [613/1000] , Step [30/40] , Loss: 0.2483479976654053\n",
      "Epoch [613/1000] , Step [40/40] , Loss: 0.2351789027452469\n",
      "Epoch [614/1000] , Step [10/40] , Loss: 0.2356856763362885\n",
      "Epoch [614/1000] , Step [20/40] , Loss: 0.2261123955249786\n",
      "Epoch [614/1000] , Step [30/40] , Loss: 0.2350430190563202\n",
      "Epoch [614/1000] , Step [40/40] , Loss: 0.1977455914020538\n",
      "Epoch [615/1000] , Step [10/40] , Loss: 0.2261161059141159\n",
      "Epoch [615/1000] , Step [20/40] , Loss: 0.2265825867652893\n",
      "Epoch [615/1000] , Step [30/40] , Loss: 0.2469937056303024\n",
      "Epoch [615/1000] , Step [40/40] , Loss: 0.2471693903207779\n",
      "Epoch [616/1000] , Step [10/40] , Loss: 0.2129417806863785\n",
      "Epoch [616/1000] , Step [20/40] , Loss: 0.2275203168392181\n",
      "Epoch [616/1000] , Step [30/40] , Loss: 0.2235980033874512\n",
      "Epoch [616/1000] , Step [40/40] , Loss: 0.2328673005104065\n",
      "Epoch [617/1000] , Step [10/40] , Loss: 0.2224389463663101\n",
      "Epoch [617/1000] , Step [20/40] , Loss: 0.2349079102277756\n",
      "Epoch [617/1000] , Step [30/40] , Loss: 0.2189772576093674\n",
      "Epoch [617/1000] , Step [40/40] , Loss: 0.2485352903604507\n",
      "Epoch [618/1000] , Step [10/40] , Loss: 0.2276386469602585\n",
      "Epoch [618/1000] , Step [20/40] , Loss: 0.2239113152027130\n",
      "Epoch [618/1000] , Step [30/40] , Loss: 0.2295659631490707\n",
      "Epoch [618/1000] , Step [40/40] , Loss: 0.2447449266910553\n",
      "Epoch [619/1000] , Step [10/40] , Loss: 0.2385525256395340\n",
      "Epoch [619/1000] , Step [20/40] , Loss: 0.2245047390460968\n",
      "Epoch [619/1000] , Step [30/40] , Loss: 0.2386876195669174\n",
      "Epoch [619/1000] , Step [40/40] , Loss: 0.2146238535642624\n",
      "Epoch [620/1000] , Step [10/40] , Loss: 0.2548358440399170\n",
      "Epoch [620/1000] , Step [20/40] , Loss: 0.2013373523950577\n",
      "Epoch [620/1000] , Step [30/40] , Loss: 0.2210165411233902\n",
      "Epoch [620/1000] , Step [40/40] , Loss: 0.2181306630373001\n",
      "Epoch [621/1000] , Step [10/40] , Loss: 0.2270969450473785\n",
      "Epoch [621/1000] , Step [20/40] , Loss: 0.2293688505887985\n",
      "Epoch [621/1000] , Step [30/40] , Loss: 0.2126132249832153\n",
      "Epoch [621/1000] , Step [40/40] , Loss: 0.2351812273263931\n",
      "Epoch [622/1000] , Step [10/40] , Loss: 0.2649117112159729\n",
      "Epoch [622/1000] , Step [20/40] , Loss: 0.2216498851776123\n",
      "Epoch [622/1000] , Step [30/40] , Loss: 0.2279063463211060\n",
      "Epoch [622/1000] , Step [40/40] , Loss: 0.2411602288484573\n",
      "Epoch [623/1000] , Step [10/40] , Loss: 0.2192287296056747\n",
      "Epoch [623/1000] , Step [20/40] , Loss: 0.2487021982669830\n",
      "Epoch [623/1000] , Step [30/40] , Loss: 0.2164234519004822\n",
      "Epoch [623/1000] , Step [40/40] , Loss: 0.2243445217609406\n",
      "Epoch [624/1000] , Step [10/40] , Loss: 0.2357079237699509\n",
      "Epoch [624/1000] , Step [20/40] , Loss: 0.2352441251277924\n",
      "Epoch [624/1000] , Step [30/40] , Loss: 0.2210956662893295\n",
      "Epoch [624/1000] , Step [40/40] , Loss: 0.2113529592752457\n",
      "Epoch [625/1000] , Step [10/40] , Loss: 0.2350452095270157\n",
      "Epoch [625/1000] , Step [20/40] , Loss: 0.2145231664180756\n",
      "Epoch [625/1000] , Step [30/40] , Loss: 0.2140619158744812\n",
      "Epoch [625/1000] , Step [40/40] , Loss: 0.2138147950172424\n",
      "Epoch [626/1000] , Step [10/40] , Loss: 0.2048835754394531\n",
      "Epoch [626/1000] , Step [20/40] , Loss: 0.2316857725381851\n",
      "Epoch [626/1000] , Step [30/40] , Loss: 0.2314736694097519\n",
      "Epoch [626/1000] , Step [40/40] , Loss: 0.2489520758390427\n",
      "Epoch [627/1000] , Step [10/40] , Loss: 0.2313410043716431\n",
      "Epoch [627/1000] , Step [20/40] , Loss: 0.2362701445817947\n",
      "Epoch [627/1000] , Step [30/40] , Loss: 0.2431951761245728\n",
      "Epoch [627/1000] , Step [40/40] , Loss: 0.2249518632888794\n",
      "Epoch [628/1000] , Step [10/40] , Loss: 0.2163276225328445\n",
      "Epoch [628/1000] , Step [20/40] , Loss: 0.2378149181604385\n",
      "Epoch [628/1000] , Step [30/40] , Loss: 0.2263385206460953\n",
      "Epoch [628/1000] , Step [40/40] , Loss: 0.2168120741844177\n",
      "Epoch [629/1000] , Step [10/40] , Loss: 0.2320750951766968\n",
      "Epoch [629/1000] , Step [20/40] , Loss: 0.2389315068721771\n",
      "Epoch [629/1000] , Step [30/40] , Loss: 0.2374677360057831\n",
      "Epoch [629/1000] , Step [40/40] , Loss: 0.2285602390766144\n",
      "Epoch [630/1000] , Step [10/40] , Loss: 0.2124563753604889\n",
      "Epoch [630/1000] , Step [20/40] , Loss: 0.2281124591827393\n",
      "Epoch [630/1000] , Step [30/40] , Loss: 0.2333810627460480\n",
      "Epoch [630/1000] , Step [40/40] , Loss: 0.2286881655454636\n",
      "Epoch [631/1000] , Step [10/40] , Loss: 0.2041607797145844\n",
      "Epoch [631/1000] , Step [20/40] , Loss: 0.2241428047418594\n",
      "Epoch [631/1000] , Step [30/40] , Loss: 0.2178514301776886\n",
      "Epoch [631/1000] , Step [40/40] , Loss: 0.2286844700574875\n",
      "Epoch [632/1000] , Step [10/40] , Loss: 0.2283912152051926\n",
      "Epoch [632/1000] , Step [20/40] , Loss: 0.2351385653018951\n",
      "Epoch [632/1000] , Step [30/40] , Loss: 0.2337767630815506\n",
      "Epoch [632/1000] , Step [40/40] , Loss: 0.2596210241317749\n",
      "Epoch [633/1000] , Step [10/40] , Loss: 0.2499721795320511\n",
      "Epoch [633/1000] , Step [20/40] , Loss: 0.2270131558179855\n",
      "Epoch [633/1000] , Step [30/40] , Loss: 0.2306011021137238\n",
      "Epoch [633/1000] , Step [40/40] , Loss: 0.2268573045730591\n",
      "Epoch [634/1000] , Step [10/40] , Loss: 0.2102301120758057\n",
      "Epoch [634/1000] , Step [20/40] , Loss: 0.2381126582622528\n",
      "Epoch [634/1000] , Step [30/40] , Loss: 0.2257852703332901\n",
      "Epoch [634/1000] , Step [40/40] , Loss: 0.2302604764699936\n",
      "Epoch [635/1000] , Step [10/40] , Loss: 0.2321392446756363\n",
      "Epoch [635/1000] , Step [20/40] , Loss: 0.2113763839006424\n",
      "Epoch [635/1000] , Step [30/40] , Loss: 0.2319178134202957\n",
      "Epoch [635/1000] , Step [40/40] , Loss: 0.2444663345813751\n",
      "Epoch [636/1000] , Step [10/40] , Loss: 0.2271737605333328\n",
      "Epoch [636/1000] , Step [20/40] , Loss: 0.2295501828193665\n",
      "Epoch [636/1000] , Step [30/40] , Loss: 0.2159352451562881\n",
      "Epoch [636/1000] , Step [40/40] , Loss: 0.2453645914793015\n",
      "Epoch [637/1000] , Step [10/40] , Loss: 0.2273870855569839\n",
      "Epoch [637/1000] , Step [20/40] , Loss: 0.2056727260351181\n",
      "Epoch [637/1000] , Step [30/40] , Loss: 0.2424859553575516\n",
      "Epoch [637/1000] , Step [40/40] , Loss: 0.2288027107715607\n",
      "Epoch [638/1000] , Step [10/40] , Loss: 0.2252599745988846\n",
      "Epoch [638/1000] , Step [20/40] , Loss: 0.2506879866123199\n",
      "Epoch [638/1000] , Step [30/40] , Loss: 0.2293153554201126\n",
      "Epoch [638/1000] , Step [40/40] , Loss: 0.2239930331707001\n",
      "Epoch [639/1000] , Step [10/40] , Loss: 0.2203602939844131\n",
      "Epoch [639/1000] , Step [20/40] , Loss: 0.2296336740255356\n",
      "Epoch [639/1000] , Step [30/40] , Loss: 0.2483662217855453\n",
      "Epoch [639/1000] , Step [40/40] , Loss: 0.2271952331066132\n",
      "Epoch [640/1000] , Step [10/40] , Loss: 0.2103012651205063\n",
      "Epoch [640/1000] , Step [20/40] , Loss: 0.2447246611118317\n",
      "Epoch [640/1000] , Step [30/40] , Loss: 0.2194589227437973\n",
      "Epoch [640/1000] , Step [40/40] , Loss: 0.2276584655046463\n",
      "Epoch [641/1000] , Step [10/40] , Loss: 0.2168508321046829\n",
      "Epoch [641/1000] , Step [20/40] , Loss: 0.2218325287103653\n",
      "Epoch [641/1000] , Step [30/40] , Loss: 0.2324065715074539\n",
      "Epoch [641/1000] , Step [40/40] , Loss: 0.2220424264669418\n",
      "Epoch [642/1000] , Step [10/40] , Loss: 0.2194827795028687\n",
      "Epoch [642/1000] , Step [20/40] , Loss: 0.2086999118328094\n",
      "Epoch [642/1000] , Step [30/40] , Loss: 0.2184686660766602\n",
      "Epoch [642/1000] , Step [40/40] , Loss: 0.2378016263246536\n",
      "Epoch [643/1000] , Step [10/40] , Loss: 0.2370688915252686\n",
      "Epoch [643/1000] , Step [20/40] , Loss: 0.2121264785528183\n",
      "Epoch [643/1000] , Step [30/40] , Loss: 0.2284228354692459\n",
      "Epoch [643/1000] , Step [40/40] , Loss: 0.2159090638160706\n",
      "Epoch [644/1000] , Step [10/40] , Loss: 0.2373408377170563\n",
      "Epoch [644/1000] , Step [20/40] , Loss: 0.2071397006511688\n",
      "Epoch [644/1000] , Step [30/40] , Loss: 0.2191846817731857\n",
      "Epoch [644/1000] , Step [40/40] , Loss: 0.2352056801319122\n",
      "Epoch [645/1000] , Step [10/40] , Loss: 0.2446131408214569\n",
      "Epoch [645/1000] , Step [20/40] , Loss: 0.2308142781257629\n",
      "Epoch [645/1000] , Step [30/40] , Loss: 0.2188757061958313\n",
      "Epoch [645/1000] , Step [40/40] , Loss: 0.2309572249650955\n",
      "Epoch [646/1000] , Step [10/40] , Loss: 0.2177412360906601\n",
      "Epoch [646/1000] , Step [20/40] , Loss: 0.2353994101285934\n",
      "Epoch [646/1000] , Step [30/40] , Loss: 0.2157427668571472\n",
      "Epoch [646/1000] , Step [40/40] , Loss: 0.2411888241767883\n",
      "Epoch [647/1000] , Step [10/40] , Loss: 0.2405314594507217\n",
      "Epoch [647/1000] , Step [20/40] , Loss: 0.2392028421163559\n",
      "Epoch [647/1000] , Step [30/40] , Loss: 0.2125099599361420\n",
      "Epoch [647/1000] , Step [40/40] , Loss: 0.2200257480144501\n",
      "Epoch [648/1000] , Step [10/40] , Loss: 0.2131792902946472\n",
      "Epoch [648/1000] , Step [20/40] , Loss: 0.2261627018451691\n",
      "Epoch [648/1000] , Step [30/40] , Loss: 0.2244263440370560\n",
      "Epoch [648/1000] , Step [40/40] , Loss: 0.2285830825567245\n",
      "Epoch [649/1000] , Step [10/40] , Loss: 0.2209684401750565\n",
      "Epoch [649/1000] , Step [20/40] , Loss: 0.2148085534572601\n",
      "Epoch [649/1000] , Step [30/40] , Loss: 0.2246733605861664\n",
      "Epoch [649/1000] , Step [40/40] , Loss: 0.2157635539770126\n",
      "Epoch [650/1000] , Step [10/40] , Loss: 0.2289900034666061\n",
      "Epoch [650/1000] , Step [20/40] , Loss: 0.2355304807424545\n",
      "Epoch [650/1000] , Step [30/40] , Loss: 0.2240370810031891\n",
      "Epoch [650/1000] , Step [40/40] , Loss: 0.2454890161752701\n",
      "Epoch [651/1000] , Step [10/40] , Loss: 0.2288345098495483\n",
      "Epoch [651/1000] , Step [20/40] , Loss: 0.2435807734727859\n",
      "Epoch [651/1000] , Step [30/40] , Loss: 0.2520523667335510\n",
      "Epoch [651/1000] , Step [40/40] , Loss: 0.2198341935873032\n",
      "Epoch [652/1000] , Step [10/40] , Loss: 0.2675474882125854\n",
      "Epoch [652/1000] , Step [20/40] , Loss: 0.2384900152683258\n",
      "Epoch [652/1000] , Step [30/40] , Loss: 0.2036712616682053\n",
      "Epoch [652/1000] , Step [40/40] , Loss: 0.2392239570617676\n",
      "Epoch [653/1000] , Step [10/40] , Loss: 0.2291183024644852\n",
      "Epoch [653/1000] , Step [20/40] , Loss: 0.2251126617193222\n",
      "Epoch [653/1000] , Step [30/40] , Loss: 0.2227038890123367\n",
      "Epoch [653/1000] , Step [40/40] , Loss: 0.2396779656410217\n",
      "Epoch [654/1000] , Step [10/40] , Loss: 0.2346045523881912\n",
      "Epoch [654/1000] , Step [20/40] , Loss: 0.2235215157270432\n",
      "Epoch [654/1000] , Step [30/40] , Loss: 0.2364791929721832\n",
      "Epoch [654/1000] , Step [40/40] , Loss: 0.2191986888647079\n",
      "Epoch [655/1000] , Step [10/40] , Loss: 0.2256444096565247\n",
      "Epoch [655/1000] , Step [20/40] , Loss: 0.2186293751001358\n",
      "Epoch [655/1000] , Step [30/40] , Loss: 0.2227049916982651\n",
      "Epoch [655/1000] , Step [40/40] , Loss: 0.2279553711414337\n",
      "Epoch [656/1000] , Step [10/40] , Loss: 0.2500002980232239\n",
      "Epoch [656/1000] , Step [20/40] , Loss: 0.2331618070602417\n",
      "Epoch [656/1000] , Step [30/40] , Loss: 0.2259702235460281\n",
      "Epoch [656/1000] , Step [40/40] , Loss: 0.2418836355209351\n",
      "Epoch [657/1000] , Step [10/40] , Loss: 0.2142036557197571\n",
      "Epoch [657/1000] , Step [20/40] , Loss: 0.2318613976240158\n",
      "Epoch [657/1000] , Step [30/40] , Loss: 0.2235269099473953\n",
      "Epoch [657/1000] , Step [40/40] , Loss: 0.2565073966979980\n",
      "Epoch [658/1000] , Step [10/40] , Loss: 0.2185324281454086\n",
      "Epoch [658/1000] , Step [20/40] , Loss: 0.2300315499305725\n",
      "Epoch [658/1000] , Step [30/40] , Loss: 0.2297399044036865\n",
      "Epoch [658/1000] , Step [40/40] , Loss: 0.2307012379169464\n",
      "Epoch [659/1000] , Step [10/40] , Loss: 0.2347244769334793\n",
      "Epoch [659/1000] , Step [20/40] , Loss: 0.2247954159975052\n",
      "Epoch [659/1000] , Step [30/40] , Loss: 0.2302140295505524\n",
      "Epoch [659/1000] , Step [40/40] , Loss: 0.2327033877372742\n",
      "Epoch [660/1000] , Step [10/40] , Loss: 0.2307666540145874\n",
      "Epoch [660/1000] , Step [20/40] , Loss: 0.2114046216011047\n",
      "Epoch [660/1000] , Step [30/40] , Loss: 0.2247546315193176\n",
      "Epoch [660/1000] , Step [40/40] , Loss: 0.2458768337965012\n",
      "Epoch [661/1000] , Step [10/40] , Loss: 0.2438823580741882\n",
      "Epoch [661/1000] , Step [20/40] , Loss: 0.2213158011436462\n",
      "Epoch [661/1000] , Step [30/40] , Loss: 0.2336127460002899\n",
      "Epoch [661/1000] , Step [40/40] , Loss: 0.2393520325422287\n",
      "Epoch [662/1000] , Step [10/40] , Loss: 0.2239938229322433\n",
      "Epoch [662/1000] , Step [20/40] , Loss: 0.2304849624633789\n",
      "Epoch [662/1000] , Step [30/40] , Loss: 0.2179062962532043\n",
      "Epoch [662/1000] , Step [40/40] , Loss: 0.2255498617887497\n",
      "Epoch [663/1000] , Step [10/40] , Loss: 0.2322546392679214\n",
      "Epoch [663/1000] , Step [20/40] , Loss: 0.2291797697544098\n",
      "Epoch [663/1000] , Step [30/40] , Loss: 0.2356106638908386\n",
      "Epoch [663/1000] , Step [40/40] , Loss: 0.2422288656234741\n",
      "Epoch [664/1000] , Step [10/40] , Loss: 0.2317052483558655\n",
      "Epoch [664/1000] , Step [20/40] , Loss: 0.2369604855775833\n",
      "Epoch [664/1000] , Step [30/40] , Loss: 0.2090005278587341\n",
      "Epoch [664/1000] , Step [40/40] , Loss: 0.2119729965925217\n",
      "Epoch [665/1000] , Step [10/40] , Loss: 0.2101957648992538\n",
      "Epoch [665/1000] , Step [20/40] , Loss: 0.2247558534145355\n",
      "Epoch [665/1000] , Step [30/40] , Loss: 0.2173703014850616\n",
      "Epoch [665/1000] , Step [40/40] , Loss: 0.2511270046234131\n",
      "Epoch [666/1000] , Step [10/40] , Loss: 0.2302676588296890\n",
      "Epoch [666/1000] , Step [20/40] , Loss: 0.2480142414569855\n",
      "Epoch [666/1000] , Step [30/40] , Loss: 0.2382592409849167\n",
      "Epoch [666/1000] , Step [40/40] , Loss: 0.2365616112947464\n",
      "Epoch [667/1000] , Step [10/40] , Loss: 0.2287100106477737\n",
      "Epoch [667/1000] , Step [20/40] , Loss: 0.2155200242996216\n",
      "Epoch [667/1000] , Step [30/40] , Loss: 0.2342728078365326\n",
      "Epoch [667/1000] , Step [40/40] , Loss: 0.2147574573755264\n",
      "Epoch [668/1000] , Step [10/40] , Loss: 0.2143172174692154\n",
      "Epoch [668/1000] , Step [20/40] , Loss: 0.2375236153602600\n",
      "Epoch [668/1000] , Step [30/40] , Loss: 0.2101897150278091\n",
      "Epoch [668/1000] , Step [40/40] , Loss: 0.2128189951181412\n",
      "Epoch [669/1000] , Step [10/40] , Loss: 0.2424806356430054\n",
      "Epoch [669/1000] , Step [20/40] , Loss: 0.2196747809648514\n",
      "Epoch [669/1000] , Step [30/40] , Loss: 0.2235948592424393\n",
      "Epoch [669/1000] , Step [40/40] , Loss: 0.2229968756437302\n",
      "Epoch [670/1000] , Step [10/40] , Loss: 0.2145826965570450\n",
      "Epoch [670/1000] , Step [20/40] , Loss: 0.2367680966854095\n",
      "Epoch [670/1000] , Step [30/40] , Loss: 0.1944165527820587\n",
      "Epoch [670/1000] , Step [40/40] , Loss: 0.2254687249660492\n",
      "Epoch [671/1000] , Step [10/40] , Loss: 0.2280632406473160\n",
      "Epoch [671/1000] , Step [20/40] , Loss: 0.2095206975936890\n",
      "Epoch [671/1000] , Step [30/40] , Loss: 0.2221730947494507\n",
      "Epoch [671/1000] , Step [40/40] , Loss: 0.2307636141777039\n",
      "Epoch [672/1000] , Step [10/40] , Loss: 0.2147743999958038\n",
      "Epoch [672/1000] , Step [20/40] , Loss: 0.2142700999975204\n",
      "Epoch [672/1000] , Step [30/40] , Loss: 0.2350193709135056\n",
      "Epoch [672/1000] , Step [40/40] , Loss: 0.2065682560205460\n",
      "Epoch [673/1000] , Step [10/40] , Loss: 0.2369735538959503\n",
      "Epoch [673/1000] , Step [20/40] , Loss: 0.2543922066688538\n",
      "Epoch [673/1000] , Step [30/40] , Loss: 0.2192597687244415\n",
      "Epoch [673/1000] , Step [40/40] , Loss: 0.2309846431016922\n",
      "Epoch [674/1000] , Step [10/40] , Loss: 0.2160609513521194\n",
      "Epoch [674/1000] , Step [20/40] , Loss: 0.2202809303998947\n",
      "Epoch [674/1000] , Step [30/40] , Loss: 0.2314101308584213\n",
      "Epoch [674/1000] , Step [40/40] , Loss: 0.2302295267581940\n",
      "Epoch [675/1000] , Step [10/40] , Loss: 0.2191335260868073\n",
      "Epoch [675/1000] , Step [20/40] , Loss: 0.2276580929756165\n",
      "Epoch [675/1000] , Step [30/40] , Loss: 0.2222643345594406\n",
      "Epoch [675/1000] , Step [40/40] , Loss: 0.2406720221042633\n",
      "Epoch [676/1000] , Step [10/40] , Loss: 0.2329007983207703\n",
      "Epoch [676/1000] , Step [20/40] , Loss: 0.2150594741106033\n",
      "Epoch [676/1000] , Step [30/40] , Loss: 0.2135892510414124\n",
      "Epoch [676/1000] , Step [40/40] , Loss: 0.2361636459827423\n",
      "Epoch [677/1000] , Step [10/40] , Loss: 0.2214621007442474\n",
      "Epoch [677/1000] , Step [20/40] , Loss: 0.2267768979072571\n",
      "Epoch [677/1000] , Step [30/40] , Loss: 0.2171301990747452\n",
      "Epoch [677/1000] , Step [40/40] , Loss: 0.2186402827501297\n",
      "Epoch [678/1000] , Step [10/40] , Loss: 0.2230236232280731\n",
      "Epoch [678/1000] , Step [20/40] , Loss: 0.2256203889846802\n",
      "Epoch [678/1000] , Step [30/40] , Loss: 0.1816415041685104\n",
      "Epoch [678/1000] , Step [40/40] , Loss: 0.2200691550970078\n",
      "Epoch [679/1000] , Step [10/40] , Loss: 0.2060704529285431\n",
      "Epoch [679/1000] , Step [20/40] , Loss: 0.2301310300827026\n",
      "Epoch [679/1000] , Step [30/40] , Loss: 0.2132300287485123\n",
      "Epoch [679/1000] , Step [40/40] , Loss: 0.2167890816926956\n",
      "Epoch [680/1000] , Step [10/40] , Loss: 0.2465809732675552\n",
      "Epoch [680/1000] , Step [20/40] , Loss: 0.2234558612108231\n",
      "Epoch [680/1000] , Step [30/40] , Loss: 0.2130497395992279\n",
      "Epoch [680/1000] , Step [40/40] , Loss: 0.2174395471811295\n",
      "Epoch [681/1000] , Step [10/40] , Loss: 0.2296380847692490\n",
      "Epoch [681/1000] , Step [20/40] , Loss: 0.2332824915647507\n",
      "Epoch [681/1000] , Step [30/40] , Loss: 0.2391117513179779\n",
      "Epoch [681/1000] , Step [40/40] , Loss: 0.2267081737518311\n",
      "Epoch [682/1000] , Step [10/40] , Loss: 0.2284481823444366\n",
      "Epoch [682/1000] , Step [20/40] , Loss: 0.1982648819684982\n",
      "Epoch [682/1000] , Step [30/40] , Loss: 0.2063143551349640\n",
      "Epoch [682/1000] , Step [40/40] , Loss: 0.2025716900825500\n",
      "Epoch [683/1000] , Step [10/40] , Loss: 0.2264120131731033\n",
      "Epoch [683/1000] , Step [20/40] , Loss: 0.2194255143404007\n",
      "Epoch [683/1000] , Step [30/40] , Loss: 0.2165645211935043\n",
      "Epoch [683/1000] , Step [40/40] , Loss: 0.2289630621671677\n",
      "Epoch [684/1000] , Step [10/40] , Loss: 0.2155709266662598\n",
      "Epoch [684/1000] , Step [20/40] , Loss: 0.2215805500745773\n",
      "Epoch [684/1000] , Step [30/40] , Loss: 0.2365582585334778\n",
      "Epoch [684/1000] , Step [40/40] , Loss: 0.2256057560443878\n",
      "Epoch [685/1000] , Step [10/40] , Loss: 0.2198693007230759\n",
      "Epoch [685/1000] , Step [20/40] , Loss: 0.2129783034324646\n",
      "Epoch [685/1000] , Step [30/40] , Loss: 0.2249358296394348\n",
      "Epoch [685/1000] , Step [40/40] , Loss: 0.2391337007284164\n",
      "Epoch [686/1000] , Step [10/40] , Loss: 0.2521275579929352\n",
      "Epoch [686/1000] , Step [20/40] , Loss: 0.2093196660280228\n",
      "Epoch [686/1000] , Step [30/40] , Loss: 0.2545459866523743\n",
      "Epoch [686/1000] , Step [40/40] , Loss: 0.2164549976587296\n",
      "Epoch [687/1000] , Step [10/40] , Loss: 0.2160837054252625\n",
      "Epoch [687/1000] , Step [20/40] , Loss: 0.2220279276371002\n",
      "Epoch [687/1000] , Step [30/40] , Loss: 0.2269700616598129\n",
      "Epoch [687/1000] , Step [40/40] , Loss: 0.2066292315721512\n",
      "Epoch [688/1000] , Step [10/40] , Loss: 0.2133212834596634\n",
      "Epoch [688/1000] , Step [20/40] , Loss: 0.2111666351556778\n",
      "Epoch [688/1000] , Step [30/40] , Loss: 0.2214797586202621\n",
      "Epoch [688/1000] , Step [40/40] , Loss: 0.2307223230600357\n",
      "Epoch [689/1000] , Step [10/40] , Loss: 0.2112477719783783\n",
      "Epoch [689/1000] , Step [20/40] , Loss: 0.2276289314031601\n",
      "Epoch [689/1000] , Step [30/40] , Loss: 0.2169986516237259\n",
      "Epoch [689/1000] , Step [40/40] , Loss: 0.2207735478878021\n",
      "Epoch [690/1000] , Step [10/40] , Loss: 0.2134218066930771\n",
      "Epoch [690/1000] , Step [20/40] , Loss: 0.2317582666873932\n",
      "Epoch [690/1000] , Step [30/40] , Loss: 0.2262601554393768\n",
      "Epoch [690/1000] , Step [40/40] , Loss: 0.2380932718515396\n",
      "Epoch [691/1000] , Step [10/40] , Loss: 0.2242880761623383\n",
      "Epoch [691/1000] , Step [20/40] , Loss: 0.2237328439950943\n",
      "Epoch [691/1000] , Step [30/40] , Loss: 0.2376924157142639\n",
      "Epoch [691/1000] , Step [40/40] , Loss: 0.2044590413570404\n",
      "Epoch [692/1000] , Step [10/40] , Loss: 0.2297306507825851\n",
      "Epoch [692/1000] , Step [20/40] , Loss: 0.2163859307765961\n",
      "Epoch [692/1000] , Step [30/40] , Loss: 0.2328303903341293\n",
      "Epoch [692/1000] , Step [40/40] , Loss: 0.2374567836523056\n",
      "Epoch [693/1000] , Step [10/40] , Loss: 0.2005642354488373\n",
      "Epoch [693/1000] , Step [20/40] , Loss: 0.2486885488033295\n",
      "Epoch [693/1000] , Step [30/40] , Loss: 0.2067668884992599\n",
      "Epoch [693/1000] , Step [40/40] , Loss: 0.2236855477094650\n",
      "Epoch [694/1000] , Step [10/40] , Loss: 0.2233474105596542\n",
      "Epoch [694/1000] , Step [20/40] , Loss: 0.2250165194272995\n",
      "Epoch [694/1000] , Step [30/40] , Loss: 0.2147538661956787\n",
      "Epoch [694/1000] , Step [40/40] , Loss: 0.2317636460065842\n",
      "Epoch [695/1000] , Step [10/40] , Loss: 0.2093067318201065\n",
      "Epoch [695/1000] , Step [20/40] , Loss: 0.2033729106187820\n",
      "Epoch [695/1000] , Step [30/40] , Loss: 0.2038328349590302\n",
      "Epoch [695/1000] , Step [40/40] , Loss: 0.2236134111881256\n",
      "Epoch [696/1000] , Step [10/40] , Loss: 0.2254909873008728\n",
      "Epoch [696/1000] , Step [20/40] , Loss: 0.2033426314592361\n",
      "Epoch [696/1000] , Step [30/40] , Loss: 0.2132284045219421\n",
      "Epoch [696/1000] , Step [40/40] , Loss: 0.2285057604312897\n",
      "Epoch [697/1000] , Step [10/40] , Loss: 0.1950808912515640\n",
      "Epoch [697/1000] , Step [20/40] , Loss: 0.2049302458763123\n",
      "Epoch [697/1000] , Step [30/40] , Loss: 0.2330376505851746\n",
      "Epoch [697/1000] , Step [40/40] , Loss: 0.2146852314472198\n",
      "Epoch [698/1000] , Step [10/40] , Loss: 0.2159182429313660\n",
      "Epoch [698/1000] , Step [20/40] , Loss: 0.2256206423044205\n",
      "Epoch [698/1000] , Step [30/40] , Loss: 0.2067256867885590\n",
      "Epoch [698/1000] , Step [40/40] , Loss: 0.2320575714111328\n",
      "Epoch [699/1000] , Step [10/40] , Loss: 0.2320040613412857\n",
      "Epoch [699/1000] , Step [20/40] , Loss: 0.2329566627740860\n",
      "Epoch [699/1000] , Step [30/40] , Loss: 0.2192642539739609\n",
      "Epoch [699/1000] , Step [40/40] , Loss: 0.2242068946361542\n",
      "Epoch [700/1000] , Step [10/40] , Loss: 0.2244806438684464\n",
      "Epoch [700/1000] , Step [20/40] , Loss: 0.2367511242628098\n",
      "Epoch [700/1000] , Step [30/40] , Loss: 0.2198226302862167\n",
      "Epoch [700/1000] , Step [40/40] , Loss: 0.2183261066675186\n",
      "Epoch [701/1000] , Step [10/40] , Loss: 0.2348787933588028\n",
      "Epoch [701/1000] , Step [20/40] , Loss: 0.2175116539001465\n",
      "Epoch [701/1000] , Step [30/40] , Loss: 0.2290810197591782\n",
      "Epoch [701/1000] , Step [40/40] , Loss: 0.2026635110378265\n",
      "Epoch [702/1000] , Step [10/40] , Loss: 0.2217654138803482\n",
      "Epoch [702/1000] , Step [20/40] , Loss: 0.2139104455709457\n",
      "Epoch [702/1000] , Step [30/40] , Loss: 0.2164874970912933\n",
      "Epoch [702/1000] , Step [40/40] , Loss: 0.2396141588687897\n",
      "Epoch [703/1000] , Step [10/40] , Loss: 0.2168314903974533\n",
      "Epoch [703/1000] , Step [20/40] , Loss: 0.2168648391962051\n",
      "Epoch [703/1000] , Step [30/40] , Loss: 0.2206519842147827\n",
      "Epoch [703/1000] , Step [40/40] , Loss: 0.2095862179994583\n",
      "Epoch [704/1000] , Step [10/40] , Loss: 0.2113738507032394\n",
      "Epoch [704/1000] , Step [20/40] , Loss: 0.2206941246986389\n",
      "Epoch [704/1000] , Step [30/40] , Loss: 0.2244949936866760\n",
      "Epoch [704/1000] , Step [40/40] , Loss: 0.2149992734193802\n",
      "Epoch [705/1000] , Step [10/40] , Loss: 0.2213266193866730\n",
      "Epoch [705/1000] , Step [20/40] , Loss: 0.2109759598970413\n",
      "Epoch [705/1000] , Step [30/40] , Loss: 0.2147812545299530\n",
      "Epoch [705/1000] , Step [40/40] , Loss: 0.2289376705884933\n",
      "Epoch [706/1000] , Step [10/40] , Loss: 0.2179043442010880\n",
      "Epoch [706/1000] , Step [20/40] , Loss: 0.2291474044322968\n",
      "Epoch [706/1000] , Step [30/40] , Loss: 0.2332872599363327\n",
      "Epoch [706/1000] , Step [40/40] , Loss: 0.2088160663843155\n",
      "Epoch [707/1000] , Step [10/40] , Loss: 0.2417296171188354\n",
      "Epoch [707/1000] , Step [20/40] , Loss: 0.2087028920650482\n",
      "Epoch [707/1000] , Step [30/40] , Loss: 0.2293538451194763\n",
      "Epoch [707/1000] , Step [40/40] , Loss: 0.2063243091106415\n",
      "Epoch [708/1000] , Step [10/40] , Loss: 0.2111825942993164\n",
      "Epoch [708/1000] , Step [20/40] , Loss: 0.2299806028604507\n",
      "Epoch [708/1000] , Step [30/40] , Loss: 0.2301357388496399\n",
      "Epoch [708/1000] , Step [40/40] , Loss: 0.2256109416484833\n",
      "Epoch [709/1000] , Step [10/40] , Loss: 0.2385145723819733\n",
      "Epoch [709/1000] , Step [20/40] , Loss: 0.2140951156616211\n",
      "Epoch [709/1000] , Step [30/40] , Loss: 0.2115365713834763\n",
      "Epoch [709/1000] , Step [40/40] , Loss: 0.1958812624216080\n",
      "Epoch [710/1000] , Step [10/40] , Loss: 0.2303741872310638\n",
      "Epoch [710/1000] , Step [20/40] , Loss: 0.2103098183870316\n",
      "Epoch [710/1000] , Step [30/40] , Loss: 0.2111417800188065\n",
      "Epoch [710/1000] , Step [40/40] , Loss: 0.2129145264625549\n",
      "Epoch [711/1000] , Step [10/40] , Loss: 0.2337464839220047\n",
      "Epoch [711/1000] , Step [20/40] , Loss: 0.2209356129169464\n",
      "Epoch [711/1000] , Step [30/40] , Loss: 0.2135710269212723\n",
      "Epoch [711/1000] , Step [40/40] , Loss: 0.2539024353027344\n",
      "Epoch [712/1000] , Step [10/40] , Loss: 0.2171025574207306\n",
      "Epoch [712/1000] , Step [20/40] , Loss: 0.2212176471948624\n",
      "Epoch [712/1000] , Step [30/40] , Loss: 0.2331505864858627\n",
      "Epoch [712/1000] , Step [40/40] , Loss: 0.2284509986639023\n",
      "Epoch [713/1000] , Step [10/40] , Loss: 0.2236756980419159\n",
      "Epoch [713/1000] , Step [20/40] , Loss: 0.2230671197175980\n",
      "Epoch [713/1000] , Step [30/40] , Loss: 0.2091933786869049\n",
      "Epoch [713/1000] , Step [40/40] , Loss: 0.2231102734804153\n",
      "Epoch [714/1000] , Step [10/40] , Loss: 0.2212518304586411\n",
      "Epoch [714/1000] , Step [20/40] , Loss: 0.2166798859834671\n",
      "Epoch [714/1000] , Step [30/40] , Loss: 0.2042833268642426\n",
      "Epoch [714/1000] , Step [40/40] , Loss: 0.2114371657371521\n",
      "Epoch [715/1000] , Step [10/40] , Loss: 0.2111999839544296\n",
      "Epoch [715/1000] , Step [20/40] , Loss: 0.2047535181045532\n",
      "Epoch [715/1000] , Step [30/40] , Loss: 0.2282221615314484\n",
      "Epoch [715/1000] , Step [40/40] , Loss: 0.2345578223466873\n",
      "Epoch [716/1000] , Step [10/40] , Loss: 0.2170099616050720\n",
      "Epoch [716/1000] , Step [20/40] , Loss: 0.2198700606822968\n",
      "Epoch [716/1000] , Step [30/40] , Loss: 0.2043297588825226\n",
      "Epoch [716/1000] , Step [40/40] , Loss: 0.1991759836673737\n",
      "Epoch [717/1000] , Step [10/40] , Loss: 0.2482228577136993\n",
      "Epoch [717/1000] , Step [20/40] , Loss: 0.2123217582702637\n",
      "Epoch [717/1000] , Step [30/40] , Loss: 0.2290636599063873\n",
      "Epoch [717/1000] , Step [40/40] , Loss: 0.2009441405534744\n",
      "Epoch [718/1000] , Step [10/40] , Loss: 0.2343490719795227\n",
      "Epoch [718/1000] , Step [20/40] , Loss: 0.2044532299041748\n",
      "Epoch [718/1000] , Step [30/40] , Loss: 0.2263782620429993\n",
      "Epoch [718/1000] , Step [40/40] , Loss: 0.2056665271520615\n",
      "Epoch [719/1000] , Step [10/40] , Loss: 0.2203819304704666\n",
      "Epoch [719/1000] , Step [20/40] , Loss: 0.2355131357908249\n",
      "Epoch [719/1000] , Step [30/40] , Loss: 0.2007636725902557\n",
      "Epoch [719/1000] , Step [40/40] , Loss: 0.2239728420972824\n",
      "Epoch [720/1000] , Step [10/40] , Loss: 0.1981535255908966\n",
      "Epoch [720/1000] , Step [20/40] , Loss: 0.2221001386642456\n",
      "Epoch [720/1000] , Step [30/40] , Loss: 0.2058963626623154\n",
      "Epoch [720/1000] , Step [40/40] , Loss: 0.2171160578727722\n",
      "Epoch [721/1000] , Step [10/40] , Loss: 0.2080255299806595\n",
      "Epoch [721/1000] , Step [20/40] , Loss: 0.2060188204050064\n",
      "Epoch [721/1000] , Step [30/40] , Loss: 0.2187670916318893\n",
      "Epoch [721/1000] , Step [40/40] , Loss: 0.2353761643171310\n",
      "Epoch [722/1000] , Step [10/40] , Loss: 0.2192543148994446\n",
      "Epoch [722/1000] , Step [20/40] , Loss: 0.2263349294662476\n",
      "Epoch [722/1000] , Step [30/40] , Loss: 0.2487242966890335\n",
      "Epoch [722/1000] , Step [40/40] , Loss: 0.2253822088241577\n",
      "Epoch [723/1000] , Step [10/40] , Loss: 0.2118629366159439\n",
      "Epoch [723/1000] , Step [20/40] , Loss: 0.2275869548320770\n",
      "Epoch [723/1000] , Step [30/40] , Loss: 0.2070175707340240\n",
      "Epoch [723/1000] , Step [40/40] , Loss: 0.2058666199445724\n",
      "Epoch [724/1000] , Step [10/40] , Loss: 0.2027518153190613\n",
      "Epoch [724/1000] , Step [20/40] , Loss: 0.1912969648838043\n",
      "Epoch [724/1000] , Step [30/40] , Loss: 0.2289799600839615\n",
      "Epoch [724/1000] , Step [40/40] , Loss: 0.2281083166599274\n",
      "Epoch [725/1000] , Step [10/40] , Loss: 0.2028318643569946\n",
      "Epoch [725/1000] , Step [20/40] , Loss: 0.2264034748077393\n",
      "Epoch [725/1000] , Step [30/40] , Loss: 0.2096201777458191\n",
      "Epoch [725/1000] , Step [40/40] , Loss: 0.2242619693279266\n",
      "Epoch [726/1000] , Step [10/40] , Loss: 0.2352650910615921\n",
      "Epoch [726/1000] , Step [20/40] , Loss: 0.2064847499132156\n",
      "Epoch [726/1000] , Step [30/40] , Loss: 0.2081551998853683\n",
      "Epoch [726/1000] , Step [40/40] , Loss: 0.1943892985582352\n",
      "Epoch [727/1000] , Step [10/40] , Loss: 0.2279572784900665\n",
      "Epoch [727/1000] , Step [20/40] , Loss: 0.2286187559366226\n",
      "Epoch [727/1000] , Step [30/40] , Loss: 0.2125181406736374\n",
      "Epoch [727/1000] , Step [40/40] , Loss: 0.2017998844385147\n",
      "Epoch [728/1000] , Step [10/40] , Loss: 0.2119253724813461\n",
      "Epoch [728/1000] , Step [20/40] , Loss: 0.2343238294124603\n",
      "Epoch [728/1000] , Step [30/40] , Loss: 0.2028153538703918\n",
      "Epoch [728/1000] , Step [40/40] , Loss: 0.2004487812519073\n",
      "Epoch [729/1000] , Step [10/40] , Loss: 0.2144214957952499\n",
      "Epoch [729/1000] , Step [20/40] , Loss: 0.2097212672233582\n",
      "Epoch [729/1000] , Step [30/40] , Loss: 0.2218319624662399\n",
      "Epoch [729/1000] , Step [40/40] , Loss: 0.2227523922920227\n",
      "Epoch [730/1000] , Step [10/40] , Loss: 0.2289811670780182\n",
      "Epoch [730/1000] , Step [20/40] , Loss: 0.2227801829576492\n",
      "Epoch [730/1000] , Step [30/40] , Loss: 0.2163503319025040\n",
      "Epoch [730/1000] , Step [40/40] , Loss: 0.2084413170814514\n",
      "Epoch [731/1000] , Step [10/40] , Loss: 0.2042648792266846\n",
      "Epoch [731/1000] , Step [20/40] , Loss: 0.2127618640661240\n",
      "Epoch [731/1000] , Step [30/40] , Loss: 0.2152219563722610\n",
      "Epoch [731/1000] , Step [40/40] , Loss: 0.2253291904926300\n",
      "Epoch [732/1000] , Step [10/40] , Loss: 0.2334738373756409\n",
      "Epoch [732/1000] , Step [20/40] , Loss: 0.2016183733940125\n",
      "Epoch [732/1000] , Step [30/40] , Loss: 0.2004662305116653\n",
      "Epoch [732/1000] , Step [40/40] , Loss: 0.2284159362316132\n",
      "Epoch [733/1000] , Step [10/40] , Loss: 0.2076539248228073\n",
      "Epoch [733/1000] , Step [20/40] , Loss: 0.2131403535604477\n",
      "Epoch [733/1000] , Step [30/40] , Loss: 0.2234219014644623\n",
      "Epoch [733/1000] , Step [40/40] , Loss: 0.2280528545379639\n",
      "Epoch [734/1000] , Step [10/40] , Loss: 0.2032611370086670\n",
      "Epoch [734/1000] , Step [20/40] , Loss: 0.2361728250980377\n",
      "Epoch [734/1000] , Step [30/40] , Loss: 0.2259597778320312\n",
      "Epoch [734/1000] , Step [40/40] , Loss: 0.2136017829179764\n",
      "Epoch [735/1000] , Step [10/40] , Loss: 0.2084005624055862\n",
      "Epoch [735/1000] , Step [20/40] , Loss: 0.2127027064561844\n",
      "Epoch [735/1000] , Step [30/40] , Loss: 0.2245087623596191\n",
      "Epoch [735/1000] , Step [40/40] , Loss: 0.2270764261484146\n",
      "Epoch [736/1000] , Step [10/40] , Loss: 0.2073701620101929\n",
      "Epoch [736/1000] , Step [20/40] , Loss: 0.2154003977775574\n",
      "Epoch [736/1000] , Step [30/40] , Loss: 0.2082477062940598\n",
      "Epoch [736/1000] , Step [40/40] , Loss: 0.1994772255420685\n",
      "Epoch [737/1000] , Step [10/40] , Loss: 0.2381355017423630\n",
      "Epoch [737/1000] , Step [20/40] , Loss: 0.2153211385011673\n",
      "Epoch [737/1000] , Step [30/40] , Loss: 0.2316586673259735\n",
      "Epoch [737/1000] , Step [40/40] , Loss: 0.2281596660614014\n",
      "Epoch [738/1000] , Step [10/40] , Loss: 0.2154558449983597\n",
      "Epoch [738/1000] , Step [20/40] , Loss: 0.2303412556648254\n",
      "Epoch [738/1000] , Step [30/40] , Loss: 0.2094018757343292\n",
      "Epoch [738/1000] , Step [40/40] , Loss: 0.2279613614082336\n",
      "Epoch [739/1000] , Step [10/40] , Loss: 0.2181254774332047\n",
      "Epoch [739/1000] , Step [20/40] , Loss: 0.2092216312885284\n",
      "Epoch [739/1000] , Step [30/40] , Loss: 0.2085017263889313\n",
      "Epoch [739/1000] , Step [40/40] , Loss: 0.2243243455886841\n",
      "Epoch [740/1000] , Step [10/40] , Loss: 0.2175704687833786\n",
      "Epoch [740/1000] , Step [20/40] , Loss: 0.1998306959867477\n",
      "Epoch [740/1000] , Step [30/40] , Loss: 0.1881846934556961\n",
      "Epoch [740/1000] , Step [40/40] , Loss: 0.2385916709899902\n",
      "Epoch [741/1000] , Step [10/40] , Loss: 0.2224086523056030\n",
      "Epoch [741/1000] , Step [20/40] , Loss: 0.2014193236827850\n",
      "Epoch [741/1000] , Step [30/40] , Loss: 0.2080225795507431\n",
      "Epoch [741/1000] , Step [40/40] , Loss: 0.2524354755878448\n",
      "Epoch [742/1000] , Step [10/40] , Loss: 0.2163660377264023\n",
      "Epoch [742/1000] , Step [20/40] , Loss: 0.2222517728805542\n",
      "Epoch [742/1000] , Step [30/40] , Loss: 0.2060696035623550\n",
      "Epoch [742/1000] , Step [40/40] , Loss: 0.2113014757633209\n",
      "Epoch [743/1000] , Step [10/40] , Loss: 0.2283650189638138\n",
      "Epoch [743/1000] , Step [20/40] , Loss: 0.2291010767221451\n",
      "Epoch [743/1000] , Step [30/40] , Loss: 0.1938027143478394\n",
      "Epoch [743/1000] , Step [40/40] , Loss: 0.2060867398977280\n",
      "Epoch [744/1000] , Step [10/40] , Loss: 0.2116536647081375\n",
      "Epoch [744/1000] , Step [20/40] , Loss: 0.2279884964227676\n",
      "Epoch [744/1000] , Step [30/40] , Loss: 0.2221503257751465\n",
      "Epoch [744/1000] , Step [40/40] , Loss: 0.2096315324306488\n",
      "Epoch [745/1000] , Step [10/40] , Loss: 0.2060720026493073\n",
      "Epoch [745/1000] , Step [20/40] , Loss: 0.2181958556175232\n",
      "Epoch [745/1000] , Step [30/40] , Loss: 0.2130969315767288\n",
      "Epoch [745/1000] , Step [40/40] , Loss: 0.1832489073276520\n",
      "Epoch [746/1000] , Step [10/40] , Loss: 0.2095029652118683\n",
      "Epoch [746/1000] , Step [20/40] , Loss: 0.1927885413169861\n",
      "Epoch [746/1000] , Step [30/40] , Loss: 0.2263460904359818\n",
      "Epoch [746/1000] , Step [40/40] , Loss: 0.2389408499002457\n",
      "Epoch [747/1000] , Step [10/40] , Loss: 0.2170424461364746\n",
      "Epoch [747/1000] , Step [20/40] , Loss: 0.2231354117393494\n",
      "Epoch [747/1000] , Step [30/40] , Loss: 0.2135350108146667\n",
      "Epoch [747/1000] , Step [40/40] , Loss: 0.2201841026544571\n",
      "Epoch [748/1000] , Step [10/40] , Loss: 0.2107620984315872\n",
      "Epoch [748/1000] , Step [20/40] , Loss: 0.2203542441129684\n",
      "Epoch [748/1000] , Step [30/40] , Loss: 0.2032606154680252\n",
      "Epoch [748/1000] , Step [40/40] , Loss: 0.2147733122110367\n",
      "Epoch [749/1000] , Step [10/40] , Loss: 0.2078624665737152\n",
      "Epoch [749/1000] , Step [20/40] , Loss: 0.2180460244417191\n",
      "Epoch [749/1000] , Step [30/40] , Loss: 0.2253586053848267\n",
      "Epoch [749/1000] , Step [40/40] , Loss: 0.1969494074583054\n",
      "Epoch [750/1000] , Step [10/40] , Loss: 0.2177036702632904\n",
      "Epoch [750/1000] , Step [20/40] , Loss: 0.2268527150154114\n",
      "Epoch [750/1000] , Step [30/40] , Loss: 0.2311303615570068\n",
      "Epoch [750/1000] , Step [40/40] , Loss: 0.2166411131620407\n",
      "Epoch [751/1000] , Step [10/40] , Loss: 0.2099164724349976\n",
      "Epoch [751/1000] , Step [20/40] , Loss: 0.2132490426301956\n",
      "Epoch [751/1000] , Step [30/40] , Loss: 0.2189514040946960\n",
      "Epoch [751/1000] , Step [40/40] , Loss: 0.2121847718954086\n",
      "Epoch [752/1000] , Step [10/40] , Loss: 0.2256621718406677\n",
      "Epoch [752/1000] , Step [20/40] , Loss: 0.2318584024906158\n",
      "Epoch [752/1000] , Step [30/40] , Loss: 0.2076496332883835\n",
      "Epoch [752/1000] , Step [40/40] , Loss: 0.2152282893657684\n",
      "Epoch [753/1000] , Step [10/40] , Loss: 0.2334665656089783\n",
      "Epoch [753/1000] , Step [20/40] , Loss: 0.2225721925497055\n",
      "Epoch [753/1000] , Step [30/40] , Loss: 0.2187159061431885\n",
      "Epoch [753/1000] , Step [40/40] , Loss: 0.2259179353713989\n",
      "Epoch [754/1000] , Step [10/40] , Loss: 0.1945127099752426\n",
      "Epoch [754/1000] , Step [20/40] , Loss: 0.2301630377769470\n",
      "Epoch [754/1000] , Step [30/40] , Loss: 0.2418977618217468\n",
      "Epoch [754/1000] , Step [40/40] , Loss: 0.2385635077953339\n",
      "Epoch [755/1000] , Step [10/40] , Loss: 0.2164763212203979\n",
      "Epoch [755/1000] , Step [20/40] , Loss: 0.2258559316396713\n",
      "Epoch [755/1000] , Step [30/40] , Loss: 0.1928597986698151\n",
      "Epoch [755/1000] , Step [40/40] , Loss: 0.2028000950813293\n",
      "Epoch [756/1000] , Step [10/40] , Loss: 0.2109341919422150\n",
      "Epoch [756/1000] , Step [20/40] , Loss: 0.1838965564966202\n",
      "Epoch [756/1000] , Step [30/40] , Loss: 0.2174455374479294\n",
      "Epoch [756/1000] , Step [40/40] , Loss: 0.2089308053255081\n",
      "Epoch [757/1000] , Step [10/40] , Loss: 0.2074394077062607\n",
      "Epoch [757/1000] , Step [20/40] , Loss: 0.2041983902454376\n",
      "Epoch [757/1000] , Step [30/40] , Loss: 0.2193652391433716\n",
      "Epoch [757/1000] , Step [40/40] , Loss: 0.2335658818483353\n",
      "Epoch [758/1000] , Step [10/40] , Loss: 0.2195352464914322\n",
      "Epoch [758/1000] , Step [20/40] , Loss: 0.2325261831283569\n",
      "Epoch [758/1000] , Step [30/40] , Loss: 0.2187547236680984\n",
      "Epoch [758/1000] , Step [40/40] , Loss: 0.2245711535215378\n",
      "Epoch [759/1000] , Step [10/40] , Loss: 0.2022223770618439\n",
      "Epoch [759/1000] , Step [20/40] , Loss: 0.1986884623765945\n",
      "Epoch [759/1000] , Step [30/40] , Loss: 0.2124489098787308\n",
      "Epoch [759/1000] , Step [40/40] , Loss: 0.2090105563402176\n",
      "Epoch [760/1000] , Step [10/40] , Loss: 0.2390787601470947\n",
      "Epoch [760/1000] , Step [20/40] , Loss: 0.2085696458816528\n",
      "Epoch [760/1000] , Step [30/40] , Loss: 0.2047822475433350\n",
      "Epoch [760/1000] , Step [40/40] , Loss: 0.2248880267143250\n",
      "Epoch [761/1000] , Step [10/40] , Loss: 0.2251922935247421\n",
      "Epoch [761/1000] , Step [20/40] , Loss: 0.2280693203210831\n",
      "Epoch [761/1000] , Step [30/40] , Loss: 0.2322260737419128\n",
      "Epoch [761/1000] , Step [40/40] , Loss: 0.2196133434772491\n",
      "Epoch [762/1000] , Step [10/40] , Loss: 0.1971159130334854\n",
      "Epoch [762/1000] , Step [20/40] , Loss: 0.2243111282587051\n",
      "Epoch [762/1000] , Step [30/40] , Loss: 0.2109147459268570\n",
      "Epoch [762/1000] , Step [40/40] , Loss: 0.2021128833293915\n",
      "Epoch [763/1000] , Step [10/40] , Loss: 0.2257293909788132\n",
      "Epoch [763/1000] , Step [20/40] , Loss: 0.1878567785024643\n",
      "Epoch [763/1000] , Step [30/40] , Loss: 0.2282691746950150\n",
      "Epoch [763/1000] , Step [40/40] , Loss: 0.2012883275747299\n",
      "Epoch [764/1000] , Step [10/40] , Loss: 0.2160558551549911\n",
      "Epoch [764/1000] , Step [20/40] , Loss: 0.2079961746931076\n",
      "Epoch [764/1000] , Step [30/40] , Loss: 0.2389113306999207\n",
      "Epoch [764/1000] , Step [40/40] , Loss: 0.2194626480340958\n",
      "Epoch [765/1000] , Step [10/40] , Loss: 0.2022934257984161\n",
      "Epoch [765/1000] , Step [20/40] , Loss: 0.2195006459951401\n",
      "Epoch [765/1000] , Step [30/40] , Loss: 0.2131901979446411\n",
      "Epoch [765/1000] , Step [40/40] , Loss: 0.2145814746618271\n",
      "Epoch [766/1000] , Step [10/40] , Loss: 0.2120676487684250\n",
      "Epoch [766/1000] , Step [20/40] , Loss: 0.2048204690217972\n",
      "Epoch [766/1000] , Step [30/40] , Loss: 0.2305337339639664\n",
      "Epoch [766/1000] , Step [40/40] , Loss: 0.2044205218553543\n",
      "Epoch [767/1000] , Step [10/40] , Loss: 0.2017906457185745\n",
      "Epoch [767/1000] , Step [20/40] , Loss: 0.2039729207754135\n",
      "Epoch [767/1000] , Step [30/40] , Loss: 0.2126351445913315\n",
      "Epoch [767/1000] , Step [40/40] , Loss: 0.1871487349271774\n",
      "Epoch [768/1000] , Step [10/40] , Loss: 0.1979352384805679\n",
      "Epoch [768/1000] , Step [20/40] , Loss: 0.2213159501552582\n",
      "Epoch [768/1000] , Step [30/40] , Loss: 0.2075850218534470\n",
      "Epoch [768/1000] , Step [40/40] , Loss: 0.2226960957050323\n",
      "Epoch [769/1000] , Step [10/40] , Loss: 0.2129868268966675\n",
      "Epoch [769/1000] , Step [20/40] , Loss: 0.2161634564399719\n",
      "Epoch [769/1000] , Step [30/40] , Loss: 0.2155078053474426\n",
      "Epoch [769/1000] , Step [40/40] , Loss: 0.2171695828437805\n",
      "Epoch [770/1000] , Step [10/40] , Loss: 0.1863000541925430\n",
      "Epoch [770/1000] , Step [20/40] , Loss: 0.2098636180162430\n",
      "Epoch [770/1000] , Step [30/40] , Loss: 0.1874394267797470\n",
      "Epoch [770/1000] , Step [40/40] , Loss: 0.2379209101200104\n",
      "Epoch [771/1000] , Step [10/40] , Loss: 0.2306708097457886\n",
      "Epoch [771/1000] , Step [20/40] , Loss: 0.2106050699949265\n",
      "Epoch [771/1000] , Step [30/40] , Loss: 0.2221436798572540\n",
      "Epoch [771/1000] , Step [40/40] , Loss: 0.2108817696571350\n",
      "Epoch [772/1000] , Step [10/40] , Loss: 0.1951764672994614\n",
      "Epoch [772/1000] , Step [20/40] , Loss: 0.2112224847078323\n",
      "Epoch [772/1000] , Step [30/40] , Loss: 0.2098014205694199\n",
      "Epoch [772/1000] , Step [40/40] , Loss: 0.2126960903406143\n",
      "Epoch [773/1000] , Step [10/40] , Loss: 0.2175982594490051\n",
      "Epoch [773/1000] , Step [20/40] , Loss: 0.1981980204582214\n",
      "Epoch [773/1000] , Step [30/40] , Loss: 0.2147712409496307\n",
      "Epoch [773/1000] , Step [40/40] , Loss: 0.2171393185853958\n",
      "Epoch [774/1000] , Step [10/40] , Loss: 0.2075355947017670\n",
      "Epoch [774/1000] , Step [20/40] , Loss: 0.2065913081169128\n",
      "Epoch [774/1000] , Step [30/40] , Loss: 0.2166736125946045\n",
      "Epoch [774/1000] , Step [40/40] , Loss: 0.2145846337080002\n",
      "Epoch [775/1000] , Step [10/40] , Loss: 0.2059283703565598\n",
      "Epoch [775/1000] , Step [20/40] , Loss: 0.2123100459575653\n",
      "Epoch [775/1000] , Step [30/40] , Loss: 0.2212757170200348\n",
      "Epoch [775/1000] , Step [40/40] , Loss: 0.2438912093639374\n",
      "Epoch [776/1000] , Step [10/40] , Loss: 0.2246846854686737\n",
      "Epoch [776/1000] , Step [20/40] , Loss: 0.2235197424888611\n",
      "Epoch [776/1000] , Step [30/40] , Loss: 0.2103964090347290\n",
      "Epoch [776/1000] , Step [40/40] , Loss: 0.1948722898960114\n",
      "Epoch [777/1000] , Step [10/40] , Loss: 0.2228644788265228\n",
      "Epoch [777/1000] , Step [20/40] , Loss: 0.2155227661132812\n",
      "Epoch [777/1000] , Step [30/40] , Loss: 0.2053285539150238\n",
      "Epoch [777/1000] , Step [40/40] , Loss: 0.2077578604221344\n",
      "Epoch [778/1000] , Step [10/40] , Loss: 0.2159477472305298\n",
      "Epoch [778/1000] , Step [20/40] , Loss: 0.1998797655105591\n",
      "Epoch [778/1000] , Step [30/40] , Loss: 0.1981118172407150\n",
      "Epoch [778/1000] , Step [40/40] , Loss: 0.2105086743831635\n",
      "Epoch [779/1000] , Step [10/40] , Loss: 0.2158618420362473\n",
      "Epoch [779/1000] , Step [20/40] , Loss: 0.2202647328376770\n",
      "Epoch [779/1000] , Step [30/40] , Loss: 0.2160433381795883\n",
      "Epoch [779/1000] , Step [40/40] , Loss: 0.2016082704067230\n",
      "Epoch [780/1000] , Step [10/40] , Loss: 0.2144978493452072\n",
      "Epoch [780/1000] , Step [20/40] , Loss: 0.2184161841869354\n",
      "Epoch [780/1000] , Step [30/40] , Loss: 0.2117270380258560\n",
      "Epoch [780/1000] , Step [40/40] , Loss: 0.2225958406925201\n",
      "Epoch [781/1000] , Step [10/40] , Loss: 0.2217739075422287\n",
      "Epoch [781/1000] , Step [20/40] , Loss: 0.2130397856235504\n",
      "Epoch [781/1000] , Step [30/40] , Loss: 0.2243752777576447\n",
      "Epoch [781/1000] , Step [40/40] , Loss: 0.2121553570032120\n",
      "Epoch [782/1000] , Step [10/40] , Loss: 0.1997202932834625\n",
      "Epoch [782/1000] , Step [20/40] , Loss: 0.2183539420366287\n",
      "Epoch [782/1000] , Step [30/40] , Loss: 0.2177503257989883\n",
      "Epoch [782/1000] , Step [40/40] , Loss: 0.1944592148065567\n",
      "Epoch [783/1000] , Step [10/40] , Loss: 0.2167027741670609\n",
      "Epoch [783/1000] , Step [20/40] , Loss: 0.2116404473781586\n",
      "Epoch [783/1000] , Step [30/40] , Loss: 0.2148804664611816\n",
      "Epoch [783/1000] , Step [40/40] , Loss: 0.2089823037385941\n",
      "Epoch [784/1000] , Step [10/40] , Loss: 0.2337799370288849\n",
      "Epoch [784/1000] , Step [20/40] , Loss: 0.2327367365360260\n",
      "Epoch [784/1000] , Step [30/40] , Loss: 0.1992468088865280\n",
      "Epoch [784/1000] , Step [40/40] , Loss: 0.2331418246030807\n",
      "Epoch [785/1000] , Step [10/40] , Loss: 0.2322874069213867\n",
      "Epoch [785/1000] , Step [20/40] , Loss: 0.2218206226825714\n",
      "Epoch [785/1000] , Step [30/40] , Loss: 0.2346227020025253\n",
      "Epoch [785/1000] , Step [40/40] , Loss: 0.2236721813678741\n",
      "Epoch [786/1000] , Step [10/40] , Loss: 0.2032086104154587\n",
      "Epoch [786/1000] , Step [20/40] , Loss: 0.1954852193593979\n",
      "Epoch [786/1000] , Step [30/40] , Loss: 0.2019474804401398\n",
      "Epoch [786/1000] , Step [40/40] , Loss: 0.2395310699939728\n",
      "Epoch [787/1000] , Step [10/40] , Loss: 0.2279517948627472\n",
      "Epoch [787/1000] , Step [20/40] , Loss: 0.2209868878126144\n",
      "Epoch [787/1000] , Step [30/40] , Loss: 0.2066122740507126\n",
      "Epoch [787/1000] , Step [40/40] , Loss: 0.2224948555231094\n",
      "Epoch [788/1000] , Step [10/40] , Loss: 0.2064497470855713\n",
      "Epoch [788/1000] , Step [20/40] , Loss: 0.2022275477647781\n",
      "Epoch [788/1000] , Step [30/40] , Loss: 0.2014150619506836\n",
      "Epoch [788/1000] , Step [40/40] , Loss: 0.1926589608192444\n",
      "Epoch [789/1000] , Step [10/40] , Loss: 0.2163478732109070\n",
      "Epoch [789/1000] , Step [20/40] , Loss: 0.2043348252773285\n",
      "Epoch [789/1000] , Step [30/40] , Loss: 0.2233404070138931\n",
      "Epoch [789/1000] , Step [40/40] , Loss: 0.2112913131713867\n",
      "Epoch [790/1000] , Step [10/40] , Loss: 0.2120789736509323\n",
      "Epoch [790/1000] , Step [20/40] , Loss: 0.2032079398632050\n",
      "Epoch [790/1000] , Step [30/40] , Loss: 0.2052925229072571\n",
      "Epoch [790/1000] , Step [40/40] , Loss: 0.2303697466850281\n",
      "Epoch [791/1000] , Step [10/40] , Loss: 0.2042990773916245\n",
      "Epoch [791/1000] , Step [20/40] , Loss: 0.2148346900939941\n",
      "Epoch [791/1000] , Step [30/40] , Loss: 0.2243591398000717\n",
      "Epoch [791/1000] , Step [40/40] , Loss: 0.2031173855066299\n",
      "Epoch [792/1000] , Step [10/40] , Loss: 0.2320834994316101\n",
      "Epoch [792/1000] , Step [20/40] , Loss: 0.2009835541248322\n",
      "Epoch [792/1000] , Step [30/40] , Loss: 0.2005766332149506\n",
      "Epoch [792/1000] , Step [40/40] , Loss: 0.2124166637659073\n",
      "Epoch [793/1000] , Step [10/40] , Loss: 0.2031348496675491\n",
      "Epoch [793/1000] , Step [20/40] , Loss: 0.2005760669708252\n",
      "Epoch [793/1000] , Step [30/40] , Loss: 0.2115411013364792\n",
      "Epoch [793/1000] , Step [40/40] , Loss: 0.1945519298315048\n",
      "Epoch [794/1000] , Step [10/40] , Loss: 0.2286336123943329\n",
      "Epoch [794/1000] , Step [20/40] , Loss: 0.1932956576347351\n",
      "Epoch [794/1000] , Step [30/40] , Loss: 0.2170151919126511\n",
      "Epoch [794/1000] , Step [40/40] , Loss: 0.2190730869770050\n",
      "Epoch [795/1000] , Step [10/40] , Loss: 0.2227533310651779\n",
      "Epoch [795/1000] , Step [20/40] , Loss: 0.2139519155025482\n",
      "Epoch [795/1000] , Step [30/40] , Loss: 0.2019015997648239\n",
      "Epoch [795/1000] , Step [40/40] , Loss: 0.2110791951417923\n",
      "Epoch [796/1000] , Step [10/40] , Loss: 0.2123756557703018\n",
      "Epoch [796/1000] , Step [20/40] , Loss: 0.2277932912111282\n",
      "Epoch [796/1000] , Step [30/40] , Loss: 0.2278013676404953\n",
      "Epoch [796/1000] , Step [40/40] , Loss: 0.1952745914459229\n",
      "Epoch [797/1000] , Step [10/40] , Loss: 0.1975031048059464\n",
      "Epoch [797/1000] , Step [20/40] , Loss: 0.2038846164941788\n",
      "Epoch [797/1000] , Step [30/40] , Loss: 0.1911611706018448\n",
      "Epoch [797/1000] , Step [40/40] , Loss: 0.2176792323589325\n",
      "Epoch [798/1000] , Step [10/40] , Loss: 0.2034379541873932\n",
      "Epoch [798/1000] , Step [20/40] , Loss: 0.2041566222906113\n",
      "Epoch [798/1000] , Step [30/40] , Loss: 0.2002641558647156\n",
      "Epoch [798/1000] , Step [40/40] , Loss: 0.1946893185377121\n",
      "Epoch [799/1000] , Step [10/40] , Loss: 0.1924800723791122\n",
      "Epoch [799/1000] , Step [20/40] , Loss: 0.2133191376924515\n",
      "Epoch [799/1000] , Step [30/40] , Loss: 0.2278970032930374\n",
      "Epoch [799/1000] , Step [40/40] , Loss: 0.2156393229961395\n",
      "Epoch [800/1000] , Step [10/40] , Loss: 0.2170699238777161\n",
      "Epoch [800/1000] , Step [20/40] , Loss: 0.1953943073749542\n",
      "Epoch [800/1000] , Step [30/40] , Loss: 0.2101834416389465\n",
      "Epoch [800/1000] , Step [40/40] , Loss: 0.2031378448009491\n",
      "Epoch [801/1000] , Step [10/40] , Loss: 0.2005265951156616\n",
      "Epoch [801/1000] , Step [20/40] , Loss: 0.2053407430648804\n",
      "Epoch [801/1000] , Step [30/40] , Loss: 0.2190634310245514\n",
      "Epoch [801/1000] , Step [40/40] , Loss: 0.1964280307292938\n",
      "Epoch [802/1000] , Step [10/40] , Loss: 0.2079741954803467\n",
      "Epoch [802/1000] , Step [20/40] , Loss: 0.1846380531787872\n",
      "Epoch [802/1000] , Step [30/40] , Loss: 0.2127580642700195\n",
      "Epoch [802/1000] , Step [40/40] , Loss: 0.2162828594446182\n",
      "Epoch [803/1000] , Step [10/40] , Loss: 0.1837134212255478\n",
      "Epoch [803/1000] , Step [20/40] , Loss: 0.2317521274089813\n",
      "Epoch [803/1000] , Step [30/40] , Loss: 0.2132056206464767\n",
      "Epoch [803/1000] , Step [40/40] , Loss: 0.2091926336288452\n",
      "Epoch [804/1000] , Step [10/40] , Loss: 0.2211929857730865\n",
      "Epoch [804/1000] , Step [20/40] , Loss: 0.2230670601129532\n",
      "Epoch [804/1000] , Step [30/40] , Loss: 0.2065018266439438\n",
      "Epoch [804/1000] , Step [40/40] , Loss: 0.1862579435110092\n",
      "Epoch [805/1000] , Step [10/40] , Loss: 0.1873959153890610\n",
      "Epoch [805/1000] , Step [20/40] , Loss: 0.2287004590034485\n",
      "Epoch [805/1000] , Step [30/40] , Loss: 0.2064513415098190\n",
      "Epoch [805/1000] , Step [40/40] , Loss: 0.1973139345645905\n",
      "Epoch [806/1000] , Step [10/40] , Loss: 0.1994393616914749\n",
      "Epoch [806/1000] , Step [20/40] , Loss: 0.2134141325950623\n",
      "Epoch [806/1000] , Step [30/40] , Loss: 0.1979720443487167\n",
      "Epoch [806/1000] , Step [40/40] , Loss: 0.2036618143320084\n",
      "Epoch [807/1000] , Step [10/40] , Loss: 0.2143380492925644\n",
      "Epoch [807/1000] , Step [20/40] , Loss: 0.2138304412364960\n",
      "Epoch [807/1000] , Step [30/40] , Loss: 0.1836623698472977\n",
      "Epoch [807/1000] , Step [40/40] , Loss: 0.2071240246295929\n",
      "Epoch [808/1000] , Step [10/40] , Loss: 0.1983019709587097\n",
      "Epoch [808/1000] , Step [20/40] , Loss: 0.2141385674476624\n",
      "Epoch [808/1000] , Step [30/40] , Loss: 0.1982094198465347\n",
      "Epoch [808/1000] , Step [40/40] , Loss: 0.2051880359649658\n",
      "Epoch [809/1000] , Step [10/40] , Loss: 0.2257373332977295\n",
      "Epoch [809/1000] , Step [20/40] , Loss: 0.2179176509380341\n",
      "Epoch [809/1000] , Step [30/40] , Loss: 0.2079058587551117\n",
      "Epoch [809/1000] , Step [40/40] , Loss: 0.2166121304035187\n",
      "Epoch [810/1000] , Step [10/40] , Loss: 0.2295478135347366\n",
      "Epoch [810/1000] , Step [20/40] , Loss: 0.2011606395244598\n",
      "Epoch [810/1000] , Step [30/40] , Loss: 0.2125168889760971\n",
      "Epoch [810/1000] , Step [40/40] , Loss: 0.1993395686149597\n",
      "Epoch [811/1000] , Step [10/40] , Loss: 0.2090492397546768\n",
      "Epoch [811/1000] , Step [20/40] , Loss: 0.2138646394014359\n",
      "Epoch [811/1000] , Step [30/40] , Loss: 0.2014085203409195\n",
      "Epoch [811/1000] , Step [40/40] , Loss: 0.1849101185798645\n",
      "Epoch [812/1000] , Step [10/40] , Loss: 0.2035285830497742\n",
      "Epoch [812/1000] , Step [20/40] , Loss: 0.1979739218950272\n",
      "Epoch [812/1000] , Step [30/40] , Loss: 0.2167328447103500\n",
      "Epoch [812/1000] , Step [40/40] , Loss: 0.2292369157075882\n",
      "Epoch [813/1000] , Step [10/40] , Loss: 0.1964673697948456\n",
      "Epoch [813/1000] , Step [20/40] , Loss: 0.1953995227813721\n",
      "Epoch [813/1000] , Step [30/40] , Loss: 0.1980338394641876\n",
      "Epoch [813/1000] , Step [40/40] , Loss: 0.1980818361043930\n",
      "Epoch [814/1000] , Step [10/40] , Loss: 0.2157655954360962\n",
      "Epoch [814/1000] , Step [20/40] , Loss: 0.2045574188232422\n",
      "Epoch [814/1000] , Step [30/40] , Loss: 0.2008198946714401\n",
      "Epoch [814/1000] , Step [40/40] , Loss: 0.1956138014793396\n",
      "Epoch [815/1000] , Step [10/40] , Loss: 0.2191586047410965\n",
      "Epoch [815/1000] , Step [20/40] , Loss: 0.2137799710035324\n",
      "Epoch [815/1000] , Step [30/40] , Loss: 0.2005438953638077\n",
      "Epoch [815/1000] , Step [40/40] , Loss: 0.2294125854969025\n",
      "Epoch [816/1000] , Step [10/40] , Loss: 0.2005240619182587\n",
      "Epoch [816/1000] , Step [20/40] , Loss: 0.2251512855291367\n",
      "Epoch [816/1000] , Step [30/40] , Loss: 0.2192582190036774\n",
      "Epoch [816/1000] , Step [40/40] , Loss: 0.2026879042387009\n",
      "Epoch [817/1000] , Step [10/40] , Loss: 0.2042942345142365\n",
      "Epoch [817/1000] , Step [20/40] , Loss: 0.1901058405637741\n",
      "Epoch [817/1000] , Step [30/40] , Loss: 0.1904996633529663\n",
      "Epoch [817/1000] , Step [40/40] , Loss: 0.2231645584106445\n",
      "Epoch [818/1000] , Step [10/40] , Loss: 0.1959364563226700\n",
      "Epoch [818/1000] , Step [20/40] , Loss: 0.2304076999425888\n",
      "Epoch [818/1000] , Step [30/40] , Loss: 0.1936727315187454\n",
      "Epoch [818/1000] , Step [40/40] , Loss: 0.2054486572742462\n",
      "Epoch [819/1000] , Step [10/40] , Loss: 0.1943930089473724\n",
      "Epoch [819/1000] , Step [20/40] , Loss: 0.2242809534072876\n",
      "Epoch [819/1000] , Step [30/40] , Loss: 0.2044792026281357\n",
      "Epoch [819/1000] , Step [40/40] , Loss: 0.2016034424304962\n",
      "Epoch [820/1000] , Step [10/40] , Loss: 0.2111148387193680\n",
      "Epoch [820/1000] , Step [20/40] , Loss: 0.2027351558208466\n",
      "Epoch [820/1000] , Step [30/40] , Loss: 0.1928682327270508\n",
      "Epoch [820/1000] , Step [40/40] , Loss: 0.2159994095563889\n",
      "Epoch [821/1000] , Step [10/40] , Loss: 0.2041347622871399\n",
      "Epoch [821/1000] , Step [20/40] , Loss: 0.2086195051670074\n",
      "Epoch [821/1000] , Step [30/40] , Loss: 0.2035585343837738\n",
      "Epoch [821/1000] , Step [40/40] , Loss: 0.2054597735404968\n",
      "Epoch [822/1000] , Step [10/40] , Loss: 0.2041977643966675\n",
      "Epoch [822/1000] , Step [20/40] , Loss: 0.1940381228923798\n",
      "Epoch [822/1000] , Step [30/40] , Loss: 0.1915162801742554\n",
      "Epoch [822/1000] , Step [40/40] , Loss: 0.2089426517486572\n",
      "Epoch [823/1000] , Step [10/40] , Loss: 0.2078034877777100\n",
      "Epoch [823/1000] , Step [20/40] , Loss: 0.2053425014019012\n",
      "Epoch [823/1000] , Step [30/40] , Loss: 0.2099681794643402\n",
      "Epoch [823/1000] , Step [40/40] , Loss: 0.2198508083820343\n",
      "Epoch [824/1000] , Step [10/40] , Loss: 0.1917560249567032\n",
      "Epoch [824/1000] , Step [20/40] , Loss: 0.2086258083581924\n",
      "Epoch [824/1000] , Step [30/40] , Loss: 0.2013873606920242\n",
      "Epoch [824/1000] , Step [40/40] , Loss: 0.1988908201456070\n",
      "Epoch [825/1000] , Step [10/40] , Loss: 0.1922325640916824\n",
      "Epoch [825/1000] , Step [20/40] , Loss: 0.2112131118774414\n",
      "Epoch [825/1000] , Step [30/40] , Loss: 0.2135824412107468\n",
      "Epoch [825/1000] , Step [40/40] , Loss: 0.2083726972341537\n",
      "Epoch [826/1000] , Step [10/40] , Loss: 0.1949808597564697\n",
      "Epoch [826/1000] , Step [20/40] , Loss: 0.2086492627859116\n",
      "Epoch [826/1000] , Step [30/40] , Loss: 0.1829835623502731\n",
      "Epoch [826/1000] , Step [40/40] , Loss: 0.2115164995193481\n",
      "Epoch [827/1000] , Step [10/40] , Loss: 0.1821522563695908\n",
      "Epoch [827/1000] , Step [20/40] , Loss: 0.2017617523670197\n",
      "Epoch [827/1000] , Step [30/40] , Loss: 0.2064789831638336\n",
      "Epoch [827/1000] , Step [40/40] , Loss: 0.1968081891536713\n",
      "Epoch [828/1000] , Step [10/40] , Loss: 0.2080843448638916\n",
      "Epoch [828/1000] , Step [20/40] , Loss: 0.1869533956050873\n",
      "Epoch [828/1000] , Step [30/40] , Loss: 0.1928224116563797\n",
      "Epoch [828/1000] , Step [40/40] , Loss: 0.2129145115613937\n",
      "Epoch [829/1000] , Step [10/40] , Loss: 0.2187484204769135\n",
      "Epoch [829/1000] , Step [20/40] , Loss: 0.2122970223426819\n",
      "Epoch [829/1000] , Step [30/40] , Loss: 0.2048582136631012\n",
      "Epoch [829/1000] , Step [40/40] , Loss: 0.2051243185997009\n",
      "Epoch [830/1000] , Step [10/40] , Loss: 0.2025773078203201\n",
      "Epoch [830/1000] , Step [20/40] , Loss: 0.2234462499618530\n",
      "Epoch [830/1000] , Step [30/40] , Loss: 0.1998554468154907\n",
      "Epoch [830/1000] , Step [40/40] , Loss: 0.2081663459539413\n",
      "Epoch [831/1000] , Step [10/40] , Loss: 0.1803579777479172\n",
      "Epoch [831/1000] , Step [20/40] , Loss: 0.2104513645172119\n",
      "Epoch [831/1000] , Step [30/40] , Loss: 0.2061594426631927\n",
      "Epoch [831/1000] , Step [40/40] , Loss: 0.1847133338451385\n",
      "Epoch [832/1000] , Step [10/40] , Loss: 0.2107599377632141\n",
      "Epoch [832/1000] , Step [20/40] , Loss: 0.2073992490768433\n",
      "Epoch [832/1000] , Step [30/40] , Loss: 0.1869814395904541\n",
      "Epoch [832/1000] , Step [40/40] , Loss: 0.1901506036520004\n",
      "Epoch [833/1000] , Step [10/40] , Loss: 0.2209010571241379\n",
      "Epoch [833/1000] , Step [20/40] , Loss: 0.1953079551458359\n",
      "Epoch [833/1000] , Step [30/40] , Loss: 0.1936736702919006\n",
      "Epoch [833/1000] , Step [40/40] , Loss: 0.1894224882125854\n",
      "Epoch [834/1000] , Step [10/40] , Loss: 0.1896933615207672\n",
      "Epoch [834/1000] , Step [20/40] , Loss: 0.2031071782112122\n",
      "Epoch [834/1000] , Step [30/40] , Loss: 0.2122078984975815\n",
      "Epoch [834/1000] , Step [40/40] , Loss: 0.1934368610382080\n",
      "Epoch [835/1000] , Step [10/40] , Loss: 0.1836771517992020\n",
      "Epoch [835/1000] , Step [20/40] , Loss: 0.2110317349433899\n",
      "Epoch [835/1000] , Step [30/40] , Loss: 0.2027744650840759\n",
      "Epoch [835/1000] , Step [40/40] , Loss: 0.2225371003150940\n",
      "Epoch [836/1000] , Step [10/40] , Loss: 0.2071001827716827\n",
      "Epoch [836/1000] , Step [20/40] , Loss: 0.2102206200361252\n",
      "Epoch [836/1000] , Step [30/40] , Loss: 0.2084402441978455\n",
      "Epoch [836/1000] , Step [40/40] , Loss: 0.1856365799903870\n",
      "Epoch [837/1000] , Step [10/40] , Loss: 0.2033616155385971\n",
      "Epoch [837/1000] , Step [20/40] , Loss: 0.1982523649930954\n",
      "Epoch [837/1000] , Step [30/40] , Loss: 0.2262903153896332\n",
      "Epoch [837/1000] , Step [40/40] , Loss: 0.2218681275844574\n",
      "Epoch [838/1000] , Step [10/40] , Loss: 0.2165250480175018\n",
      "Epoch [838/1000] , Step [20/40] , Loss: 0.1971964240074158\n",
      "Epoch [838/1000] , Step [30/40] , Loss: 0.1951041966676712\n",
      "Epoch [838/1000] , Step [40/40] , Loss: 0.1847203969955444\n",
      "Epoch [839/1000] , Step [10/40] , Loss: 0.2191943675279617\n",
      "Epoch [839/1000] , Step [20/40] , Loss: 0.2195132523775101\n",
      "Epoch [839/1000] , Step [30/40] , Loss: 0.2140838205814362\n",
      "Epoch [839/1000] , Step [40/40] , Loss: 0.2177036553621292\n",
      "Epoch [840/1000] , Step [10/40] , Loss: 0.2193684726953506\n",
      "Epoch [840/1000] , Step [20/40] , Loss: 0.1972430050373077\n",
      "Epoch [840/1000] , Step [30/40] , Loss: 0.2080238461494446\n",
      "Epoch [840/1000] , Step [40/40] , Loss: 0.1970267742872238\n",
      "Epoch [841/1000] , Step [10/40] , Loss: 0.1826391667127609\n",
      "Epoch [841/1000] , Step [20/40] , Loss: 0.2152325958013535\n",
      "Epoch [841/1000] , Step [30/40] , Loss: 0.2005326598882675\n",
      "Epoch [841/1000] , Step [40/40] , Loss: 0.2105690836906433\n",
      "Epoch [842/1000] , Step [10/40] , Loss: 0.2076166272163391\n",
      "Epoch [842/1000] , Step [20/40] , Loss: 0.2122320085763931\n",
      "Epoch [842/1000] , Step [30/40] , Loss: 0.2007066905498505\n",
      "Epoch [842/1000] , Step [40/40] , Loss: 0.1842931658029556\n",
      "Epoch [843/1000] , Step [10/40] , Loss: 0.2025388479232788\n",
      "Epoch [843/1000] , Step [20/40] , Loss: 0.1893656551837921\n",
      "Epoch [843/1000] , Step [30/40] , Loss: 0.2218802571296692\n",
      "Epoch [843/1000] , Step [40/40] , Loss: 0.1930817365646362\n",
      "Epoch [844/1000] , Step [10/40] , Loss: 0.2074799537658691\n",
      "Epoch [844/1000] , Step [20/40] , Loss: 0.1966916173696518\n",
      "Epoch [844/1000] , Step [30/40] , Loss: 0.1981441676616669\n",
      "Epoch [844/1000] , Step [40/40] , Loss: 0.1920699775218964\n",
      "Epoch [845/1000] , Step [10/40] , Loss: 0.2056463062763214\n",
      "Epoch [845/1000] , Step [20/40] , Loss: 0.2018152177333832\n",
      "Epoch [845/1000] , Step [30/40] , Loss: 0.2002319395542145\n",
      "Epoch [845/1000] , Step [40/40] , Loss: 0.1906434446573257\n",
      "Epoch [846/1000] , Step [10/40] , Loss: 0.2138273268938065\n",
      "Epoch [846/1000] , Step [20/40] , Loss: 0.2151098549365997\n",
      "Epoch [846/1000] , Step [30/40] , Loss: 0.2035671323537827\n",
      "Epoch [846/1000] , Step [40/40] , Loss: 0.2060865610837936\n",
      "Epoch [847/1000] , Step [10/40] , Loss: 0.1984511762857437\n",
      "Epoch [847/1000] , Step [20/40] , Loss: 0.2144642174243927\n",
      "Epoch [847/1000] , Step [30/40] , Loss: 0.1939566880464554\n",
      "Epoch [847/1000] , Step [40/40] , Loss: 0.2232416570186615\n",
      "Epoch [848/1000] , Step [10/40] , Loss: 0.2020985633134842\n",
      "Epoch [848/1000] , Step [20/40] , Loss: 0.2252530753612518\n",
      "Epoch [848/1000] , Step [30/40] , Loss: 0.2077911943197250\n",
      "Epoch [848/1000] , Step [40/40] , Loss: 0.2071726471185684\n",
      "Epoch [849/1000] , Step [10/40] , Loss: 0.2006337195634842\n",
      "Epoch [849/1000] , Step [20/40] , Loss: 0.2036735415458679\n",
      "Epoch [849/1000] , Step [30/40] , Loss: 0.1902160346508026\n",
      "Epoch [849/1000] , Step [40/40] , Loss: 0.2077021896839142\n",
      "Epoch [850/1000] , Step [10/40] , Loss: 0.2097143232822418\n",
      "Epoch [850/1000] , Step [20/40] , Loss: 0.2184325456619263\n",
      "Epoch [850/1000] , Step [30/40] , Loss: 0.1825172007083893\n",
      "Epoch [850/1000] , Step [40/40] , Loss: 0.1853434294462204\n",
      "Epoch [851/1000] , Step [10/40] , Loss: 0.2010686695575714\n",
      "Epoch [851/1000] , Step [20/40] , Loss: 0.1974254399538040\n",
      "Epoch [851/1000] , Step [30/40] , Loss: 0.1927549988031387\n",
      "Epoch [851/1000] , Step [40/40] , Loss: 0.1801673322916031\n",
      "Epoch [852/1000] , Step [10/40] , Loss: 0.1929707527160645\n",
      "Epoch [852/1000] , Step [20/40] , Loss: 0.1996165812015533\n",
      "Epoch [852/1000] , Step [30/40] , Loss: 0.1847044229507446\n",
      "Epoch [852/1000] , Step [40/40] , Loss: 0.2069168090820312\n",
      "Epoch [853/1000] , Step [10/40] , Loss: 0.2036452144384384\n",
      "Epoch [853/1000] , Step [20/40] , Loss: 0.1966893523931503\n",
      "Epoch [853/1000] , Step [30/40] , Loss: 0.2069955468177795\n",
      "Epoch [853/1000] , Step [40/40] , Loss: 0.1763177812099457\n",
      "Epoch [854/1000] , Step [10/40] , Loss: 0.1921590119600296\n",
      "Epoch [854/1000] , Step [20/40] , Loss: 0.2043488025665283\n",
      "Epoch [854/1000] , Step [30/40] , Loss: 0.2053636312484741\n",
      "Epoch [854/1000] , Step [40/40] , Loss: 0.2042998671531677\n",
      "Epoch [855/1000] , Step [10/40] , Loss: 0.2130289375782013\n",
      "Epoch [855/1000] , Step [20/40] , Loss: 0.2041809558868408\n",
      "Epoch [855/1000] , Step [30/40] , Loss: 0.2065283358097076\n",
      "Epoch [855/1000] , Step [40/40] , Loss: 0.1854709237813950\n",
      "Epoch [856/1000] , Step [10/40] , Loss: 0.2136355340480804\n",
      "Epoch [856/1000] , Step [20/40] , Loss: 0.2040769606828690\n",
      "Epoch [856/1000] , Step [30/40] , Loss: 0.2019436508417130\n",
      "Epoch [856/1000] , Step [40/40] , Loss: 0.1909030675888062\n",
      "Epoch [857/1000] , Step [10/40] , Loss: 0.1932486593723297\n",
      "Epoch [857/1000] , Step [20/40] , Loss: 0.1879432648420334\n",
      "Epoch [857/1000] , Step [30/40] , Loss: 0.2078688889741898\n",
      "Epoch [857/1000] , Step [40/40] , Loss: 0.1908850669860840\n",
      "Epoch [858/1000] , Step [10/40] , Loss: 0.2079057693481445\n",
      "Epoch [858/1000] , Step [20/40] , Loss: 0.2126759439706802\n",
      "Epoch [858/1000] , Step [30/40] , Loss: 0.1938666701316833\n",
      "Epoch [858/1000] , Step [40/40] , Loss: 0.2189106345176697\n",
      "Epoch [859/1000] , Step [10/40] , Loss: 0.2154559493064880\n",
      "Epoch [859/1000] , Step [20/40] , Loss: 0.2255829423666000\n",
      "Epoch [859/1000] , Step [30/40] , Loss: 0.2119799405336380\n",
      "Epoch [859/1000] , Step [40/40] , Loss: 0.2249496132135391\n",
      "Epoch [860/1000] , Step [10/40] , Loss: 0.2339681982994080\n",
      "Epoch [860/1000] , Step [20/40] , Loss: 0.1721618175506592\n",
      "Epoch [860/1000] , Step [30/40] , Loss: 0.2187535762786865\n",
      "Epoch [860/1000] , Step [40/40] , Loss: 0.1905882954597473\n",
      "Epoch [861/1000] , Step [10/40] , Loss: 0.1781765520572662\n",
      "Epoch [861/1000] , Step [20/40] , Loss: 0.2045872807502747\n",
      "Epoch [861/1000] , Step [30/40] , Loss: 0.1941940635442734\n",
      "Epoch [861/1000] , Step [40/40] , Loss: 0.1870942562818527\n",
      "Epoch [862/1000] , Step [10/40] , Loss: 0.1849847882986069\n",
      "Epoch [862/1000] , Step [20/40] , Loss: 0.2072873413562775\n",
      "Epoch [862/1000] , Step [30/40] , Loss: 0.2060153931379318\n",
      "Epoch [862/1000] , Step [40/40] , Loss: 0.1797269135713577\n",
      "Epoch [863/1000] , Step [10/40] , Loss: 0.2073131948709488\n",
      "Epoch [863/1000] , Step [20/40] , Loss: 0.1963404268026352\n",
      "Epoch [863/1000] , Step [30/40] , Loss: 0.1843142062425613\n",
      "Epoch [863/1000] , Step [40/40] , Loss: 0.2097309231758118\n",
      "Epoch [864/1000] , Step [10/40] , Loss: 0.2146168351173401\n",
      "Epoch [864/1000] , Step [20/40] , Loss: 0.1946666687726974\n",
      "Epoch [864/1000] , Step [30/40] , Loss: 0.2114548385143280\n",
      "Epoch [864/1000] , Step [40/40] , Loss: 0.1622895896434784\n",
      "Epoch [865/1000] , Step [10/40] , Loss: 0.2139033675193787\n",
      "Epoch [865/1000] , Step [20/40] , Loss: 0.1870330423116684\n",
      "Epoch [865/1000] , Step [30/40] , Loss: 0.1949950009584427\n",
      "Epoch [865/1000] , Step [40/40] , Loss: 0.2074178904294968\n",
      "Epoch [866/1000] , Step [10/40] , Loss: 0.2110584378242493\n",
      "Epoch [866/1000] , Step [20/40] , Loss: 0.1883659213781357\n",
      "Epoch [866/1000] , Step [30/40] , Loss: 0.1788955777883530\n",
      "Epoch [866/1000] , Step [40/40] , Loss: 0.2010972648859024\n",
      "Epoch [867/1000] , Step [10/40] , Loss: 0.1897577792406082\n",
      "Epoch [867/1000] , Step [20/40] , Loss: 0.2002929598093033\n",
      "Epoch [867/1000] , Step [30/40] , Loss: 0.2067236900329590\n",
      "Epoch [867/1000] , Step [40/40] , Loss: 0.2100605070590973\n",
      "Epoch [868/1000] , Step [10/40] , Loss: 0.2152704894542694\n",
      "Epoch [868/1000] , Step [20/40] , Loss: 0.2079336047172546\n",
      "Epoch [868/1000] , Step [30/40] , Loss: 0.2105807512998581\n",
      "Epoch [868/1000] , Step [40/40] , Loss: 0.2111261785030365\n",
      "Epoch [869/1000] , Step [10/40] , Loss: 0.1835654079914093\n",
      "Epoch [869/1000] , Step [20/40] , Loss: 0.2174722552299500\n",
      "Epoch [869/1000] , Step [30/40] , Loss: 0.2019585222005844\n",
      "Epoch [869/1000] , Step [40/40] , Loss: 0.2210076153278351\n",
      "Epoch [870/1000] , Step [10/40] , Loss: 0.2001319676637650\n",
      "Epoch [870/1000] , Step [20/40] , Loss: 0.2101527750492096\n",
      "Epoch [870/1000] , Step [30/40] , Loss: 0.1944112330675125\n",
      "Epoch [870/1000] , Step [40/40] , Loss: 0.1818336099386215\n",
      "Epoch [871/1000] , Step [10/40] , Loss: 0.1992526799440384\n",
      "Epoch [871/1000] , Step [20/40] , Loss: 0.2155772447586060\n",
      "Epoch [871/1000] , Step [30/40] , Loss: 0.2040639817714691\n",
      "Epoch [871/1000] , Step [40/40] , Loss: 0.1942183524370193\n",
      "Epoch [872/1000] , Step [10/40] , Loss: 0.2177345752716064\n",
      "Epoch [872/1000] , Step [20/40] , Loss: 0.1942566484212875\n",
      "Epoch [872/1000] , Step [30/40] , Loss: 0.2068135589361191\n",
      "Epoch [872/1000] , Step [40/40] , Loss: 0.2048571556806564\n",
      "Epoch [873/1000] , Step [10/40] , Loss: 0.1903281211853027\n",
      "Epoch [873/1000] , Step [20/40] , Loss: 0.1920365542173386\n",
      "Epoch [873/1000] , Step [30/40] , Loss: 0.1978468298912048\n",
      "Epoch [873/1000] , Step [40/40] , Loss: 0.2034090757369995\n",
      "Epoch [874/1000] , Step [10/40] , Loss: 0.2021670490503311\n",
      "Epoch [874/1000] , Step [20/40] , Loss: 0.2034172564744949\n",
      "Epoch [874/1000] , Step [30/40] , Loss: 0.1772324144840240\n",
      "Epoch [874/1000] , Step [40/40] , Loss: 0.1890668720006943\n",
      "Epoch [875/1000] , Step [10/40] , Loss: 0.2039291709661484\n",
      "Epoch [875/1000] , Step [20/40] , Loss: 0.2053102105855942\n",
      "Epoch [875/1000] , Step [30/40] , Loss: 0.1949446052312851\n",
      "Epoch [875/1000] , Step [40/40] , Loss: 0.1845219433307648\n",
      "Epoch [876/1000] , Step [10/40] , Loss: 0.1938351988792419\n",
      "Epoch [876/1000] , Step [20/40] , Loss: 0.1860264837741852\n",
      "Epoch [876/1000] , Step [30/40] , Loss: 0.1891986876726151\n",
      "Epoch [876/1000] , Step [40/40] , Loss: 0.1938822716474533\n",
      "Epoch [877/1000] , Step [10/40] , Loss: 0.1807174831628799\n",
      "Epoch [877/1000] , Step [20/40] , Loss: 0.1945341825485229\n",
      "Epoch [877/1000] , Step [30/40] , Loss: 0.1976695209741592\n",
      "Epoch [877/1000] , Step [40/40] , Loss: 0.2040391117334366\n",
      "Epoch [878/1000] , Step [10/40] , Loss: 0.1990318000316620\n",
      "Epoch [878/1000] , Step [20/40] , Loss: 0.2042074799537659\n",
      "Epoch [878/1000] , Step [30/40] , Loss: 0.1935490965843201\n",
      "Epoch [878/1000] , Step [40/40] , Loss: 0.1907954216003418\n",
      "Epoch [879/1000] , Step [10/40] , Loss: 0.1822930872440338\n",
      "Epoch [879/1000] , Step [20/40] , Loss: 0.1952415555715561\n",
      "Epoch [879/1000] , Step [30/40] , Loss: 0.1815451532602310\n",
      "Epoch [879/1000] , Step [40/40] , Loss: 0.1970005929470062\n",
      "Epoch [880/1000] , Step [10/40] , Loss: 0.1946161389350891\n",
      "Epoch [880/1000] , Step [20/40] , Loss: 0.1832234710454941\n",
      "Epoch [880/1000] , Step [30/40] , Loss: 0.2045952677726746\n",
      "Epoch [880/1000] , Step [40/40] , Loss: 0.1804711371660233\n",
      "Epoch [881/1000] , Step [10/40] , Loss: 0.2100330889225006\n",
      "Epoch [881/1000] , Step [20/40] , Loss: 0.1917277276515961\n",
      "Epoch [881/1000] , Step [30/40] , Loss: 0.1605594307184219\n",
      "Epoch [881/1000] , Step [40/40] , Loss: 0.2215624153614044\n",
      "Epoch [882/1000] , Step [10/40] , Loss: 0.2087304890155792\n",
      "Epoch [882/1000] , Step [20/40] , Loss: 0.1922214627265930\n",
      "Epoch [882/1000] , Step [30/40] , Loss: 0.1972120851278305\n",
      "Epoch [882/1000] , Step [40/40] , Loss: 0.2106646597385406\n",
      "Epoch [883/1000] , Step [10/40] , Loss: 0.1904443353414536\n",
      "Epoch [883/1000] , Step [20/40] , Loss: 0.1890174746513367\n",
      "Epoch [883/1000] , Step [30/40] , Loss: 0.1862884759902954\n",
      "Epoch [883/1000] , Step [40/40] , Loss: 0.1924170404672623\n",
      "Epoch [884/1000] , Step [10/40] , Loss: 0.1990850269794464\n",
      "Epoch [884/1000] , Step [20/40] , Loss: 0.1894303262233734\n",
      "Epoch [884/1000] , Step [30/40] , Loss: 0.1914225071668625\n",
      "Epoch [884/1000] , Step [40/40] , Loss: 0.2021535933017731\n",
      "Epoch [885/1000] , Step [10/40] , Loss: 0.2043394297361374\n",
      "Epoch [885/1000] , Step [20/40] , Loss: 0.2076793909072876\n",
      "Epoch [885/1000] , Step [30/40] , Loss: 0.2004615813493729\n",
      "Epoch [885/1000] , Step [40/40] , Loss: 0.2100554406642914\n",
      "Epoch [886/1000] , Step [10/40] , Loss: 0.1834456026554108\n",
      "Epoch [886/1000] , Step [20/40] , Loss: 0.1881559193134308\n",
      "Epoch [886/1000] , Step [30/40] , Loss: 0.2139279842376709\n",
      "Epoch [886/1000] , Step [40/40] , Loss: 0.2192864716053009\n",
      "Epoch [887/1000] , Step [10/40] , Loss: 0.1984231323003769\n",
      "Epoch [887/1000] , Step [20/40] , Loss: 0.1695051640272141\n",
      "Epoch [887/1000] , Step [30/40] , Loss: 0.2056678384542465\n",
      "Epoch [887/1000] , Step [40/40] , Loss: 0.2067175358533859\n",
      "Epoch [888/1000] , Step [10/40] , Loss: 0.2021716982126236\n",
      "Epoch [888/1000] , Step [20/40] , Loss: 0.1859593242406845\n",
      "Epoch [888/1000] , Step [30/40] , Loss: 0.2023469656705856\n",
      "Epoch [888/1000] , Step [40/40] , Loss: 0.1815435737371445\n",
      "Epoch [889/1000] , Step [10/40] , Loss: 0.1963710337877274\n",
      "Epoch [889/1000] , Step [20/40] , Loss: 0.2029057890176773\n",
      "Epoch [889/1000] , Step [30/40] , Loss: 0.1864276677370071\n",
      "Epoch [889/1000] , Step [40/40] , Loss: 0.1907968670129776\n",
      "Epoch [890/1000] , Step [10/40] , Loss: 0.2060925662517548\n",
      "Epoch [890/1000] , Step [20/40] , Loss: 0.2085699439048767\n",
      "Epoch [890/1000] , Step [30/40] , Loss: 0.1873830556869507\n",
      "Epoch [890/1000] , Step [40/40] , Loss: 0.1903204023838043\n",
      "Epoch [891/1000] , Step [10/40] , Loss: 0.2117468118667603\n",
      "Epoch [891/1000] , Step [20/40] , Loss: 0.1832156926393509\n",
      "Epoch [891/1000] , Step [30/40] , Loss: 0.2035353630781174\n",
      "Epoch [891/1000] , Step [40/40] , Loss: 0.2064046561717987\n",
      "Epoch [892/1000] , Step [10/40] , Loss: 0.1891089677810669\n",
      "Epoch [892/1000] , Step [20/40] , Loss: 0.1936560124158859\n",
      "Epoch [892/1000] , Step [30/40] , Loss: 0.1948934942483902\n",
      "Epoch [892/1000] , Step [40/40] , Loss: 0.1929828673601151\n",
      "Epoch [893/1000] , Step [10/40] , Loss: 0.1926596015691757\n",
      "Epoch [893/1000] , Step [20/40] , Loss: 0.1847970485687256\n",
      "Epoch [893/1000] , Step [30/40] , Loss: 0.2171950638294220\n",
      "Epoch [893/1000] , Step [40/40] , Loss: 0.1760457605123520\n",
      "Epoch [894/1000] , Step [10/40] , Loss: 0.1855534315109253\n",
      "Epoch [894/1000] , Step [20/40] , Loss: 0.2119892388582230\n",
      "Epoch [894/1000] , Step [30/40] , Loss: 0.2018331140279770\n",
      "Epoch [894/1000] , Step [40/40] , Loss: 0.1823777109384537\n",
      "Epoch [895/1000] , Step [10/40] , Loss: 0.2044821977615356\n",
      "Epoch [895/1000] , Step [20/40] , Loss: 0.1852677017450333\n",
      "Epoch [895/1000] , Step [30/40] , Loss: 0.1773733794689178\n",
      "Epoch [895/1000] , Step [40/40] , Loss: 0.2071259468793869\n",
      "Epoch [896/1000] , Step [10/40] , Loss: 0.1985382139682770\n",
      "Epoch [896/1000] , Step [20/40] , Loss: 0.1941866278648376\n",
      "Epoch [896/1000] , Step [30/40] , Loss: 0.1973452568054199\n",
      "Epoch [896/1000] , Step [40/40] , Loss: 0.1690241992473602\n",
      "Epoch [897/1000] , Step [10/40] , Loss: 0.1669110953807831\n",
      "Epoch [897/1000] , Step [20/40] , Loss: 0.2069422751665115\n",
      "Epoch [897/1000] , Step [30/40] , Loss: 0.1952834278345108\n",
      "Epoch [897/1000] , Step [40/40] , Loss: 0.2120210230350494\n",
      "Epoch [898/1000] , Step [10/40] , Loss: 0.2101761549711227\n",
      "Epoch [898/1000] , Step [20/40] , Loss: 0.1901106238365173\n",
      "Epoch [898/1000] , Step [30/40] , Loss: 0.1968461722135544\n",
      "Epoch [898/1000] , Step [40/40] , Loss: 0.2107284665107727\n",
      "Epoch [899/1000] , Step [10/40] , Loss: 0.1763064265251160\n",
      "Epoch [899/1000] , Step [20/40] , Loss: 0.1860491782426834\n",
      "Epoch [899/1000] , Step [30/40] , Loss: 0.1838960647583008\n",
      "Epoch [899/1000] , Step [40/40] , Loss: 0.1937129199504852\n",
      "Epoch [900/1000] , Step [10/40] , Loss: 0.1956615895032883\n",
      "Epoch [900/1000] , Step [20/40] , Loss: 0.1969722658395767\n",
      "Epoch [900/1000] , Step [30/40] , Loss: 0.1910669952630997\n",
      "Epoch [900/1000] , Step [40/40] , Loss: 0.2112124562263489\n",
      "Epoch [901/1000] , Step [10/40] , Loss: 0.1964457780122757\n",
      "Epoch [901/1000] , Step [20/40] , Loss: 0.1854646205902100\n",
      "Epoch [901/1000] , Step [30/40] , Loss: 0.1869945973157883\n",
      "Epoch [901/1000] , Step [40/40] , Loss: 0.1992727965116501\n",
      "Epoch [902/1000] , Step [10/40] , Loss: 0.1940455436706543\n",
      "Epoch [902/1000] , Step [20/40] , Loss: 0.2022873461246490\n",
      "Epoch [902/1000] , Step [30/40] , Loss: 0.2025318145751953\n",
      "Epoch [902/1000] , Step [40/40] , Loss: 0.1816817671060562\n",
      "Epoch [903/1000] , Step [10/40] , Loss: 0.2111620306968689\n",
      "Epoch [903/1000] , Step [20/40] , Loss: 0.1920283436775208\n",
      "Epoch [903/1000] , Step [30/40] , Loss: 0.1806814521551132\n",
      "Epoch [903/1000] , Step [40/40] , Loss: 0.1996193081140518\n",
      "Epoch [904/1000] , Step [10/40] , Loss: 0.1989821791648865\n",
      "Epoch [904/1000] , Step [20/40] , Loss: 0.1943161040544510\n",
      "Epoch [904/1000] , Step [30/40] , Loss: 0.1986428797245026\n",
      "Epoch [904/1000] , Step [40/40] , Loss: 0.1938651055097580\n",
      "Epoch [905/1000] , Step [10/40] , Loss: 0.2161743193864822\n",
      "Epoch [905/1000] , Step [20/40] , Loss: 0.1909053623676300\n",
      "Epoch [905/1000] , Step [30/40] , Loss: 0.1955302208662033\n",
      "Epoch [905/1000] , Step [40/40] , Loss: 0.1847424060106277\n",
      "Epoch [906/1000] , Step [10/40] , Loss: 0.2023161053657532\n",
      "Epoch [906/1000] , Step [20/40] , Loss: 0.1822873950004578\n",
      "Epoch [906/1000] , Step [30/40] , Loss: 0.2186839729547501\n",
      "Epoch [906/1000] , Step [40/40] , Loss: 0.1907573491334915\n",
      "Epoch [907/1000] , Step [10/40] , Loss: 0.2081099152565002\n",
      "Epoch [907/1000] , Step [20/40] , Loss: 0.1909083127975464\n",
      "Epoch [907/1000] , Step [30/40] , Loss: 0.1937523186206818\n",
      "Epoch [907/1000] , Step [40/40] , Loss: 0.1872583925724030\n",
      "Epoch [908/1000] , Step [10/40] , Loss: 0.1911524087190628\n",
      "Epoch [908/1000] , Step [20/40] , Loss: 0.1986128836870193\n",
      "Epoch [908/1000] , Step [30/40] , Loss: 0.1934836506843567\n",
      "Epoch [908/1000] , Step [40/40] , Loss: 0.1886852234601974\n",
      "Epoch [909/1000] , Step [10/40] , Loss: 0.2161068618297577\n",
      "Epoch [909/1000] , Step [20/40] , Loss: 0.1896626949310303\n",
      "Epoch [909/1000] , Step [30/40] , Loss: 0.2151153832674026\n",
      "Epoch [909/1000] , Step [40/40] , Loss: 0.1895173788070679\n",
      "Epoch [910/1000] , Step [10/40] , Loss: 0.1842626184225082\n",
      "Epoch [910/1000] , Step [20/40] , Loss: 0.1899690181016922\n",
      "Epoch [910/1000] , Step [30/40] , Loss: 0.2016296386718750\n",
      "Epoch [910/1000] , Step [40/40] , Loss: 0.1934087127447128\n",
      "Epoch [911/1000] , Step [10/40] , Loss: 0.1911118775606155\n",
      "Epoch [911/1000] , Step [20/40] , Loss: 0.1753431111574173\n",
      "Epoch [911/1000] , Step [30/40] , Loss: 0.2011207938194275\n",
      "Epoch [911/1000] , Step [40/40] , Loss: 0.2178858071565628\n",
      "Epoch [912/1000] , Step [10/40] , Loss: 0.2013735771179199\n",
      "Epoch [912/1000] , Step [20/40] , Loss: 0.2047516405582428\n",
      "Epoch [912/1000] , Step [30/40] , Loss: 0.1898716837167740\n",
      "Epoch [912/1000] , Step [40/40] , Loss: 0.1780121028423309\n",
      "Epoch [913/1000] , Step [10/40] , Loss: 0.1974219679832458\n",
      "Epoch [913/1000] , Step [20/40] , Loss: 0.2027331441640854\n",
      "Epoch [913/1000] , Step [30/40] , Loss: 0.2114021331071854\n",
      "Epoch [913/1000] , Step [40/40] , Loss: 0.2097792923450470\n",
      "Epoch [914/1000] , Step [10/40] , Loss: 0.1704230010509491\n",
      "Epoch [914/1000] , Step [20/40] , Loss: 0.2047836184501648\n",
      "Epoch [914/1000] , Step [30/40] , Loss: 0.1843267679214478\n",
      "Epoch [914/1000] , Step [40/40] , Loss: 0.2030562311410904\n",
      "Epoch [915/1000] , Step [10/40] , Loss: 0.1831364184617996\n",
      "Epoch [915/1000] , Step [20/40] , Loss: 0.2012854367494583\n",
      "Epoch [915/1000] , Step [30/40] , Loss: 0.1896239072084427\n",
      "Epoch [915/1000] , Step [40/40] , Loss: 0.1920657306909561\n",
      "Epoch [916/1000] , Step [10/40] , Loss: 0.1912117153406143\n",
      "Epoch [916/1000] , Step [20/40] , Loss: 0.1844778805971146\n",
      "Epoch [916/1000] , Step [30/40] , Loss: 0.2018944472074509\n",
      "Epoch [916/1000] , Step [40/40] , Loss: 0.2049731314182281\n",
      "Epoch [917/1000] , Step [10/40] , Loss: 0.1806697845458984\n",
      "Epoch [917/1000] , Step [20/40] , Loss: 0.1951850205659866\n",
      "Epoch [917/1000] , Step [30/40] , Loss: 0.1752509921789169\n",
      "Epoch [917/1000] , Step [40/40] , Loss: 0.1982314735651016\n",
      "Epoch [918/1000] , Step [10/40] , Loss: 0.1777964383363724\n",
      "Epoch [918/1000] , Step [20/40] , Loss: 0.1824001073837280\n",
      "Epoch [918/1000] , Step [30/40] , Loss: 0.1969873160123825\n",
      "Epoch [918/1000] , Step [40/40] , Loss: 0.2042321264743805\n",
      "Epoch [919/1000] , Step [10/40] , Loss: 0.1913076043128967\n",
      "Epoch [919/1000] , Step [20/40] , Loss: 0.1994767636060715\n",
      "Epoch [919/1000] , Step [30/40] , Loss: 0.1933700889348984\n",
      "Epoch [919/1000] , Step [40/40] , Loss: 0.1689793318510056\n",
      "Epoch [920/1000] , Step [10/40] , Loss: 0.2015074640512466\n",
      "Epoch [920/1000] , Step [20/40] , Loss: 0.1813138723373413\n",
      "Epoch [920/1000] , Step [30/40] , Loss: 0.2017236351966858\n",
      "Epoch [920/1000] , Step [40/40] , Loss: 0.1809866875410080\n",
      "Epoch [921/1000] , Step [10/40] , Loss: 0.2058455795049667\n",
      "Epoch [921/1000] , Step [20/40] , Loss: 0.1663956195116043\n",
      "Epoch [921/1000] , Step [30/40] , Loss: 0.2059118449687958\n",
      "Epoch [921/1000] , Step [40/40] , Loss: 0.2012585401535034\n",
      "Epoch [922/1000] , Step [10/40] , Loss: 0.1870409697294235\n",
      "Epoch [922/1000] , Step [20/40] , Loss: 0.1939521878957748\n",
      "Epoch [922/1000] , Step [30/40] , Loss: 0.1898887157440186\n",
      "Epoch [922/1000] , Step [40/40] , Loss: 0.1960128843784332\n",
      "Epoch [923/1000] , Step [10/40] , Loss: 0.1988715976476669\n",
      "Epoch [923/1000] , Step [20/40] , Loss: 0.1986592561006546\n",
      "Epoch [923/1000] , Step [30/40] , Loss: 0.1938756555318832\n",
      "Epoch [923/1000] , Step [40/40] , Loss: 0.1964824646711349\n",
      "Epoch [924/1000] , Step [10/40] , Loss: 0.1907053589820862\n",
      "Epoch [924/1000] , Step [20/40] , Loss: 0.1865490376949310\n",
      "Epoch [924/1000] , Step [30/40] , Loss: 0.1728365272283554\n",
      "Epoch [924/1000] , Step [40/40] , Loss: 0.1804433166980743\n",
      "Epoch [925/1000] , Step [10/40] , Loss: 0.1807697862386703\n",
      "Epoch [925/1000] , Step [20/40] , Loss: 0.1906991153955460\n",
      "Epoch [925/1000] , Step [30/40] , Loss: 0.1872848123311996\n",
      "Epoch [925/1000] , Step [40/40] , Loss: 0.1836371868848801\n",
      "Epoch [926/1000] , Step [10/40] , Loss: 0.1907188892364502\n",
      "Epoch [926/1000] , Step [20/40] , Loss: 0.1915163546800613\n",
      "Epoch [926/1000] , Step [30/40] , Loss: 0.1895875483751297\n",
      "Epoch [926/1000] , Step [40/40] , Loss: 0.1873844414949417\n",
      "Epoch [927/1000] , Step [10/40] , Loss: 0.1977319270372391\n",
      "Epoch [927/1000] , Step [20/40] , Loss: 0.1837874203920364\n",
      "Epoch [927/1000] , Step [30/40] , Loss: 0.1937370598316193\n",
      "Epoch [927/1000] , Step [40/40] , Loss: 0.2045539021492004\n",
      "Epoch [928/1000] , Step [10/40] , Loss: 0.1796847283840179\n",
      "Epoch [928/1000] , Step [20/40] , Loss: 0.2101156115531921\n",
      "Epoch [928/1000] , Step [30/40] , Loss: 0.2224196642637253\n",
      "Epoch [928/1000] , Step [40/40] , Loss: 0.1777466088533401\n",
      "Epoch [929/1000] , Step [10/40] , Loss: 0.1800248622894287\n",
      "Epoch [929/1000] , Step [20/40] , Loss: 0.1983774602413177\n",
      "Epoch [929/1000] , Step [30/40] , Loss: 0.2038183063268661\n",
      "Epoch [929/1000] , Step [40/40] , Loss: 0.2015969157218933\n",
      "Epoch [930/1000] , Step [10/40] , Loss: 0.1872548013925552\n",
      "Epoch [930/1000] , Step [20/40] , Loss: 0.1973805427551270\n",
      "Epoch [930/1000] , Step [30/40] , Loss: 0.1759707331657410\n",
      "Epoch [930/1000] , Step [40/40] , Loss: 0.1957712471485138\n",
      "Epoch [931/1000] , Step [10/40] , Loss: 0.1876141577959061\n",
      "Epoch [931/1000] , Step [20/40] , Loss: 0.1896742880344391\n",
      "Epoch [931/1000] , Step [30/40] , Loss: 0.1951776891946793\n",
      "Epoch [931/1000] , Step [40/40] , Loss: 0.2049844563007355\n",
      "Epoch [932/1000] , Step [10/40] , Loss: 0.2022369652986526\n",
      "Epoch [932/1000] , Step [20/40] , Loss: 0.1934557259082794\n",
      "Epoch [932/1000] , Step [30/40] , Loss: 0.1854432076215744\n",
      "Epoch [932/1000] , Step [40/40] , Loss: 0.2028070539236069\n",
      "Epoch [933/1000] , Step [10/40] , Loss: 0.1853311210870743\n",
      "Epoch [933/1000] , Step [20/40] , Loss: 0.1945588588714600\n",
      "Epoch [933/1000] , Step [30/40] , Loss: 0.1983269900083542\n",
      "Epoch [933/1000] , Step [40/40] , Loss: 0.2002118080854416\n",
      "Epoch [934/1000] , Step [10/40] , Loss: 0.2021858096122742\n",
      "Epoch [934/1000] , Step [20/40] , Loss: 0.1874212324619293\n",
      "Epoch [934/1000] , Step [30/40] , Loss: 0.1842120289802551\n",
      "Epoch [934/1000] , Step [40/40] , Loss: 0.1734936237335205\n",
      "Epoch [935/1000] , Step [10/40] , Loss: 0.2193332314491272\n",
      "Epoch [935/1000] , Step [20/40] , Loss: 0.2069881409406662\n",
      "Epoch [935/1000] , Step [30/40] , Loss: 0.2074427902698517\n",
      "Epoch [935/1000] , Step [40/40] , Loss: 0.2016067206859589\n",
      "Epoch [936/1000] , Step [10/40] , Loss: 0.1702435314655304\n",
      "Epoch [936/1000] , Step [20/40] , Loss: 0.1904013007879257\n",
      "Epoch [936/1000] , Step [30/40] , Loss: 0.1874939650297165\n",
      "Epoch [936/1000] , Step [40/40] , Loss: 0.1707441210746765\n",
      "Epoch [937/1000] , Step [10/40] , Loss: 0.2154094129800797\n",
      "Epoch [937/1000] , Step [20/40] , Loss: 0.1997090578079224\n",
      "Epoch [937/1000] , Step [30/40] , Loss: 0.1677468419075012\n",
      "Epoch [937/1000] , Step [40/40] , Loss: 0.1925259530544281\n",
      "Epoch [938/1000] , Step [10/40] , Loss: 0.1995733678340912\n",
      "Epoch [938/1000] , Step [20/40] , Loss: 0.1949916183948517\n",
      "Epoch [938/1000] , Step [30/40] , Loss: 0.1970217972993851\n",
      "Epoch [938/1000] , Step [40/40] , Loss: 0.1846412718296051\n",
      "Epoch [939/1000] , Step [10/40] , Loss: 0.2011770457029343\n",
      "Epoch [939/1000] , Step [20/40] , Loss: 0.1845127940177917\n",
      "Epoch [939/1000] , Step [30/40] , Loss: 0.1806893199682236\n",
      "Epoch [939/1000] , Step [40/40] , Loss: 0.2045397162437439\n",
      "Epoch [940/1000] , Step [10/40] , Loss: 0.1776324510574341\n",
      "Epoch [940/1000] , Step [20/40] , Loss: 0.1969873458147049\n",
      "Epoch [940/1000] , Step [30/40] , Loss: 0.2011317759752274\n",
      "Epoch [940/1000] , Step [40/40] , Loss: 0.1924071162939072\n",
      "Epoch [941/1000] , Step [10/40] , Loss: 0.1987783163785934\n",
      "Epoch [941/1000] , Step [20/40] , Loss: 0.1856015622615814\n",
      "Epoch [941/1000] , Step [30/40] , Loss: 0.1967443823814392\n",
      "Epoch [941/1000] , Step [40/40] , Loss: 0.1603421568870544\n",
      "Epoch [942/1000] , Step [10/40] , Loss: 0.2023839205503464\n",
      "Epoch [942/1000] , Step [20/40] , Loss: 0.1867451816797256\n",
      "Epoch [942/1000] , Step [30/40] , Loss: 0.1825968474149704\n",
      "Epoch [942/1000] , Step [40/40] , Loss: 0.1735793501138687\n",
      "Epoch [943/1000] , Step [10/40] , Loss: 0.1728081405162811\n",
      "Epoch [943/1000] , Step [20/40] , Loss: 0.1996114104986191\n",
      "Epoch [943/1000] , Step [30/40] , Loss: 0.1882588863372803\n",
      "Epoch [943/1000] , Step [40/40] , Loss: 0.2005062103271484\n",
      "Epoch [944/1000] , Step [10/40] , Loss: 0.2085933685302734\n",
      "Epoch [944/1000] , Step [20/40] , Loss: 0.2023164927959442\n",
      "Epoch [944/1000] , Step [30/40] , Loss: 0.1923702806234360\n",
      "Epoch [944/1000] , Step [40/40] , Loss: 0.2067120969295502\n",
      "Epoch [945/1000] , Step [10/40] , Loss: 0.1914630234241486\n",
      "Epoch [945/1000] , Step [20/40] , Loss: 0.1862678676843643\n",
      "Epoch [945/1000] , Step [30/40] , Loss: 0.1689620316028595\n",
      "Epoch [945/1000] , Step [40/40] , Loss: 0.1776872724294662\n",
      "Epoch [946/1000] , Step [10/40] , Loss: 0.1861383765935898\n",
      "Epoch [946/1000] , Step [20/40] , Loss: 0.1826764643192291\n",
      "Epoch [946/1000] , Step [30/40] , Loss: 0.1980391293764114\n",
      "Epoch [946/1000] , Step [40/40] , Loss: 0.1977834254503250\n",
      "Epoch [947/1000] , Step [10/40] , Loss: 0.1739357411861420\n",
      "Epoch [947/1000] , Step [20/40] , Loss: 0.2076396793127060\n",
      "Epoch [947/1000] , Step [30/40] , Loss: 0.2067767083644867\n",
      "Epoch [947/1000] , Step [40/40] , Loss: 0.1889717876911163\n",
      "Epoch [948/1000] , Step [10/40] , Loss: 0.1925397962331772\n",
      "Epoch [948/1000] , Step [20/40] , Loss: 0.1880735456943512\n",
      "Epoch [948/1000] , Step [30/40] , Loss: 0.1773366630077362\n",
      "Epoch [948/1000] , Step [40/40] , Loss: 0.1849706172943115\n",
      "Epoch [949/1000] , Step [10/40] , Loss: 0.1804108470678329\n",
      "Epoch [949/1000] , Step [20/40] , Loss: 0.1916847825050354\n",
      "Epoch [949/1000] , Step [30/40] , Loss: 0.1958995461463928\n",
      "Epoch [949/1000] , Step [40/40] , Loss: 0.1859528571367264\n",
      "Epoch [950/1000] , Step [10/40] , Loss: 0.1825343668460846\n",
      "Epoch [950/1000] , Step [20/40] , Loss: 0.1800944209098816\n",
      "Epoch [950/1000] , Step [30/40] , Loss: 0.1868968009948730\n",
      "Epoch [950/1000] , Step [40/40] , Loss: 0.2062731981277466\n",
      "Epoch [951/1000] , Step [10/40] , Loss: 0.1834635883569717\n",
      "Epoch [951/1000] , Step [20/40] , Loss: 0.1778545528650284\n",
      "Epoch [951/1000] , Step [30/40] , Loss: 0.1944572031497955\n",
      "Epoch [951/1000] , Step [40/40] , Loss: 0.2067482769489288\n",
      "Epoch [952/1000] , Step [10/40] , Loss: 0.1835747212171555\n",
      "Epoch [952/1000] , Step [20/40] , Loss: 0.1943666338920593\n",
      "Epoch [952/1000] , Step [30/40] , Loss: 0.1775438636541367\n",
      "Epoch [952/1000] , Step [40/40] , Loss: 0.1668568700551987\n",
      "Epoch [953/1000] , Step [10/40] , Loss: 0.1832225620746613\n",
      "Epoch [953/1000] , Step [20/40] , Loss: 0.1849109083414078\n",
      "Epoch [953/1000] , Step [30/40] , Loss: 0.2083593904972076\n",
      "Epoch [953/1000] , Step [40/40] , Loss: 0.1803032755851746\n",
      "Epoch [954/1000] , Step [10/40] , Loss: 0.1847772598266602\n",
      "Epoch [954/1000] , Step [20/40] , Loss: 0.1701128482818604\n",
      "Epoch [954/1000] , Step [30/40] , Loss: 0.1709629595279694\n",
      "Epoch [954/1000] , Step [40/40] , Loss: 0.1831842958927155\n",
      "Epoch [955/1000] , Step [10/40] , Loss: 0.1893861442804337\n",
      "Epoch [955/1000] , Step [20/40] , Loss: 0.1844838559627533\n",
      "Epoch [955/1000] , Step [30/40] , Loss: 0.1855308562517166\n",
      "Epoch [955/1000] , Step [40/40] , Loss: 0.1826041638851166\n",
      "Epoch [956/1000] , Step [10/40] , Loss: 0.1837165802717209\n",
      "Epoch [956/1000] , Step [20/40] , Loss: 0.2033171802759171\n",
      "Epoch [956/1000] , Step [30/40] , Loss: 0.1974916458129883\n",
      "Epoch [956/1000] , Step [40/40] , Loss: 0.2011792808771133\n",
      "Epoch [957/1000] , Step [10/40] , Loss: 0.1936957985162735\n",
      "Epoch [957/1000] , Step [20/40] , Loss: 0.1790661215782166\n",
      "Epoch [957/1000] , Step [30/40] , Loss: 0.1947724670171738\n",
      "Epoch [957/1000] , Step [40/40] , Loss: 0.1923987120389938\n",
      "Epoch [958/1000] , Step [10/40] , Loss: 0.1897583156824112\n",
      "Epoch [958/1000] , Step [20/40] , Loss: 0.1928316652774811\n",
      "Epoch [958/1000] , Step [30/40] , Loss: 0.1752886921167374\n",
      "Epoch [958/1000] , Step [40/40] , Loss: 0.1837020516395569\n",
      "Epoch [959/1000] , Step [10/40] , Loss: 0.1862463206052780\n",
      "Epoch [959/1000] , Step [20/40] , Loss: 0.1956001520156860\n",
      "Epoch [959/1000] , Step [30/40] , Loss: 0.1963257044553757\n",
      "Epoch [959/1000] , Step [40/40] , Loss: 0.1678830832242966\n",
      "Epoch [960/1000] , Step [10/40] , Loss: 0.1877662092447281\n",
      "Epoch [960/1000] , Step [20/40] , Loss: 0.1734216511249542\n",
      "Epoch [960/1000] , Step [30/40] , Loss: 0.1875177472829819\n",
      "Epoch [960/1000] , Step [40/40] , Loss: 0.2159436494112015\n",
      "Epoch [961/1000] , Step [10/40] , Loss: 0.1905336976051331\n",
      "Epoch [961/1000] , Step [20/40] , Loss: 0.1909669488668442\n",
      "Epoch [961/1000] , Step [30/40] , Loss: 0.1693059355020523\n",
      "Epoch [961/1000] , Step [40/40] , Loss: 0.1837370395660400\n",
      "Epoch [962/1000] , Step [10/40] , Loss: 0.1900014430284500\n",
      "Epoch [962/1000] , Step [20/40] , Loss: 0.1830378323793411\n",
      "Epoch [962/1000] , Step [30/40] , Loss: 0.1972012221813202\n",
      "Epoch [962/1000] , Step [40/40] , Loss: 0.1758593022823334\n",
      "Epoch [963/1000] , Step [10/40] , Loss: 0.1814564615488052\n",
      "Epoch [963/1000] , Step [20/40] , Loss: 0.1840842366218567\n",
      "Epoch [963/1000] , Step [30/40] , Loss: 0.2017283886671066\n",
      "Epoch [963/1000] , Step [40/40] , Loss: 0.1777770668268204\n",
      "Epoch [964/1000] , Step [10/40] , Loss: 0.1846360266208649\n",
      "Epoch [964/1000] , Step [20/40] , Loss: 0.1868490576744080\n",
      "Epoch [964/1000] , Step [30/40] , Loss: 0.1958704292774200\n",
      "Epoch [964/1000] , Step [40/40] , Loss: 0.1663888096809387\n",
      "Epoch [965/1000] , Step [10/40] , Loss: 0.1637100726366043\n",
      "Epoch [965/1000] , Step [20/40] , Loss: 0.1773191988468170\n",
      "Epoch [965/1000] , Step [30/40] , Loss: 0.1836469322443008\n",
      "Epoch [965/1000] , Step [40/40] , Loss: 0.1892849951982498\n",
      "Epoch [966/1000] , Step [10/40] , Loss: 0.1855396628379822\n",
      "Epoch [966/1000] , Step [20/40] , Loss: 0.1888004094362259\n",
      "Epoch [966/1000] , Step [30/40] , Loss: 0.1792852133512497\n",
      "Epoch [966/1000] , Step [40/40] , Loss: 0.1824921071529388\n",
      "Epoch [967/1000] , Step [10/40] , Loss: 0.1888077557086945\n",
      "Epoch [967/1000] , Step [20/40] , Loss: 0.1974388509988785\n",
      "Epoch [967/1000] , Step [30/40] , Loss: 0.1971321702003479\n",
      "Epoch [967/1000] , Step [40/40] , Loss: 0.1763979345560074\n",
      "Epoch [968/1000] , Step [10/40] , Loss: 0.1965457201004028\n",
      "Epoch [968/1000] , Step [20/40] , Loss: 0.1772325634956360\n",
      "Epoch [968/1000] , Step [30/40] , Loss: 0.2018186151981354\n",
      "Epoch [968/1000] , Step [40/40] , Loss: 0.1958006918430328\n",
      "Epoch [969/1000] , Step [10/40] , Loss: 0.1794561743736267\n",
      "Epoch [969/1000] , Step [20/40] , Loss: 0.1752232760190964\n",
      "Epoch [969/1000] , Step [30/40] , Loss: 0.1854118853807449\n",
      "Epoch [969/1000] , Step [40/40] , Loss: 0.1767839938402176\n",
      "Epoch [970/1000] , Step [10/40] , Loss: 0.1889034807682037\n",
      "Epoch [970/1000] , Step [20/40] , Loss: 0.1902780085802078\n",
      "Epoch [970/1000] , Step [30/40] , Loss: 0.1754270493984222\n",
      "Epoch [970/1000] , Step [40/40] , Loss: 0.1728519946336746\n",
      "Epoch [971/1000] , Step [10/40] , Loss: 0.1866883635520935\n",
      "Epoch [971/1000] , Step [20/40] , Loss: 0.1997705996036530\n",
      "Epoch [971/1000] , Step [30/40] , Loss: 0.1933074891567230\n",
      "Epoch [971/1000] , Step [40/40] , Loss: 0.1903920918703079\n",
      "Epoch [972/1000] , Step [10/40] , Loss: 0.1791467964649200\n",
      "Epoch [972/1000] , Step [20/40] , Loss: 0.1962810456752777\n",
      "Epoch [972/1000] , Step [30/40] , Loss: 0.1888841539621353\n",
      "Epoch [972/1000] , Step [40/40] , Loss: 0.1949502974748611\n",
      "Epoch [973/1000] , Step [10/40] , Loss: 0.1891181617975235\n",
      "Epoch [973/1000] , Step [20/40] , Loss: 0.1853791773319244\n",
      "Epoch [973/1000] , Step [30/40] , Loss: 0.1705071181058884\n",
      "Epoch [973/1000] , Step [40/40] , Loss: 0.1739251464605331\n",
      "Epoch [974/1000] , Step [10/40] , Loss: 0.2045385539531708\n",
      "Epoch [974/1000] , Step [20/40] , Loss: 0.1748348921537399\n",
      "Epoch [974/1000] , Step [30/40] , Loss: 0.1868664920330048\n",
      "Epoch [974/1000] , Step [40/40] , Loss: 0.1406839489936829\n",
      "Epoch [975/1000] , Step [10/40] , Loss: 0.1856027245521545\n",
      "Epoch [975/1000] , Step [20/40] , Loss: 0.1875755637884140\n",
      "Epoch [975/1000] , Step [30/40] , Loss: 0.1862465590238571\n",
      "Epoch [975/1000] , Step [40/40] , Loss: 0.1757055670022964\n",
      "Epoch [976/1000] , Step [10/40] , Loss: 0.1994563043117523\n",
      "Epoch [976/1000] , Step [20/40] , Loss: 0.1948440074920654\n",
      "Epoch [976/1000] , Step [30/40] , Loss: 0.1934583336114883\n",
      "Epoch [976/1000] , Step [40/40] , Loss: 0.1931835412979126\n",
      "Epoch [977/1000] , Step [10/40] , Loss: 0.1795198619365692\n",
      "Epoch [977/1000] , Step [20/40] , Loss: 0.1640520244836807\n",
      "Epoch [977/1000] , Step [30/40] , Loss: 0.1902547031641006\n",
      "Epoch [977/1000] , Step [40/40] , Loss: 0.1947692185640335\n",
      "Epoch [978/1000] , Step [10/40] , Loss: 0.1874248981475830\n",
      "Epoch [978/1000] , Step [20/40] , Loss: 0.1786621659994125\n",
      "Epoch [978/1000] , Step [30/40] , Loss: 0.1735083162784576\n",
      "Epoch [978/1000] , Step [40/40] , Loss: 0.1914998292922974\n",
      "Epoch [979/1000] , Step [10/40] , Loss: 0.1872534751892090\n",
      "Epoch [979/1000] , Step [20/40] , Loss: 0.1825981587171555\n",
      "Epoch [979/1000] , Step [30/40] , Loss: 0.2014627009630203\n",
      "Epoch [979/1000] , Step [40/40] , Loss: 0.1682942360639572\n",
      "Epoch [980/1000] , Step [10/40] , Loss: 0.1904351711273193\n",
      "Epoch [980/1000] , Step [20/40] , Loss: 0.1693131178617477\n",
      "Epoch [980/1000] , Step [30/40] , Loss: 0.1867405325174332\n",
      "Epoch [980/1000] , Step [40/40] , Loss: 0.1950415223836899\n",
      "Epoch [981/1000] , Step [10/40] , Loss: 0.1802097856998444\n",
      "Epoch [981/1000] , Step [20/40] , Loss: 0.1968558430671692\n",
      "Epoch [981/1000] , Step [30/40] , Loss: 0.1849368661642075\n",
      "Epoch [981/1000] , Step [40/40] , Loss: 0.1753149032592773\n",
      "Epoch [982/1000] , Step [10/40] , Loss: 0.1705757677555084\n",
      "Epoch [982/1000] , Step [20/40] , Loss: 0.2058405578136444\n",
      "Epoch [982/1000] , Step [30/40] , Loss: 0.1872881203889847\n",
      "Epoch [982/1000] , Step [40/40] , Loss: 0.1733831167221069\n",
      "Epoch [983/1000] , Step [10/40] , Loss: 0.1899638324975967\n",
      "Epoch [983/1000] , Step [20/40] , Loss: 0.1693434864282608\n",
      "Epoch [983/1000] , Step [30/40] , Loss: 0.1860636174678802\n",
      "Epoch [983/1000] , Step [40/40] , Loss: 0.1773935705423355\n",
      "Epoch [984/1000] , Step [10/40] , Loss: 0.1760987937450409\n",
      "Epoch [984/1000] , Step [20/40] , Loss: 0.1796804666519165\n",
      "Epoch [984/1000] , Step [30/40] , Loss: 0.1847548931837082\n",
      "Epoch [984/1000] , Step [40/40] , Loss: 0.1587439626455307\n",
      "Epoch [985/1000] , Step [10/40] , Loss: 0.1891337931156158\n",
      "Epoch [985/1000] , Step [20/40] , Loss: 0.1889936327934265\n",
      "Epoch [985/1000] , Step [30/40] , Loss: 0.1867375820875168\n",
      "Epoch [985/1000] , Step [40/40] , Loss: 0.1878484487533569\n",
      "Epoch [986/1000] , Step [10/40] , Loss: 0.1806654334068298\n",
      "Epoch [986/1000] , Step [20/40] , Loss: 0.1844804733991623\n",
      "Epoch [986/1000] , Step [30/40] , Loss: 0.1853143423795700\n",
      "Epoch [986/1000] , Step [40/40] , Loss: 0.1622145473957062\n",
      "Epoch [987/1000] , Step [10/40] , Loss: 0.1832994371652603\n",
      "Epoch [987/1000] , Step [20/40] , Loss: 0.1646050512790680\n",
      "Epoch [987/1000] , Step [30/40] , Loss: 0.1939764469861984\n",
      "Epoch [987/1000] , Step [40/40] , Loss: 0.1893516182899475\n",
      "Epoch [988/1000] , Step [10/40] , Loss: 0.1656221896409988\n",
      "Epoch [988/1000] , Step [20/40] , Loss: 0.1800210177898407\n",
      "Epoch [988/1000] , Step [30/40] , Loss: 0.1619984954595566\n",
      "Epoch [988/1000] , Step [40/40] , Loss: 0.1586311757564545\n",
      "Epoch [989/1000] , Step [10/40] , Loss: 0.1742488592863083\n",
      "Epoch [989/1000] , Step [20/40] , Loss: 0.1846066117286682\n",
      "Epoch [989/1000] , Step [30/40] , Loss: 0.1782884746789932\n",
      "Epoch [989/1000] , Step [40/40] , Loss: 0.1723955124616623\n",
      "Epoch [990/1000] , Step [10/40] , Loss: 0.1997053921222687\n",
      "Epoch [990/1000] , Step [20/40] , Loss: 0.1762677878141403\n",
      "Epoch [990/1000] , Step [30/40] , Loss: 0.1730808913707733\n",
      "Epoch [990/1000] , Step [40/40] , Loss: 0.1791934221982956\n",
      "Epoch [991/1000] , Step [10/40] , Loss: 0.1734480559825897\n",
      "Epoch [991/1000] , Step [20/40] , Loss: 0.1698597669601440\n",
      "Epoch [991/1000] , Step [30/40] , Loss: 0.1760178953409195\n",
      "Epoch [991/1000] , Step [40/40] , Loss: 0.2002807855606079\n",
      "Epoch [992/1000] , Step [10/40] , Loss: 0.1792978495359421\n",
      "Epoch [992/1000] , Step [20/40] , Loss: 0.1903374940156937\n",
      "Epoch [992/1000] , Step [30/40] , Loss: 0.1680068075656891\n",
      "Epoch [992/1000] , Step [40/40] , Loss: 0.1847259104251862\n",
      "Epoch [993/1000] , Step [10/40] , Loss: 0.1682760417461395\n",
      "Epoch [993/1000] , Step [20/40] , Loss: 0.2049680203199387\n",
      "Epoch [993/1000] , Step [30/40] , Loss: 0.1717395931482315\n",
      "Epoch [993/1000] , Step [40/40] , Loss: 0.1590973734855652\n",
      "Epoch [994/1000] , Step [10/40] , Loss: 0.1837969124317169\n",
      "Epoch [994/1000] , Step [20/40] , Loss: 0.1589709818363190\n",
      "Epoch [994/1000] , Step [30/40] , Loss: 0.1914205849170685\n",
      "Epoch [994/1000] , Step [40/40] , Loss: 0.1852045804262161\n",
      "Epoch [995/1000] , Step [10/40] , Loss: 0.1696464717388153\n",
      "Epoch [995/1000] , Step [20/40] , Loss: 0.1774456053972244\n",
      "Epoch [995/1000] , Step [30/40] , Loss: 0.1915533840656281\n",
      "Epoch [995/1000] , Step [40/40] , Loss: 0.1733713150024414\n",
      "Epoch [996/1000] , Step [10/40] , Loss: 0.1808910071849823\n",
      "Epoch [996/1000] , Step [20/40] , Loss: 0.1802338808774948\n",
      "Epoch [996/1000] , Step [30/40] , Loss: 0.1853978782892227\n",
      "Epoch [996/1000] , Step [40/40] , Loss: 0.1759095042943954\n",
      "Epoch [997/1000] , Step [10/40] , Loss: 0.1639157533645630\n",
      "Epoch [997/1000] , Step [20/40] , Loss: 0.1741478443145752\n",
      "Epoch [997/1000] , Step [30/40] , Loss: 0.2093495428562164\n",
      "Epoch [997/1000] , Step [40/40] , Loss: 0.1950097382068634\n",
      "Epoch [998/1000] , Step [10/40] , Loss: 0.1952226459980011\n",
      "Epoch [998/1000] , Step [20/40] , Loss: 0.1724160462617874\n",
      "Epoch [998/1000] , Step [30/40] , Loss: 0.1712294369935989\n",
      "Epoch [998/1000] , Step [40/40] , Loss: 0.1562737077474594\n",
      "Epoch [999/1000] , Step [10/40] , Loss: 0.1770953834056854\n",
      "Epoch [999/1000] , Step [20/40] , Loss: 0.1977483332157135\n",
      "Epoch [999/1000] , Step [30/40] , Loss: 0.1826121509075165\n",
      "Epoch [999/1000] , Step [40/40] , Loss: 0.1763780564069748\n",
      "Epoch [1000/1000] , Step [10/40] , Loss: 0.1815755367279053\n",
      "Epoch [1000/1000] , Step [20/40] , Loss: 0.1752294301986694\n",
      "Epoch [1000/1000] , Step [30/40] , Loss: 0.1898647397756577\n",
      "Epoch [1000/1000] , Step [40/40] , Loss: 0.1817190647125244\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i , (input_init_conditions,input_x_loc,input_time,Actual_y) in enumerate(train_loader):\n",
    "        input1 = input_init_conditions\n",
    "        input1 = input1.to(device)\n",
    "\n",
    "        input2 = torch.cat((input_x_loc,input_time),-1)\n",
    "        input2 = input2.to(device)\n",
    "\n",
    "        Actual_y = Actual_y.to(device)\n",
    "        input_time.to(device)\n",
    "\n",
    "        Outputs = model(input1,input2)\n",
    "\n",
    "        input2_BC1 = torch.cat((torch.zeros(input_time.size(0),1),input_time),-1).to(device)\n",
    "        target_BC1 = torch.zeros(input_time.size(0),device=device)#.to(device)\n",
    "        predicted_BC1 = model(input1,input2_BC1)\n",
    "        loss_BC1 = torch.mean((predicted_BC1-target_BC1)**2)\n",
    "\n",
    "        input2_BC2 = torch.cat((torch.ones(input_time.size(0),1),input_time),-1).to(device)\n",
    "        target_BC2 = torch.zeros(input_time.size(0),device=device) #.to(device)\n",
    "        predicted_BC2 = model(input1,input2_BC2)\n",
    "        loss_BC2 = torch.mean((predicted_BC2-target_BC2)**2)\n",
    "\n",
    "        #Physics_loss = \n",
    "\n",
    "        #Physics_loss = torch.mean()\n",
    "        \n",
    "        loss = criterion(Outputs.unsqueeze(-1),Actual_y)  + 1000*(loss_BC1 + loss_BC2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimiser.step()    \n",
    "        optimiser.zero_grad()\n",
    "        loss_rec.append(loss.item())\n",
    "\n",
    "        if (i+1) % 10 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoch}] , Step [{i+1}/{total_samples}] , Loss: {loss.item():.16f}')\n",
    "            #y_locations_test = model(input1[1],input2_physics)\n",
    "            #plt.plot(x_locations.detach().numpy(),y_locations_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_locations_test = model(input1[1].expand(len(input2_physics),-1),input2_physics.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2246e-16, -6.3424e-02, -1.2659e-01,  ...,  1.2659e-01,\n",
       "          6.3424e-02,  1.2246e-16],\n",
       "        [-1.2246e-16, -6.3424e-02, -1.2659e-01,  ...,  1.2659e-01,\n",
       "          6.3424e-02,  1.2246e-16],\n",
       "        [-1.2246e-16, -6.3424e-02, -1.2659e-01,  ...,  1.2659e-01,\n",
       "          6.3424e-02,  1.2246e-16],\n",
       "        ...,\n",
       "        [-1.2246e-16, -6.3424e-02, -1.2659e-01,  ...,  1.2659e-01,\n",
       "          6.3424e-02,  1.2246e-16],\n",
       "        [-1.2246e-16, -6.3424e-02, -1.2659e-01,  ...,  1.2659e-01,\n",
       "          6.3424e-02,  1.2246e-16],\n",
       "        [-1.2246e-16, -6.3424e-02, -1.2659e-01,  ...,  1.2659e-01,\n",
       "          6.3424e-02,  1.2246e-16]], device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[1].expand(100,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e333bba780>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_locations.cpu().detach().numpy(),y_locations_test.cpu().detach().numpy())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_time.size(0)\n",
    "torch.ones(input_time.size(0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1543],\n",
       "        [0.0000, 0.2234],\n",
       "        [0.0000, 0.1273],\n",
       "        [0.0000, 0.3046],\n",
       "        [0.0000, 0.3267],\n",
       "        [0.0000, 0.2004],\n",
       "        [0.0000, 0.0852],\n",
       "        [0.0000, 0.0691],\n",
       "        [0.0000, 0.0170],\n",
       "        [0.0000, 0.1764],\n",
       "        [0.0000, 0.0521],\n",
       "        [0.0000, 0.0802],\n",
       "        [0.0000, 0.2435],\n",
       "        [0.0000, 0.0531],\n",
       "        [0.0000, 0.2054],\n",
       "        [0.0000, 0.2465],\n",
       "        [0.0000, 0.1132],\n",
       "        [0.0000, 0.2435],\n",
       "        [0.0000, 0.2705],\n",
       "        [0.0000, 0.1283],\n",
       "        [0.0000, 0.0070],\n",
       "        [0.0000, 0.0451],\n",
       "        [0.0000, 0.3277],\n",
       "        [0.0000, 0.2555],\n",
       "        [0.0000, 0.3136],\n",
       "        [0.0000, 0.1152],\n",
       "        [0.0000, 0.1804],\n",
       "        [0.0000, 0.0832],\n",
       "        [0.0000, 0.2214],\n",
       "        [0.0000, 0.1222],\n",
       "        [0.0000, 0.1052],\n",
       "        [0.0000, 0.2655],\n",
       "        [0.0000, 0.1964],\n",
       "        [0.0000, 0.1553],\n",
       "        [0.0000, 0.3036],\n",
       "        [0.0000, 0.1663],\n",
       "        [0.0000, 0.3166],\n",
       "        [0.0000, 0.1533],\n",
       "        [0.0000, 0.1313],\n",
       "        [0.0000, 0.1052],\n",
       "        [0.0000, 0.1994],\n",
       "        [0.0000, 0.2124],\n",
       "        [0.0000, 0.0170],\n",
       "        [0.0000, 0.3226],\n",
       "        [0.0000, 0.1463],\n",
       "        [0.0000, 0.2004],\n",
       "        [0.0000, 0.3086],\n",
       "        [0.0000, 0.0731],\n",
       "        [0.0000, 0.2325],\n",
       "        [0.0000, 0.1092],\n",
       "        [0.0000, 0.1663],\n",
       "        [0.0000, 0.2906],\n",
       "        [0.0000, 0.1623],\n",
       "        [0.0000, 0.0140],\n",
       "        [0.0000, 0.2104],\n",
       "        [0.0000, 0.1784],\n",
       "        [0.0000, 0.0331],\n",
       "        [0.0000, 0.0802],\n",
       "        [0.0000, 0.2876],\n",
       "        [0.0000, 0.0491],\n",
       "        [0.0000, 0.1483],\n",
       "        [0.0000, 0.1944],\n",
       "        [0.0000, 0.1002],\n",
       "        [0.0000, 0.3076],\n",
       "        [0.0000, 0.1814],\n",
       "        [0.0000, 0.1814],\n",
       "        [0.0000, 0.1152],\n",
       "        [0.0000, 0.1593],\n",
       "        [0.0000, 0.1764],\n",
       "        [0.0000, 0.2655],\n",
       "        [0.0000, 0.3176],\n",
       "        [0.0000, 0.0912],\n",
       "        [0.0000, 0.1212],\n",
       "        [0.0000, 0.2054],\n",
       "        [0.0000, 0.0341],\n",
       "        [0.0000, 0.0681],\n",
       "        [0.0000, 0.3086],\n",
       "        [0.0000, 0.1864],\n",
       "        [0.0000, 0.1182],\n",
       "        [0.0000, 0.2024],\n",
       "        [0.0000, 0.1463],\n",
       "        [0.0000, 0.1293],\n",
       "        [0.0000, 0.2074],\n",
       "        [0.0000, 0.0952],\n",
       "        [0.0000, 0.2255],\n",
       "        [0.0000, 0.0471],\n",
       "        [0.0000, 0.0661],\n",
       "        [0.0000, 0.2705],\n",
       "        [0.0000, 0.0862],\n",
       "        [0.0000, 0.2094],\n",
       "        [0.0000, 0.1162],\n",
       "        [0.0000, 0.1192],\n",
       "        [0.0000, 0.1002],\n",
       "        [0.0000, 0.1593],\n",
       "        [0.0000, 0.1313],\n",
       "        [0.0000, 0.0982],\n",
       "        [0.0000, 0.2104],\n",
       "        [0.0000, 0.0731],\n",
       "        [0.0000, 0.1623],\n",
       "        [0.0000, 0.2074],\n",
       "        [0.0000, 0.1713],\n",
       "        [0.0000, 0.0060],\n",
       "        [0.0000, 0.0230],\n",
       "        [0.0000, 0.1323],\n",
       "        [0.0000, 0.1834],\n",
       "        [0.0000, 0.1593],\n",
       "        [0.0000, 0.2866],\n",
       "        [0.0000, 0.0511],\n",
       "        [0.0000, 0.1423],\n",
       "        [0.0000, 0.0130],\n",
       "        [0.0000, 0.1904],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.2595],\n",
       "        [0.0000, 0.2425],\n",
       "        [0.0000, 0.1824],\n",
       "        [0.0000, 0.2275],\n",
       "        [0.0000, 0.0782],\n",
       "        [0.0000, 0.3086],\n",
       "        [0.0000, 0.0150],\n",
       "        [0.0000, 0.0170],\n",
       "        [0.0000, 0.0090],\n",
       "        [0.0000, 0.0401],\n",
       "        [0.0000, 0.2154],\n",
       "        [0.0000, 0.2545],\n",
       "        [0.0000, 0.1293],\n",
       "        [0.0000, 0.2946],\n",
       "        [0.0000, 0.1954],\n",
       "        [0.0000, 0.1082],\n",
       "        [0.0000, 0.2505],\n",
       "        [0.0000, 0.1162],\n",
       "        [0.0000, 0.0721],\n",
       "        [0.0000, 0.1242],\n",
       "        [0.0000, 0.2766],\n",
       "        [0.0000, 0.2174],\n",
       "        [0.0000, 0.1333],\n",
       "        [0.0000, 0.2685],\n",
       "        [0.0000, 0.2575],\n",
       "        [0.0000, 0.3287],\n",
       "        [0.0000, 0.1373],\n",
       "        [0.0000, 0.1493],\n",
       "        [0.0000, 0.2365],\n",
       "        [0.0000, 0.0882],\n",
       "        [0.0000, 0.1854],\n",
       "        [0.0000, 0.1723],\n",
       "        [0.0000, 0.2255],\n",
       "        [0.0000, 0.2555],\n",
       "        [0.0000, 0.2405],\n",
       "        [0.0000, 0.0220],\n",
       "        [0.0000, 0.2094],\n",
       "        [0.0000, 0.0922],\n",
       "        [0.0000, 0.0010],\n",
       "        [0.0000, 0.3006],\n",
       "        [0.0000, 0.3206],\n",
       "        [0.0000, 0.1202],\n",
       "        [0.0000, 0.0170],\n",
       "        [0.0000, 0.2144],\n",
       "        [0.0000, 0.1643],\n",
       "        [0.0000, 0.1603],\n",
       "        [0.0000, 0.3006],\n",
       "        [0.0000, 0.0591],\n",
       "        [0.0000, 0.2104],\n",
       "        [0.0000, 0.2064],\n",
       "        [0.0000, 0.1954],\n",
       "        [0.0000, 0.2916],\n",
       "        [0.0000, 0.3016],\n",
       "        [0.0000, 0.0120],\n",
       "        [0.0000, 0.0461],\n",
       "        [0.0000, 0.0271],\n",
       "        [0.0000, 0.1784],\n",
       "        [0.0000, 0.1563],\n",
       "        [0.0000, 0.1152],\n",
       "        [0.0000, 0.3056],\n",
       "        [0.0000, 0.1703],\n",
       "        [0.0000, 0.1333],\n",
       "        [0.0000, 0.1553],\n",
       "        [0.0000, 0.1904],\n",
       "        [0.0000, 0.2355],\n",
       "        [0.0000, 0.1463],\n",
       "        [0.0000, 0.0772],\n",
       "        [0.0000, 0.0681],\n",
       "        [0.0000, 0.2395],\n",
       "        [0.0000, 0.1443],\n",
       "        [0.0000, 0.0291],\n",
       "        [0.0000, 0.0741],\n",
       "        [0.0000, 0.0902],\n",
       "        [0.0000, 0.0321],\n",
       "        [0.0000, 0.0752],\n",
       "        [0.0000, 0.2525],\n",
       "        [0.0000, 0.2655],\n",
       "        [0.0000, 0.0150],\n",
       "        [0.0000, 0.0952],\n",
       "        [0.0000, 0.0391],\n",
       "        [0.0000, 0.0110],\n",
       "        [0.0000, 0.1373],\n",
       "        [0.0000, 0.1052],\n",
       "        [0.0000, 0.2635],\n",
       "        [0.0000, 0.2435],\n",
       "        [0.0000, 0.3297],\n",
       "        [0.0000, 0.0230],\n",
       "        [0.0000, 0.0912],\n",
       "        [0.0000, 0.1042],\n",
       "        [0.0000, 0.1754],\n",
       "        [0.0000, 0.1202],\n",
       "        [0.0000, 0.1192],\n",
       "        [0.0000, 0.2134],\n",
       "        [0.0000, 0.3257],\n",
       "        [0.0000, 0.0741],\n",
       "        [0.0000, 0.2335],\n",
       "        [0.0000, 0.0812],\n",
       "        [0.0000, 0.2715],\n",
       "        [0.0000, 0.0882],\n",
       "        [0.0000, 0.0832],\n",
       "        [0.0000, 0.2856],\n",
       "        [0.0000, 0.1062],\n",
       "        [0.0000, 0.2595],\n",
       "        [0.0000, 0.3196],\n",
       "        [0.0000, 0.2485],\n",
       "        [0.0000, 0.1293],\n",
       "        [0.0000, 0.2756],\n",
       "        [0.0000, 0.2224],\n",
       "        [0.0000, 0.0972],\n",
       "        [0.0000, 0.1082],\n",
       "        [0.0000, 0.1964],\n",
       "        [0.0000, 0.2194],\n",
       "        [0.0000, 0.1563],\n",
       "        [0.0000, 0.3046],\n",
       "        [0.0000, 0.2665],\n",
       "        [0.0000, 0.0431],\n",
       "        [0.0000, 0.2776],\n",
       "        [0.0000, 0.0441],\n",
       "        [0.0000, 0.1242],\n",
       "        [0.0000, 0.0942],\n",
       "        [0.0000, 0.1743],\n",
       "        [0.0000, 0.1443],\n",
       "        [0.0000, 0.0782],\n",
       "        [0.0000, 0.2204],\n",
       "        [0.0000, 0.2355],\n",
       "        [0.0000, 0.1042],\n",
       "        [0.0000, 0.1273],\n",
       "        [0.0000, 0.2966],\n",
       "        [0.0000, 0.1052],\n",
       "        [0.0000, 0.1062],\n",
       "        [0.0000, 0.2525],\n",
       "        [0.0000, 0.2735],\n",
       "        [0.0000, 0.1122],\n",
       "        [0.0000, 0.1673],\n",
       "        [0.0000, 0.3006],\n",
       "        [0.0000, 0.1764],\n",
       "        [0.0000, 0.0691],\n",
       "        [0.0000, 0.0381],\n",
       "        [0.0000, 0.1022],\n",
       "        [0.0000, 0.1283],\n",
       "        [0.0000, 0.0521],\n",
       "        [0.0000, 0.1473],\n",
       "        [0.0000, 0.2836],\n",
       "        [0.0000, 0.3176],\n",
       "        [0.0000, 0.1253],\n",
       "        [0.0000, 0.1152],\n",
       "        [0.0000, 0.2786],\n",
       "        [0.0000, 0.1433],\n",
       "        [0.0000, 0.2084],\n",
       "        [0.0000, 0.2655],\n",
       "        [0.0000, 0.1713],\n",
       "        [0.0000, 0.1884],\n",
       "        [0.0000, 0.2836],\n",
       "        [0.0000, 0.2275],\n",
       "        [0.0000, 0.0681],\n",
       "        [0.0000, 0.2234],\n",
       "        [0.0000, 0.0261],\n",
       "        [0.0000, 0.1082],\n",
       "        [0.0000, 0.0291],\n",
       "        [0.0000, 0.2104],\n",
       "        [0.0000, 0.2184],\n",
       "        [0.0000, 0.1132],\n",
       "        [0.0000, 0.2635],\n",
       "        [0.0000, 0.2826],\n",
       "        [0.0000, 0.1483],\n",
       "        [0.0000, 0.3116],\n",
       "        [0.0000, 0.1794],\n",
       "        [0.0000, 0.1844],\n",
       "        [0.0000, 0.2826],\n",
       "        [0.0000, 0.1844],\n",
       "        [0.0000, 0.3196],\n",
       "        [0.0000, 0.2224],\n",
       "        [0.0000, 0.1673],\n",
       "        [0.0000, 0.1563],\n",
       "        [0.0000, 0.1723],\n",
       "        [0.0000, 0.1954],\n",
       "        [0.0000, 0.2645],\n",
       "        [0.0000, 0.0832],\n",
       "        [0.0000, 0.2024],\n",
       "        [0.0000, 0.3277],\n",
       "        [0.0000, 0.0240],\n",
       "        [0.0000, 0.1042],\n",
       "        [0.0000, 0.1663],\n",
       "        [0.0000, 0.2645],\n",
       "        [0.0000, 0.1623],\n",
       "        [0.0000, 0.0892],\n",
       "        [0.0000, 0.1593],\n",
       "        [0.0000, 0.0331]], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2_BC1 = torch.cat((torch.zeros(input_time.size(0),1),input_time),-1).to(device)\n",
    "input2_BC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_BC1 = torch.zeros(input_time.size(0))\n",
    "target_BC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m predicted_BC1 \u001b[38;5;241m=\u001b[39m model(input1,input2_BC1)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# predicted_BC1\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loss_BC1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((\u001b[43mpredicted_BC1\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtarget_BC1\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      4\u001b[0m loss_BC1\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "predicted_BC1 = model(input1,input2_BC1)\n",
    "# predicted_BC1\n",
    "loss_BC1 = torch.mean((predicted_BC1-target_BC1)**2)\n",
    "loss_BC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_BC_0 = torch.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_rec[1000:])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(y,torch.tensor([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_input_1 = torch.tensor(np.random.rand(65,100),dtype=torch.float32).to(device)\n",
    "trial_input_2 = torch.tensor(np.random.rand(65,2),dtype=torch.float32).to(device)\n",
    "model(trial_input_1,trial_input_2).mean()\n",
    "model(trial_input_1,trial_input_2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Khushi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
