{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepONet,self).__init__()\n",
    "        self.Branch_L1 = nn.Linear(100,20)\n",
    "        self.Branch_L2 = nn.Linear(20,20)\n",
    "        self.Branch_L3 = nn.Linear(20,20)\n",
    "        self.Branch_L4 = nn.Linear(20,20)\n",
    "        self.Branch_L5 = nn.Linear(20,100)\n",
    "\n",
    "        self.Trunk_L1 = nn.Linear(2,20)\n",
    "        self.Trunk_L2 = nn.Linear(20,20)\n",
    "        self.Trunk_L3 = nn.Linear(20,20)\n",
    "        self.Trunk_L4 = nn.Linear(20,20)\n",
    "        self.Trunk_L5 = nn.Linear(20,100)\n",
    "\n",
    "    def forward(self,y_0,x_loc_and_time):\n",
    "        # Branch\n",
    "        b = F.tanh(self.Branch_L1(y_0))\n",
    "        b = F.tanh(self.Branch_L2(b))\n",
    "        b = F.tanh(self.Branch_L3(b))\n",
    "        b = F.tanh(self.Branch_L4(b))\n",
    "        b = self.Branch_L5(b)\n",
    "\n",
    "        tr = F.tanh(self.Trunk_L1(x_loc_and_time))\n",
    "        tr = F.tanh(self.Trunk_L2(tr))\n",
    "        tr = F.tanh(self.Trunk_L3(tr))\n",
    "        tr = F.tanh(self.Trunk_L4(tr))\n",
    "        tr = self.Trunk_L5(tr)\n",
    "\n",
    "        #output = torch.matmul(b,tr.t()).sum(dim=0)\n",
    "        output = torch.sum(b * tr, dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = DeepONet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepONet(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dim=64, num_layers=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            branch_input_dim (int): Dimension of the branch input (e.g., function discretization).\n",
    "            trunk_input_dim (int): Dimension of the trunk input (e.g., coordinates in the domain).\n",
    "            hidden_dim (int): Number of neurons in the hidden layers.\n",
    "            num_layers (int): Number of layers in branch and trunk networks.\n",
    "        \"\"\"\n",
    "        super(DeepONet, self).__init__()\n",
    "        \n",
    "        # Branch Network\n",
    "        branch_layers = [nn.Linear(branch_input_dim, hidden_dim), nn.ReLU()]\n",
    "        for _ in range(num_layers - 1):\n",
    "            branch_layers += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU()]\n",
    "        self.branch_net = nn.Sequential(*branch_layers)\n",
    "        \n",
    "        # Trunk Network\n",
    "        trunk_layers = [nn.Linear(trunk_input_dim, hidden_dim), nn.ReLU()]\n",
    "        for _ in range(num_layers - 1):\n",
    "            trunk_layers += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU()]\n",
    "        self.trunk_net = nn.Sequential(*trunk_layers)\n",
    "        \n",
    "        # Final layer: combines branch and trunk features\n",
    "        self.basis_layer = nn.Linear(hidden_dim, hidden_dim, bias=False)  # no bias for clean dot product\n",
    "    \n",
    "    def forward(self, branch_input, trunk_input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            branch_input (Tensor): Input tensor for branch network, shape [batch_size, branch_input_dim].\n",
    "            trunk_input (Tensor): Input tensor for trunk network, shape [batch_size, trunk_input_dim].\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Predicted output, shape [batch_size].\n",
    "        \"\"\"\n",
    "        # Pass inputs through branch and trunk networks\n",
    "        branch_output = self.branch_net(branch_input)  # [batch_size, hidden_dim]\n",
    "        trunk_output = self.trunk_net(trunk_input)    # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Combine using dot product\n",
    "        combined_output = torch.sum(self.basis_layer(branch_output) * trunk_output, dim=1)  # [batch_size]\n",
    "        \n",
    "        return combined_output\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input dimensions\n",
    "    branch_input_dim = 100  # e.g., 100 points from the input function\n",
    "    trunk_input_dim = 2     # e.g., x and y coordinates\n",
    "    \n",
    "    # Initialize DeepONet\n",
    "    model = DeepONet(branch_input_dim, trunk_input_dim)\n",
    "    \n",
    "    # Dummy inputs\n",
    "    batch_size = 8\n",
    "    branch_input = torch.randn(batch_size, branch_input_dim)  # Function input samples\n",
    "    trunk_input = torch.randn(batch_size, trunk_input_dim)    # Coordinate inputs\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(branch_input, trunk_input)\n",
    "    print(\"Output shape:\", output.shape)  # Should be [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONet(100,2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv('sin_pix.csv',index_col=0).dropna().to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 103)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,transform=None):\n",
    "        self.initial_conditions = torch.from_numpy(database[:,0:100])\n",
    "        self.x_location = torch.from_numpy(database[:,[100]])\n",
    "        self.time_vale = torch.from_numpy(database[:,[101]])\n",
    "        self.true_y_value = torch.from_numpy(database[:,[102]])\n",
    "        self.n_samples = database.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.initial_conditions[index] , self.x_location[index] , self.time_vale[index] , self.true_y_value[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x211ae0e7350>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y,_,_,_ = dataset_data.__getitem__(1)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7*dataset_data.__len__())\n",
    "test_size = dataset_data.__len__() - train_size\n",
    "\n",
    "batchsize = 2500\n",
    "\n",
    "Burger_train_data , Burger_test_data = torch.utils.data.random_split(Data(),[train_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=Burger_train_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "data = data_iter.__next__()\n",
    "Init_val , x_loc, time, y_value = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2888 10\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "total_samples = len(train_loader)\n",
    "n_iterations = math.ceil(total_samples/300)\n",
    "print(total_samples,n_iterations)\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "loss_rec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] , Step [10/2888] , Loss: 0.6074839830398560\n",
      "Epoch [1/10] , Step [20/2888] , Loss: 0.5669051408767700\n",
      "Epoch [1/10] , Step [30/2888] , Loss: 0.4830687046051025\n",
      "Epoch [1/10] , Step [40/2888] , Loss: 0.5410313010215759\n",
      "Epoch [1/10] , Step [50/2888] , Loss: 0.5452060699462891\n",
      "Epoch [1/10] , Step [60/2888] , Loss: 0.3254669308662415\n",
      "Epoch [1/10] , Step [70/2888] , Loss: 0.4217885136604309\n",
      "Epoch [1/10] , Step [80/2888] , Loss: 0.2965095341205597\n",
      "Epoch [1/10] , Step [90/2888] , Loss: 0.4818367660045624\n",
      "Epoch [1/10] , Step [100/2888] , Loss: 0.5568741559982300\n",
      "Epoch [1/10] , Step [110/2888] , Loss: 0.3839237987995148\n",
      "Epoch [1/10] , Step [120/2888] , Loss: 0.1718582063913345\n",
      "Epoch [1/10] , Step [130/2888] , Loss: 0.4819245934486389\n",
      "Epoch [1/10] , Step [140/2888] , Loss: 0.1567747890949249\n",
      "Epoch [1/10] , Step [150/2888] , Loss: 0.4383225440979004\n",
      "Epoch [1/10] , Step [160/2888] , Loss: 0.6023303270339966\n",
      "Epoch [1/10] , Step [170/2888] , Loss: 0.5035705566406250\n",
      "Epoch [1/10] , Step [180/2888] , Loss: 0.3228648900985718\n",
      "Epoch [1/10] , Step [190/2888] , Loss: 0.5339239835739136\n",
      "Epoch [1/10] , Step [200/2888] , Loss: 0.5722053050994873\n",
      "Epoch [1/10] , Step [210/2888] , Loss: 0.6141526699066162\n",
      "Epoch [1/10] , Step [220/2888] , Loss: 0.5838732719421387\n",
      "Epoch [1/10] , Step [230/2888] , Loss: 0.7132431268692017\n",
      "Epoch [1/10] , Step [240/2888] , Loss: 0.4422900378704071\n",
      "Epoch [1/10] , Step [250/2888] , Loss: 0.2897335588932037\n",
      "Epoch [1/10] , Step [260/2888] , Loss: 0.6027852296829224\n",
      "Epoch [1/10] , Step [270/2888] , Loss: 0.4854687154293060\n",
      "Epoch [1/10] , Step [280/2888] , Loss: 0.5720239281654358\n",
      "Epoch [1/10] , Step [290/2888] , Loss: 0.4616938829421997\n",
      "Epoch [1/10] , Step [300/2888] , Loss: 0.3637700080871582\n",
      "Epoch [1/10] , Step [310/2888] , Loss: 0.3912636637687683\n",
      "Epoch [1/10] , Step [320/2888] , Loss: 0.5772556066513062\n",
      "Epoch [1/10] , Step [330/2888] , Loss: 0.4949180185794830\n",
      "Epoch [1/10] , Step [340/2888] , Loss: 0.5112750530242920\n",
      "Epoch [1/10] , Step [350/2888] , Loss: 0.6403477787971497\n",
      "Epoch [1/10] , Step [360/2888] , Loss: 0.5804992914199829\n",
      "Epoch [1/10] , Step [370/2888] , Loss: 0.4811382591724396\n",
      "Epoch [1/10] , Step [380/2888] , Loss: 0.5048521757125854\n",
      "Epoch [1/10] , Step [390/2888] , Loss: 0.5444506406784058\n",
      "Epoch [1/10] , Step [400/2888] , Loss: 0.4089485406875610\n",
      "Epoch [1/10] , Step [410/2888] , Loss: 0.4575043320655823\n",
      "Epoch [1/10] , Step [420/2888] , Loss: 0.3945073485374451\n",
      "Epoch [1/10] , Step [430/2888] , Loss: 0.6406667828559875\n",
      "Epoch [1/10] , Step [440/2888] , Loss: 0.2793039083480835\n",
      "Epoch [1/10] , Step [450/2888] , Loss: 0.5072465538978577\n",
      "Epoch [1/10] , Step [460/2888] , Loss: 0.4718100726604462\n",
      "Epoch [1/10] , Step [470/2888] , Loss: 0.5143315792083740\n",
      "Epoch [1/10] , Step [480/2888] , Loss: 0.4427879154682159\n",
      "Epoch [1/10] , Step [490/2888] , Loss: 0.4682451188564301\n",
      "Epoch [1/10] , Step [500/2888] , Loss: 0.3916546702384949\n",
      "Epoch [1/10] , Step [510/2888] , Loss: 0.3377475738525391\n",
      "Epoch [1/10] , Step [520/2888] , Loss: 0.4703391194343567\n",
      "Epoch [1/10] , Step [530/2888] , Loss: 0.4926369786262512\n",
      "Epoch [1/10] , Step [540/2888] , Loss: 0.5025923848152161\n",
      "Epoch [1/10] , Step [550/2888] , Loss: 0.4900358915328979\n",
      "Epoch [1/10] , Step [560/2888] , Loss: 0.4690123796463013\n",
      "Epoch [1/10] , Step [570/2888] , Loss: 0.4102961719036102\n",
      "Epoch [1/10] , Step [580/2888] , Loss: 0.4775215387344360\n",
      "Epoch [1/10] , Step [590/2888] , Loss: 0.4566861987113953\n",
      "Epoch [1/10] , Step [600/2888] , Loss: 0.5319927930831909\n",
      "Epoch [1/10] , Step [610/2888] , Loss: 0.6183868646621704\n",
      "Epoch [1/10] , Step [620/2888] , Loss: 0.5060634016990662\n",
      "Epoch [1/10] , Step [630/2888] , Loss: 0.4200511574745178\n",
      "Epoch [1/10] , Step [640/2888] , Loss: 0.4113850593566895\n",
      "Epoch [1/10] , Step [650/2888] , Loss: 0.4598620533943176\n",
      "Epoch [1/10] , Step [660/2888] , Loss: 0.5488060712814331\n",
      "Epoch [1/10] , Step [670/2888] , Loss: 0.5184921026229858\n",
      "Epoch [1/10] , Step [680/2888] , Loss: 0.5536693930625916\n",
      "Epoch [1/10] , Step [690/2888] , Loss: 0.4773978888988495\n",
      "Epoch [1/10] , Step [700/2888] , Loss: 0.3346852660179138\n",
      "Epoch [1/10] , Step [710/2888] , Loss: 0.6803976893424988\n",
      "Epoch [1/10] , Step [720/2888] , Loss: 0.4555715620517731\n",
      "Epoch [1/10] , Step [730/2888] , Loss: 0.3840303122997284\n",
      "Epoch [1/10] , Step [740/2888] , Loss: 0.2981868386268616\n",
      "Epoch [1/10] , Step [750/2888] , Loss: 0.5175749659538269\n",
      "Epoch [1/10] , Step [760/2888] , Loss: 0.7226915359497070\n",
      "Epoch [1/10] , Step [770/2888] , Loss: 0.3235570490360260\n",
      "Epoch [1/10] , Step [780/2888] , Loss: 0.6975463032722473\n",
      "Epoch [1/10] , Step [790/2888] , Loss: 0.5423650741577148\n",
      "Epoch [1/10] , Step [800/2888] , Loss: 0.3795168399810791\n",
      "Epoch [1/10] , Step [810/2888] , Loss: 0.6408392786979675\n",
      "Epoch [1/10] , Step [820/2888] , Loss: 0.4849057793617249\n",
      "Epoch [1/10] , Step [830/2888] , Loss: 0.3947589993476868\n",
      "Epoch [1/10] , Step [840/2888] , Loss: 0.3900133669376373\n",
      "Epoch [1/10] , Step [850/2888] , Loss: 0.5276360511779785\n",
      "Epoch [1/10] , Step [860/2888] , Loss: 0.2628316581249237\n",
      "Epoch [1/10] , Step [870/2888] , Loss: 0.7754943966865540\n",
      "Epoch [1/10] , Step [880/2888] , Loss: 0.3202773928642273\n",
      "Epoch [1/10] , Step [890/2888] , Loss: 0.4405587017536163\n",
      "Epoch [1/10] , Step [900/2888] , Loss: 0.7199686765670776\n",
      "Epoch [1/10] , Step [910/2888] , Loss: 0.5946638584136963\n",
      "Epoch [1/10] , Step [920/2888] , Loss: 0.3964421749114990\n",
      "Epoch [1/10] , Step [930/2888] , Loss: 0.6128816604614258\n",
      "Epoch [1/10] , Step [940/2888] , Loss: 0.5169022083282471\n",
      "Epoch [1/10] , Step [950/2888] , Loss: 0.4916584491729736\n",
      "Epoch [1/10] , Step [960/2888] , Loss: 0.4430384933948517\n",
      "Epoch [1/10] , Step [970/2888] , Loss: 0.3896884322166443\n",
      "Epoch [1/10] , Step [980/2888] , Loss: 0.6103062033653259\n",
      "Epoch [1/10] , Step [990/2888] , Loss: 0.5414131283760071\n",
      "Epoch [1/10] , Step [1000/2888] , Loss: 0.4142048060894012\n",
      "Epoch [1/10] , Step [1010/2888] , Loss: 0.4781914353370667\n",
      "Epoch [1/10] , Step [1020/2888] , Loss: 0.5120595693588257\n",
      "Epoch [1/10] , Step [1030/2888] , Loss: 0.4492498934268951\n",
      "Epoch [1/10] , Step [1040/2888] , Loss: 0.5037840604782104\n",
      "Epoch [1/10] , Step [1050/2888] , Loss: 0.6344337463378906\n",
      "Epoch [1/10] , Step [1060/2888] , Loss: 0.4222760796546936\n",
      "Epoch [1/10] , Step [1070/2888] , Loss: 0.6589542031288147\n",
      "Epoch [1/10] , Step [1080/2888] , Loss: 0.5268872380256653\n",
      "Epoch [1/10] , Step [1090/2888] , Loss: 0.3029208779335022\n",
      "Epoch [1/10] , Step [1100/2888] , Loss: 0.4132660031318665\n",
      "Epoch [1/10] , Step [1110/2888] , Loss: 0.5011323690414429\n",
      "Epoch [1/10] , Step [1120/2888] , Loss: 0.5029144287109375\n",
      "Epoch [1/10] , Step [1130/2888] , Loss: 0.4223525822162628\n",
      "Epoch [1/10] , Step [1140/2888] , Loss: 0.4766009449958801\n",
      "Epoch [1/10] , Step [1150/2888] , Loss: 0.6711376905441284\n",
      "Epoch [1/10] , Step [1160/2888] , Loss: 0.4894990622997284\n",
      "Epoch [1/10] , Step [1170/2888] , Loss: 0.3933418989181519\n",
      "Epoch [1/10] , Step [1180/2888] , Loss: 0.6324233412742615\n",
      "Epoch [1/10] , Step [1190/2888] , Loss: 0.2669686377048492\n",
      "Epoch [1/10] , Step [1200/2888] , Loss: 0.6962979435920715\n",
      "Epoch [1/10] , Step [1210/2888] , Loss: 0.7425520420074463\n",
      "Epoch [1/10] , Step [1220/2888] , Loss: 0.3829125165939331\n",
      "Epoch [1/10] , Step [1230/2888] , Loss: 0.4415407776832581\n",
      "Epoch [1/10] , Step [1240/2888] , Loss: 0.5384320616722107\n",
      "Epoch [1/10] , Step [1250/2888] , Loss: 0.6283569335937500\n",
      "Epoch [1/10] , Step [1260/2888] , Loss: 0.4449731707572937\n",
      "Epoch [1/10] , Step [1270/2888] , Loss: 0.3756152391433716\n",
      "Epoch [1/10] , Step [1280/2888] , Loss: 0.1997857838869095\n",
      "Epoch [1/10] , Step [1290/2888] , Loss: 0.5068250894546509\n",
      "Epoch [1/10] , Step [1300/2888] , Loss: 0.3936056494712830\n",
      "Epoch [1/10] , Step [1310/2888] , Loss: 0.3330388069152832\n",
      "Epoch [1/10] , Step [1320/2888] , Loss: 0.5432723760604858\n",
      "Epoch [1/10] , Step [1330/2888] , Loss: 0.6701341271400452\n",
      "Epoch [1/10] , Step [1340/2888] , Loss: 0.5794613957405090\n",
      "Epoch [1/10] , Step [1350/2888] , Loss: 0.5095404982566833\n",
      "Epoch [1/10] , Step [1360/2888] , Loss: 0.6293409466743469\n",
      "Epoch [1/10] , Step [1370/2888] , Loss: 0.4324415028095245\n",
      "Epoch [1/10] , Step [1380/2888] , Loss: 0.4528920948505402\n",
      "Epoch [1/10] , Step [1390/2888] , Loss: 0.5794005393981934\n",
      "Epoch [1/10] , Step [1400/2888] , Loss: 0.5200178027153015\n",
      "Epoch [1/10] , Step [1410/2888] , Loss: 0.4774956703186035\n",
      "Epoch [1/10] , Step [1420/2888] , Loss: 0.5636816620826721\n",
      "Epoch [1/10] , Step [1430/2888] , Loss: 0.3718829154968262\n",
      "Epoch [1/10] , Step [1440/2888] , Loss: 0.3638283312320709\n",
      "Epoch [1/10] , Step [1450/2888] , Loss: 0.6859538555145264\n",
      "Epoch [1/10] , Step [1460/2888] , Loss: 0.5687034130096436\n",
      "Epoch [1/10] , Step [1470/2888] , Loss: 0.5158184766769409\n",
      "Epoch [1/10] , Step [1480/2888] , Loss: 0.3767950832843781\n",
      "Epoch [1/10] , Step [1490/2888] , Loss: 0.6110198497772217\n",
      "Epoch [1/10] , Step [1500/2888] , Loss: 0.3479833900928497\n",
      "Epoch [1/10] , Step [1510/2888] , Loss: 0.5329395532608032\n",
      "Epoch [1/10] , Step [1520/2888] , Loss: 0.5231591463088989\n",
      "Epoch [1/10] , Step [1530/2888] , Loss: 0.6037654876708984\n",
      "Epoch [1/10] , Step [1540/2888] , Loss: 0.5943312644958496\n",
      "Epoch [1/10] , Step [1550/2888] , Loss: 0.2306697964668274\n",
      "Epoch [1/10] , Step [1560/2888] , Loss: 0.3909764289855957\n",
      "Epoch [1/10] , Step [1570/2888] , Loss: 0.6383529901504517\n",
      "Epoch [1/10] , Step [1580/2888] , Loss: 0.6252191066741943\n",
      "Epoch [1/10] , Step [1590/2888] , Loss: 0.3537503182888031\n",
      "Epoch [1/10] , Step [1600/2888] , Loss: 0.4484863281250000\n",
      "Epoch [1/10] , Step [1610/2888] , Loss: 0.3315238058567047\n",
      "Epoch [1/10] , Step [1620/2888] , Loss: 0.4337699413299561\n",
      "Epoch [1/10] , Step [1630/2888] , Loss: 0.2700857818126678\n",
      "Epoch [1/10] , Step [1640/2888] , Loss: 0.3680045604705811\n",
      "Epoch [1/10] , Step [1650/2888] , Loss: 0.4623598456382751\n",
      "Epoch [1/10] , Step [1660/2888] , Loss: 0.5359042882919312\n",
      "Epoch [1/10] , Step [1670/2888] , Loss: 0.5130303502082825\n",
      "Epoch [1/10] , Step [1680/2888] , Loss: 0.7725464105606079\n",
      "Epoch [1/10] , Step [1690/2888] , Loss: 0.2745530009269714\n",
      "Epoch [1/10] , Step [1700/2888] , Loss: 0.6104148626327515\n",
      "Epoch [1/10] , Step [1710/2888] , Loss: 0.5043485760688782\n",
      "Epoch [1/10] , Step [1720/2888] , Loss: 0.4685052633285522\n",
      "Epoch [1/10] , Step [1730/2888] , Loss: 0.3536886870861053\n",
      "Epoch [1/10] , Step [1740/2888] , Loss: 0.4533200263977051\n",
      "Epoch [1/10] , Step [1750/2888] , Loss: 0.4999892115592957\n",
      "Epoch [1/10] , Step [1760/2888] , Loss: 0.5138155817985535\n",
      "Epoch [1/10] , Step [1770/2888] , Loss: 0.0528982244431973\n",
      "Epoch [1/10] , Step [1780/2888] , Loss: 0.5385453701019287\n",
      "Epoch [1/10] , Step [1790/2888] , Loss: 0.4491456151008606\n",
      "Epoch [1/10] , Step [1800/2888] , Loss: 0.7031308412551880\n",
      "Epoch [1/10] , Step [1810/2888] , Loss: 0.5095815658569336\n",
      "Epoch [1/10] , Step [1820/2888] , Loss: 0.7284564375877380\n",
      "Epoch [1/10] , Step [1830/2888] , Loss: 0.4328703284263611\n",
      "Epoch [1/10] , Step [1840/2888] , Loss: 0.6076865196228027\n",
      "Epoch [1/10] , Step [1850/2888] , Loss: 0.5952687859535217\n",
      "Epoch [1/10] , Step [1860/2888] , Loss: 0.5252028107643127\n",
      "Epoch [1/10] , Step [1870/2888] , Loss: 0.4485718607902527\n",
      "Epoch [1/10] , Step [1880/2888] , Loss: 0.3711945414543152\n",
      "Epoch [1/10] , Step [1890/2888] , Loss: 0.5221463441848755\n",
      "Epoch [1/10] , Step [1900/2888] , Loss: 0.4261940717697144\n",
      "Epoch [1/10] , Step [1910/2888] , Loss: 0.3471746742725372\n",
      "Epoch [1/10] , Step [1920/2888] , Loss: 0.3759701251983643\n",
      "Epoch [1/10] , Step [1930/2888] , Loss: 0.4051398634910583\n",
      "Epoch [1/10] , Step [1940/2888] , Loss: 0.3396129906177521\n",
      "Epoch [1/10] , Step [1950/2888] , Loss: 0.5146293044090271\n",
      "Epoch [1/10] , Step [1960/2888] , Loss: 0.4888180196285248\n",
      "Epoch [1/10] , Step [1970/2888] , Loss: 0.5889753699302673\n",
      "Epoch [1/10] , Step [1980/2888] , Loss: 0.3764982819557190\n",
      "Epoch [1/10] , Step [1990/2888] , Loss: 0.3720168471336365\n",
      "Epoch [1/10] , Step [2000/2888] , Loss: 0.4596753418445587\n",
      "Epoch [1/10] , Step [2010/2888] , Loss: 0.2962640821933746\n",
      "Epoch [1/10] , Step [2020/2888] , Loss: 0.5149202346801758\n",
      "Epoch [1/10] , Step [2030/2888] , Loss: 0.4197485446929932\n",
      "Epoch [1/10] , Step [2040/2888] , Loss: 0.6758534312248230\n",
      "Epoch [1/10] , Step [2050/2888] , Loss: 0.3362284302711487\n",
      "Epoch [1/10] , Step [2060/2888] , Loss: 0.5768527984619141\n",
      "Epoch [1/10] , Step [2070/2888] , Loss: 0.4085520505905151\n",
      "Epoch [1/10] , Step [2080/2888] , Loss: 0.4620808362960815\n",
      "Epoch [1/10] , Step [2090/2888] , Loss: 0.5892679095268250\n",
      "Epoch [1/10] , Step [2100/2888] , Loss: 0.1820434927940369\n",
      "Epoch [1/10] , Step [2110/2888] , Loss: 0.5028941631317139\n",
      "Epoch [1/10] , Step [2120/2888] , Loss: 0.5195059776306152\n",
      "Epoch [1/10] , Step [2130/2888] , Loss: 0.4387170970439911\n",
      "Epoch [1/10] , Step [2140/2888] , Loss: 0.5956990718841553\n",
      "Epoch [1/10] , Step [2150/2888] , Loss: 0.5634608268737793\n",
      "Epoch [1/10] , Step [2160/2888] , Loss: 0.4941176772117615\n",
      "Epoch [1/10] , Step [2170/2888] , Loss: 0.2816095948219299\n",
      "Epoch [1/10] , Step [2180/2888] , Loss: 0.4444010257720947\n",
      "Epoch [1/10] , Step [2190/2888] , Loss: 0.4687204957008362\n",
      "Epoch [1/10] , Step [2200/2888] , Loss: 0.3033013939857483\n",
      "Epoch [1/10] , Step [2210/2888] , Loss: 0.3828026056289673\n",
      "Epoch [1/10] , Step [2220/2888] , Loss: 0.3747614622116089\n",
      "Epoch [1/10] , Step [2230/2888] , Loss: 0.5208549499511719\n",
      "Epoch [1/10] , Step [2240/2888] , Loss: 0.3310291469097137\n",
      "Epoch [1/10] , Step [2250/2888] , Loss: 0.3751819729804993\n",
      "Epoch [1/10] , Step [2260/2888] , Loss: 0.6328404545783997\n",
      "Epoch [1/10] , Step [2270/2888] , Loss: 0.6283361911773682\n",
      "Epoch [1/10] , Step [2280/2888] , Loss: 0.5059198737144470\n",
      "Epoch [1/10] , Step [2290/2888] , Loss: 0.3181448280811310\n",
      "Epoch [1/10] , Step [2300/2888] , Loss: 0.3113403916358948\n",
      "Epoch [1/10] , Step [2310/2888] , Loss: 0.4406111240386963\n",
      "Epoch [1/10] , Step [2320/2888] , Loss: 0.6722387671470642\n",
      "Epoch [1/10] , Step [2330/2888] , Loss: 0.3953261375427246\n",
      "Epoch [1/10] , Step [2340/2888] , Loss: 0.3719363212585449\n",
      "Epoch [1/10] , Step [2350/2888] , Loss: 0.4361370801925659\n",
      "Epoch [1/10] , Step [2360/2888] , Loss: 0.4924892485141754\n",
      "Epoch [1/10] , Step [2370/2888] , Loss: 0.7136830687522888\n",
      "Epoch [1/10] , Step [2380/2888] , Loss: 0.4150459766387939\n",
      "Epoch [1/10] , Step [2390/2888] , Loss: 0.4640508890151978\n",
      "Epoch [1/10] , Step [2400/2888] , Loss: 0.2876814603805542\n",
      "Epoch [1/10] , Step [2410/2888] , Loss: 0.5360745787620544\n",
      "Epoch [1/10] , Step [2420/2888] , Loss: 0.4972880780696869\n",
      "Epoch [1/10] , Step [2430/2888] , Loss: 0.3306678235530853\n",
      "Epoch [1/10] , Step [2440/2888] , Loss: 0.5500426292419434\n",
      "Epoch [1/10] , Step [2450/2888] , Loss: 0.4338866770267487\n",
      "Epoch [1/10] , Step [2460/2888] , Loss: 0.4441392719745636\n",
      "Epoch [1/10] , Step [2470/2888] , Loss: 0.3288519978523254\n",
      "Epoch [1/10] , Step [2480/2888] , Loss: 0.3814661800861359\n",
      "Epoch [1/10] , Step [2490/2888] , Loss: 0.3125946521759033\n",
      "Epoch [1/10] , Step [2500/2888] , Loss: 0.2960113286972046\n",
      "Epoch [1/10] , Step [2510/2888] , Loss: 0.6071888208389282\n",
      "Epoch [1/10] , Step [2520/2888] , Loss: 0.5788055062294006\n",
      "Epoch [1/10] , Step [2530/2888] , Loss: 0.4407600760459900\n",
      "Epoch [1/10] , Step [2540/2888] , Loss: 0.2442900836467743\n",
      "Epoch [1/10] , Step [2550/2888] , Loss: 0.4297292828559875\n",
      "Epoch [1/10] , Step [2560/2888] , Loss: 0.6043050885200500\n",
      "Epoch [1/10] , Step [2570/2888] , Loss: 0.5814809799194336\n",
      "Epoch [1/10] , Step [2580/2888] , Loss: 0.6151174306869507\n",
      "Epoch [1/10] , Step [2590/2888] , Loss: 0.6708387136459351\n",
      "Epoch [1/10] , Step [2600/2888] , Loss: 0.2157211154699326\n",
      "Epoch [1/10] , Step [2610/2888] , Loss: 0.5050362944602966\n",
      "Epoch [1/10] , Step [2620/2888] , Loss: 0.3749068975448608\n",
      "Epoch [1/10] , Step [2630/2888] , Loss: 0.6878523230552673\n",
      "Epoch [1/10] , Step [2640/2888] , Loss: 0.4411049485206604\n",
      "Epoch [1/10] , Step [2650/2888] , Loss: 0.4359907209873199\n",
      "Epoch [1/10] , Step [2660/2888] , Loss: 0.2580887675285339\n",
      "Epoch [1/10] , Step [2670/2888] , Loss: 0.4418867826461792\n",
      "Epoch [1/10] , Step [2680/2888] , Loss: 0.3916442990303040\n",
      "Epoch [1/10] , Step [2690/2888] , Loss: 0.4849729835987091\n",
      "Epoch [1/10] , Step [2700/2888] , Loss: 0.3316412866115570\n",
      "Epoch [1/10] , Step [2710/2888] , Loss: 0.2302634716033936\n",
      "Epoch [1/10] , Step [2720/2888] , Loss: 0.4935345053672791\n",
      "Epoch [1/10] , Step [2730/2888] , Loss: 0.5475257635116577\n",
      "Epoch [1/10] , Step [2740/2888] , Loss: 0.4203444719314575\n",
      "Epoch [1/10] , Step [2750/2888] , Loss: 0.5468894243240356\n",
      "Epoch [1/10] , Step [2760/2888] , Loss: 0.6565400362014771\n",
      "Epoch [1/10] , Step [2770/2888] , Loss: 0.5235489010810852\n",
      "Epoch [1/10] , Step [2780/2888] , Loss: 0.4733254015445709\n",
      "Epoch [1/10] , Step [2790/2888] , Loss: 0.3272884488105774\n",
      "Epoch [1/10] , Step [2800/2888] , Loss: 0.5783653855323792\n",
      "Epoch [1/10] , Step [2810/2888] , Loss: 0.4536743462085724\n",
      "Epoch [1/10] , Step [2820/2888] , Loss: 0.4607992470264435\n",
      "Epoch [1/10] , Step [2830/2888] , Loss: 0.8249568343162537\n",
      "Epoch [1/10] , Step [2840/2888] , Loss: 0.4394246637821198\n",
      "Epoch [1/10] , Step [2850/2888] , Loss: 0.3041514754295349\n",
      "Epoch [1/10] , Step [2860/2888] , Loss: 0.4098856747150421\n",
      "Epoch [1/10] , Step [2870/2888] , Loss: 0.4591535925865173\n",
      "Epoch [1/10] , Step [2880/2888] , Loss: 0.3758338689804077\n",
      "Epoch [2/10] , Step [10/2888] , Loss: 0.5396534800529480\n",
      "Epoch [2/10] , Step [20/2888] , Loss: 0.5744685530662537\n",
      "Epoch [2/10] , Step [30/2888] , Loss: 0.3987174332141876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] , Step [40/2888] , Loss: 0.3972056508064270\n",
      "Epoch [2/10] , Step [50/2888] , Loss: 0.5260297656059265\n",
      "Epoch [2/10] , Step [60/2888] , Loss: 0.4793160259723663\n",
      "Epoch [2/10] , Step [70/2888] , Loss: 0.5819978117942810\n",
      "Epoch [2/10] , Step [80/2888] , Loss: 0.3787530064582825\n",
      "Epoch [2/10] , Step [90/2888] , Loss: 0.4273822307586670\n",
      "Epoch [2/10] , Step [100/2888] , Loss: 0.3846902251243591\n",
      "Epoch [2/10] , Step [110/2888] , Loss: 0.6422303318977356\n",
      "Epoch [2/10] , Step [120/2888] , Loss: 0.5362609028816223\n",
      "Epoch [2/10] , Step [130/2888] , Loss: 0.5863925218582153\n",
      "Epoch [2/10] , Step [140/2888] , Loss: 0.3073419928550720\n",
      "Epoch [2/10] , Step [150/2888] , Loss: 0.5299744009971619\n",
      "Epoch [2/10] , Step [160/2888] , Loss: 0.6341608762741089\n",
      "Epoch [2/10] , Step [170/2888] , Loss: 0.3075975179672241\n",
      "Epoch [2/10] , Step [180/2888] , Loss: 0.5627171397209167\n",
      "Epoch [2/10] , Step [190/2888] , Loss: 0.7179961800575256\n",
      "Epoch [2/10] , Step [200/2888] , Loss: 0.4814790785312653\n",
      "Epoch [2/10] , Step [210/2888] , Loss: 0.4940178990364075\n",
      "Epoch [2/10] , Step [220/2888] , Loss: 0.7732907533645630\n",
      "Epoch [2/10] , Step [230/2888] , Loss: 0.4465404450893402\n",
      "Epoch [2/10] , Step [240/2888] , Loss: 0.3544918596744537\n",
      "Epoch [2/10] , Step [250/2888] , Loss: 0.3389371633529663\n",
      "Epoch [2/10] , Step [260/2888] , Loss: 0.5280082225799561\n",
      "Epoch [2/10] , Step [270/2888] , Loss: 0.7158070206642151\n",
      "Epoch [2/10] , Step [280/2888] , Loss: 0.6640504002571106\n",
      "Epoch [2/10] , Step [290/2888] , Loss: 0.3392084240913391\n",
      "Epoch [2/10] , Step [300/2888] , Loss: 0.6201697587966919\n",
      "Epoch [2/10] , Step [310/2888] , Loss: 0.3346600234508514\n",
      "Epoch [2/10] , Step [320/2888] , Loss: 0.5277121663093567\n",
      "Epoch [2/10] , Step [330/2888] , Loss: 0.3204405009746552\n",
      "Epoch [2/10] , Step [340/2888] , Loss: 0.4404914975166321\n",
      "Epoch [2/10] , Step [350/2888] , Loss: 0.4806475043296814\n",
      "Epoch [2/10] , Step [360/2888] , Loss: 0.4885023832321167\n",
      "Epoch [2/10] , Step [370/2888] , Loss: 0.2544528841972351\n",
      "Epoch [2/10] , Step [380/2888] , Loss: 0.4695561826229095\n",
      "Epoch [2/10] , Step [390/2888] , Loss: 0.3687489330768585\n",
      "Epoch [2/10] , Step [400/2888] , Loss: 0.4805349409580231\n",
      "Epoch [2/10] , Step [410/2888] , Loss: 0.4722853004932404\n",
      "Epoch [2/10] , Step [420/2888] , Loss: 0.5724462866783142\n",
      "Epoch [2/10] , Step [430/2888] , Loss: 0.5491166114807129\n",
      "Epoch [2/10] , Step [440/2888] , Loss: 0.5115628838539124\n",
      "Epoch [2/10] , Step [450/2888] , Loss: 0.4801063537597656\n",
      "Epoch [2/10] , Step [460/2888] , Loss: 0.3922528028488159\n",
      "Epoch [2/10] , Step [470/2888] , Loss: 0.6340712904930115\n",
      "Epoch [2/10] , Step [480/2888] , Loss: 0.4026286303997040\n",
      "Epoch [2/10] , Step [490/2888] , Loss: 0.4344351291656494\n",
      "Epoch [2/10] , Step [500/2888] , Loss: 0.2908917069435120\n",
      "Epoch [2/10] , Step [510/2888] , Loss: 0.4112961590290070\n",
      "Epoch [2/10] , Step [520/2888] , Loss: 0.5480168461799622\n",
      "Epoch [2/10] , Step [530/2888] , Loss: 0.4901766777038574\n",
      "Epoch [2/10] , Step [540/2888] , Loss: 0.6964223384857178\n",
      "Epoch [2/10] , Step [550/2888] , Loss: 0.4012395143508911\n",
      "Epoch [2/10] , Step [560/2888] , Loss: 0.4122450053691864\n",
      "Epoch [2/10] , Step [570/2888] , Loss: 0.4994282126426697\n",
      "Epoch [2/10] , Step [580/2888] , Loss: 0.5281021595001221\n",
      "Epoch [2/10] , Step [590/2888] , Loss: 0.3598146736621857\n",
      "Epoch [2/10] , Step [600/2888] , Loss: 0.3319892287254333\n",
      "Epoch [2/10] , Step [610/2888] , Loss: 0.3579509258270264\n",
      "Epoch [2/10] , Step [620/2888] , Loss: 0.2953735888004303\n",
      "Epoch [2/10] , Step [630/2888] , Loss: 0.1952312588691711\n",
      "Epoch [2/10] , Step [640/2888] , Loss: 0.6150551438331604\n",
      "Epoch [2/10] , Step [650/2888] , Loss: 0.4442794620990753\n",
      "Epoch [2/10] , Step [660/2888] , Loss: 0.4235413670539856\n",
      "Epoch [2/10] , Step [670/2888] , Loss: 0.4173478186130524\n",
      "Epoch [2/10] , Step [680/2888] , Loss: 0.4234403967857361\n",
      "Epoch [2/10] , Step [690/2888] , Loss: 0.5115067362785339\n",
      "Epoch [2/10] , Step [700/2888] , Loss: 0.4998267889022827\n",
      "Epoch [2/10] , Step [710/2888] , Loss: 0.5149378180503845\n",
      "Epoch [2/10] , Step [720/2888] , Loss: 0.5963451266288757\n",
      "Epoch [2/10] , Step [730/2888] , Loss: 0.4764704108238220\n",
      "Epoch [2/10] , Step [740/2888] , Loss: 0.3945416510105133\n",
      "Epoch [2/10] , Step [750/2888] , Loss: 0.4481832981109619\n",
      "Epoch [2/10] , Step [760/2888] , Loss: 0.4173953533172607\n",
      "Epoch [2/10] , Step [770/2888] , Loss: 0.6978279352188110\n",
      "Epoch [2/10] , Step [780/2888] , Loss: 0.3438595831394196\n",
      "Epoch [2/10] , Step [790/2888] , Loss: 0.8787781000137329\n",
      "Epoch [2/10] , Step [800/2888] , Loss: 0.5135343670845032\n",
      "Epoch [2/10] , Step [810/2888] , Loss: 0.6458070278167725\n",
      "Epoch [2/10] , Step [820/2888] , Loss: 0.7160410881042480\n",
      "Epoch [2/10] , Step [830/2888] , Loss: 0.4557946324348450\n",
      "Epoch [2/10] , Step [840/2888] , Loss: 0.5060221552848816\n",
      "Epoch [2/10] , Step [850/2888] , Loss: 0.4330872595310211\n",
      "Epoch [2/10] , Step [860/2888] , Loss: 0.3702982366085052\n",
      "Epoch [2/10] , Step [870/2888] , Loss: 0.5263682603836060\n",
      "Epoch [2/10] , Step [880/2888] , Loss: 0.4189802706241608\n",
      "Epoch [2/10] , Step [890/2888] , Loss: 0.3650040626525879\n",
      "Epoch [2/10] , Step [900/2888] , Loss: 0.5707090497016907\n",
      "Epoch [2/10] , Step [910/2888] , Loss: 0.3640535473823547\n",
      "Epoch [2/10] , Step [920/2888] , Loss: 0.5793848633766174\n",
      "Epoch [2/10] , Step [930/2888] , Loss: 0.5081130266189575\n",
      "Epoch [2/10] , Step [940/2888] , Loss: 0.3888452351093292\n",
      "Epoch [2/10] , Step [950/2888] , Loss: 0.5341811180114746\n",
      "Epoch [2/10] , Step [960/2888] , Loss: 0.4287815093994141\n",
      "Epoch [2/10] , Step [970/2888] , Loss: 0.4431875348091125\n",
      "Epoch [2/10] , Step [980/2888] , Loss: 0.4882484674453735\n",
      "Epoch [2/10] , Step [990/2888] , Loss: 0.6557621359825134\n",
      "Epoch [2/10] , Step [1000/2888] , Loss: 0.5467430353164673\n",
      "Epoch [2/10] , Step [1010/2888] , Loss: 0.7594698667526245\n",
      "Epoch [2/10] , Step [1020/2888] , Loss: 0.6270087361335754\n",
      "Epoch [2/10] , Step [1030/2888] , Loss: 0.4912405014038086\n",
      "Epoch [2/10] , Step [1040/2888] , Loss: 0.6458087563514709\n",
      "Epoch [2/10] , Step [1050/2888] , Loss: 0.4931136369705200\n",
      "Epoch [2/10] , Step [1060/2888] , Loss: 0.2349146157503128\n",
      "Epoch [2/10] , Step [1070/2888] , Loss: 0.2640410065650940\n",
      "Epoch [2/10] , Step [1080/2888] , Loss: 0.5575670003890991\n",
      "Epoch [2/10] , Step [1090/2888] , Loss: 0.6038183569908142\n",
      "Epoch [2/10] , Step [1100/2888] , Loss: 0.4323033392429352\n",
      "Epoch [2/10] , Step [1110/2888] , Loss: 0.4169785976409912\n",
      "Epoch [2/10] , Step [1120/2888] , Loss: 0.4552146792411804\n",
      "Epoch [2/10] , Step [1130/2888] , Loss: 0.3765863478183746\n",
      "Epoch [2/10] , Step [1140/2888] , Loss: 0.4949767887592316\n",
      "Epoch [2/10] , Step [1150/2888] , Loss: 0.5096698999404907\n",
      "Epoch [2/10] , Step [1160/2888] , Loss: 0.4639234542846680\n",
      "Epoch [2/10] , Step [1170/2888] , Loss: 0.5527629852294922\n",
      "Epoch [2/10] , Step [1180/2888] , Loss: 0.4950842857360840\n",
      "Epoch [2/10] , Step [1190/2888] , Loss: 0.3373084664344788\n",
      "Epoch [2/10] , Step [1200/2888] , Loss: 0.4038273394107819\n",
      "Epoch [2/10] , Step [1210/2888] , Loss: 0.4898270070552826\n",
      "Epoch [2/10] , Step [1220/2888] , Loss: 0.3735511898994446\n",
      "Epoch [2/10] , Step [1230/2888] , Loss: 0.5467617511749268\n",
      "Epoch [2/10] , Step [1240/2888] , Loss: 0.5253253579139709\n",
      "Epoch [2/10] , Step [1250/2888] , Loss: 0.5811027288436890\n",
      "Epoch [2/10] , Step [1260/2888] , Loss: 0.4668150544166565\n",
      "Epoch [2/10] , Step [1270/2888] , Loss: 0.6342713832855225\n",
      "Epoch [2/10] , Step [1280/2888] , Loss: 0.5401964783668518\n",
      "Epoch [2/10] , Step [1290/2888] , Loss: 0.3253427743911743\n",
      "Epoch [2/10] , Step [1300/2888] , Loss: 0.5646241307258606\n",
      "Epoch [2/10] , Step [1310/2888] , Loss: 0.5996533036231995\n",
      "Epoch [2/10] , Step [1320/2888] , Loss: 0.5014605522155762\n",
      "Epoch [2/10] , Step [1330/2888] , Loss: 0.5648323893547058\n",
      "Epoch [2/10] , Step [1340/2888] , Loss: 0.5288712978363037\n",
      "Epoch [2/10] , Step [1350/2888] , Loss: 0.3275313377380371\n",
      "Epoch [2/10] , Step [1360/2888] , Loss: 0.3462542891502380\n",
      "Epoch [2/10] , Step [1370/2888] , Loss: 0.4534301459789276\n",
      "Epoch [2/10] , Step [1380/2888] , Loss: 0.4936681687831879\n",
      "Epoch [2/10] , Step [1390/2888] , Loss: 0.5754383206367493\n",
      "Epoch [2/10] , Step [1400/2888] , Loss: 0.3803938925266266\n",
      "Epoch [2/10] , Step [1410/2888] , Loss: 0.5794727802276611\n",
      "Epoch [2/10] , Step [1420/2888] , Loss: 0.4553447663784027\n",
      "Epoch [2/10] , Step [1430/2888] , Loss: 0.3264346420764923\n",
      "Epoch [2/10] , Step [1440/2888] , Loss: 0.4857339859008789\n",
      "Epoch [2/10] , Step [1450/2888] , Loss: 0.5969534516334534\n",
      "Epoch [2/10] , Step [1460/2888] , Loss: 0.3324412703514099\n",
      "Epoch [2/10] , Step [1470/2888] , Loss: 0.6155261993408203\n",
      "Epoch [2/10] , Step [1480/2888] , Loss: 0.4574856162071228\n",
      "Epoch [2/10] , Step [1490/2888] , Loss: 0.4151284098625183\n",
      "Epoch [2/10] , Step [1500/2888] , Loss: 0.4758091270923615\n",
      "Epoch [2/10] , Step [1510/2888] , Loss: 0.2805289030075073\n",
      "Epoch [2/10] , Step [1520/2888] , Loss: 0.5268192887306213\n",
      "Epoch [2/10] , Step [1530/2888] , Loss: 0.3640221953392029\n",
      "Epoch [2/10] , Step [1540/2888] , Loss: 0.5756835341453552\n",
      "Epoch [2/10] , Step [1550/2888] , Loss: 0.3277519941329956\n",
      "Epoch [2/10] , Step [1560/2888] , Loss: 0.6368271708488464\n",
      "Epoch [2/10] , Step [1570/2888] , Loss: 0.2873972356319427\n",
      "Epoch [2/10] , Step [1580/2888] , Loss: 0.5848845243453979\n",
      "Epoch [2/10] , Step [1590/2888] , Loss: 0.4644636809825897\n",
      "Epoch [2/10] , Step [1600/2888] , Loss: 0.5340016484260559\n",
      "Epoch [2/10] , Step [1610/2888] , Loss: 0.6458293199539185\n",
      "Epoch [2/10] , Step [1620/2888] , Loss: 0.4439013600349426\n",
      "Epoch [2/10] , Step [1630/2888] , Loss: 0.2132479846477509\n",
      "Epoch [2/10] , Step [1640/2888] , Loss: 0.4784429371356964\n",
      "Epoch [2/10] , Step [1650/2888] , Loss: 0.3572456836700439\n",
      "Epoch [2/10] , Step [1660/2888] , Loss: 0.4104113876819611\n",
      "Epoch [2/10] , Step [1670/2888] , Loss: 0.5243810415267944\n",
      "Epoch [2/10] , Step [1680/2888] , Loss: 0.2668975293636322\n",
      "Epoch [2/10] , Step [1690/2888] , Loss: 0.5282573103904724\n",
      "Epoch [2/10] , Step [1700/2888] , Loss: 0.4592548608779907\n",
      "Epoch [2/10] , Step [1710/2888] , Loss: 0.5646490454673767\n",
      "Epoch [2/10] , Step [1720/2888] , Loss: 0.5872213840484619\n",
      "Epoch [2/10] , Step [1730/2888] , Loss: 0.3873501121997833\n",
      "Epoch [2/10] , Step [1740/2888] , Loss: 0.6233803629875183\n",
      "Epoch [2/10] , Step [1750/2888] , Loss: 0.5106898546218872\n",
      "Epoch [2/10] , Step [1760/2888] , Loss: 0.3351724743843079\n",
      "Epoch [2/10] , Step [1770/2888] , Loss: 0.5426627993583679\n",
      "Epoch [2/10] , Step [1780/2888] , Loss: 0.3492319583892822\n",
      "Epoch [2/10] , Step [1790/2888] , Loss: 0.5792592167854309\n",
      "Epoch [2/10] , Step [1800/2888] , Loss: 0.4848685860633850\n",
      "Epoch [2/10] , Step [1810/2888] , Loss: 0.4462587833404541\n",
      "Epoch [2/10] , Step [1820/2888] , Loss: 0.5615445971488953\n",
      "Epoch [2/10] , Step [1830/2888] , Loss: 0.4029272496700287\n",
      "Epoch [2/10] , Step [1840/2888] , Loss: 0.4500314295291901\n",
      "Epoch [2/10] , Step [1850/2888] , Loss: 0.3138227164745331\n",
      "Epoch [2/10] , Step [1860/2888] , Loss: 0.3725719153881073\n",
      "Epoch [2/10] , Step [1870/2888] , Loss: 0.5732681751251221\n",
      "Epoch [2/10] , Step [1880/2888] , Loss: 0.5890475511550903\n",
      "Epoch [2/10] , Step [1890/2888] , Loss: 0.5179797410964966\n",
      "Epoch [2/10] , Step [1900/2888] , Loss: 0.2519828379154205\n",
      "Epoch [2/10] , Step [1910/2888] , Loss: 0.3258922398090363\n",
      "Epoch [2/10] , Step [1920/2888] , Loss: 0.3528672456741333\n",
      "Epoch [2/10] , Step [1930/2888] , Loss: 0.3762871026992798\n",
      "Epoch [2/10] , Step [1940/2888] , Loss: 0.3061664104461670\n",
      "Epoch [2/10] , Step [1950/2888] , Loss: 0.4319495260715485\n",
      "Epoch [2/10] , Step [1960/2888] , Loss: 0.6968923807144165\n",
      "Epoch [2/10] , Step [1970/2888] , Loss: 0.5530573725700378\n",
      "Epoch [2/10] , Step [1980/2888] , Loss: 0.5961967706680298\n",
      "Epoch [2/10] , Step [1990/2888] , Loss: 0.5073850154876709\n",
      "Epoch [2/10] , Step [2000/2888] , Loss: 0.6889884471893311\n",
      "Epoch [2/10] , Step [2010/2888] , Loss: 0.5566167235374451\n",
      "Epoch [2/10] , Step [2020/2888] , Loss: 0.4320101737976074\n",
      "Epoch [2/10] , Step [2030/2888] , Loss: 0.4825118184089661\n",
      "Epoch [2/10] , Step [2040/2888] , Loss: 0.2459799051284790\n",
      "Epoch [2/10] , Step [2050/2888] , Loss: 0.5248162150382996\n",
      "Epoch [2/10] , Step [2060/2888] , Loss: 0.6294669508934021\n",
      "Epoch [2/10] , Step [2070/2888] , Loss: 0.4456775486469269\n",
      "Epoch [2/10] , Step [2080/2888] , Loss: 0.5419244766235352\n",
      "Epoch [2/10] , Step [2090/2888] , Loss: 0.3705837130546570\n",
      "Epoch [2/10] , Step [2100/2888] , Loss: 0.4551311731338501\n",
      "Epoch [2/10] , Step [2110/2888] , Loss: 0.5173764824867249\n",
      "Epoch [2/10] , Step [2120/2888] , Loss: 0.3373505175113678\n",
      "Epoch [2/10] , Step [2130/2888] , Loss: 0.2356084883213043\n",
      "Epoch [2/10] , Step [2140/2888] , Loss: 0.6027995347976685\n",
      "Epoch [2/10] , Step [2150/2888] , Loss: 0.3241148293018341\n",
      "Epoch [2/10] , Step [2160/2888] , Loss: 0.3761063516139984\n",
      "Epoch [2/10] , Step [2170/2888] , Loss: 0.1788581460714340\n",
      "Epoch [2/10] , Step [2180/2888] , Loss: 0.3856497406959534\n",
      "Epoch [2/10] , Step [2190/2888] , Loss: 0.7022265791893005\n",
      "Epoch [2/10] , Step [2200/2888] , Loss: 0.5324787497520447\n",
      "Epoch [2/10] , Step [2210/2888] , Loss: 0.6427159309387207\n",
      "Epoch [2/10] , Step [2220/2888] , Loss: 0.3719429671764374\n",
      "Epoch [2/10] , Step [2230/2888] , Loss: 0.3600988984107971\n",
      "Epoch [2/10] , Step [2240/2888] , Loss: 0.3018693625926971\n",
      "Epoch [2/10] , Step [2250/2888] , Loss: 0.7779251337051392\n",
      "Epoch [2/10] , Step [2260/2888] , Loss: 0.5015258789062500\n",
      "Epoch [2/10] , Step [2270/2888] , Loss: 0.2140597999095917\n",
      "Epoch [2/10] , Step [2280/2888] , Loss: 0.4674991369247437\n",
      "Epoch [2/10] , Step [2290/2888] , Loss: 0.3568649888038635\n",
      "Epoch [2/10] , Step [2300/2888] , Loss: 0.6308935880661011\n",
      "Epoch [2/10] , Step [2310/2888] , Loss: 0.5701446533203125\n",
      "Epoch [2/10] , Step [2320/2888] , Loss: 0.3655313253402710\n",
      "Epoch [2/10] , Step [2330/2888] , Loss: 0.4642172753810883\n",
      "Epoch [2/10] , Step [2340/2888] , Loss: 0.5754426717758179\n",
      "Epoch [2/10] , Step [2350/2888] , Loss: 0.4722056090831757\n",
      "Epoch [2/10] , Step [2360/2888] , Loss: 0.5003597736358643\n",
      "Epoch [2/10] , Step [2370/2888] , Loss: 0.4853953719139099\n",
      "Epoch [2/10] , Step [2380/2888] , Loss: 0.4809616208076477\n",
      "Epoch [2/10] , Step [2390/2888] , Loss: 0.5196540355682373\n",
      "Epoch [2/10] , Step [2400/2888] , Loss: 0.6539493799209595\n",
      "Epoch [2/10] , Step [2410/2888] , Loss: 0.2957096099853516\n",
      "Epoch [2/10] , Step [2420/2888] , Loss: 0.4608999788761139\n",
      "Epoch [2/10] , Step [2430/2888] , Loss: 0.5347225069999695\n",
      "Epoch [2/10] , Step [2440/2888] , Loss: 0.5179182291030884\n",
      "Epoch [2/10] , Step [2450/2888] , Loss: 0.6103053689002991\n",
      "Epoch [2/10] , Step [2460/2888] , Loss: 0.3618267476558685\n",
      "Epoch [2/10] , Step [2470/2888] , Loss: 0.3532973229885101\n",
      "Epoch [2/10] , Step [2480/2888] , Loss: 0.5492560863494873\n",
      "Epoch [2/10] , Step [2490/2888] , Loss: 0.5412514209747314\n",
      "Epoch [2/10] , Step [2500/2888] , Loss: 0.3508464694023132\n",
      "Epoch [2/10] , Step [2510/2888] , Loss: 0.4266029000282288\n",
      "Epoch [2/10] , Step [2520/2888] , Loss: 0.4314877986907959\n",
      "Epoch [2/10] , Step [2530/2888] , Loss: 0.3715505301952362\n",
      "Epoch [2/10] , Step [2540/2888] , Loss: 0.5018990039825439\n",
      "Epoch [2/10] , Step [2550/2888] , Loss: 0.6553593277931213\n",
      "Epoch [2/10] , Step [2560/2888] , Loss: 0.4176036119461060\n",
      "Epoch [2/10] , Step [2570/2888] , Loss: 0.4332372844219208\n",
      "Epoch [2/10] , Step [2580/2888] , Loss: 0.4492390453815460\n",
      "Epoch [2/10] , Step [2590/2888] , Loss: 0.6403954625129700\n",
      "Epoch [2/10] , Step [2600/2888] , Loss: 0.6295570135116577\n",
      "Epoch [2/10] , Step [2610/2888] , Loss: 0.8113923668861389\n",
      "Epoch [2/10] , Step [2620/2888] , Loss: 0.5134757757186890\n",
      "Epoch [2/10] , Step [2630/2888] , Loss: 0.3100245893001556\n",
      "Epoch [2/10] , Step [2640/2888] , Loss: 0.5530799031257629\n",
      "Epoch [2/10] , Step [2650/2888] , Loss: 0.5307736992835999\n",
      "Epoch [2/10] , Step [2660/2888] , Loss: 0.5833792686462402\n",
      "Epoch [2/10] , Step [2670/2888] , Loss: 0.5764027237892151\n",
      "Epoch [2/10] , Step [2680/2888] , Loss: 0.5308735370635986\n",
      "Epoch [2/10] , Step [2690/2888] , Loss: 0.3558402061462402\n",
      "Epoch [2/10] , Step [2700/2888] , Loss: 0.3632778823375702\n",
      "Epoch [2/10] , Step [2710/2888] , Loss: 0.5398516058921814\n",
      "Epoch [2/10] , Step [2720/2888] , Loss: 0.6192722320556641\n",
      "Epoch [2/10] , Step [2730/2888] , Loss: 0.5636937022209167\n",
      "Epoch [2/10] , Step [2740/2888] , Loss: 0.5822497010231018\n",
      "Epoch [2/10] , Step [2750/2888] , Loss: 0.5982282161712646\n",
      "Epoch [2/10] , Step [2760/2888] , Loss: 0.4226266741752625\n",
      "Epoch [2/10] , Step [2770/2888] , Loss: 0.3806336820125580\n",
      "Epoch [2/10] , Step [2780/2888] , Loss: 0.5248133540153503\n",
      "Epoch [2/10] , Step [2790/2888] , Loss: 0.3312101364135742\n",
      "Epoch [2/10] , Step [2800/2888] , Loss: 0.5376740097999573\n",
      "Epoch [2/10] , Step [2810/2888] , Loss: 0.4372134804725647\n",
      "Epoch [2/10] , Step [2820/2888] , Loss: 0.6825217008590698\n",
      "Epoch [2/10] , Step [2830/2888] , Loss: 0.5785301923751831\n",
      "Epoch [2/10] , Step [2840/2888] , Loss: 0.4961964786052704\n",
      "Epoch [2/10] , Step [2850/2888] , Loss: 0.4708543419837952\n",
      "Epoch [2/10] , Step [2860/2888] , Loss: 0.3725234866142273\n",
      "Epoch [2/10] , Step [2870/2888] , Loss: 0.6228001117706299\n",
      "Epoch [2/10] , Step [2880/2888] , Loss: 0.7412467002868652\n",
      "Epoch [3/10] , Step [10/2888] , Loss: 0.6265384554862976\n",
      "Epoch [3/10] , Step [20/2888] , Loss: 0.4038001298904419\n",
      "Epoch [3/10] , Step [30/2888] , Loss: 0.4033769667148590\n",
      "Epoch [3/10] , Step [40/2888] , Loss: 0.5731365084648132\n",
      "Epoch [3/10] , Step [50/2888] , Loss: 0.5729504227638245\n",
      "Epoch [3/10] , Step [60/2888] , Loss: 0.4680532813072205\n",
      "Epoch [3/10] , Step [70/2888] , Loss: 0.5350924134254456\n",
      "Epoch [3/10] , Step [80/2888] , Loss: 0.5239533185958862\n",
      "Epoch [3/10] , Step [90/2888] , Loss: 0.6573647856712341\n",
      "Epoch [3/10] , Step [100/2888] , Loss: 0.6050869226455688\n",
      "Epoch [3/10] , Step [110/2888] , Loss: 0.2122979313135147\n",
      "Epoch [3/10] , Step [120/2888] , Loss: 0.4894752204418182\n",
      "Epoch [3/10] , Step [130/2888] , Loss: 0.4062201678752899\n",
      "Epoch [3/10] , Step [140/2888] , Loss: 0.4309166371822357\n",
      "Epoch [3/10] , Step [150/2888] , Loss: 0.3656612634658813\n",
      "Epoch [3/10] , Step [160/2888] , Loss: 0.4204139709472656\n",
      "Epoch [3/10] , Step [170/2888] , Loss: 0.5054786205291748\n",
      "Epoch [3/10] , Step [180/2888] , Loss: 0.4884774386882782\n",
      "Epoch [3/10] , Step [190/2888] , Loss: 0.3912873864173889\n",
      "Epoch [3/10] , Step [200/2888] , Loss: 0.4320285022258759\n",
      "Epoch [3/10] , Step [210/2888] , Loss: 0.5454861521720886\n",
      "Epoch [3/10] , Step [220/2888] , Loss: 0.3660203814506531\n",
      "Epoch [3/10] , Step [230/2888] , Loss: 0.2868346869945526\n",
      "Epoch [3/10] , Step [240/2888] , Loss: 0.3789775371551514\n",
      "Epoch [3/10] , Step [250/2888] , Loss: 0.5533993244171143\n",
      "Epoch [3/10] , Step [260/2888] , Loss: 0.3326039314270020\n",
      "Epoch [3/10] , Step [270/2888] , Loss: 0.2853065729141235\n",
      "Epoch [3/10] , Step [280/2888] , Loss: 0.6601952314376831\n",
      "Epoch [3/10] , Step [290/2888] , Loss: 0.4139828383922577\n",
      "Epoch [3/10] , Step [300/2888] , Loss: 0.4870777428150177\n",
      "Epoch [3/10] , Step [310/2888] , Loss: 0.5370370149612427\n",
      "Epoch [3/10] , Step [320/2888] , Loss: 0.5627011656761169\n",
      "Epoch [3/10] , Step [330/2888] , Loss: 0.4225999116897583\n",
      "Epoch [3/10] , Step [340/2888] , Loss: 0.6355642080307007\n",
      "Epoch [3/10] , Step [350/2888] , Loss: 0.5865275859832764\n",
      "Epoch [3/10] , Step [360/2888] , Loss: 0.4605607986450195\n",
      "Epoch [3/10] , Step [370/2888] , Loss: 0.5063295364379883\n",
      "Epoch [3/10] , Step [380/2888] , Loss: 0.2850234210491180\n",
      "Epoch [3/10] , Step [390/2888] , Loss: 0.4425515532493591\n",
      "Epoch [3/10] , Step [400/2888] , Loss: 0.5443702936172485\n",
      "Epoch [3/10] , Step [410/2888] , Loss: 0.4057465195655823\n",
      "Epoch [3/10] , Step [420/2888] , Loss: 0.2977359294891357\n",
      "Epoch [3/10] , Step [430/2888] , Loss: 0.4153463244438171\n",
      "Epoch [3/10] , Step [440/2888] , Loss: 0.6558262705802917\n",
      "Epoch [3/10] , Step [450/2888] , Loss: 0.5317675471305847\n",
      "Epoch [3/10] , Step [460/2888] , Loss: 0.4466135501861572\n",
      "Epoch [3/10] , Step [470/2888] , Loss: 0.6081226468086243\n",
      "Epoch [3/10] , Step [480/2888] , Loss: 0.2721240818500519\n",
      "Epoch [3/10] , Step [490/2888] , Loss: 0.4511338472366333\n",
      "Epoch [3/10] , Step [500/2888] , Loss: 0.2553410232067108\n",
      "Epoch [3/10] , Step [510/2888] , Loss: 0.6451320052146912\n",
      "Epoch [3/10] , Step [520/2888] , Loss: 0.5979138016700745\n",
      "Epoch [3/10] , Step [530/2888] , Loss: 0.4231262505054474\n",
      "Epoch [3/10] , Step [540/2888] , Loss: 0.5176348090171814\n",
      "Epoch [3/10] , Step [550/2888] , Loss: 0.4689569175243378\n",
      "Epoch [3/10] , Step [560/2888] , Loss: 0.6319891214370728\n",
      "Epoch [3/10] , Step [570/2888] , Loss: 0.5677903890609741\n",
      "Epoch [3/10] , Step [580/2888] , Loss: 0.5304322838783264\n",
      "Epoch [3/10] , Step [590/2888] , Loss: 0.4508188962936401\n",
      "Epoch [3/10] , Step [600/2888] , Loss: 0.4877860248088837\n",
      "Epoch [3/10] , Step [610/2888] , Loss: 0.5518616437911987\n",
      "Epoch [3/10] , Step [620/2888] , Loss: 0.4334672689437866\n",
      "Epoch [3/10] , Step [630/2888] , Loss: 0.6147685647010803\n",
      "Epoch [3/10] , Step [640/2888] , Loss: 0.4090732634067535\n",
      "Epoch [3/10] , Step [650/2888] , Loss: 0.5719435811042786\n",
      "Epoch [3/10] , Step [660/2888] , Loss: 0.3273260295391083\n",
      "Epoch [3/10] , Step [670/2888] , Loss: 0.5448179244995117\n",
      "Epoch [3/10] , Step [680/2888] , Loss: 0.4986625611782074\n",
      "Epoch [3/10] , Step [690/2888] , Loss: 0.3657492697238922\n",
      "Epoch [3/10] , Step [700/2888] , Loss: 0.6387550830841064\n",
      "Epoch [3/10] , Step [710/2888] , Loss: 0.5089359879493713\n",
      "Epoch [3/10] , Step [720/2888] , Loss: 0.3968456983566284\n",
      "Epoch [3/10] , Step [730/2888] , Loss: 0.4040534496307373\n",
      "Epoch [3/10] , Step [740/2888] , Loss: 0.6731677651405334\n",
      "Epoch [3/10] , Step [750/2888] , Loss: 0.5423817634582520\n",
      "Epoch [3/10] , Step [760/2888] , Loss: 0.4613539874553680\n",
      "Epoch [3/10] , Step [770/2888] , Loss: 0.4891963303089142\n",
      "Epoch [3/10] , Step [780/2888] , Loss: 0.6210360527038574\n",
      "Epoch [3/10] , Step [790/2888] , Loss: 0.5380911231040955\n",
      "Epoch [3/10] , Step [800/2888] , Loss: 0.3157500326633453\n",
      "Epoch [3/10] , Step [810/2888] , Loss: 0.5221067667007446\n",
      "Epoch [3/10] , Step [820/2888] , Loss: 0.4761169254779816\n",
      "Epoch [3/10] , Step [830/2888] , Loss: 0.4167099595069885\n",
      "Epoch [3/10] , Step [840/2888] , Loss: 0.2913259267807007\n",
      "Epoch [3/10] , Step [850/2888] , Loss: 0.4382301867008209\n",
      "Epoch [3/10] , Step [860/2888] , Loss: 0.6004112958908081\n",
      "Epoch [3/10] , Step [870/2888] , Loss: 0.5807021260261536\n",
      "Epoch [3/10] , Step [880/2888] , Loss: 0.3738624751567841\n",
      "Epoch [3/10] , Step [890/2888] , Loss: 0.5023808479309082\n",
      "Epoch [3/10] , Step [900/2888] , Loss: 0.5909814238548279\n",
      "Epoch [3/10] , Step [910/2888] , Loss: 0.5171887278556824\n",
      "Epoch [3/10] , Step [920/2888] , Loss: 0.4002672433853149\n",
      "Epoch [3/10] , Step [930/2888] , Loss: 0.7249622344970703\n",
      "Epoch [3/10] , Step [940/2888] , Loss: 0.5574461221694946\n",
      "Epoch [3/10] , Step [950/2888] , Loss: 0.6513507366180420\n",
      "Epoch [3/10] , Step [960/2888] , Loss: 0.5948694944381714\n",
      "Epoch [3/10] , Step [970/2888] , Loss: 0.5981577634811401\n",
      "Epoch [3/10] , Step [980/2888] , Loss: 0.7924181818962097\n",
      "Epoch [3/10] , Step [990/2888] , Loss: 0.5547862052917480\n",
      "Epoch [3/10] , Step [1000/2888] , Loss: 0.5940940380096436\n",
      "Epoch [3/10] , Step [1010/2888] , Loss: 0.4905694723129272\n",
      "Epoch [3/10] , Step [1020/2888] , Loss: 0.5461097359657288\n",
      "Epoch [3/10] , Step [1030/2888] , Loss: 0.4294789135456085\n",
      "Epoch [3/10] , Step [1040/2888] , Loss: 0.4784044027328491\n",
      "Epoch [3/10] , Step [1050/2888] , Loss: 0.7011340856552124\n",
      "Epoch [3/10] , Step [1060/2888] , Loss: 0.5212315917015076\n",
      "Epoch [3/10] , Step [1070/2888] , Loss: 0.4976419210433960\n",
      "Epoch [3/10] , Step [1080/2888] , Loss: 0.3688265681266785\n",
      "Epoch [3/10] , Step [1090/2888] , Loss: 0.2368018180131912\n",
      "Epoch [3/10] , Step [1100/2888] , Loss: 0.3704084753990173\n",
      "Epoch [3/10] , Step [1110/2888] , Loss: 0.2682498097419739\n",
      "Epoch [3/10] , Step [1120/2888] , Loss: 0.3564141094684601\n",
      "Epoch [3/10] , Step [1130/2888] , Loss: 0.4249169826507568\n",
      "Epoch [3/10] , Step [1140/2888] , Loss: 0.5481315255165100\n",
      "Epoch [3/10] , Step [1150/2888] , Loss: 0.5108517408370972\n",
      "Epoch [3/10] , Step [1160/2888] , Loss: 0.5101137757301331\n",
      "Epoch [3/10] , Step [1170/2888] , Loss: 0.5892121791839600\n",
      "Epoch [3/10] , Step [1180/2888] , Loss: 0.3577679395675659\n",
      "Epoch [3/10] , Step [1190/2888] , Loss: 0.4844968616962433\n",
      "Epoch [3/10] , Step [1200/2888] , Loss: 0.5883334875106812\n",
      "Epoch [3/10] , Step [1210/2888] , Loss: 0.5581378936767578\n",
      "Epoch [3/10] , Step [1220/2888] , Loss: 0.5400644540786743\n",
      "Epoch [3/10] , Step [1230/2888] , Loss: 0.4622651934623718\n",
      "Epoch [3/10] , Step [1240/2888] , Loss: 0.3570421934127808\n",
      "Epoch [3/10] , Step [1250/2888] , Loss: 0.5639107227325439\n",
      "Epoch [3/10] , Step [1260/2888] , Loss: 0.2549963593482971\n",
      "Epoch [3/10] , Step [1270/2888] , Loss: 0.5384824872016907\n",
      "Epoch [3/10] , Step [1280/2888] , Loss: 0.5304540991783142\n",
      "Epoch [3/10] , Step [1290/2888] , Loss: 0.4522562623023987\n",
      "Epoch [3/10] , Step [1300/2888] , Loss: 0.4529837667942047\n",
      "Epoch [3/10] , Step [1310/2888] , Loss: 0.7227078080177307\n",
      "Epoch [3/10] , Step [1320/2888] , Loss: 0.4154765307903290\n",
      "Epoch [3/10] , Step [1330/2888] , Loss: 0.5591225624084473\n",
      "Epoch [3/10] , Step [1340/2888] , Loss: 0.6574807167053223\n",
      "Epoch [3/10] , Step [1350/2888] , Loss: 0.4265109002590179\n",
      "Epoch [3/10] , Step [1360/2888] , Loss: 0.3104793727397919\n",
      "Epoch [3/10] , Step [1370/2888] , Loss: 0.3930214345455170\n",
      "Epoch [3/10] , Step [1380/2888] , Loss: 0.3769703507423401\n",
      "Epoch [3/10] , Step [1390/2888] , Loss: 0.3889894783496857\n",
      "Epoch [3/10] , Step [1400/2888] , Loss: 0.5242618322372437\n",
      "Epoch [3/10] , Step [1410/2888] , Loss: 0.5203839540481567\n",
      "Epoch [3/10] , Step [1420/2888] , Loss: 0.5796922445297241\n",
      "Epoch [3/10] , Step [1430/2888] , Loss: 0.4863141775131226\n",
      "Epoch [3/10] , Step [1440/2888] , Loss: 0.4343324601650238\n",
      "Epoch [3/10] , Step [1450/2888] , Loss: 0.2557351291179657\n",
      "Epoch [3/10] , Step [1460/2888] , Loss: 0.4994723498821259\n",
      "Epoch [3/10] , Step [1470/2888] , Loss: 0.3609399795532227\n",
      "Epoch [3/10] , Step [1480/2888] , Loss: 0.4693469703197479\n",
      "Epoch [3/10] , Step [1490/2888] , Loss: 0.3288342952728271\n",
      "Epoch [3/10] , Step [1500/2888] , Loss: 0.3165796995162964\n",
      "Epoch [3/10] , Step [1510/2888] , Loss: 0.4511435329914093\n",
      "Epoch [3/10] , Step [1520/2888] , Loss: 0.4364752769470215\n",
      "Epoch [3/10] , Step [1530/2888] , Loss: 0.4953760206699371\n",
      "Epoch [3/10] , Step [1540/2888] , Loss: 0.3668426871299744\n",
      "Epoch [3/10] , Step [1550/2888] , Loss: 0.5527045726776123\n",
      "Epoch [3/10] , Step [1560/2888] , Loss: 0.4107030034065247\n",
      "Epoch [3/10] , Step [1570/2888] , Loss: 0.5861716270446777\n",
      "Epoch [3/10] , Step [1580/2888] , Loss: 0.4078424870967865\n",
      "Epoch [3/10] , Step [1590/2888] , Loss: 0.5509812831878662\n",
      "Epoch [3/10] , Step [1600/2888] , Loss: 0.6289117336273193\n",
      "Epoch [3/10] , Step [1610/2888] , Loss: 0.6920224428176880\n",
      "Epoch [3/10] , Step [1620/2888] , Loss: 0.7017003297805786\n",
      "Epoch [3/10] , Step [1630/2888] , Loss: 0.2615838944911957\n",
      "Epoch [3/10] , Step [1640/2888] , Loss: 0.5431689023971558\n",
      "Epoch [3/10] , Step [1650/2888] , Loss: 0.3458172678947449\n",
      "Epoch [3/10] , Step [1660/2888] , Loss: 0.3890081644058228\n",
      "Epoch [3/10] , Step [1670/2888] , Loss: 0.5778123140335083\n",
      "Epoch [3/10] , Step [1680/2888] , Loss: 0.4203204512596130\n",
      "Epoch [3/10] , Step [1690/2888] , Loss: 0.3212452232837677\n",
      "Epoch [3/10] , Step [1700/2888] , Loss: 0.5484928488731384\n",
      "Epoch [3/10] , Step [1710/2888] , Loss: 0.5563075542449951\n",
      "Epoch [3/10] , Step [1720/2888] , Loss: 0.4459620714187622\n",
      "Epoch [3/10] , Step [1730/2888] , Loss: 0.4094054698944092\n",
      "Epoch [3/10] , Step [1740/2888] , Loss: 0.3744845986366272\n",
      "Epoch [3/10] , Step [1750/2888] , Loss: 0.0906931236386299\n",
      "Epoch [3/10] , Step [1760/2888] , Loss: 0.4855200648307800\n",
      "Epoch [3/10] , Step [1770/2888] , Loss: 0.4785624146461487\n",
      "Epoch [3/10] , Step [1780/2888] , Loss: 0.4810334444046021\n",
      "Epoch [3/10] , Step [1790/2888] , Loss: 0.5898294448852539\n",
      "Epoch [3/10] , Step [1800/2888] , Loss: 0.8006756305694580\n",
      "Epoch [3/10] , Step [1810/2888] , Loss: 0.2411805838346481\n",
      "Epoch [3/10] , Step [1820/2888] , Loss: 0.2560083270072937\n",
      "Epoch [3/10] , Step [1830/2888] , Loss: 0.4729494452476501\n",
      "Epoch [3/10] , Step [1840/2888] , Loss: 0.5008504986763000\n",
      "Epoch [3/10] , Step [1850/2888] , Loss: 0.6366727948188782\n",
      "Epoch [3/10] , Step [1860/2888] , Loss: 0.6970434784889221\n",
      "Epoch [3/10] , Step [1870/2888] , Loss: 0.4927896559238434\n",
      "Epoch [3/10] , Step [1880/2888] , Loss: 0.2163021266460419\n",
      "Epoch [3/10] , Step [1890/2888] , Loss: 0.4710444808006287\n",
      "Epoch [3/10] , Step [1900/2888] , Loss: 0.5247555971145630\n",
      "Epoch [3/10] , Step [1910/2888] , Loss: 0.5923621058464050\n",
      "Epoch [3/10] , Step [1920/2888] , Loss: 0.3260514438152313\n",
      "Epoch [3/10] , Step [1930/2888] , Loss: 0.5636612772941589\n",
      "Epoch [3/10] , Step [1940/2888] , Loss: 0.4549677371978760\n",
      "Epoch [3/10] , Step [1950/2888] , Loss: 0.5306663513183594\n",
      "Epoch [3/10] , Step [1960/2888] , Loss: 0.3253373503684998\n",
      "Epoch [3/10] , Step [1970/2888] , Loss: 0.3730567097663879\n",
      "Epoch [3/10] , Step [1980/2888] , Loss: 0.5444803833961487\n",
      "Epoch [3/10] , Step [1990/2888] , Loss: 0.5327532291412354\n",
      "Epoch [3/10] , Step [2000/2888] , Loss: 0.4581800103187561\n",
      "Epoch [3/10] , Step [2010/2888] , Loss: 0.6202785968780518\n",
      "Epoch [3/10] , Step [2020/2888] , Loss: 0.4749872684478760\n",
      "Epoch [3/10] , Step [2030/2888] , Loss: 0.6649675965309143\n",
      "Epoch [3/10] , Step [2040/2888] , Loss: 0.3566887378692627\n",
      "Epoch [3/10] , Step [2050/2888] , Loss: 0.6249589323997498\n",
      "Epoch [3/10] , Step [2060/2888] , Loss: 0.3574286103248596\n",
      "Epoch [3/10] , Step [2070/2888] , Loss: 0.5116011500358582\n",
      "Epoch [3/10] , Step [2080/2888] , Loss: 0.1854855716228485\n",
      "Epoch [3/10] , Step [2090/2888] , Loss: 0.4796364903450012\n",
      "Epoch [3/10] , Step [2100/2888] , Loss: 0.5473328828811646\n",
      "Epoch [3/10] , Step [2110/2888] , Loss: 0.4789896905422211\n",
      "Epoch [3/10] , Step [2120/2888] , Loss: 0.4895144999027252\n",
      "Epoch [3/10] , Step [2130/2888] , Loss: 0.3105212450027466\n",
      "Epoch [3/10] , Step [2140/2888] , Loss: 0.4784989953041077\n",
      "Epoch [3/10] , Step [2150/2888] , Loss: 0.1590044051408768\n",
      "Epoch [3/10] , Step [2160/2888] , Loss: 0.5469641685485840\n",
      "Epoch [3/10] , Step [2170/2888] , Loss: 0.3379301726818085\n",
      "Epoch [3/10] , Step [2180/2888] , Loss: 0.6090987920761108\n",
      "Epoch [3/10] , Step [2190/2888] , Loss: 0.6776167750358582\n",
      "Epoch [3/10] , Step [2200/2888] , Loss: 0.4877429008483887\n",
      "Epoch [3/10] , Step [2210/2888] , Loss: 0.3572455346584320\n",
      "Epoch [3/10] , Step [2220/2888] , Loss: 0.3536227345466614\n",
      "Epoch [3/10] , Step [2230/2888] , Loss: 0.7140126228332520\n",
      "Epoch [3/10] , Step [2240/2888] , Loss: 0.2877281904220581\n",
      "Epoch [3/10] , Step [2250/2888] , Loss: 0.3554705381393433\n",
      "Epoch [3/10] , Step [2260/2888] , Loss: 0.3584349453449249\n",
      "Epoch [3/10] , Step [2270/2888] , Loss: 0.4649380445480347\n",
      "Epoch [3/10] , Step [2280/2888] , Loss: 0.4013808965682983\n",
      "Epoch [3/10] , Step [2290/2888] , Loss: 0.6420645117759705\n",
      "Epoch [3/10] , Step [2300/2888] , Loss: 0.5701989531517029\n",
      "Epoch [3/10] , Step [2310/2888] , Loss: 0.5362769365310669\n",
      "Epoch [3/10] , Step [2320/2888] , Loss: 0.4713471233844757\n",
      "Epoch [3/10] , Step [2330/2888] , Loss: 0.4684875905513763\n",
      "Epoch [3/10] , Step [2340/2888] , Loss: 0.4764201939105988\n",
      "Epoch [3/10] , Step [2350/2888] , Loss: 0.4731675386428833\n",
      "Epoch [3/10] , Step [2360/2888] , Loss: 0.5671265721321106\n",
      "Epoch [3/10] , Step [2370/2888] , Loss: 0.4061597287654877\n",
      "Epoch [3/10] , Step [2380/2888] , Loss: 0.3870935142040253\n",
      "Epoch [3/10] , Step [2390/2888] , Loss: 0.6623608469963074\n",
      "Epoch [3/10] , Step [2400/2888] , Loss: 0.4403517544269562\n",
      "Epoch [3/10] , Step [2410/2888] , Loss: 0.3387148380279541\n",
      "Epoch [3/10] , Step [2420/2888] , Loss: 0.7089471220970154\n",
      "Epoch [3/10] , Step [2430/2888] , Loss: 0.3634321689605713\n",
      "Epoch [3/10] , Step [2440/2888] , Loss: 0.4695319831371307\n",
      "Epoch [3/10] , Step [2450/2888] , Loss: 0.5051977634429932\n",
      "Epoch [3/10] , Step [2460/2888] , Loss: 0.4745340943336487\n",
      "Epoch [3/10] , Step [2470/2888] , Loss: 0.5134163498878479\n",
      "Epoch [3/10] , Step [2480/2888] , Loss: 0.4389408528804779\n",
      "Epoch [3/10] , Step [2490/2888] , Loss: 0.5287349224090576\n",
      "Epoch [3/10] , Step [2500/2888] , Loss: 0.6969279646873474\n",
      "Epoch [3/10] , Step [2510/2888] , Loss: 0.5139300227165222\n",
      "Epoch [3/10] , Step [2520/2888] , Loss: 0.2862565517425537\n",
      "Epoch [3/10] , Step [2530/2888] , Loss: 0.3201150000095367\n",
      "Epoch [3/10] , Step [2540/2888] , Loss: 0.4116428494453430\n",
      "Epoch [3/10] , Step [2550/2888] , Loss: 0.4046194255352020\n",
      "Epoch [3/10] , Step [2560/2888] , Loss: 0.3884289860725403\n",
      "Epoch [3/10] , Step [2570/2888] , Loss: 0.4867854714393616\n",
      "Epoch [3/10] , Step [2580/2888] , Loss: 0.3316345214843750\n",
      "Epoch [3/10] , Step [2590/2888] , Loss: 0.3816314041614532\n",
      "Epoch [3/10] , Step [2600/2888] , Loss: 0.4346979260444641\n",
      "Epoch [3/10] , Step [2610/2888] , Loss: 0.5638715028762817\n",
      "Epoch [3/10] , Step [2620/2888] , Loss: 0.5439165234565735\n",
      "Epoch [3/10] , Step [2630/2888] , Loss: 0.6045417785644531\n",
      "Epoch [3/10] , Step [2640/2888] , Loss: 0.8014787435531616\n",
      "Epoch [3/10] , Step [2650/2888] , Loss: 0.4161504805088043\n",
      "Epoch [3/10] , Step [2660/2888] , Loss: 0.5121440887451172\n",
      "Epoch [3/10] , Step [2670/2888] , Loss: 0.5068583488464355\n",
      "Epoch [3/10] , Step [2680/2888] , Loss: 0.4452760219573975\n",
      "Epoch [3/10] , Step [2690/2888] , Loss: 0.6704077124595642\n",
      "Epoch [3/10] , Step [2700/2888] , Loss: 0.5806913971900940\n",
      "Epoch [3/10] , Step [2710/2888] , Loss: 0.5062034130096436\n",
      "Epoch [3/10] , Step [2720/2888] , Loss: 0.5715564489364624\n",
      "Epoch [3/10] , Step [2730/2888] , Loss: 0.2924798727035522\n",
      "Epoch [3/10] , Step [2740/2888] , Loss: 0.4303710460662842\n",
      "Epoch [3/10] , Step [2750/2888] , Loss: 0.4331640005111694\n",
      "Epoch [3/10] , Step [2760/2888] , Loss: 0.5203548669815063\n",
      "Epoch [3/10] , Step [2770/2888] , Loss: 0.2178891897201538\n",
      "Epoch [3/10] , Step [2780/2888] , Loss: 0.4760849475860596\n",
      "Epoch [3/10] , Step [2790/2888] , Loss: 0.3976161479949951\n",
      "Epoch [3/10] , Step [2800/2888] , Loss: 0.3435849845409393\n",
      "Epoch [3/10] , Step [2810/2888] , Loss: 0.3525955080986023\n",
      "Epoch [3/10] , Step [2820/2888] , Loss: 0.5269240140914917\n",
      "Epoch [3/10] , Step [2830/2888] , Loss: 0.4806203246116638\n",
      "Epoch [3/10] , Step [2840/2888] , Loss: 0.5902081131935120\n",
      "Epoch [3/10] , Step [2850/2888] , Loss: 0.3904628753662109\n",
      "Epoch [3/10] , Step [2860/2888] , Loss: 0.4705933928489685\n",
      "Epoch [3/10] , Step [2870/2888] , Loss: 0.2421551942825317\n",
      "Epoch [3/10] , Step [2880/2888] , Loss: 0.2359813749790192\n",
      "Epoch [4/10] , Step [10/2888] , Loss: 0.5646010041236877\n",
      "Epoch [4/10] , Step [20/2888] , Loss: 0.3204823732376099\n",
      "Epoch [4/10] , Step [30/2888] , Loss: 0.1787831038236618\n",
      "Epoch [4/10] , Step [40/2888] , Loss: 0.6437163352966309\n",
      "Epoch [4/10] , Step [50/2888] , Loss: 0.3116837143898010\n",
      "Epoch [4/10] , Step [60/2888] , Loss: 0.3680262565612793\n",
      "Epoch [4/10] , Step [70/2888] , Loss: 0.4666715860366821\n",
      "Epoch [4/10] , Step [80/2888] , Loss: 0.4652124047279358\n",
      "Epoch [4/10] , Step [90/2888] , Loss: 0.6202685832977295\n",
      "Epoch [4/10] , Step [100/2888] , Loss: 0.4909812211990356\n",
      "Epoch [4/10] , Step [110/2888] , Loss: 0.6565766334533691\n",
      "Epoch [4/10] , Step [120/2888] , Loss: 0.5292873382568359\n",
      "Epoch [4/10] , Step [130/2888] , Loss: 0.4506813585758209\n",
      "Epoch [4/10] , Step [140/2888] , Loss: 0.7150141596794128\n",
      "Epoch [4/10] , Step [150/2888] , Loss: 0.6307569146156311\n",
      "Epoch [4/10] , Step [160/2888] , Loss: 0.5588748455047607\n",
      "Epoch [4/10] , Step [170/2888] , Loss: 0.5528669357299805\n",
      "Epoch [4/10] , Step [180/2888] , Loss: 0.5747266411781311\n",
      "Epoch [4/10] , Step [190/2888] , Loss: 0.7138072252273560\n",
      "Epoch [4/10] , Step [200/2888] , Loss: 0.4589020907878876\n",
      "Epoch [4/10] , Step [210/2888] , Loss: 0.3678539395332336\n",
      "Epoch [4/10] , Step [220/2888] , Loss: 0.4670122861862183\n",
      "Epoch [4/10] , Step [230/2888] , Loss: 0.3928163647651672\n",
      "Epoch [4/10] , Step [240/2888] , Loss: 0.2209055423736572\n",
      "Epoch [4/10] , Step [250/2888] , Loss: 0.4543419480323792\n",
      "Epoch [4/10] , Step [260/2888] , Loss: 0.6202811598777771\n",
      "Epoch [4/10] , Step [270/2888] , Loss: 0.5132751464843750\n",
      "Epoch [4/10] , Step [280/2888] , Loss: 0.3926027715206146\n",
      "Epoch [4/10] , Step [290/2888] , Loss: 0.4535294175148010\n",
      "Epoch [4/10] , Step [300/2888] , Loss: 0.4310678243637085\n",
      "Epoch [4/10] , Step [310/2888] , Loss: 0.4270021617412567\n",
      "Epoch [4/10] , Step [320/2888] , Loss: 0.5438589453697205\n",
      "Epoch [4/10] , Step [330/2888] , Loss: 0.4945858120918274\n",
      "Epoch [4/10] , Step [340/2888] , Loss: 0.5222705602645874\n",
      "Epoch [4/10] , Step [350/2888] , Loss: 0.7621034383773804\n",
      "Epoch [4/10] , Step [360/2888] , Loss: 0.4749119877815247\n",
      "Epoch [4/10] , Step [370/2888] , Loss: 0.4763110280036926\n",
      "Epoch [4/10] , Step [380/2888] , Loss: 0.4156104922294617\n",
      "Epoch [4/10] , Step [390/2888] , Loss: 0.4293908476829529\n",
      "Epoch [4/10] , Step [400/2888] , Loss: 0.4580080211162567\n",
      "Epoch [4/10] , Step [410/2888] , Loss: 0.4479175806045532\n",
      "Epoch [4/10] , Step [420/2888] , Loss: 0.4609277844429016\n",
      "Epoch [4/10] , Step [430/2888] , Loss: 0.5725905299186707\n",
      "Epoch [4/10] , Step [440/2888] , Loss: 0.5132327079772949\n",
      "Epoch [4/10] , Step [450/2888] , Loss: 0.5434079766273499\n",
      "Epoch [4/10] , Step [460/2888] , Loss: 0.2974041104316711\n",
      "Epoch [4/10] , Step [470/2888] , Loss: 0.5767559409141541\n",
      "Epoch [4/10] , Step [480/2888] , Loss: 0.4403387606143951\n",
      "Epoch [4/10] , Step [490/2888] , Loss: 0.4550562202930450\n",
      "Epoch [4/10] , Step [500/2888] , Loss: 0.5203927755355835\n",
      "Epoch [4/10] , Step [510/2888] , Loss: 0.1548644900321960\n",
      "Epoch [4/10] , Step [520/2888] , Loss: 0.5174590349197388\n",
      "Epoch [4/10] , Step [530/2888] , Loss: 0.2344854027032852\n",
      "Epoch [4/10] , Step [540/2888] , Loss: 0.4025404453277588\n",
      "Epoch [4/10] , Step [550/2888] , Loss: 0.4797547161579132\n",
      "Epoch [4/10] , Step [560/2888] , Loss: 0.4717123806476593\n",
      "Epoch [4/10] , Step [570/2888] , Loss: 0.4733749032020569\n",
      "Epoch [4/10] , Step [580/2888] , Loss: 0.3446296751499176\n",
      "Epoch [4/10] , Step [590/2888] , Loss: 0.4365790188312531\n",
      "Epoch [4/10] , Step [600/2888] , Loss: 0.7169463038444519\n",
      "Epoch [4/10] , Step [610/2888] , Loss: 0.3797902166843414\n",
      "Epoch [4/10] , Step [620/2888] , Loss: 0.5071379542350769\n",
      "Epoch [4/10] , Step [630/2888] , Loss: 0.5916422605514526\n",
      "Epoch [4/10] , Step [640/2888] , Loss: 0.5142551064491272\n",
      "Epoch [4/10] , Step [650/2888] , Loss: 0.5978906154632568\n",
      "Epoch [4/10] , Step [660/2888] , Loss: 0.2601368725299835\n",
      "Epoch [4/10] , Step [670/2888] , Loss: 0.6197136044502258\n",
      "Epoch [4/10] , Step [680/2888] , Loss: 0.4747877120971680\n",
      "Epoch [4/10] , Step [690/2888] , Loss: 0.4285364747047424\n",
      "Epoch [4/10] , Step [700/2888] , Loss: 0.4505285322666168\n",
      "Epoch [4/10] , Step [710/2888] , Loss: 0.6626503467559814\n",
      "Epoch [4/10] , Step [720/2888] , Loss: 0.4689258635044098\n",
      "Epoch [4/10] , Step [730/2888] , Loss: 0.3992120325565338\n",
      "Epoch [4/10] , Step [740/2888] , Loss: 0.4805426895618439\n",
      "Epoch [4/10] , Step [750/2888] , Loss: 0.4157707393169403\n",
      "Epoch [4/10] , Step [760/2888] , Loss: 0.4071623086929321\n",
      "Epoch [4/10] , Step [770/2888] , Loss: 0.4491989612579346\n",
      "Epoch [4/10] , Step [780/2888] , Loss: 0.5498667955398560\n",
      "Epoch [4/10] , Step [790/2888] , Loss: 0.4616874754428864\n",
      "Epoch [4/10] , Step [800/2888] , Loss: 0.5154302716255188\n",
      "Epoch [4/10] , Step [810/2888] , Loss: 0.3566241562366486\n",
      "Epoch [4/10] , Step [820/2888] , Loss: 0.5393582582473755\n",
      "Epoch [4/10] , Step [830/2888] , Loss: 0.6666253805160522\n",
      "Epoch [4/10] , Step [840/2888] , Loss: 0.5334448814392090\n",
      "Epoch [4/10] , Step [850/2888] , Loss: 0.4408419430255890\n",
      "Epoch [4/10] , Step [860/2888] , Loss: 0.3301173150539398\n",
      "Epoch [4/10] , Step [870/2888] , Loss: 0.5344456434249878\n",
      "Epoch [4/10] , Step [880/2888] , Loss: 0.7194396257400513\n",
      "Epoch [4/10] , Step [890/2888] , Loss: 0.4452984333038330\n",
      "Epoch [4/10] , Step [900/2888] , Loss: 0.6160545349121094\n",
      "Epoch [4/10] , Step [910/2888] , Loss: 0.5469721555709839\n",
      "Epoch [4/10] , Step [920/2888] , Loss: 0.5307468771934509\n",
      "Epoch [4/10] , Step [930/2888] , Loss: 0.4514532387256622\n",
      "Epoch [4/10] , Step [940/2888] , Loss: 0.3862976431846619\n",
      "Epoch [4/10] , Step [950/2888] , Loss: 0.6555991172790527\n",
      "Epoch [4/10] , Step [960/2888] , Loss: 0.5140863656997681\n",
      "Epoch [4/10] , Step [970/2888] , Loss: 0.5157107710838318\n",
      "Epoch [4/10] , Step [980/2888] , Loss: 0.5871595144271851\n",
      "Epoch [4/10] , Step [990/2888] , Loss: 0.4506943821907043\n",
      "Epoch [4/10] , Step [1000/2888] , Loss: 0.5955071449279785\n",
      "Epoch [4/10] , Step [1010/2888] , Loss: 0.6130701899528503\n",
      "Epoch [4/10] , Step [1020/2888] , Loss: 0.4508969485759735\n",
      "Epoch [4/10] , Step [1030/2888] , Loss: 0.5278396606445312\n",
      "Epoch [4/10] , Step [1040/2888] , Loss: 0.6012791991233826\n",
      "Epoch [4/10] , Step [1050/2888] , Loss: 0.7341554164886475\n",
      "Epoch [4/10] , Step [1060/2888] , Loss: 0.4898300468921661\n",
      "Epoch [4/10] , Step [1070/2888] , Loss: 0.2821786999702454\n",
      "Epoch [4/10] , Step [1080/2888] , Loss: 0.2873762845993042\n",
      "Epoch [4/10] , Step [1090/2888] , Loss: 0.5070566534996033\n",
      "Epoch [4/10] , Step [1100/2888] , Loss: 0.5417305231094360\n",
      "Epoch [4/10] , Step [1110/2888] , Loss: 0.5945383906364441\n",
      "Epoch [4/10] , Step [1120/2888] , Loss: 0.4185023307800293\n",
      "Epoch [4/10] , Step [1130/2888] , Loss: 0.7593359947204590\n",
      "Epoch [4/10] , Step [1140/2888] , Loss: 0.4280144572257996\n",
      "Epoch [4/10] , Step [1150/2888] , Loss: 0.5199841856956482\n",
      "Epoch [4/10] , Step [1160/2888] , Loss: 0.4595211744308472\n",
      "Epoch [4/10] , Step [1170/2888] , Loss: 0.3260931670665741\n",
      "Epoch [4/10] , Step [1180/2888] , Loss: 0.4876509308815002\n",
      "Epoch [4/10] , Step [1190/2888] , Loss: 0.4056634306907654\n",
      "Epoch [4/10] , Step [1200/2888] , Loss: 0.5916240811347961\n",
      "Epoch [4/10] , Step [1210/2888] , Loss: 0.3429956436157227\n",
      "Epoch [4/10] , Step [1220/2888] , Loss: 0.4620053768157959\n",
      "Epoch [4/10] , Step [1230/2888] , Loss: 0.5054721832275391\n",
      "Epoch [4/10] , Step [1240/2888] , Loss: 0.5770053267478943\n",
      "Epoch [4/10] , Step [1250/2888] , Loss: 0.3405762910842896\n",
      "Epoch [4/10] , Step [1260/2888] , Loss: 0.4067948162555695\n",
      "Epoch [4/10] , Step [1270/2888] , Loss: 0.6874750852584839\n",
      "Epoch [4/10] , Step [1280/2888] , Loss: 0.3301325440406799\n",
      "Epoch [4/10] , Step [1290/2888] , Loss: 0.5533943176269531\n",
      "Epoch [4/10] , Step [1300/2888] , Loss: 0.3455524146556854\n",
      "Epoch [4/10] , Step [1310/2888] , Loss: 0.3838537931442261\n",
      "Epoch [4/10] , Step [1320/2888] , Loss: 0.7278032302856445\n",
      "Epoch [4/10] , Step [1330/2888] , Loss: 0.4506323039531708\n",
      "Epoch [4/10] , Step [1340/2888] , Loss: 0.4710216224193573\n",
      "Epoch [4/10] , Step [1350/2888] , Loss: 0.5645307302474976\n",
      "Epoch [4/10] , Step [1360/2888] , Loss: 0.5929208993911743\n",
      "Epoch [4/10] , Step [1370/2888] , Loss: 0.6288667917251587\n",
      "Epoch [4/10] , Step [1380/2888] , Loss: 0.4004050195217133\n",
      "Epoch [4/10] , Step [1390/2888] , Loss: 0.3969728350639343\n",
      "Epoch [4/10] , Step [1400/2888] , Loss: 0.3493141233921051\n",
      "Epoch [4/10] , Step [1410/2888] , Loss: 0.4954840540885925\n",
      "Epoch [4/10] , Step [1420/2888] , Loss: 0.6594014763832092\n",
      "Epoch [4/10] , Step [1430/2888] , Loss: 0.3836987316608429\n",
      "Epoch [4/10] , Step [1440/2888] , Loss: 0.3871961832046509\n",
      "Epoch [4/10] , Step [1450/2888] , Loss: 0.3216697871685028\n",
      "Epoch [4/10] , Step [1460/2888] , Loss: 0.4232211112976074\n",
      "Epoch [4/10] , Step [1470/2888] , Loss: 0.6119803786277771\n",
      "Epoch [4/10] , Step [1480/2888] , Loss: 0.4827612936496735\n",
      "Epoch [4/10] , Step [1490/2888] , Loss: 0.4118984937667847\n",
      "Epoch [4/10] , Step [1500/2888] , Loss: 0.3390632867813110\n",
      "Epoch [4/10] , Step [1510/2888] , Loss: 0.4956271648406982\n",
      "Epoch [4/10] , Step [1520/2888] , Loss: 0.3927640318870544\n",
      "Epoch [4/10] , Step [1530/2888] , Loss: 0.4472924768924713\n",
      "Epoch [4/10] , Step [1540/2888] , Loss: 0.5101299285888672\n",
      "Epoch [4/10] , Step [1550/2888] , Loss: 0.4538240730762482\n",
      "Epoch [4/10] , Step [1560/2888] , Loss: 0.4837734699249268\n",
      "Epoch [4/10] , Step [1570/2888] , Loss: 0.2631336450576782\n",
      "Epoch [4/10] , Step [1580/2888] , Loss: 0.6805863380432129\n",
      "Epoch [4/10] , Step [1590/2888] , Loss: 0.3252624273300171\n",
      "Epoch [4/10] , Step [1600/2888] , Loss: 0.6341179013252258\n",
      "Epoch [4/10] , Step [1610/2888] , Loss: 0.5963689684867859\n",
      "Epoch [4/10] , Step [1620/2888] , Loss: 0.3054434061050415\n",
      "Epoch [4/10] , Step [1630/2888] , Loss: 0.5192809104919434\n",
      "Epoch [4/10] , Step [1640/2888] , Loss: 0.4103313684463501\n",
      "Epoch [4/10] , Step [1650/2888] , Loss: 0.3114975988864899\n",
      "Epoch [4/10] , Step [1660/2888] , Loss: 0.6705971956253052\n",
      "Epoch [4/10] , Step [1670/2888] , Loss: 0.6667388081550598\n",
      "Epoch [4/10] , Step [1680/2888] , Loss: 0.2998197972774506\n",
      "Epoch [4/10] , Step [1690/2888] , Loss: 0.4436914920806885\n",
      "Epoch [4/10] , Step [1700/2888] , Loss: 0.4905082583427429\n",
      "Epoch [4/10] , Step [1710/2888] , Loss: 0.3144291043281555\n",
      "Epoch [4/10] , Step [1720/2888] , Loss: 0.5898317098617554\n",
      "Epoch [4/10] , Step [1730/2888] , Loss: 0.5727427005767822\n",
      "Epoch [4/10] , Step [1740/2888] , Loss: 0.5333164930343628\n",
      "Epoch [4/10] , Step [1750/2888] , Loss: 0.5802738666534424\n",
      "Epoch [4/10] , Step [1760/2888] , Loss: 0.4639027118682861\n",
      "Epoch [4/10] , Step [1770/2888] , Loss: 0.3031371831893921\n",
      "Epoch [4/10] , Step [1780/2888] , Loss: 0.4438101351261139\n",
      "Epoch [4/10] , Step [1790/2888] , Loss: 0.5874324440956116\n",
      "Epoch [4/10] , Step [1800/2888] , Loss: 0.4588595330715179\n",
      "Epoch [4/10] , Step [1810/2888] , Loss: 0.4905025362968445\n",
      "Epoch [4/10] , Step [1820/2888] , Loss: 0.4295645952224731\n",
      "Epoch [4/10] , Step [1830/2888] , Loss: 0.4615520238876343\n",
      "Epoch [4/10] , Step [1840/2888] , Loss: 0.6475576162338257\n",
      "Epoch [4/10] , Step [1850/2888] , Loss: 0.5195767283439636\n",
      "Epoch [4/10] , Step [1860/2888] , Loss: 0.4806027412414551\n",
      "Epoch [4/10] , Step [1870/2888] , Loss: 0.5396715402603149\n",
      "Epoch [4/10] , Step [1880/2888] , Loss: 0.4409969747066498\n",
      "Epoch [4/10] , Step [1890/2888] , Loss: 0.4317891001701355\n",
      "Epoch [4/10] , Step [1900/2888] , Loss: 0.6955111622810364\n",
      "Epoch [4/10] , Step [1910/2888] , Loss: 0.4422795772552490\n",
      "Epoch [4/10] , Step [1920/2888] , Loss: 0.4627858996391296\n",
      "Epoch [4/10] , Step [1930/2888] , Loss: 0.4769224524497986\n",
      "Epoch [4/10] , Step [1940/2888] , Loss: 0.1791712045669556\n",
      "Epoch [4/10] , Step [1950/2888] , Loss: 0.3152896165847778\n",
      "Epoch [4/10] , Step [1960/2888] , Loss: 0.4686175882816315\n",
      "Epoch [4/10] , Step [1970/2888] , Loss: 0.3039369285106659\n",
      "Epoch [4/10] , Step [1980/2888] , Loss: 0.5423452854156494\n",
      "Epoch [4/10] , Step [1990/2888] , Loss: 0.6242830157279968\n",
      "Epoch [4/10] , Step [2000/2888] , Loss: 0.3334017992019653\n",
      "Epoch [4/10] , Step [2010/2888] , Loss: 0.4271834492683411\n",
      "Epoch [4/10] , Step [2020/2888] , Loss: 0.4258679151535034\n",
      "Epoch [4/10] , Step [2030/2888] , Loss: 0.3462913632392883\n",
      "Epoch [4/10] , Step [2040/2888] , Loss: 0.3921143710613251\n",
      "Epoch [4/10] , Step [2050/2888] , Loss: 0.5598787069320679\n",
      "Epoch [4/10] , Step [2060/2888] , Loss: 0.3182883858680725\n",
      "Epoch [4/10] , Step [2070/2888] , Loss: 0.3284889459609985\n",
      "Epoch [4/10] , Step [2080/2888] , Loss: 0.5720630884170532\n",
      "Epoch [4/10] , Step [2090/2888] , Loss: 0.3060628771781921\n",
      "Epoch [4/10] , Step [2100/2888] , Loss: 0.4169112443923950\n",
      "Epoch [4/10] , Step [2110/2888] , Loss: 0.5234575867652893\n",
      "Epoch [4/10] , Step [2120/2888] , Loss: 0.3394473195075989\n",
      "Epoch [4/10] , Step [2130/2888] , Loss: 0.4529935717582703\n",
      "Epoch [4/10] , Step [2140/2888] , Loss: 0.3758738040924072\n",
      "Epoch [4/10] , Step [2150/2888] , Loss: 0.4180771708488464\n",
      "Epoch [4/10] , Step [2160/2888] , Loss: 0.5170003771781921\n",
      "Epoch [4/10] , Step [2170/2888] , Loss: 0.5546597838401794\n",
      "Epoch [4/10] , Step [2180/2888] , Loss: 0.4079791903495789\n",
      "Epoch [4/10] , Step [2190/2888] , Loss: 0.4550082683563232\n",
      "Epoch [4/10] , Step [2200/2888] , Loss: 0.5489903092384338\n",
      "Epoch [4/10] , Step [2210/2888] , Loss: 0.4725501537322998\n",
      "Epoch [4/10] , Step [2220/2888] , Loss: 0.3318838179111481\n",
      "Epoch [4/10] , Step [2230/2888] , Loss: 0.4021151065826416\n",
      "Epoch [4/10] , Step [2240/2888] , Loss: 0.5473303198814392\n",
      "Epoch [4/10] , Step [2250/2888] , Loss: 0.3454200625419617\n",
      "Epoch [4/10] , Step [2260/2888] , Loss: 0.4921664893627167\n",
      "Epoch [4/10] , Step [2270/2888] , Loss: 0.4228489696979523\n",
      "Epoch [4/10] , Step [2280/2888] , Loss: 0.4836153388023376\n",
      "Epoch [4/10] , Step [2290/2888] , Loss: 0.4198309779167175\n",
      "Epoch [4/10] , Step [2300/2888] , Loss: 0.4081318676471710\n",
      "Epoch [4/10] , Step [2310/2888] , Loss: 0.4616713225841522\n",
      "Epoch [4/10] , Step [2320/2888] , Loss: 0.3153015375137329\n",
      "Epoch [4/10] , Step [2330/2888] , Loss: 0.4647496342658997\n",
      "Epoch [4/10] , Step [2340/2888] , Loss: 0.3543142974376678\n",
      "Epoch [4/10] , Step [2350/2888] , Loss: 0.5173471570014954\n",
      "Epoch [4/10] , Step [2360/2888] , Loss: 0.5101658701896667\n",
      "Epoch [4/10] , Step [2370/2888] , Loss: 0.5114125609397888\n",
      "Epoch [4/10] , Step [2380/2888] , Loss: 0.6345022320747375\n",
      "Epoch [4/10] , Step [2390/2888] , Loss: 0.4842194616794586\n",
      "Epoch [4/10] , Step [2400/2888] , Loss: 0.4647021889686584\n",
      "Epoch [4/10] , Step [2410/2888] , Loss: 0.4147804677486420\n",
      "Epoch [4/10] , Step [2420/2888] , Loss: 0.5664128065109253\n",
      "Epoch [4/10] , Step [2430/2888] , Loss: 0.5248250961303711\n",
      "Epoch [4/10] , Step [2440/2888] , Loss: 0.5271588563919067\n",
      "Epoch [4/10] , Step [2450/2888] , Loss: 0.1819896847009659\n",
      "Epoch [4/10] , Step [2460/2888] , Loss: 0.5231387615203857\n",
      "Epoch [4/10] , Step [2470/2888] , Loss: 0.3762613534927368\n",
      "Epoch [4/10] , Step [2480/2888] , Loss: 0.4030336141586304\n",
      "Epoch [4/10] , Step [2490/2888] , Loss: 0.4614732861518860\n",
      "Epoch [4/10] , Step [2500/2888] , Loss: 0.5719776749610901\n",
      "Epoch [4/10] , Step [2510/2888] , Loss: 0.4783374369144440\n",
      "Epoch [4/10] , Step [2520/2888] , Loss: 0.2528857886791229\n",
      "Epoch [4/10] , Step [2530/2888] , Loss: 0.5325828790664673\n",
      "Epoch [4/10] , Step [2540/2888] , Loss: 0.3215419054031372\n",
      "Epoch [4/10] , Step [2550/2888] , Loss: 0.3719011843204498\n",
      "Epoch [4/10] , Step [2560/2888] , Loss: 0.3103434443473816\n",
      "Epoch [4/10] , Step [2570/2888] , Loss: 0.5395855307579041\n",
      "Epoch [4/10] , Step [2580/2888] , Loss: 0.5586981773376465\n",
      "Epoch [4/10] , Step [2590/2888] , Loss: 0.2532152831554413\n",
      "Epoch [4/10] , Step [2600/2888] , Loss: 0.5680934786796570\n",
      "Epoch [4/10] , Step [2610/2888] , Loss: 0.3760073184967041\n",
      "Epoch [4/10] , Step [2620/2888] , Loss: 0.3665885925292969\n",
      "Epoch [4/10] , Step [2630/2888] , Loss: 0.5964468717575073\n",
      "Epoch [4/10] , Step [2640/2888] , Loss: 0.3691501319408417\n",
      "Epoch [4/10] , Step [2650/2888] , Loss: 0.4423555135726929\n",
      "Epoch [4/10] , Step [2660/2888] , Loss: 0.5806786417961121\n",
      "Epoch [4/10] , Step [2670/2888] , Loss: 0.6066278219223022\n",
      "Epoch [4/10] , Step [2680/2888] , Loss: 0.6764841675758362\n",
      "Epoch [4/10] , Step [2690/2888] , Loss: 0.6029642820358276\n",
      "Epoch [4/10] , Step [2700/2888] , Loss: 0.3908764719963074\n",
      "Epoch [4/10] , Step [2710/2888] , Loss: 0.5275180339813232\n",
      "Epoch [4/10] , Step [2720/2888] , Loss: 0.6923036575317383\n",
      "Epoch [4/10] , Step [2730/2888] , Loss: 0.4510004222393036\n",
      "Epoch [4/10] , Step [2740/2888] , Loss: 0.6421456336975098\n",
      "Epoch [4/10] , Step [2750/2888] , Loss: 0.5924168229103088\n",
      "Epoch [4/10] , Step [2760/2888] , Loss: 0.4395744204521179\n",
      "Epoch [4/10] , Step [2770/2888] , Loss: 0.6968643069267273\n",
      "Epoch [4/10] , Step [2780/2888] , Loss: 0.5649086236953735\n",
      "Epoch [4/10] , Step [2790/2888] , Loss: 0.3357060253620148\n",
      "Epoch [4/10] , Step [2800/2888] , Loss: 0.6886298060417175\n",
      "Epoch [4/10] , Step [2810/2888] , Loss: 0.3788193464279175\n",
      "Epoch [4/10] , Step [2820/2888] , Loss: 0.5375014543533325\n",
      "Epoch [4/10] , Step [2830/2888] , Loss: 0.4554859399795532\n",
      "Epoch [4/10] , Step [2840/2888] , Loss: 0.5910252928733826\n",
      "Epoch [4/10] , Step [2850/2888] , Loss: 0.5081091523170471\n",
      "Epoch [4/10] , Step [2860/2888] , Loss: 0.3999977111816406\n",
      "Epoch [4/10] , Step [2870/2888] , Loss: 0.4562248587608337\n",
      "Epoch [4/10] , Step [2880/2888] , Loss: 0.4922704100608826\n",
      "Epoch [5/10] , Step [10/2888] , Loss: 0.4619906544685364\n",
      "Epoch [5/10] , Step [20/2888] , Loss: 0.3681793808937073\n",
      "Epoch [5/10] , Step [30/2888] , Loss: 0.4684212207794189\n",
      "Epoch [5/10] , Step [40/2888] , Loss: 0.4666676819324493\n",
      "Epoch [5/10] , Step [50/2888] , Loss: 0.5420266985893250\n",
      "Epoch [5/10] , Step [60/2888] , Loss: 0.3785867094993591\n",
      "Epoch [5/10] , Step [70/2888] , Loss: 0.4621412456035614\n",
      "Epoch [5/10] , Step [80/2888] , Loss: 0.3032879233360291\n",
      "Epoch [5/10] , Step [90/2888] , Loss: 0.4165300726890564\n",
      "Epoch [5/10] , Step [100/2888] , Loss: 0.3388223052024841\n",
      "Epoch [5/10] , Step [110/2888] , Loss: 0.3717010915279388\n",
      "Epoch [5/10] , Step [120/2888] , Loss: 0.4200963377952576\n",
      "Epoch [5/10] , Step [130/2888] , Loss: 0.4822164475917816\n",
      "Epoch [5/10] , Step [140/2888] , Loss: 0.2616489529609680\n",
      "Epoch [5/10] , Step [150/2888] , Loss: 0.5621905922889709\n",
      "Epoch [5/10] , Step [160/2888] , Loss: 0.5505841374397278\n",
      "Epoch [5/10] , Step [170/2888] , Loss: 0.4339946806430817\n",
      "Epoch [5/10] , Step [180/2888] , Loss: 0.4381383359432220\n",
      "Epoch [5/10] , Step [190/2888] , Loss: 0.4895842671394348\n",
      "Epoch [5/10] , Step [200/2888] , Loss: 0.5583662986755371\n",
      "Epoch [5/10] , Step [210/2888] , Loss: 0.5635929107666016\n",
      "Epoch [5/10] , Step [220/2888] , Loss: 0.3497568070888519\n",
      "Epoch [5/10] , Step [230/2888] , Loss: 0.6764807701110840\n",
      "Epoch [5/10] , Step [240/2888] , Loss: 0.5881174206733704\n",
      "Epoch [5/10] , Step [250/2888] , Loss: 0.5547841191291809\n",
      "Epoch [5/10] , Step [260/2888] , Loss: 0.6026455163955688\n",
      "Epoch [5/10] , Step [270/2888] , Loss: 0.6351850032806396\n",
      "Epoch [5/10] , Step [280/2888] , Loss: 0.4719081223011017\n",
      "Epoch [5/10] , Step [290/2888] , Loss: 0.5882504582405090\n",
      "Epoch [5/10] , Step [300/2888] , Loss: 0.3903246521949768\n",
      "Epoch [5/10] , Step [310/2888] , Loss: 0.4625053107738495\n",
      "Epoch [5/10] , Step [320/2888] , Loss: 0.4510572850704193\n",
      "Epoch [5/10] , Step [330/2888] , Loss: 0.5369666814804077\n",
      "Epoch [5/10] , Step [340/2888] , Loss: 0.6740668416023254\n",
      "Epoch [5/10] , Step [350/2888] , Loss: 0.4661918878555298\n",
      "Epoch [5/10] , Step [360/2888] , Loss: 0.5764053463935852\n",
      "Epoch [5/10] , Step [370/2888] , Loss: 0.3414180874824524\n",
      "Epoch [5/10] , Step [380/2888] , Loss: 0.3601225614547729\n",
      "Epoch [5/10] , Step [390/2888] , Loss: 0.4778619110584259\n",
      "Epoch [5/10] , Step [400/2888] , Loss: 0.3262993097305298\n",
      "Epoch [5/10] , Step [410/2888] , Loss: 0.4118230342864990\n",
      "Epoch [5/10] , Step [420/2888] , Loss: 0.3534198701381683\n",
      "Epoch [5/10] , Step [430/2888] , Loss: 0.5455694794654846\n",
      "Epoch [5/10] , Step [440/2888] , Loss: 0.4241594076156616\n",
      "Epoch [5/10] , Step [450/2888] , Loss: 0.4587723910808563\n",
      "Epoch [5/10] , Step [460/2888] , Loss: 0.6412944793701172\n",
      "Epoch [5/10] , Step [470/2888] , Loss: 0.4780344367027283\n",
      "Epoch [5/10] , Step [480/2888] , Loss: 0.4227107763290405\n",
      "Epoch [5/10] , Step [490/2888] , Loss: 0.3518350720405579\n",
      "Epoch [5/10] , Step [500/2888] , Loss: 0.7077643275260925\n",
      "Epoch [5/10] , Step [510/2888] , Loss: 0.4132357537746429\n",
      "Epoch [5/10] , Step [520/2888] , Loss: 0.4668258726596832\n",
      "Epoch [5/10] , Step [530/2888] , Loss: 0.4824589490890503\n",
      "Epoch [5/10] , Step [540/2888] , Loss: 0.3714400529861450\n",
      "Epoch [5/10] , Step [550/2888] , Loss: 0.4606257081031799\n",
      "Epoch [5/10] , Step [560/2888] , Loss: 0.6031668782234192\n",
      "Epoch [5/10] , Step [570/2888] , Loss: 0.4025313258171082\n",
      "Epoch [5/10] , Step [580/2888] , Loss: 0.4571018815040588\n",
      "Epoch [5/10] , Step [590/2888] , Loss: 0.4963575601577759\n",
      "Epoch [5/10] , Step [600/2888] , Loss: 0.5601370930671692\n",
      "Epoch [5/10] , Step [610/2888] , Loss: 0.5755084753036499\n",
      "Epoch [5/10] , Step [620/2888] , Loss: 0.4476288557052612\n",
      "Epoch [5/10] , Step [630/2888] , Loss: 0.4853219985961914\n",
      "Epoch [5/10] , Step [640/2888] , Loss: 0.3446582555770874\n",
      "Epoch [5/10] , Step [650/2888] , Loss: 0.3491321802139282\n",
      "Epoch [5/10] , Step [660/2888] , Loss: 0.4818405210971832\n",
      "Epoch [5/10] , Step [670/2888] , Loss: 0.4851135909557343\n",
      "Epoch [5/10] , Step [680/2888] , Loss: 0.5485423207283020\n",
      "Epoch [5/10] , Step [690/2888] , Loss: 0.5991426706314087\n",
      "Epoch [5/10] , Step [700/2888] , Loss: 0.4047483503818512\n",
      "Epoch [5/10] , Step [710/2888] , Loss: 0.3678571581840515\n",
      "Epoch [5/10] , Step [720/2888] , Loss: 0.4795778989791870\n",
      "Epoch [5/10] , Step [730/2888] , Loss: 0.4017830491065979\n",
      "Epoch [5/10] , Step [740/2888] , Loss: 0.3967005908489227\n",
      "Epoch [5/10] , Step [750/2888] , Loss: 0.4634828567504883\n",
      "Epoch [5/10] , Step [760/2888] , Loss: 0.5098608136177063\n",
      "Epoch [5/10] , Step [770/2888] , Loss: 0.4946267604827881\n",
      "Epoch [5/10] , Step [780/2888] , Loss: 0.4549553990364075\n",
      "Epoch [5/10] , Step [790/2888] , Loss: 0.5937313437461853\n",
      "Epoch [5/10] , Step [800/2888] , Loss: 0.3134377002716064\n",
      "Epoch [5/10] , Step [810/2888] , Loss: 0.2480009198188782\n",
      "Epoch [5/10] , Step [820/2888] , Loss: 0.4710205197334290\n",
      "Epoch [5/10] , Step [830/2888] , Loss: 0.4574168920516968\n",
      "Epoch [5/10] , Step [840/2888] , Loss: 0.5567808747291565\n",
      "Epoch [5/10] , Step [850/2888] , Loss: 0.3961167633533478\n",
      "Epoch [5/10] , Step [860/2888] , Loss: 0.5379373431205750\n",
      "Epoch [5/10] , Step [870/2888] , Loss: 0.5116620063781738\n",
      "Epoch [5/10] , Step [880/2888] , Loss: 0.6244903206825256\n",
      "Epoch [5/10] , Step [890/2888] , Loss: 0.3708364069461823\n",
      "Epoch [5/10] , Step [900/2888] , Loss: 0.3512569665908813\n",
      "Epoch [5/10] , Step [910/2888] , Loss: 0.4758217632770538\n",
      "Epoch [5/10] , Step [920/2888] , Loss: 0.5144048929214478\n",
      "Epoch [5/10] , Step [930/2888] , Loss: 0.6053060293197632\n",
      "Epoch [5/10] , Step [940/2888] , Loss: 0.4766176342964172\n",
      "Epoch [5/10] , Step [950/2888] , Loss: 0.3842392265796661\n",
      "Epoch [5/10] , Step [960/2888] , Loss: 0.6623473167419434\n",
      "Epoch [5/10] , Step [970/2888] , Loss: 0.3262286484241486\n",
      "Epoch [5/10] , Step [980/2888] , Loss: 0.5704681873321533\n",
      "Epoch [5/10] , Step [990/2888] , Loss: 0.5186073780059814\n",
      "Epoch [5/10] , Step [1000/2888] , Loss: 0.2502322793006897\n",
      "Epoch [5/10] , Step [1010/2888] , Loss: 0.6225276589393616\n",
      "Epoch [5/10] , Step [1020/2888] , Loss: 0.4532521069049835\n",
      "Epoch [5/10] , Step [1030/2888] , Loss: 0.4805123805999756\n",
      "Epoch [5/10] , Step [1040/2888] , Loss: 0.4249946475028992\n",
      "Epoch [5/10] , Step [1050/2888] , Loss: 0.6983529925346375\n",
      "Epoch [5/10] , Step [1060/2888] , Loss: 0.3259254395961761\n",
      "Epoch [5/10] , Step [1070/2888] , Loss: 0.8572649359703064\n",
      "Epoch [5/10] , Step [1080/2888] , Loss: 0.7050054073333740\n",
      "Epoch [5/10] , Step [1090/2888] , Loss: 0.3907844126224518\n",
      "Epoch [5/10] , Step [1100/2888] , Loss: 0.3865949511528015\n",
      "Epoch [5/10] , Step [1110/2888] , Loss: 0.4590415656566620\n",
      "Epoch [5/10] , Step [1120/2888] , Loss: 0.6731829047203064\n",
      "Epoch [5/10] , Step [1130/2888] , Loss: 0.6030364036560059\n",
      "Epoch [5/10] , Step [1140/2888] , Loss: 0.6794703006744385\n",
      "Epoch [5/10] , Step [1150/2888] , Loss: 0.5825774073600769\n",
      "Epoch [5/10] , Step [1160/2888] , Loss: 0.4421064853668213\n",
      "Epoch [5/10] , Step [1170/2888] , Loss: 0.2934929728507996\n",
      "Epoch [5/10] , Step [1180/2888] , Loss: 0.4649458229541779\n",
      "Epoch [5/10] , Step [1190/2888] , Loss: 0.4112188816070557\n",
      "Epoch [5/10] , Step [1200/2888] , Loss: 0.2800495326519012\n",
      "Epoch [5/10] , Step [1210/2888] , Loss: 0.7053378820419312\n",
      "Epoch [5/10] , Step [1220/2888] , Loss: 0.5051086544990540\n",
      "Epoch [5/10] , Step [1230/2888] , Loss: 0.3593346178531647\n",
      "Epoch [5/10] , Step [1240/2888] , Loss: 0.4741374254226685\n",
      "Epoch [5/10] , Step [1250/2888] , Loss: 0.4597193896770477\n",
      "Epoch [5/10] , Step [1260/2888] , Loss: 0.5673376917839050\n",
      "Epoch [5/10] , Step [1270/2888] , Loss: 0.3218758702278137\n",
      "Epoch [5/10] , Step [1280/2888] , Loss: 0.1848385781049728\n",
      "Epoch [5/10] , Step [1290/2888] , Loss: 0.4967441856861115\n",
      "Epoch [5/10] , Step [1300/2888] , Loss: 0.6405890583992004\n",
      "Epoch [5/10] , Step [1310/2888] , Loss: 0.6614511609077454\n",
      "Epoch [5/10] , Step [1320/2888] , Loss: 0.3471944928169250\n",
      "Epoch [5/10] , Step [1330/2888] , Loss: 0.7085597515106201\n",
      "Epoch [5/10] , Step [1340/2888] , Loss: 0.4773885011672974\n",
      "Epoch [5/10] , Step [1350/2888] , Loss: 0.5789126157760620\n",
      "Epoch [5/10] , Step [1360/2888] , Loss: 0.2595639526844025\n",
      "Epoch [5/10] , Step [1370/2888] , Loss: 0.2593842744827271\n",
      "Epoch [5/10] , Step [1380/2888] , Loss: 0.4474128484725952\n",
      "Epoch [5/10] , Step [1390/2888] , Loss: 0.3619678616523743\n",
      "Epoch [5/10] , Step [1400/2888] , Loss: 0.3281287848949432\n",
      "Epoch [5/10] , Step [1410/2888] , Loss: 0.3184452354907990\n",
      "Epoch [5/10] , Step [1420/2888] , Loss: 0.4691115319728851\n",
      "Epoch [5/10] , Step [1430/2888] , Loss: 0.5645864009857178\n",
      "Epoch [5/10] , Step [1440/2888] , Loss: 0.4864242970943451\n",
      "Epoch [5/10] , Step [1450/2888] , Loss: 0.5527555942535400\n",
      "Epoch [5/10] , Step [1460/2888] , Loss: 0.3878206610679626\n",
      "Epoch [5/10] , Step [1470/2888] , Loss: 0.4101275205612183\n",
      "Epoch [5/10] , Step [1480/2888] , Loss: 0.6249229311943054\n",
      "Epoch [5/10] , Step [1490/2888] , Loss: 0.5079928040504456\n",
      "Epoch [5/10] , Step [1500/2888] , Loss: 0.2498334944248199\n",
      "Epoch [5/10] , Step [1510/2888] , Loss: 0.5101280808448792\n",
      "Epoch [5/10] , Step [1520/2888] , Loss: 0.4167055487632751\n",
      "Epoch [5/10] , Step [1530/2888] , Loss: 0.6400401592254639\n",
      "Epoch [5/10] , Step [1540/2888] , Loss: 0.4427726864814758\n",
      "Epoch [5/10] , Step [1550/2888] , Loss: 0.4916869401931763\n",
      "Epoch [5/10] , Step [1560/2888] , Loss: 0.4434645175933838\n",
      "Epoch [5/10] , Step [1570/2888] , Loss: 0.5173838734626770\n",
      "Epoch [5/10] , Step [1580/2888] , Loss: 0.5155502557754517\n",
      "Epoch [5/10] , Step [1590/2888] , Loss: 0.4351734817028046\n",
      "Epoch [5/10] , Step [1600/2888] , Loss: 0.2352899461984634\n",
      "Epoch [5/10] , Step [1610/2888] , Loss: 0.3129757046699524\n",
      "Epoch [5/10] , Step [1620/2888] , Loss: 0.2044507712125778\n",
      "Epoch [5/10] , Step [1630/2888] , Loss: 0.2731837034225464\n",
      "Epoch [5/10] , Step [1640/2888] , Loss: 0.4612819254398346\n",
      "Epoch [5/10] , Step [1650/2888] , Loss: 0.4242729544639587\n",
      "Epoch [5/10] , Step [1660/2888] , Loss: 0.5148693919181824\n",
      "Epoch [5/10] , Step [1670/2888] , Loss: 0.3890840411186218\n",
      "Epoch [5/10] , Step [1680/2888] , Loss: 0.6773942708969116\n",
      "Epoch [5/10] , Step [1690/2888] , Loss: 0.7338631153106689\n",
      "Epoch [5/10] , Step [1700/2888] , Loss: 0.3009667694568634\n",
      "Epoch [5/10] , Step [1710/2888] , Loss: 0.4932903647422791\n",
      "Epoch [5/10] , Step [1720/2888] , Loss: 0.5935426354408264\n",
      "Epoch [5/10] , Step [1730/2888] , Loss: 0.3947089612483978\n",
      "Epoch [5/10] , Step [1740/2888] , Loss: 0.4051384031772614\n",
      "Epoch [5/10] , Step [1750/2888] , Loss: 0.5047789216041565\n",
      "Epoch [5/10] , Step [1760/2888] , Loss: 0.6842196583747864\n",
      "Epoch [5/10] , Step [1770/2888] , Loss: 0.5071069598197937\n",
      "Epoch [5/10] , Step [1780/2888] , Loss: 0.3869001269340515\n",
      "Epoch [5/10] , Step [1790/2888] , Loss: 0.4026343524456024\n",
      "Epoch [5/10] , Step [1800/2888] , Loss: 0.6241499781608582\n",
      "Epoch [5/10] , Step [1810/2888] , Loss: 0.6523924469947815\n",
      "Epoch [5/10] , Step [1820/2888] , Loss: 0.4646964073181152\n",
      "Epoch [5/10] , Step [1830/2888] , Loss: 0.3576364219188690\n",
      "Epoch [5/10] , Step [1840/2888] , Loss: 0.4661055803298950\n",
      "Epoch [5/10] , Step [1850/2888] , Loss: 0.3929815888404846\n",
      "Epoch [5/10] , Step [1860/2888] , Loss: 0.5839690566062927\n",
      "Epoch [5/10] , Step [1870/2888] , Loss: 0.4889425933361053\n",
      "Epoch [5/10] , Step [1880/2888] , Loss: 0.5499870777130127\n",
      "Epoch [5/10] , Step [1890/2888] , Loss: 0.5613842010498047\n",
      "Epoch [5/10] , Step [1900/2888] , Loss: 0.4102077782154083\n",
      "Epoch [5/10] , Step [1910/2888] , Loss: 0.4714527428150177\n",
      "Epoch [5/10] , Step [1920/2888] , Loss: 0.4342442750930786\n",
      "Epoch [5/10] , Step [1930/2888] , Loss: 0.4979198276996613\n",
      "Epoch [5/10] , Step [1940/2888] , Loss: 0.4781489074230194\n",
      "Epoch [5/10] , Step [1950/2888] , Loss: 0.5833157300949097\n",
      "Epoch [5/10] , Step [1960/2888] , Loss: 0.6035560369491577\n",
      "Epoch [5/10] , Step [1970/2888] , Loss: 0.6108841896057129\n",
      "Epoch [5/10] , Step [1980/2888] , Loss: 0.3406912982463837\n",
      "Epoch [5/10] , Step [1990/2888] , Loss: 0.4877300262451172\n",
      "Epoch [5/10] , Step [2000/2888] , Loss: 0.4446823894977570\n",
      "Epoch [5/10] , Step [2010/2888] , Loss: 0.4169310033321381\n",
      "Epoch [5/10] , Step [2020/2888] , Loss: 0.5424518585205078\n",
      "Epoch [5/10] , Step [2030/2888] , Loss: 0.4141942560672760\n",
      "Epoch [5/10] , Step [2040/2888] , Loss: 0.7058067321777344\n",
      "Epoch [5/10] , Step [2050/2888] , Loss: 0.4273943901062012\n",
      "Epoch [5/10] , Step [2060/2888] , Loss: 0.3199838101863861\n",
      "Epoch [5/10] , Step [2070/2888] , Loss: 0.4545665085315704\n",
      "Epoch [5/10] , Step [2080/2888] , Loss: 0.6011158227920532\n",
      "Epoch [5/10] , Step [2090/2888] , Loss: 0.2932547330856323\n",
      "Epoch [5/10] , Step [2100/2888] , Loss: 0.3934871554374695\n",
      "Epoch [5/10] , Step [2110/2888] , Loss: 0.4594561457633972\n",
      "Epoch [5/10] , Step [2120/2888] , Loss: 0.4739453494548798\n",
      "Epoch [5/10] , Step [2130/2888] , Loss: 0.7803288698196411\n",
      "Epoch [5/10] , Step [2140/2888] , Loss: 0.4719959795475006\n",
      "Epoch [5/10] , Step [2150/2888] , Loss: 0.5704458355903625\n",
      "Epoch [5/10] , Step [2160/2888] , Loss: 0.5730388760566711\n",
      "Epoch [5/10] , Step [2170/2888] , Loss: 0.3009733557701111\n",
      "Epoch [5/10] , Step [2180/2888] , Loss: 0.6192003488540649\n",
      "Epoch [5/10] , Step [2190/2888] , Loss: 0.3830501139163971\n",
      "Epoch [5/10] , Step [2200/2888] , Loss: 0.5167243480682373\n",
      "Epoch [5/10] , Step [2210/2888] , Loss: 0.4807789623737335\n",
      "Epoch [5/10] , Step [2220/2888] , Loss: 0.4351953864097595\n",
      "Epoch [5/10] , Step [2230/2888] , Loss: 0.5635353922843933\n",
      "Epoch [5/10] , Step [2240/2888] , Loss: 0.3956578373908997\n",
      "Epoch [5/10] , Step [2250/2888] , Loss: 0.6378707289695740\n",
      "Epoch [5/10] , Step [2260/2888] , Loss: 0.5399439334869385\n",
      "Epoch [5/10] , Step [2270/2888] , Loss: 0.6066137552261353\n",
      "Epoch [5/10] , Step [2280/2888] , Loss: 0.2049314081668854\n",
      "Epoch [5/10] , Step [2290/2888] , Loss: 0.6023448109626770\n",
      "Epoch [5/10] , Step [2300/2888] , Loss: 0.2135815322399139\n",
      "Epoch [5/10] , Step [2310/2888] , Loss: 0.5316105484962463\n",
      "Epoch [5/10] , Step [2320/2888] , Loss: 0.3661874532699585\n",
      "Epoch [5/10] , Step [2330/2888] , Loss: 0.4672536253929138\n",
      "Epoch [5/10] , Step [2340/2888] , Loss: 0.4306228458881378\n",
      "Epoch [5/10] , Step [2350/2888] , Loss: 0.1997037231922150\n",
      "Epoch [5/10] , Step [2360/2888] , Loss: 0.3616029024124146\n",
      "Epoch [5/10] , Step [2370/2888] , Loss: 0.5522603392601013\n",
      "Epoch [5/10] , Step [2380/2888] , Loss: 0.3685643374919891\n",
      "Epoch [5/10] , Step [2390/2888] , Loss: 0.8912221789360046\n",
      "Epoch [5/10] , Step [2400/2888] , Loss: 0.6842359900474548\n",
      "Epoch [5/10] , Step [2410/2888] , Loss: 0.2386639416217804\n",
      "Epoch [5/10] , Step [2420/2888] , Loss: 0.4343765079975128\n",
      "Epoch [5/10] , Step [2430/2888] , Loss: 0.3300512433052063\n",
      "Epoch [5/10] , Step [2440/2888] , Loss: 0.3460893034934998\n",
      "Epoch [5/10] , Step [2450/2888] , Loss: 0.2803878188133240\n",
      "Epoch [5/10] , Step [2460/2888] , Loss: 0.3771374225616455\n",
      "Epoch [5/10] , Step [2470/2888] , Loss: 0.3986675441265106\n",
      "Epoch [5/10] , Step [2480/2888] , Loss: 0.3712603747844696\n",
      "Epoch [5/10] , Step [2490/2888] , Loss: 0.5717082619667053\n",
      "Epoch [5/10] , Step [2500/2888] , Loss: 0.5763491392135620\n",
      "Epoch [5/10] , Step [2510/2888] , Loss: 0.5476089119911194\n",
      "Epoch [5/10] , Step [2520/2888] , Loss: 0.2568503916263580\n",
      "Epoch [5/10] , Step [2530/2888] , Loss: 0.4824180305004120\n",
      "Epoch [5/10] , Step [2540/2888] , Loss: 0.6900408267974854\n",
      "Epoch [5/10] , Step [2550/2888] , Loss: 0.5954843759536743\n",
      "Epoch [5/10] , Step [2560/2888] , Loss: 0.4631968140602112\n",
      "Epoch [5/10] , Step [2570/2888] , Loss: 0.3117541074752808\n",
      "Epoch [5/10] , Step [2580/2888] , Loss: 0.4780193567276001\n",
      "Epoch [5/10] , Step [2590/2888] , Loss: 0.5850692391395569\n",
      "Epoch [5/10] , Step [2600/2888] , Loss: 0.5780039429664612\n",
      "Epoch [5/10] , Step [2610/2888] , Loss: 0.2058776766061783\n",
      "Epoch [5/10] , Step [2620/2888] , Loss: 0.3781692385673523\n",
      "Epoch [5/10] , Step [2630/2888] , Loss: 0.4303219914436340\n",
      "Epoch [5/10] , Step [2640/2888] , Loss: 0.3275406062602997\n",
      "Epoch [5/10] , Step [2650/2888] , Loss: 0.5241996049880981\n",
      "Epoch [5/10] , Step [2660/2888] , Loss: 0.6457683444023132\n",
      "Epoch [5/10] , Step [2670/2888] , Loss: 0.2138887643814087\n",
      "Epoch [5/10] , Step [2680/2888] , Loss: 0.8099814057350159\n",
      "Epoch [5/10] , Step [2690/2888] , Loss: 0.4503778219223022\n",
      "Epoch [5/10] , Step [2700/2888] , Loss: 0.4967531561851501\n",
      "Epoch [5/10] , Step [2710/2888] , Loss: 0.5463984012603760\n",
      "Epoch [5/10] , Step [2720/2888] , Loss: 0.3353008627891541\n",
      "Epoch [5/10] , Step [2730/2888] , Loss: 0.5818617343902588\n",
      "Epoch [5/10] , Step [2740/2888] , Loss: 0.4626321494579315\n",
      "Epoch [5/10] , Step [2750/2888] , Loss: 0.4544153809547424\n",
      "Epoch [5/10] , Step [2760/2888] , Loss: 0.6437742114067078\n",
      "Epoch [5/10] , Step [2770/2888] , Loss: 0.5035165548324585\n",
      "Epoch [5/10] , Step [2780/2888] , Loss: 0.4933534264564514\n",
      "Epoch [5/10] , Step [2790/2888] , Loss: 0.4715292453765869\n",
      "Epoch [5/10] , Step [2800/2888] , Loss: 0.4442572593688965\n",
      "Epoch [5/10] , Step [2810/2888] , Loss: 0.2952340245246887\n",
      "Epoch [5/10] , Step [2820/2888] , Loss: 0.3845081925392151\n",
      "Epoch [5/10] , Step [2830/2888] , Loss: 0.6035590171813965\n",
      "Epoch [5/10] , Step [2840/2888] , Loss: 0.3754206299781799\n",
      "Epoch [5/10] , Step [2850/2888] , Loss: 0.3041052222251892\n",
      "Epoch [5/10] , Step [2860/2888] , Loss: 0.6050922870635986\n",
      "Epoch [5/10] , Step [2870/2888] , Loss: 0.3084734976291656\n",
      "Epoch [5/10] , Step [2880/2888] , Loss: 0.3127504885196686\n",
      "Epoch [6/10] , Step [10/2888] , Loss: 0.3266493678092957\n",
      "Epoch [6/10] , Step [20/2888] , Loss: 0.3896116912364960\n",
      "Epoch [6/10] , Step [30/2888] , Loss: 0.2868109047412872\n",
      "Epoch [6/10] , Step [40/2888] , Loss: 0.5430051088333130\n",
      "Epoch [6/10] , Step [50/2888] , Loss: 0.4164467453956604\n",
      "Epoch [6/10] , Step [60/2888] , Loss: 0.3563355207443237\n",
      "Epoch [6/10] , Step [70/2888] , Loss: 0.4034447073936462\n",
      "Epoch [6/10] , Step [80/2888] , Loss: 0.7204225063323975\n",
      "Epoch [6/10] , Step [90/2888] , Loss: 0.4570538699626923\n",
      "Epoch [6/10] , Step [100/2888] , Loss: 0.4903820753097534\n",
      "Epoch [6/10] , Step [110/2888] , Loss: 0.4719780683517456\n",
      "Epoch [6/10] , Step [120/2888] , Loss: 0.4567937552928925\n",
      "Epoch [6/10] , Step [130/2888] , Loss: 0.3571211099624634\n",
      "Epoch [6/10] , Step [140/2888] , Loss: 0.2774345874786377\n",
      "Epoch [6/10] , Step [150/2888] , Loss: 0.4914415180683136\n",
      "Epoch [6/10] , Step [160/2888] , Loss: 0.2685151100158691\n",
      "Epoch [6/10] , Step [170/2888] , Loss: 0.5353515148162842\n",
      "Epoch [6/10] , Step [180/2888] , Loss: 0.2817815542221069\n",
      "Epoch [6/10] , Step [190/2888] , Loss: 0.4046833515167236\n",
      "Epoch [6/10] , Step [200/2888] , Loss: 0.3864940106868744\n",
      "Epoch [6/10] , Step [210/2888] , Loss: 0.3921550214290619\n",
      "Epoch [6/10] , Step [220/2888] , Loss: 0.4574263989925385\n",
      "Epoch [6/10] , Step [230/2888] , Loss: 0.2608525454998016\n",
      "Epoch [6/10] , Step [240/2888] , Loss: 0.2235042452812195\n",
      "Epoch [6/10] , Step [250/2888] , Loss: 0.3395954668521881\n",
      "Epoch [6/10] , Step [260/2888] , Loss: 0.6771949529647827\n",
      "Epoch [6/10] , Step [270/2888] , Loss: 0.6128896474838257\n",
      "Epoch [6/10] , Step [280/2888] , Loss: 0.4660269021987915\n",
      "Epoch [6/10] , Step [290/2888] , Loss: 0.2629358470439911\n",
      "Epoch [6/10] , Step [300/2888] , Loss: 0.4882768392562866\n",
      "Epoch [6/10] , Step [310/2888] , Loss: 0.5187079906463623\n",
      "Epoch [6/10] , Step [320/2888] , Loss: 0.3193823993206024\n",
      "Epoch [6/10] , Step [330/2888] , Loss: 0.5323120355606079\n",
      "Epoch [6/10] , Step [340/2888] , Loss: 0.3901029527187347\n",
      "Epoch [6/10] , Step [350/2888] , Loss: 0.5414452552795410\n",
      "Epoch [6/10] , Step [360/2888] , Loss: 0.3329351842403412\n",
      "Epoch [6/10] , Step [370/2888] , Loss: 0.5611202716827393\n",
      "Epoch [6/10] , Step [380/2888] , Loss: 0.3422441482543945\n",
      "Epoch [6/10] , Step [390/2888] , Loss: 0.4866046309471130\n",
      "Epoch [6/10] , Step [400/2888] , Loss: 0.4083500504493713\n",
      "Epoch [6/10] , Step [410/2888] , Loss: 0.5766574144363403\n",
      "Epoch [6/10] , Step [420/2888] , Loss: 0.3463987112045288\n",
      "Epoch [6/10] , Step [430/2888] , Loss: 0.5948971509933472\n",
      "Epoch [6/10] , Step [440/2888] , Loss: 0.4144243299961090\n",
      "Epoch [6/10] , Step [450/2888] , Loss: 0.5061779618263245\n",
      "Epoch [6/10] , Step [460/2888] , Loss: 0.3699694275856018\n",
      "Epoch [6/10] , Step [470/2888] , Loss: 0.5013654232025146\n",
      "Epoch [6/10] , Step [480/2888] , Loss: 0.5690501332283020\n",
      "Epoch [6/10] , Step [490/2888] , Loss: 0.4272446632385254\n",
      "Epoch [6/10] , Step [500/2888] , Loss: 0.4245292246341705\n",
      "Epoch [6/10] , Step [510/2888] , Loss: 0.5320228934288025\n",
      "Epoch [6/10] , Step [520/2888] , Loss: 0.6299208998680115\n",
      "Epoch [6/10] , Step [530/2888] , Loss: 0.5908905863761902\n",
      "Epoch [6/10] , Step [540/2888] , Loss: 0.4878661036491394\n",
      "Epoch [6/10] , Step [550/2888] , Loss: 0.4586965441703796\n",
      "Epoch [6/10] , Step [560/2888] , Loss: 0.3582235276699066\n",
      "Epoch [6/10] , Step [570/2888] , Loss: 0.5244892239570618\n",
      "Epoch [6/10] , Step [580/2888] , Loss: 0.5341252684593201\n",
      "Epoch [6/10] , Step [590/2888] , Loss: 0.4930004477500916\n",
      "Epoch [6/10] , Step [600/2888] , Loss: 0.1040387079119682\n",
      "Epoch [6/10] , Step [610/2888] , Loss: 0.2852706909179688\n",
      "Epoch [6/10] , Step [620/2888] , Loss: 0.4942614734172821\n",
      "Epoch [6/10] , Step [630/2888] , Loss: 0.3225211799144745\n",
      "Epoch [6/10] , Step [640/2888] , Loss: 0.3994053304195404\n",
      "Epoch [6/10] , Step [650/2888] , Loss: 0.3600885868072510\n",
      "Epoch [6/10] , Step [660/2888] , Loss: 0.4263910353183746\n",
      "Epoch [6/10] , Step [670/2888] , Loss: 0.6761711835861206\n",
      "Epoch [6/10] , Step [680/2888] , Loss: 0.3075444102287292\n",
      "Epoch [6/10] , Step [690/2888] , Loss: 0.5217582583427429\n",
      "Epoch [6/10] , Step [700/2888] , Loss: 0.4804891943931580\n",
      "Epoch [6/10] , Step [710/2888] , Loss: 0.6705096364021301\n",
      "Epoch [6/10] , Step [720/2888] , Loss: 0.4737918972969055\n",
      "Epoch [6/10] , Step [730/2888] , Loss: 0.5582332611083984\n",
      "Epoch [6/10] , Step [740/2888] , Loss: 0.4986613094806671\n",
      "Epoch [6/10] , Step [750/2888] , Loss: 0.3620102107524872\n",
      "Epoch [6/10] , Step [760/2888] , Loss: 0.4502040743827820\n",
      "Epoch [6/10] , Step [770/2888] , Loss: 0.7073425650596619\n",
      "Epoch [6/10] , Step [780/2888] , Loss: 0.5891286730766296\n",
      "Epoch [6/10] , Step [790/2888] , Loss: 0.4174529910087585\n",
      "Epoch [6/10] , Step [800/2888] , Loss: 0.3164129257202148\n",
      "Epoch [6/10] , Step [810/2888] , Loss: 0.4481008648872375\n",
      "Epoch [6/10] , Step [820/2888] , Loss: 0.6333245635032654\n",
      "Epoch [6/10] , Step [830/2888] , Loss: 0.4578548073768616\n",
      "Epoch [6/10] , Step [840/2888] , Loss: 0.3678877055644989\n",
      "Epoch [6/10] , Step [850/2888] , Loss: 0.6536062955856323\n",
      "Epoch [6/10] , Step [860/2888] , Loss: 0.4444359540939331\n",
      "Epoch [6/10] , Step [870/2888] , Loss: 0.4797289669513702\n",
      "Epoch [6/10] , Step [880/2888] , Loss: 0.4844047725200653\n",
      "Epoch [6/10] , Step [890/2888] , Loss: 0.5454763174057007\n",
      "Epoch [6/10] , Step [900/2888] , Loss: 0.5217750072479248\n",
      "Epoch [6/10] , Step [910/2888] , Loss: 0.2356505095958710\n",
      "Epoch [6/10] , Step [920/2888] , Loss: 0.5511100292205811\n",
      "Epoch [6/10] , Step [930/2888] , Loss: 0.6275640726089478\n",
      "Epoch [6/10] , Step [940/2888] , Loss: 0.4664286375045776\n",
      "Epoch [6/10] , Step [950/2888] , Loss: 0.6803303956985474\n",
      "Epoch [6/10] , Step [960/2888] , Loss: 0.6379498243331909\n",
      "Epoch [6/10] , Step [970/2888] , Loss: 0.4692879021167755\n",
      "Epoch [6/10] , Step [980/2888] , Loss: 0.6122846603393555\n",
      "Epoch [6/10] , Step [990/2888] , Loss: 0.1014699116349220\n",
      "Epoch [6/10] , Step [1000/2888] , Loss: 0.4885722398757935\n",
      "Epoch [6/10] , Step [1010/2888] , Loss: 0.7371849417686462\n",
      "Epoch [6/10] , Step [1020/2888] , Loss: 0.5839788317680359\n",
      "Epoch [6/10] , Step [1030/2888] , Loss: 0.4345507621765137\n",
      "Epoch [6/10] , Step [1040/2888] , Loss: 0.7315959930419922\n",
      "Epoch [6/10] , Step [1050/2888] , Loss: 0.4143648445606232\n",
      "Epoch [6/10] , Step [1060/2888] , Loss: 0.4090401530265808\n",
      "Epoch [6/10] , Step [1070/2888] , Loss: 0.5548396706581116\n",
      "Epoch [6/10] , Step [1080/2888] , Loss: 0.4461935460567474\n",
      "Epoch [6/10] , Step [1090/2888] , Loss: 0.6846292018890381\n",
      "Epoch [6/10] , Step [1100/2888] , Loss: 0.2630714178085327\n",
      "Epoch [6/10] , Step [1110/2888] , Loss: 0.3910499513149261\n",
      "Epoch [6/10] , Step [1120/2888] , Loss: 0.5019738078117371\n",
      "Epoch [6/10] , Step [1130/2888] , Loss: 0.6662710905075073\n",
      "Epoch [6/10] , Step [1140/2888] , Loss: 0.5855829119682312\n",
      "Epoch [6/10] , Step [1150/2888] , Loss: 0.4283419549465179\n",
      "Epoch [6/10] , Step [1160/2888] , Loss: 0.5545408129692078\n",
      "Epoch [6/10] , Step [1170/2888] , Loss: 0.1323547959327698\n",
      "Epoch [6/10] , Step [1180/2888] , Loss: 0.4130704402923584\n",
      "Epoch [6/10] , Step [1190/2888] , Loss: 0.3341888785362244\n",
      "Epoch [6/10] , Step [1200/2888] , Loss: 0.6123672127723694\n",
      "Epoch [6/10] , Step [1210/2888] , Loss: 0.5930809974670410\n",
      "Epoch [6/10] , Step [1220/2888] , Loss: 0.3344100415706635\n",
      "Epoch [6/10] , Step [1230/2888] , Loss: 0.7676588296890259\n",
      "Epoch [6/10] , Step [1240/2888] , Loss: 0.6247652173042297\n",
      "Epoch [6/10] , Step [1250/2888] , Loss: 0.3658462762832642\n",
      "Epoch [6/10] , Step [1260/2888] , Loss: 0.2609628736972809\n",
      "Epoch [6/10] , Step [1270/2888] , Loss: 0.5529588460922241\n",
      "Epoch [6/10] , Step [1280/2888] , Loss: 0.5604721307754517\n",
      "Epoch [6/10] , Step [1290/2888] , Loss: 0.3852390646934509\n",
      "Epoch [6/10] , Step [1300/2888] , Loss: 0.5335237383842468\n",
      "Epoch [6/10] , Step [1310/2888] , Loss: 0.5204240083694458\n",
      "Epoch [6/10] , Step [1320/2888] , Loss: 0.6462780237197876\n",
      "Epoch [6/10] , Step [1330/2888] , Loss: 0.2060392647981644\n",
      "Epoch [6/10] , Step [1340/2888] , Loss: 0.5262755751609802\n",
      "Epoch [6/10] , Step [1350/2888] , Loss: 0.6090753674507141\n",
      "Epoch [6/10] , Step [1360/2888] , Loss: 0.4985697865486145\n",
      "Epoch [6/10] , Step [1370/2888] , Loss: 0.6686018109321594\n",
      "Epoch [6/10] , Step [1380/2888] , Loss: 0.6522572636604309\n",
      "Epoch [6/10] , Step [1390/2888] , Loss: 0.3286997377872467\n",
      "Epoch [6/10] , Step [1400/2888] , Loss: 0.3155819773674011\n",
      "Epoch [6/10] , Step [1410/2888] , Loss: 0.6610257029533386\n",
      "Epoch [6/10] , Step [1420/2888] , Loss: 0.3089283108711243\n",
      "Epoch [6/10] , Step [1430/2888] , Loss: 0.4322296380996704\n",
      "Epoch [6/10] , Step [1440/2888] , Loss: 0.5692066550254822\n",
      "Epoch [6/10] , Step [1450/2888] , Loss: 0.4617263972759247\n",
      "Epoch [6/10] , Step [1460/2888] , Loss: 0.5748946070671082\n",
      "Epoch [6/10] , Step [1470/2888] , Loss: 0.3333696424961090\n",
      "Epoch [6/10] , Step [1480/2888] , Loss: 0.4062214195728302\n",
      "Epoch [6/10] , Step [1490/2888] , Loss: 0.5226546525955200\n",
      "Epoch [6/10] , Step [1500/2888] , Loss: 0.3935292661190033\n",
      "Epoch [6/10] , Step [1510/2888] , Loss: 0.5551251769065857\n",
      "Epoch [6/10] , Step [1520/2888] , Loss: 0.5287512540817261\n",
      "Epoch [6/10] , Step [1530/2888] , Loss: 0.4352342486381531\n",
      "Epoch [6/10] , Step [1540/2888] , Loss: 0.1570084840059280\n",
      "Epoch [6/10] , Step [1550/2888] , Loss: 0.7327329516410828\n",
      "Epoch [6/10] , Step [1560/2888] , Loss: 0.4268926382064819\n",
      "Epoch [6/10] , Step [1570/2888] , Loss: 0.4743843376636505\n",
      "Epoch [6/10] , Step [1580/2888] , Loss: 0.4603592157363892\n",
      "Epoch [6/10] , Step [1590/2888] , Loss: 0.2142321914434433\n",
      "Epoch [6/10] , Step [1600/2888] , Loss: 0.5611110329627991\n",
      "Epoch [6/10] , Step [1610/2888] , Loss: 0.5343229174613953\n",
      "Epoch [6/10] , Step [1620/2888] , Loss: 0.3086841106414795\n",
      "Epoch [6/10] , Step [1630/2888] , Loss: 0.2776969671249390\n",
      "Epoch [6/10] , Step [1640/2888] , Loss: 0.3089982271194458\n",
      "Epoch [6/10] , Step [1650/2888] , Loss: 0.4671707451343536\n",
      "Epoch [6/10] , Step [1660/2888] , Loss: 0.3521004319190979\n",
      "Epoch [6/10] , Step [1670/2888] , Loss: 0.1307536512613297\n",
      "Epoch [6/10] , Step [1680/2888] , Loss: 0.2014750987291336\n",
      "Epoch [6/10] , Step [1690/2888] , Loss: 0.5422890186309814\n",
      "Epoch [6/10] , Step [1700/2888] , Loss: 0.6739568710327148\n",
      "Epoch [6/10] , Step [1710/2888] , Loss: 0.6879825592041016\n",
      "Epoch [6/10] , Step [1720/2888] , Loss: 0.3091518580913544\n",
      "Epoch [6/10] , Step [1730/2888] , Loss: 0.6030650138854980\n",
      "Epoch [6/10] , Step [1740/2888] , Loss: 0.4526394009590149\n",
      "Epoch [6/10] , Step [1750/2888] , Loss: 0.5271173119544983\n",
      "Epoch [6/10] , Step [1760/2888] , Loss: 0.4254058599472046\n",
      "Epoch [6/10] , Step [1770/2888] , Loss: 0.4956775605678558\n",
      "Epoch [6/10] , Step [1780/2888] , Loss: 0.4496685266494751\n",
      "Epoch [6/10] , Step [1790/2888] , Loss: 0.5271226167678833\n",
      "Epoch [6/10] , Step [1800/2888] , Loss: 0.2566038966178894\n",
      "Epoch [6/10] , Step [1810/2888] , Loss: 0.3148213922977448\n",
      "Epoch [6/10] , Step [1820/2888] , Loss: 0.7086595892906189\n",
      "Epoch [6/10] , Step [1830/2888] , Loss: 0.3605038225650787\n",
      "Epoch [6/10] , Step [1840/2888] , Loss: 0.6151657104492188\n",
      "Epoch [6/10] , Step [1850/2888] , Loss: 0.3227078020572662\n",
      "Epoch [6/10] , Step [1860/2888] , Loss: 0.4896488487720490\n",
      "Epoch [6/10] , Step [1870/2888] , Loss: 0.4148887693881989\n",
      "Epoch [6/10] , Step [1880/2888] , Loss: 0.5384680032730103\n",
      "Epoch [6/10] , Step [1890/2888] , Loss: 0.2749627828598022\n",
      "Epoch [6/10] , Step [1900/2888] , Loss: 0.5080472826957703\n",
      "Epoch [6/10] , Step [1910/2888] , Loss: 0.4132271707057953\n",
      "Epoch [6/10] , Step [1920/2888] , Loss: 0.2198337763547897\n",
      "Epoch [6/10] , Step [1930/2888] , Loss: 0.4992887973785400\n",
      "Epoch [6/10] , Step [1940/2888] , Loss: 0.2933144569396973\n",
      "Epoch [6/10] , Step [1950/2888] , Loss: 0.5236303210258484\n",
      "Epoch [6/10] , Step [1960/2888] , Loss: 0.6010108590126038\n",
      "Epoch [6/10] , Step [1970/2888] , Loss: 0.5164585709571838\n",
      "Epoch [6/10] , Step [1980/2888] , Loss: 0.5186465978622437\n",
      "Epoch [6/10] , Step [1990/2888] , Loss: 0.6881337165832520\n",
      "Epoch [6/10] , Step [2000/2888] , Loss: 0.4642616510391235\n",
      "Epoch [6/10] , Step [2010/2888] , Loss: 0.3829331696033478\n",
      "Epoch [6/10] , Step [2020/2888] , Loss: 0.4442220926284790\n",
      "Epoch [6/10] , Step [2030/2888] , Loss: 0.4680015146732330\n",
      "Epoch [6/10] , Step [2040/2888] , Loss: 0.2909553647041321\n",
      "Epoch [6/10] , Step [2050/2888] , Loss: 0.6078411340713501\n",
      "Epoch [6/10] , Step [2060/2888] , Loss: 0.4827490150928497\n",
      "Epoch [6/10] , Step [2070/2888] , Loss: 0.5592888593673706\n",
      "Epoch [6/10] , Step [2080/2888] , Loss: 0.2793138325214386\n",
      "Epoch [6/10] , Step [2090/2888] , Loss: 0.5212315917015076\n",
      "Epoch [6/10] , Step [2100/2888] , Loss: 0.5084226727485657\n",
      "Epoch [6/10] , Step [2110/2888] , Loss: 0.5618216991424561\n",
      "Epoch [6/10] , Step [2120/2888] , Loss: 0.6421229243278503\n",
      "Epoch [6/10] , Step [2130/2888] , Loss: 0.4909253716468811\n",
      "Epoch [6/10] , Step [2140/2888] , Loss: 0.5798457264900208\n",
      "Epoch [6/10] , Step [2150/2888] , Loss: 0.2758987247943878\n",
      "Epoch [6/10] , Step [2160/2888] , Loss: 0.5834356546401978\n",
      "Epoch [6/10] , Step [2170/2888] , Loss: 0.4460131525993347\n",
      "Epoch [6/10] , Step [2180/2888] , Loss: 0.1408307999372482\n",
      "Epoch [6/10] , Step [2190/2888] , Loss: 0.6051146388053894\n",
      "Epoch [6/10] , Step [2200/2888] , Loss: 0.3555841147899628\n",
      "Epoch [6/10] , Step [2210/2888] , Loss: 0.4982673227787018\n",
      "Epoch [6/10] , Step [2220/2888] , Loss: 0.4132142961025238\n",
      "Epoch [6/10] , Step [2230/2888] , Loss: 0.4558908343315125\n",
      "Epoch [6/10] , Step [2240/2888] , Loss: 0.3748469054698944\n",
      "Epoch [6/10] , Step [2250/2888] , Loss: 0.4192472696304321\n",
      "Epoch [6/10] , Step [2260/2888] , Loss: 0.5936034917831421\n",
      "Epoch [6/10] , Step [2270/2888] , Loss: 0.4201843142509460\n",
      "Epoch [6/10] , Step [2280/2888] , Loss: 0.5387809276580811\n",
      "Epoch [6/10] , Step [2290/2888] , Loss: 0.2853411734104156\n",
      "Epoch [6/10] , Step [2300/2888] , Loss: 0.3519846796989441\n",
      "Epoch [6/10] , Step [2310/2888] , Loss: 0.2524586617946625\n",
      "Epoch [6/10] , Step [2320/2888] , Loss: 0.4841097891330719\n",
      "Epoch [6/10] , Step [2330/2888] , Loss: 0.5367168784141541\n",
      "Epoch [6/10] , Step [2340/2888] , Loss: 0.4055625498294830\n",
      "Epoch [6/10] , Step [2350/2888] , Loss: 0.4608996212482452\n",
      "Epoch [6/10] , Step [2360/2888] , Loss: 0.4715224504470825\n",
      "Epoch [6/10] , Step [2370/2888] , Loss: 0.4531645476818085\n",
      "Epoch [6/10] , Step [2380/2888] , Loss: 0.6983489990234375\n",
      "Epoch [6/10] , Step [2390/2888] , Loss: 0.4230192899703979\n",
      "Epoch [6/10] , Step [2400/2888] , Loss: 0.4892990887165070\n",
      "Epoch [6/10] , Step [2410/2888] , Loss: 0.4247374832630157\n",
      "Epoch [6/10] , Step [2420/2888] , Loss: 0.5732368230819702\n",
      "Epoch [6/10] , Step [2430/2888] , Loss: 0.5008021593093872\n",
      "Epoch [6/10] , Step [2440/2888] , Loss: 0.4301294386386871\n",
      "Epoch [6/10] , Step [2450/2888] , Loss: 0.4383452534675598\n",
      "Epoch [6/10] , Step [2460/2888] , Loss: 0.4181124567985535\n",
      "Epoch [6/10] , Step [2470/2888] , Loss: 0.1094526052474976\n",
      "Epoch [6/10] , Step [2480/2888] , Loss: 0.4653235375881195\n",
      "Epoch [6/10] , Step [2490/2888] , Loss: 0.4749390780925751\n",
      "Epoch [6/10] , Step [2500/2888] , Loss: 0.4099685251712799\n",
      "Epoch [6/10] , Step [2510/2888] , Loss: 0.3835275173187256\n",
      "Epoch [6/10] , Step [2520/2888] , Loss: 0.4838174581527710\n",
      "Epoch [6/10] , Step [2530/2888] , Loss: 0.3850383162498474\n",
      "Epoch [6/10] , Step [2540/2888] , Loss: 0.4996404945850372\n",
      "Epoch [6/10] , Step [2550/2888] , Loss: 0.5626862645149231\n",
      "Epoch [6/10] , Step [2560/2888] , Loss: 0.1477611958980560\n",
      "Epoch [6/10] , Step [2570/2888] , Loss: 0.2984247803688049\n",
      "Epoch [6/10] , Step [2580/2888] , Loss: 0.4491439163684845\n",
      "Epoch [6/10] , Step [2590/2888] , Loss: 0.4616849422454834\n",
      "Epoch [6/10] , Step [2600/2888] , Loss: 0.6030534505844116\n",
      "Epoch [6/10] , Step [2610/2888] , Loss: 0.2547188103199005\n",
      "Epoch [6/10] , Step [2620/2888] , Loss: 0.4659988582134247\n",
      "Epoch [6/10] , Step [2630/2888] , Loss: 0.5677564144134521\n",
      "Epoch [6/10] , Step [2640/2888] , Loss: 0.3818923234939575\n",
      "Epoch [6/10] , Step [2650/2888] , Loss: 0.3074104785919189\n",
      "Epoch [6/10] , Step [2660/2888] , Loss: 0.4852299690246582\n",
      "Epoch [6/10] , Step [2670/2888] , Loss: 0.5664183497428894\n",
      "Epoch [6/10] , Step [2680/2888] , Loss: 0.3750867843627930\n",
      "Epoch [6/10] , Step [2690/2888] , Loss: 0.2676706910133362\n",
      "Epoch [6/10] , Step [2700/2888] , Loss: 0.4033286869525909\n",
      "Epoch [6/10] , Step [2710/2888] , Loss: 0.5977957844734192\n",
      "Epoch [6/10] , Step [2720/2888] , Loss: 0.4984978437423706\n",
      "Epoch [6/10] , Step [2730/2888] , Loss: 0.5135960578918457\n",
      "Epoch [6/10] , Step [2740/2888] , Loss: 0.4755914211273193\n",
      "Epoch [6/10] , Step [2750/2888] , Loss: 0.4922078847885132\n",
      "Epoch [6/10] , Step [2760/2888] , Loss: 0.4803472161293030\n",
      "Epoch [6/10] , Step [2770/2888] , Loss: 0.5045591592788696\n",
      "Epoch [6/10] , Step [2780/2888] , Loss: 0.2969443798065186\n",
      "Epoch [6/10] , Step [2790/2888] , Loss: 0.5529151558876038\n",
      "Epoch [6/10] , Step [2800/2888] , Loss: 0.5215712189674377\n",
      "Epoch [6/10] , Step [2810/2888] , Loss: 0.3972554802894592\n",
      "Epoch [6/10] , Step [2820/2888] , Loss: 0.4275671243667603\n",
      "Epoch [6/10] , Step [2830/2888] , Loss: 0.3839008510112762\n",
      "Epoch [6/10] , Step [2840/2888] , Loss: 0.3441984653472900\n",
      "Epoch [6/10] , Step [2850/2888] , Loss: 0.6446821689605713\n",
      "Epoch [6/10] , Step [2860/2888] , Loss: 0.5036119222640991\n",
      "Epoch [6/10] , Step [2870/2888] , Loss: 0.5904132723808289\n",
      "Epoch [6/10] , Step [2880/2888] , Loss: 0.6957545280456543\n",
      "Epoch [7/10] , Step [10/2888] , Loss: 0.2531782388687134\n",
      "Epoch [7/10] , Step [20/2888] , Loss: 0.4230511188507080\n",
      "Epoch [7/10] , Step [30/2888] , Loss: 0.4738208055496216\n",
      "Epoch [7/10] , Step [40/2888] , Loss: 0.4920342564582825\n",
      "Epoch [7/10] , Step [50/2888] , Loss: 0.5805404186248779\n",
      "Epoch [7/10] , Step [60/2888] , Loss: 0.7173087596893311\n",
      "Epoch [7/10] , Step [70/2888] , Loss: 0.2791666686534882\n",
      "Epoch [7/10] , Step [80/2888] , Loss: 0.5173415541648865\n",
      "Epoch [7/10] , Step [90/2888] , Loss: 0.4558895826339722\n",
      "Epoch [7/10] , Step [100/2888] , Loss: 0.3298613727092743\n",
      "Epoch [7/10] , Step [110/2888] , Loss: 0.4639304578304291\n",
      "Epoch [7/10] , Step [120/2888] , Loss: 0.3126456439495087\n",
      "Epoch [7/10] , Step [130/2888] , Loss: 0.6062241196632385\n",
      "Epoch [7/10] , Step [140/2888] , Loss: 0.5616313815116882\n",
      "Epoch [7/10] , Step [150/2888] , Loss: 0.5833178162574768\n",
      "Epoch [7/10] , Step [160/2888] , Loss: 0.3235039114952087\n",
      "Epoch [7/10] , Step [170/2888] , Loss: 0.5628557205200195\n",
      "Epoch [7/10] , Step [180/2888] , Loss: 0.6643726825714111\n",
      "Epoch [7/10] , Step [190/2888] , Loss: 0.3136066794395447\n",
      "Epoch [7/10] , Step [200/2888] , Loss: 0.5025041103363037\n",
      "Epoch [7/10] , Step [210/2888] , Loss: 0.2922879755496979\n",
      "Epoch [7/10] , Step [220/2888] , Loss: 0.5262374877929688\n",
      "Epoch [7/10] , Step [230/2888] , Loss: 0.4001285433769226\n",
      "Epoch [7/10] , Step [240/2888] , Loss: 0.3517086207866669\n",
      "Epoch [7/10] , Step [250/2888] , Loss: 0.2807032763957977\n",
      "Epoch [7/10] , Step [260/2888] , Loss: 0.3793956339359283\n",
      "Epoch [7/10] , Step [270/2888] , Loss: 0.5490398406982422\n",
      "Epoch [7/10] , Step [280/2888] , Loss: 0.4854401350021362\n",
      "Epoch [7/10] , Step [290/2888] , Loss: 0.5542455315589905\n",
      "Epoch [7/10] , Step [300/2888] , Loss: 0.4149115085601807\n",
      "Epoch [7/10] , Step [310/2888] , Loss: 0.4920326769351959\n",
      "Epoch [7/10] , Step [320/2888] , Loss: 0.6530277132987976\n",
      "Epoch [7/10] , Step [330/2888] , Loss: 0.6184497475624084\n",
      "Epoch [7/10] , Step [340/2888] , Loss: 0.2634338438510895\n",
      "Epoch [7/10] , Step [350/2888] , Loss: 0.7276323437690735\n",
      "Epoch [7/10] , Step [360/2888] , Loss: 0.3123998045921326\n",
      "Epoch [7/10] , Step [370/2888] , Loss: 0.4564081430435181\n",
      "Epoch [7/10] , Step [380/2888] , Loss: 0.4540362358093262\n",
      "Epoch [7/10] , Step [390/2888] , Loss: 0.5706697702407837\n",
      "Epoch [7/10] , Step [400/2888] , Loss: 0.4759187996387482\n",
      "Epoch [7/10] , Step [410/2888] , Loss: 0.5486678481101990\n",
      "Epoch [7/10] , Step [420/2888] , Loss: 0.4313658773899078\n",
      "Epoch [7/10] , Step [430/2888] , Loss: 0.3383091986179352\n",
      "Epoch [7/10] , Step [440/2888] , Loss: 0.5133353471755981\n",
      "Epoch [7/10] , Step [450/2888] , Loss: 0.5964964032173157\n",
      "Epoch [7/10] , Step [460/2888] , Loss: 0.6414248943328857\n",
      "Epoch [7/10] , Step [470/2888] , Loss: 0.3413219749927521\n",
      "Epoch [7/10] , Step [480/2888] , Loss: 0.4952803850173950\n",
      "Epoch [7/10] , Step [490/2888] , Loss: 0.5703182220458984\n",
      "Epoch [7/10] , Step [500/2888] , Loss: 0.4418756961822510\n",
      "Epoch [7/10] , Step [510/2888] , Loss: 0.4696067571640015\n",
      "Epoch [7/10] , Step [520/2888] , Loss: 0.5401369929313660\n",
      "Epoch [7/10] , Step [530/2888] , Loss: 0.4060501456260681\n",
      "Epoch [7/10] , Step [540/2888] , Loss: 0.5681681036949158\n",
      "Epoch [7/10] , Step [550/2888] , Loss: 0.4608238041400909\n",
      "Epoch [7/10] , Step [560/2888] , Loss: 0.4265939593315125\n",
      "Epoch [7/10] , Step [570/2888] , Loss: 0.4644707739353180\n",
      "Epoch [7/10] , Step [580/2888] , Loss: 0.3115614354610443\n",
      "Epoch [7/10] , Step [590/2888] , Loss: 0.3586333990097046\n",
      "Epoch [7/10] , Step [600/2888] , Loss: 0.5780518054962158\n",
      "Epoch [7/10] , Step [610/2888] , Loss: 0.2753095030784607\n",
      "Epoch [7/10] , Step [620/2888] , Loss: 0.2510972917079926\n",
      "Epoch [7/10] , Step [630/2888] , Loss: 0.2745121717453003\n",
      "Epoch [7/10] , Step [640/2888] , Loss: 0.5738704800605774\n",
      "Epoch [7/10] , Step [650/2888] , Loss: 0.6522272825241089\n",
      "Epoch [7/10] , Step [660/2888] , Loss: 0.6270056962966919\n",
      "Epoch [7/10] , Step [670/2888] , Loss: 0.3038076162338257\n",
      "Epoch [7/10] , Step [680/2888] , Loss: 0.4820437133312225\n",
      "Epoch [7/10] , Step [690/2888] , Loss: 0.6649541258811951\n",
      "Epoch [7/10] , Step [700/2888] , Loss: 0.5205637216567993\n",
      "Epoch [7/10] , Step [710/2888] , Loss: 0.3712917566299438\n",
      "Epoch [7/10] , Step [720/2888] , Loss: 0.3636049032211304\n",
      "Epoch [7/10] , Step [730/2888] , Loss: 0.4834572672843933\n",
      "Epoch [7/10] , Step [740/2888] , Loss: 0.4446193873882294\n",
      "Epoch [7/10] , Step [750/2888] , Loss: 0.6299707889556885\n",
      "Epoch [7/10] , Step [760/2888] , Loss: 0.6965852975845337\n",
      "Epoch [7/10] , Step [770/2888] , Loss: 0.3779886364936829\n",
      "Epoch [7/10] , Step [780/2888] , Loss: 0.5673472881317139\n",
      "Epoch [7/10] , Step [790/2888] , Loss: 0.5722646117210388\n",
      "Epoch [7/10] , Step [800/2888] , Loss: 0.6445532441139221\n",
      "Epoch [7/10] , Step [810/2888] , Loss: 0.3244343400001526\n",
      "Epoch [7/10] , Step [820/2888] , Loss: 0.3631226122379303\n",
      "Epoch [7/10] , Step [830/2888] , Loss: 0.4646935164928436\n",
      "Epoch [7/10] , Step [840/2888] , Loss: 0.4048619866371155\n",
      "Epoch [7/10] , Step [850/2888] , Loss: 0.3813058733940125\n",
      "Epoch [7/10] , Step [860/2888] , Loss: 0.3631463348865509\n",
      "Epoch [7/10] , Step [870/2888] , Loss: 0.4750429391860962\n",
      "Epoch [7/10] , Step [880/2888] , Loss: 0.3712575435638428\n",
      "Epoch [7/10] , Step [890/2888] , Loss: 0.3908708393573761\n",
      "Epoch [7/10] , Step [900/2888] , Loss: 0.5036400556564331\n",
      "Epoch [7/10] , Step [910/2888] , Loss: 0.4762042760848999\n",
      "Epoch [7/10] , Step [920/2888] , Loss: 0.2708305716514587\n",
      "Epoch [7/10] , Step [930/2888] , Loss: 0.4688140451908112\n",
      "Epoch [7/10] , Step [940/2888] , Loss: 0.3671333193778992\n",
      "Epoch [7/10] , Step [950/2888] , Loss: 0.4365375638008118\n",
      "Epoch [7/10] , Step [960/2888] , Loss: 0.3995792865753174\n",
      "Epoch [7/10] , Step [970/2888] , Loss: 0.2822419404983521\n",
      "Epoch [7/10] , Step [980/2888] , Loss: 0.3638852834701538\n",
      "Epoch [7/10] , Step [990/2888] , Loss: 0.6006239056587219\n",
      "Epoch [7/10] , Step [1000/2888] , Loss: 0.4342439770698547\n",
      "Epoch [7/10] , Step [1010/2888] , Loss: 0.4222911596298218\n",
      "Epoch [7/10] , Step [1020/2888] , Loss: 0.4513584971427917\n",
      "Epoch [7/10] , Step [1030/2888] , Loss: 0.5166577100753784\n",
      "Epoch [7/10] , Step [1040/2888] , Loss: 0.5101456642150879\n",
      "Epoch [7/10] , Step [1050/2888] , Loss: 0.3119318485260010\n",
      "Epoch [7/10] , Step [1060/2888] , Loss: 0.4305495917797089\n",
      "Epoch [7/10] , Step [1070/2888] , Loss: 0.5107020735740662\n",
      "Epoch [7/10] , Step [1080/2888] , Loss: 0.4896136522293091\n",
      "Epoch [7/10] , Step [1090/2888] , Loss: 0.4286079108715057\n",
      "Epoch [7/10] , Step [1100/2888] , Loss: 0.2656188607215881\n",
      "Epoch [7/10] , Step [1110/2888] , Loss: 0.4864778518676758\n",
      "Epoch [7/10] , Step [1120/2888] , Loss: 0.5028153061866760\n",
      "Epoch [7/10] , Step [1130/2888] , Loss: 0.2628108263015747\n",
      "Epoch [7/10] , Step [1140/2888] , Loss: 0.5032516121864319\n",
      "Epoch [7/10] , Step [1150/2888] , Loss: 0.4324653148651123\n",
      "Epoch [7/10] , Step [1160/2888] , Loss: 0.2415782213211060\n",
      "Epoch [7/10] , Step [1170/2888] , Loss: 0.5539575219154358\n",
      "Epoch [7/10] , Step [1180/2888] , Loss: 0.5446701049804688\n",
      "Epoch [7/10] , Step [1190/2888] , Loss: 0.5952240228652954\n",
      "Epoch [7/10] , Step [1200/2888] , Loss: 0.3406573235988617\n",
      "Epoch [7/10] , Step [1210/2888] , Loss: 0.4996136724948883\n",
      "Epoch [7/10] , Step [1220/2888] , Loss: 0.5850686430931091\n",
      "Epoch [7/10] , Step [1230/2888] , Loss: 0.5682415962219238\n",
      "Epoch [7/10] , Step [1240/2888] , Loss: 0.5938869714736938\n",
      "Epoch [7/10] , Step [1250/2888] , Loss: 0.5198149085044861\n",
      "Epoch [7/10] , Step [1260/2888] , Loss: 0.4137490987777710\n",
      "Epoch [7/10] , Step [1270/2888] , Loss: 0.4452926218509674\n",
      "Epoch [7/10] , Step [1280/2888] , Loss: 0.4814714789390564\n",
      "Epoch [7/10] , Step [1290/2888] , Loss: 0.4607923924922943\n",
      "Epoch [7/10] , Step [1300/2888] , Loss: 0.2828682363033295\n",
      "Epoch [7/10] , Step [1310/2888] , Loss: 0.3612924218177795\n",
      "Epoch [7/10] , Step [1320/2888] , Loss: 0.4794632494449615\n",
      "Epoch [7/10] , Step [1330/2888] , Loss: 0.6038509607315063\n",
      "Epoch [7/10] , Step [1340/2888] , Loss: 0.5430895686149597\n",
      "Epoch [7/10] , Step [1350/2888] , Loss: 0.4827654063701630\n",
      "Epoch [7/10] , Step [1360/2888] , Loss: 0.4807018041610718\n",
      "Epoch [7/10] , Step [1370/2888] , Loss: 0.5452437996864319\n",
      "Epoch [7/10] , Step [1380/2888] , Loss: 0.4155834019184113\n",
      "Epoch [7/10] , Step [1390/2888] , Loss: 0.2775403559207916\n",
      "Epoch [7/10] , Step [1400/2888] , Loss: 0.3923550248146057\n",
      "Epoch [7/10] , Step [1410/2888] , Loss: 0.5204364657402039\n",
      "Epoch [7/10] , Step [1420/2888] , Loss: 0.6055862307548523\n",
      "Epoch [7/10] , Step [1430/2888] , Loss: 0.3448761105537415\n",
      "Epoch [7/10] , Step [1440/2888] , Loss: 0.4016170501708984\n",
      "Epoch [7/10] , Step [1450/2888] , Loss: 0.5035666227340698\n",
      "Epoch [7/10] , Step [1460/2888] , Loss: 0.4183637797832489\n",
      "Epoch [7/10] , Step [1470/2888] , Loss: 0.2937586307525635\n",
      "Epoch [7/10] , Step [1480/2888] , Loss: 0.4718402624130249\n",
      "Epoch [7/10] , Step [1490/2888] , Loss: 0.6094065308570862\n",
      "Epoch [7/10] , Step [1500/2888] , Loss: 0.5784542560577393\n",
      "Epoch [7/10] , Step [1510/2888] , Loss: 0.3187122046947479\n",
      "Epoch [7/10] , Step [1520/2888] , Loss: 0.2073246091604233\n",
      "Epoch [7/10] , Step [1530/2888] , Loss: 0.5509930849075317\n",
      "Epoch [7/10] , Step [1540/2888] , Loss: 0.4002692103385925\n",
      "Epoch [7/10] , Step [1550/2888] , Loss: 0.5392181277275085\n",
      "Epoch [7/10] , Step [1560/2888] , Loss: 0.4070242047309875\n",
      "Epoch [7/10] , Step [1570/2888] , Loss: 0.4823354780673981\n",
      "Epoch [7/10] , Step [1580/2888] , Loss: 0.4495484232902527\n",
      "Epoch [7/10] , Step [1590/2888] , Loss: 0.5059264302253723\n",
      "Epoch [7/10] , Step [1600/2888] , Loss: 0.3825184106826782\n",
      "Epoch [7/10] , Step [1610/2888] , Loss: 0.5915278196334839\n",
      "Epoch [7/10] , Step [1620/2888] , Loss: 0.3227002620697021\n",
      "Epoch [7/10] , Step [1630/2888] , Loss: 0.5664282441139221\n",
      "Epoch [7/10] , Step [1640/2888] , Loss: 0.4355786740779877\n",
      "Epoch [7/10] , Step [1650/2888] , Loss: 0.3537291586399078\n",
      "Epoch [7/10] , Step [1660/2888] , Loss: 0.5936841368675232\n",
      "Epoch [7/10] , Step [1670/2888] , Loss: 0.4653164744377136\n",
      "Epoch [7/10] , Step [1680/2888] , Loss: 0.7125907540321350\n",
      "Epoch [7/10] , Step [1690/2888] , Loss: 0.2793987691402435\n",
      "Epoch [7/10] , Step [1700/2888] , Loss: 0.4990390539169312\n",
      "Epoch [7/10] , Step [1710/2888] , Loss: 0.4585799276828766\n",
      "Epoch [7/10] , Step [1720/2888] , Loss: 0.1513733863830566\n",
      "Epoch [7/10] , Step [1730/2888] , Loss: 0.4873404800891876\n",
      "Epoch [7/10] , Step [1740/2888] , Loss: 0.2572588026523590\n",
      "Epoch [7/10] , Step [1750/2888] , Loss: 0.2499920725822449\n",
      "Epoch [7/10] , Step [1760/2888] , Loss: 0.4518751502037048\n",
      "Epoch [7/10] , Step [1770/2888] , Loss: 0.5298295021057129\n",
      "Epoch [7/10] , Step [1780/2888] , Loss: 0.5392659902572632\n",
      "Epoch [7/10] , Step [1790/2888] , Loss: 0.5001755952835083\n",
      "Epoch [7/10] , Step [1800/2888] , Loss: 0.6467846632003784\n",
      "Epoch [7/10] , Step [1810/2888] , Loss: 0.2868783473968506\n",
      "Epoch [7/10] , Step [1820/2888] , Loss: 0.5157322287559509\n",
      "Epoch [7/10] , Step [1830/2888] , Loss: 0.2360852509737015\n",
      "Epoch [7/10] , Step [1840/2888] , Loss: 0.4684163928031921\n",
      "Epoch [7/10] , Step [1850/2888] , Loss: 0.5050354599952698\n",
      "Epoch [7/10] , Step [1860/2888] , Loss: 0.4871427118778229\n",
      "Epoch [7/10] , Step [1870/2888] , Loss: 0.5354389548301697\n",
      "Epoch [7/10] , Step [1880/2888] , Loss: 0.4068671762943268\n",
      "Epoch [7/10] , Step [1890/2888] , Loss: 0.4394158720970154\n",
      "Epoch [7/10] , Step [1900/2888] , Loss: 0.6209700703620911\n",
      "Epoch [7/10] , Step [1910/2888] , Loss: 0.5178739428520203\n",
      "Epoch [7/10] , Step [1920/2888] , Loss: 0.5731970071792603\n",
      "Epoch [7/10] , Step [1930/2888] , Loss: 0.5537788867950439\n",
      "Epoch [7/10] , Step [1940/2888] , Loss: 0.4123806655406952\n",
      "Epoch [7/10] , Step [1950/2888] , Loss: 0.3411220610141754\n",
      "Epoch [7/10] , Step [1960/2888] , Loss: 0.3568948507308960\n",
      "Epoch [7/10] , Step [1970/2888] , Loss: 0.4814790189266205\n",
      "Epoch [7/10] , Step [1980/2888] , Loss: 0.3154671192169189\n",
      "Epoch [7/10] , Step [1990/2888] , Loss: 0.6579391956329346\n",
      "Epoch [7/10] , Step [2000/2888] , Loss: 0.6204184293746948\n",
      "Epoch [7/10] , Step [2010/2888] , Loss: 0.4461812376976013\n",
      "Epoch [7/10] , Step [2020/2888] , Loss: 0.5579420328140259\n",
      "Epoch [7/10] , Step [2030/2888] , Loss: 0.6838902831077576\n",
      "Epoch [7/10] , Step [2040/2888] , Loss: 0.6871731877326965\n",
      "Epoch [7/10] , Step [2050/2888] , Loss: 0.3393583595752716\n",
      "Epoch [7/10] , Step [2060/2888] , Loss: 0.3540676832199097\n",
      "Epoch [7/10] , Step [2070/2888] , Loss: 0.5441801548004150\n",
      "Epoch [7/10] , Step [2080/2888] , Loss: 0.5521721243858337\n",
      "Epoch [7/10] , Step [2090/2888] , Loss: 0.3840021193027496\n",
      "Epoch [7/10] , Step [2100/2888] , Loss: 0.4307431578636169\n",
      "Epoch [7/10] , Step [2110/2888] , Loss: 0.4858958423137665\n",
      "Epoch [7/10] , Step [2120/2888] , Loss: 0.5057575702667236\n",
      "Epoch [7/10] , Step [2130/2888] , Loss: 0.4665367305278778\n",
      "Epoch [7/10] , Step [2140/2888] , Loss: 0.6211529970169067\n",
      "Epoch [7/10] , Step [2150/2888] , Loss: 0.3124922215938568\n",
      "Epoch [7/10] , Step [2160/2888] , Loss: 0.4957156181335449\n",
      "Epoch [7/10] , Step [2170/2888] , Loss: 0.5454704761505127\n",
      "Epoch [7/10] , Step [2180/2888] , Loss: 0.4217986464500427\n",
      "Epoch [7/10] , Step [2190/2888] , Loss: 0.1401585042476654\n",
      "Epoch [7/10] , Step [2200/2888] , Loss: 0.5246224403381348\n",
      "Epoch [7/10] , Step [2210/2888] , Loss: 0.6323744058609009\n",
      "Epoch [7/10] , Step [2220/2888] , Loss: 0.3070304095745087\n",
      "Epoch [7/10] , Step [2230/2888] , Loss: 0.3615985810756683\n",
      "Epoch [7/10] , Step [2240/2888] , Loss: 0.3806369006633759\n",
      "Epoch [7/10] , Step [2250/2888] , Loss: 0.4499078392982483\n",
      "Epoch [7/10] , Step [2260/2888] , Loss: 0.4778596460819244\n",
      "Epoch [7/10] , Step [2270/2888] , Loss: 0.4719943702220917\n",
      "Epoch [7/10] , Step [2280/2888] , Loss: 0.5927215814590454\n",
      "Epoch [7/10] , Step [2290/2888] , Loss: 0.4324572682380676\n",
      "Epoch [7/10] , Step [2300/2888] , Loss: 0.4758936464786530\n",
      "Epoch [7/10] , Step [2310/2888] , Loss: 0.4887909293174744\n",
      "Epoch [7/10] , Step [2320/2888] , Loss: 0.3194799423217773\n",
      "Epoch [7/10] , Step [2330/2888] , Loss: 0.5590988993644714\n",
      "Epoch [7/10] , Step [2340/2888] , Loss: 0.6863762140274048\n",
      "Epoch [7/10] , Step [2350/2888] , Loss: 0.4376079142093658\n",
      "Epoch [7/10] , Step [2360/2888] , Loss: 0.3708502352237701\n",
      "Epoch [7/10] , Step [2370/2888] , Loss: 0.4965564608573914\n",
      "Epoch [7/10] , Step [2380/2888] , Loss: 0.4315583705902100\n",
      "Epoch [7/10] , Step [2390/2888] , Loss: 0.4257586002349854\n",
      "Epoch [7/10] , Step [2400/2888] , Loss: 0.5105755925178528\n",
      "Epoch [7/10] , Step [2410/2888] , Loss: 0.3148306608200073\n",
      "Epoch [7/10] , Step [2420/2888] , Loss: 0.4850600361824036\n",
      "Epoch [7/10] , Step [2430/2888] , Loss: 0.3112743794918060\n",
      "Epoch [7/10] , Step [2440/2888] , Loss: 0.5535085201263428\n",
      "Epoch [7/10] , Step [2450/2888] , Loss: 0.2517676651477814\n",
      "Epoch [7/10] , Step [2460/2888] , Loss: 0.6311368346214294\n",
      "Epoch [7/10] , Step [2470/2888] , Loss: 0.4236797988414764\n",
      "Epoch [7/10] , Step [2480/2888] , Loss: 0.3945372998714447\n",
      "Epoch [7/10] , Step [2490/2888] , Loss: 0.4618337750434875\n",
      "Epoch [7/10] , Step [2500/2888] , Loss: 0.4593855142593384\n",
      "Epoch [7/10] , Step [2510/2888] , Loss: 0.4667397439479828\n",
      "Epoch [7/10] , Step [2520/2888] , Loss: 0.3706528544425964\n",
      "Epoch [7/10] , Step [2530/2888] , Loss: 0.4857878088951111\n",
      "Epoch [7/10] , Step [2540/2888] , Loss: 0.5930958986282349\n",
      "Epoch [7/10] , Step [2550/2888] , Loss: 0.5482758283615112\n",
      "Epoch [7/10] , Step [2560/2888] , Loss: 0.3651480674743652\n",
      "Epoch [7/10] , Step [2570/2888] , Loss: 0.5452167987823486\n",
      "Epoch [7/10] , Step [2580/2888] , Loss: 0.4706498384475708\n",
      "Epoch [7/10] , Step [2590/2888] , Loss: 0.3271425366401672\n",
      "Epoch [7/10] , Step [2600/2888] , Loss: 0.3621418774127960\n",
      "Epoch [7/10] , Step [2610/2888] , Loss: 0.2859027385711670\n",
      "Epoch [7/10] , Step [2620/2888] , Loss: 0.2198248207569122\n",
      "Epoch [7/10] , Step [2630/2888] , Loss: 0.4995880126953125\n",
      "Epoch [7/10] , Step [2640/2888] , Loss: 0.5097728967666626\n",
      "Epoch [7/10] , Step [2650/2888] , Loss: 0.6447166204452515\n",
      "Epoch [7/10] , Step [2660/2888] , Loss: 0.6024966835975647\n",
      "Epoch [7/10] , Step [2670/2888] , Loss: 0.3922344148159027\n",
      "Epoch [7/10] , Step [2680/2888] , Loss: 0.3670979142189026\n",
      "Epoch [7/10] , Step [2690/2888] , Loss: 0.4540908634662628\n",
      "Epoch [7/10] , Step [2700/2888] , Loss: 0.5475721359252930\n",
      "Epoch [7/10] , Step [2710/2888] , Loss: 0.4230553805828094\n",
      "Epoch [7/10] , Step [2720/2888] , Loss: 0.5545511841773987\n",
      "Epoch [7/10] , Step [2730/2888] , Loss: 0.5486860871315002\n",
      "Epoch [7/10] , Step [2740/2888] , Loss: 0.3605265319347382\n",
      "Epoch [7/10] , Step [2750/2888] , Loss: 0.3181886672973633\n",
      "Epoch [7/10] , Step [2760/2888] , Loss: 0.6064551472663879\n",
      "Epoch [7/10] , Step [2770/2888] , Loss: 0.4823115468025208\n",
      "Epoch [7/10] , Step [2780/2888] , Loss: 0.4455643594264984\n",
      "Epoch [7/10] , Step [2790/2888] , Loss: 0.3796730041503906\n",
      "Epoch [7/10] , Step [2800/2888] , Loss: 0.2540712952613831\n",
      "Epoch [7/10] , Step [2810/2888] , Loss: 0.4671019911766052\n",
      "Epoch [7/10] , Step [2820/2888] , Loss: 0.7114287614822388\n",
      "Epoch [7/10] , Step [2830/2888] , Loss: 0.4140983819961548\n",
      "Epoch [7/10] , Step [2840/2888] , Loss: 0.3500021994113922\n",
      "Epoch [7/10] , Step [2850/2888] , Loss: 0.1857781708240509\n",
      "Epoch [7/10] , Step [2860/2888] , Loss: 0.4601565003395081\n",
      "Epoch [7/10] , Step [2870/2888] , Loss: 0.7767046093940735\n",
      "Epoch [7/10] , Step [2880/2888] , Loss: 0.4524423778057098\n",
      "Epoch [8/10] , Step [10/2888] , Loss: 0.4608606100082397\n",
      "Epoch [8/10] , Step [20/2888] , Loss: 0.4718077182769775\n",
      "Epoch [8/10] , Step [30/2888] , Loss: 0.2656403183937073\n",
      "Epoch [8/10] , Step [40/2888] , Loss: 0.7009220123291016\n",
      "Epoch [8/10] , Step [50/2888] , Loss: 0.2489914298057556\n",
      "Epoch [8/10] , Step [60/2888] , Loss: 0.3850767612457275\n",
      "Epoch [8/10] , Step [70/2888] , Loss: 0.6349519491195679\n",
      "Epoch [8/10] , Step [80/2888] , Loss: 0.4056239724159241\n",
      "Epoch [8/10] , Step [90/2888] , Loss: 0.6470887064933777\n",
      "Epoch [8/10] , Step [100/2888] , Loss: 0.5672240853309631\n",
      "Epoch [8/10] , Step [110/2888] , Loss: 0.5248090624809265\n",
      "Epoch [8/10] , Step [120/2888] , Loss: 0.4508785605430603\n",
      "Epoch [8/10] , Step [130/2888] , Loss: 0.5319050550460815\n",
      "Epoch [8/10] , Step [140/2888] , Loss: 0.5915377736091614\n",
      "Epoch [8/10] , Step [150/2888] , Loss: 0.5847824215888977\n",
      "Epoch [8/10] , Step [160/2888] , Loss: 0.5726991891860962\n",
      "Epoch [8/10] , Step [170/2888] , Loss: 0.3615367710590363\n",
      "Epoch [8/10] , Step [180/2888] , Loss: 0.4954726099967957\n",
      "Epoch [8/10] , Step [190/2888] , Loss: 0.5446232557296753\n",
      "Epoch [8/10] , Step [200/2888] , Loss: 0.6968870759010315\n",
      "Epoch [8/10] , Step [210/2888] , Loss: 0.6460775136947632\n",
      "Epoch [8/10] , Step [220/2888] , Loss: 0.4782704710960388\n",
      "Epoch [8/10] , Step [230/2888] , Loss: 0.4876149594783783\n",
      "Epoch [8/10] , Step [240/2888] , Loss: 0.5339031219482422\n",
      "Epoch [8/10] , Step [250/2888] , Loss: 0.6552206873893738\n",
      "Epoch [8/10] , Step [260/2888] , Loss: 0.4095289111137390\n",
      "Epoch [8/10] , Step [270/2888] , Loss: 0.4627234935760498\n",
      "Epoch [8/10] , Step [280/2888] , Loss: 0.3333823382854462\n",
      "Epoch [8/10] , Step [290/2888] , Loss: 0.3588329255580902\n",
      "Epoch [8/10] , Step [300/2888] , Loss: 0.5020015835762024\n",
      "Epoch [8/10] , Step [310/2888] , Loss: 0.6470496058464050\n",
      "Epoch [8/10] , Step [320/2888] , Loss: 0.4860389828681946\n",
      "Epoch [8/10] , Step [330/2888] , Loss: 0.3797230422496796\n",
      "Epoch [8/10] , Step [340/2888] , Loss: 0.5780236721038818\n",
      "Epoch [8/10] , Step [350/2888] , Loss: 0.4909953474998474\n",
      "Epoch [8/10] , Step [360/2888] , Loss: 0.4981022775173187\n",
      "Epoch [8/10] , Step [370/2888] , Loss: 0.6174374222755432\n",
      "Epoch [8/10] , Step [380/2888] , Loss: 0.4069643914699554\n",
      "Epoch [8/10] , Step [390/2888] , Loss: 0.4636169970035553\n",
      "Epoch [8/10] , Step [400/2888] , Loss: 0.4029538631439209\n",
      "Epoch [8/10] , Step [410/2888] , Loss: 0.5145116448402405\n",
      "Epoch [8/10] , Step [420/2888] , Loss: 0.5511518120765686\n",
      "Epoch [8/10] , Step [430/2888] , Loss: 0.3158836364746094\n",
      "Epoch [8/10] , Step [440/2888] , Loss: 0.3414360284805298\n",
      "Epoch [8/10] , Step [450/2888] , Loss: 0.5149311423301697\n",
      "Epoch [8/10] , Step [460/2888] , Loss: 0.2917581498622894\n",
      "Epoch [8/10] , Step [470/2888] , Loss: 0.5493311285972595\n",
      "Epoch [8/10] , Step [480/2888] , Loss: 0.5965293645858765\n",
      "Epoch [8/10] , Step [490/2888] , Loss: 0.4451620280742645\n",
      "Epoch [8/10] , Step [500/2888] , Loss: 0.4061190187931061\n",
      "Epoch [8/10] , Step [510/2888] , Loss: 0.3103897273540497\n",
      "Epoch [8/10] , Step [520/2888] , Loss: 0.5443355441093445\n",
      "Epoch [8/10] , Step [530/2888] , Loss: 0.4817498028278351\n",
      "Epoch [8/10] , Step [540/2888] , Loss: 0.4245451688766479\n",
      "Epoch [8/10] , Step [550/2888] , Loss: 0.3478938341140747\n",
      "Epoch [8/10] , Step [560/2888] , Loss: 0.3832514286041260\n",
      "Epoch [8/10] , Step [570/2888] , Loss: 0.3947529196739197\n",
      "Epoch [8/10] , Step [580/2888] , Loss: 0.2568438649177551\n",
      "Epoch [8/10] , Step [590/2888] , Loss: 0.5920091867446899\n",
      "Epoch [8/10] , Step [600/2888] , Loss: 0.6826719045639038\n",
      "Epoch [8/10] , Step [610/2888] , Loss: 0.3241131007671356\n",
      "Epoch [8/10] , Step [620/2888] , Loss: 0.4158518016338348\n",
      "Epoch [8/10] , Step [630/2888] , Loss: 0.3259096741676331\n",
      "Epoch [8/10] , Step [640/2888] , Loss: 0.6001676321029663\n",
      "Epoch [8/10] , Step [650/2888] , Loss: 0.5760471820831299\n",
      "Epoch [8/10] , Step [660/2888] , Loss: 0.2911685705184937\n",
      "Epoch [8/10] , Step [670/2888] , Loss: 0.5238553285598755\n",
      "Epoch [8/10] , Step [680/2888] , Loss: 0.5683792829513550\n",
      "Epoch [8/10] , Step [690/2888] , Loss: 0.4501496553421021\n",
      "Epoch [8/10] , Step [700/2888] , Loss: 0.4724078774452209\n",
      "Epoch [8/10] , Step [710/2888] , Loss: 0.5953528881072998\n",
      "Epoch [8/10] , Step [720/2888] , Loss: 0.5191865563392639\n",
      "Epoch [8/10] , Step [730/2888] , Loss: 0.4515772759914398\n",
      "Epoch [8/10] , Step [740/2888] , Loss: 0.4348595738410950\n",
      "Epoch [8/10] , Step [750/2888] , Loss: 0.3745585978031158\n",
      "Epoch [8/10] , Step [760/2888] , Loss: 0.4685237705707550\n",
      "Epoch [8/10] , Step [770/2888] , Loss: 0.6408230066299438\n",
      "Epoch [8/10] , Step [780/2888] , Loss: 0.3518916666507721\n",
      "Epoch [8/10] , Step [790/2888] , Loss: 0.4367106854915619\n",
      "Epoch [8/10] , Step [800/2888] , Loss: 0.5822173953056335\n",
      "Epoch [8/10] , Step [810/2888] , Loss: 0.4933424592018127\n",
      "Epoch [8/10] , Step [820/2888] , Loss: 0.6070950031280518\n",
      "Epoch [8/10] , Step [830/2888] , Loss: 0.4467047452926636\n",
      "Epoch [8/10] , Step [840/2888] , Loss: 0.4442302882671356\n",
      "Epoch [8/10] , Step [850/2888] , Loss: 0.6159266233444214\n",
      "Epoch [8/10] , Step [860/2888] , Loss: 0.4058619141578674\n",
      "Epoch [8/10] , Step [870/2888] , Loss: 0.4631997942924500\n",
      "Epoch [8/10] , Step [880/2888] , Loss: 0.5849324464797974\n",
      "Epoch [8/10] , Step [890/2888] , Loss: 0.4384331405162811\n",
      "Epoch [8/10] , Step [900/2888] , Loss: 0.3918303847312927\n",
      "Epoch [8/10] , Step [910/2888] , Loss: 0.4892713725566864\n",
      "Epoch [8/10] , Step [920/2888] , Loss: 0.6640263795852661\n",
      "Epoch [8/10] , Step [930/2888] , Loss: 0.4020155966281891\n",
      "Epoch [8/10] , Step [940/2888] , Loss: 0.4272991418838501\n",
      "Epoch [8/10] , Step [950/2888] , Loss: 0.3300729393959045\n",
      "Epoch [8/10] , Step [960/2888] , Loss: 0.4693694412708282\n",
      "Epoch [8/10] , Step [970/2888] , Loss: 0.4237326383590698\n",
      "Epoch [8/10] , Step [980/2888] , Loss: 0.6422706842422485\n",
      "Epoch [8/10] , Step [990/2888] , Loss: 0.4455348253250122\n",
      "Epoch [8/10] , Step [1000/2888] , Loss: 0.2428749650716782\n",
      "Epoch [8/10] , Step [1010/2888] , Loss: 0.5409909486770630\n",
      "Epoch [8/10] , Step [1020/2888] , Loss: 0.6759920120239258\n",
      "Epoch [8/10] , Step [1030/2888] , Loss: 0.5352939367294312\n",
      "Epoch [8/10] , Step [1040/2888] , Loss: 0.3056995868682861\n",
      "Epoch [8/10] , Step [1050/2888] , Loss: 0.6244082450866699\n",
      "Epoch [8/10] , Step [1060/2888] , Loss: 0.3419796526432037\n",
      "Epoch [8/10] , Step [1070/2888] , Loss: 0.3901840150356293\n",
      "Epoch [8/10] , Step [1080/2888] , Loss: 0.2403099834918976\n",
      "Epoch [8/10] , Step [1090/2888] , Loss: 0.4432340860366821\n",
      "Epoch [8/10] , Step [1100/2888] , Loss: 0.5038628578186035\n",
      "Epoch [8/10] , Step [1110/2888] , Loss: 0.4770497679710388\n",
      "Epoch [8/10] , Step [1120/2888] , Loss: 0.5035486817359924\n",
      "Epoch [8/10] , Step [1130/2888] , Loss: 0.5281693339347839\n",
      "Epoch [8/10] , Step [1140/2888] , Loss: 0.5756856203079224\n",
      "Epoch [8/10] , Step [1150/2888] , Loss: 0.4175575971603394\n",
      "Epoch [8/10] , Step [1160/2888] , Loss: 0.3785063326358795\n",
      "Epoch [8/10] , Step [1170/2888] , Loss: 0.4649437069892883\n",
      "Epoch [8/10] , Step [1180/2888] , Loss: 0.2905661463737488\n",
      "Epoch [8/10] , Step [1190/2888] , Loss: 0.7631580829620361\n",
      "Epoch [8/10] , Step [1200/2888] , Loss: 0.4662727713584900\n",
      "Epoch [8/10] , Step [1210/2888] , Loss: 0.3633759617805481\n",
      "Epoch [8/10] , Step [1220/2888] , Loss: 0.2864080071449280\n",
      "Epoch [8/10] , Step [1230/2888] , Loss: 0.2695266604423523\n",
      "Epoch [8/10] , Step [1240/2888] , Loss: 0.5226622223854065\n",
      "Epoch [8/10] , Step [1250/2888] , Loss: 0.4325216114521027\n",
      "Epoch [8/10] , Step [1260/2888] , Loss: 0.3756048679351807\n",
      "Epoch [8/10] , Step [1270/2888] , Loss: 0.3732281625270844\n",
      "Epoch [8/10] , Step [1280/2888] , Loss: 0.4689072370529175\n",
      "Epoch [8/10] , Step [1290/2888] , Loss: 0.4519115686416626\n",
      "Epoch [8/10] , Step [1300/2888] , Loss: 0.4050269424915314\n",
      "Epoch [8/10] , Step [1310/2888] , Loss: 0.4362505674362183\n",
      "Epoch [8/10] , Step [1320/2888] , Loss: 0.3629101216793060\n",
      "Epoch [8/10] , Step [1330/2888] , Loss: 0.3559296131134033\n",
      "Epoch [8/10] , Step [1340/2888] , Loss: 0.3099576234817505\n",
      "Epoch [8/10] , Step [1350/2888] , Loss: 0.4564904272556305\n",
      "Epoch [8/10] , Step [1360/2888] , Loss: 0.3637900948524475\n",
      "Epoch [8/10] , Step [1370/2888] , Loss: 0.5245555639266968\n",
      "Epoch [8/10] , Step [1380/2888] , Loss: 0.3374733924865723\n",
      "Epoch [8/10] , Step [1390/2888] , Loss: 0.6883168220520020\n",
      "Epoch [8/10] , Step [1400/2888] , Loss: 0.3466691374778748\n",
      "Epoch [8/10] , Step [1410/2888] , Loss: 0.6976132392883301\n",
      "Epoch [8/10] , Step [1420/2888] , Loss: 0.4759004712104797\n",
      "Epoch [8/10] , Step [1430/2888] , Loss: 0.4106283485889435\n",
      "Epoch [8/10] , Step [1440/2888] , Loss: 0.4958474636077881\n",
      "Epoch [8/10] , Step [1450/2888] , Loss: 0.3730576038360596\n",
      "Epoch [8/10] , Step [1460/2888] , Loss: 0.5330525636672974\n",
      "Epoch [8/10] , Step [1470/2888] , Loss: 0.5360590219497681\n",
      "Epoch [8/10] , Step [1480/2888] , Loss: 0.5043556690216064\n",
      "Epoch [8/10] , Step [1490/2888] , Loss: 0.5720579028129578\n",
      "Epoch [8/10] , Step [1500/2888] , Loss: 0.5056447386741638\n",
      "Epoch [8/10] , Step [1510/2888] , Loss: 0.3904352486133575\n",
      "Epoch [8/10] , Step [1520/2888] , Loss: 0.4623916149139404\n",
      "Epoch [8/10] , Step [1530/2888] , Loss: 0.4838115274906158\n",
      "Epoch [8/10] , Step [1540/2888] , Loss: 0.5954422354698181\n",
      "Epoch [8/10] , Step [1550/2888] , Loss: 0.6843007206916809\n",
      "Epoch [8/10] , Step [1560/2888] , Loss: 0.5462263822555542\n",
      "Epoch [8/10] , Step [1570/2888] , Loss: 0.4886121749877930\n",
      "Epoch [8/10] , Step [1580/2888] , Loss: 0.5516071915626526\n",
      "Epoch [8/10] , Step [1590/2888] , Loss: 0.2995034158229828\n",
      "Epoch [8/10] , Step [1600/2888] , Loss: 0.5595739483833313\n",
      "Epoch [8/10] , Step [1610/2888] , Loss: 0.4212573766708374\n",
      "Epoch [8/10] , Step [1620/2888] , Loss: 0.5309828519821167\n",
      "Epoch [8/10] , Step [1630/2888] , Loss: 0.5578880310058594\n",
      "Epoch [8/10] , Step [1640/2888] , Loss: 0.3747429847717285\n",
      "Epoch [8/10] , Step [1650/2888] , Loss: 0.4369602203369141\n",
      "Epoch [8/10] , Step [1660/2888] , Loss: 0.5458412170410156\n",
      "Epoch [8/10] , Step [1670/2888] , Loss: 0.2874633073806763\n",
      "Epoch [8/10] , Step [1680/2888] , Loss: 0.5317824482917786\n",
      "Epoch [8/10] , Step [1690/2888] , Loss: 0.5227667689323425\n",
      "Epoch [8/10] , Step [1700/2888] , Loss: 0.4252236187458038\n",
      "Epoch [8/10] , Step [1710/2888] , Loss: 0.4166663885116577\n",
      "Epoch [8/10] , Step [1720/2888] , Loss: 0.6372202634811401\n",
      "Epoch [8/10] , Step [1730/2888] , Loss: 0.5982825160026550\n",
      "Epoch [8/10] , Step [1740/2888] , Loss: 0.5457874536514282\n",
      "Epoch [8/10] , Step [1750/2888] , Loss: 0.5175575017929077\n",
      "Epoch [8/10] , Step [1760/2888] , Loss: 0.2957523763179779\n",
      "Epoch [8/10] , Step [1770/2888] , Loss: 0.5438990592956543\n",
      "Epoch [8/10] , Step [1780/2888] , Loss: 0.5492866039276123\n",
      "Epoch [8/10] , Step [1790/2888] , Loss: 0.4201732277870178\n",
      "Epoch [8/10] , Step [1800/2888] , Loss: 0.4329726696014404\n",
      "Epoch [8/10] , Step [1810/2888] , Loss: 0.2793655395507812\n",
      "Epoch [8/10] , Step [1820/2888] , Loss: 0.7065238356590271\n",
      "Epoch [8/10] , Step [1830/2888] , Loss: 0.3013245761394501\n",
      "Epoch [8/10] , Step [1840/2888] , Loss: 0.4159318804740906\n",
      "Epoch [8/10] , Step [1850/2888] , Loss: 0.2342360615730286\n",
      "Epoch [8/10] , Step [1860/2888] , Loss: 0.3561699688434601\n",
      "Epoch [8/10] , Step [1870/2888] , Loss: 0.5306000709533691\n",
      "Epoch [8/10] , Step [1880/2888] , Loss: 0.3882482945919037\n",
      "Epoch [8/10] , Step [1890/2888] , Loss: 0.3208326399326324\n",
      "Epoch [8/10] , Step [1900/2888] , Loss: 0.3315971195697784\n",
      "Epoch [8/10] , Step [1910/2888] , Loss: 0.5490496158599854\n",
      "Epoch [8/10] , Step [1920/2888] , Loss: 0.3266963660717010\n",
      "Epoch [8/10] , Step [1930/2888] , Loss: 0.3614536523818970\n",
      "Epoch [8/10] , Step [1940/2888] , Loss: 0.6260387897491455\n",
      "Epoch [8/10] , Step [1950/2888] , Loss: 0.2647606134414673\n",
      "Epoch [8/10] , Step [1960/2888] , Loss: 0.5010616779327393\n",
      "Epoch [8/10] , Step [1970/2888] , Loss: 0.5375757813453674\n",
      "Epoch [8/10] , Step [1980/2888] , Loss: 0.3214566111564636\n",
      "Epoch [8/10] , Step [1990/2888] , Loss: 0.6460988521575928\n",
      "Epoch [8/10] , Step [2000/2888] , Loss: 0.5995441675186157\n",
      "Epoch [8/10] , Step [2010/2888] , Loss: 0.5289176106452942\n",
      "Epoch [8/10] , Step [2020/2888] , Loss: 0.5684639215469360\n",
      "Epoch [8/10] , Step [2030/2888] , Loss: 0.2170619070529938\n",
      "Epoch [8/10] , Step [2040/2888] , Loss: 0.5809601545333862\n",
      "Epoch [8/10] , Step [2050/2888] , Loss: 0.3097044229507446\n",
      "Epoch [8/10] , Step [2060/2888] , Loss: 0.5126528739929199\n",
      "Epoch [8/10] , Step [2070/2888] , Loss: 0.5707739591598511\n",
      "Epoch [8/10] , Step [2080/2888] , Loss: 0.4165533781051636\n",
      "Epoch [8/10] , Step [2090/2888] , Loss: 0.5510725975036621\n",
      "Epoch [8/10] , Step [2100/2888] , Loss: 0.4664162397384644\n",
      "Epoch [8/10] , Step [2110/2888] , Loss: 0.6167192459106445\n",
      "Epoch [8/10] , Step [2120/2888] , Loss: 0.5412095189094543\n",
      "Epoch [8/10] , Step [2130/2888] , Loss: 0.4986351132392883\n",
      "Epoch [8/10] , Step [2140/2888] , Loss: 0.6183657646179199\n",
      "Epoch [8/10] , Step [2150/2888] , Loss: 0.5268195867538452\n",
      "Epoch [8/10] , Step [2160/2888] , Loss: 0.2928093075752258\n",
      "Epoch [8/10] , Step [2170/2888] , Loss: 0.4144783020019531\n",
      "Epoch [8/10] , Step [2180/2888] , Loss: 0.6416500210762024\n",
      "Epoch [8/10] , Step [2190/2888] , Loss: 0.4163838326931000\n",
      "Epoch [8/10] , Step [2200/2888] , Loss: 0.4665012061595917\n",
      "Epoch [8/10] , Step [2210/2888] , Loss: 0.3325375020503998\n",
      "Epoch [8/10] , Step [2220/2888] , Loss: 0.1176446750760078\n",
      "Epoch [8/10] , Step [2230/2888] , Loss: 0.2506048381328583\n",
      "Epoch [8/10] , Step [2240/2888] , Loss: 0.5555996298789978\n",
      "Epoch [8/10] , Step [2250/2888] , Loss: 0.4714472293853760\n",
      "Epoch [8/10] , Step [2260/2888] , Loss: 0.3531712889671326\n",
      "Epoch [8/10] , Step [2270/2888] , Loss: 0.3994114696979523\n",
      "Epoch [8/10] , Step [2280/2888] , Loss: 0.4762873649597168\n",
      "Epoch [8/10] , Step [2290/2888] , Loss: 0.6128892302513123\n",
      "Epoch [8/10] , Step [2300/2888] , Loss: 0.4455748498439789\n",
      "Epoch [8/10] , Step [2310/2888] , Loss: 0.5685647726058960\n",
      "Epoch [8/10] , Step [2320/2888] , Loss: 0.7887249588966370\n",
      "Epoch [8/10] , Step [2330/2888] , Loss: 0.4210175871849060\n",
      "Epoch [8/10] , Step [2340/2888] , Loss: 0.4661487042903900\n",
      "Epoch [8/10] , Step [2350/2888] , Loss: 0.5809875726699829\n",
      "Epoch [8/10] , Step [2360/2888] , Loss: 0.5722705721855164\n",
      "Epoch [8/10] , Step [2370/2888] , Loss: 0.5434637069702148\n",
      "Epoch [8/10] , Step [2380/2888] , Loss: 0.3483436107635498\n",
      "Epoch [8/10] , Step [2390/2888] , Loss: 0.3422905802726746\n",
      "Epoch [8/10] , Step [2400/2888] , Loss: 0.3845204114913940\n",
      "Epoch [8/10] , Step [2410/2888] , Loss: 0.4509361386299133\n",
      "Epoch [8/10] , Step [2420/2888] , Loss: 0.3244141936302185\n",
      "Epoch [8/10] , Step [2430/2888] , Loss: 0.3997048437595367\n",
      "Epoch [8/10] , Step [2440/2888] , Loss: 0.5670631527900696\n",
      "Epoch [8/10] , Step [2450/2888] , Loss: 0.4868572056293488\n",
      "Epoch [8/10] , Step [2460/2888] , Loss: 0.4682274758815765\n",
      "Epoch [8/10] , Step [2470/2888] , Loss: 0.3991436064243317\n",
      "Epoch [8/10] , Step [2480/2888] , Loss: 0.4607567191123962\n",
      "Epoch [8/10] , Step [2490/2888] , Loss: 0.5400888919830322\n",
      "Epoch [8/10] , Step [2500/2888] , Loss: 0.4867603182792664\n",
      "Epoch [8/10] , Step [2510/2888] , Loss: 0.3380151987075806\n",
      "Epoch [8/10] , Step [2520/2888] , Loss: 0.6032609343528748\n",
      "Epoch [8/10] , Step [2530/2888] , Loss: 0.7216637730598450\n",
      "Epoch [8/10] , Step [2540/2888] , Loss: 0.5885564088821411\n",
      "Epoch [8/10] , Step [2550/2888] , Loss: 0.5698559284210205\n",
      "Epoch [8/10] , Step [2560/2888] , Loss: 0.3703770041465759\n",
      "Epoch [8/10] , Step [2570/2888] , Loss: 0.5222840309143066\n",
      "Epoch [8/10] , Step [2580/2888] , Loss: 0.5008344054222107\n",
      "Epoch [8/10] , Step [2590/2888] , Loss: 0.5899550318717957\n",
      "Epoch [8/10] , Step [2600/2888] , Loss: 0.6608221530914307\n",
      "Epoch [8/10] , Step [2610/2888] , Loss: 0.5616291761398315\n",
      "Epoch [8/10] , Step [2620/2888] , Loss: 0.4958993494510651\n",
      "Epoch [8/10] , Step [2630/2888] , Loss: 0.6377286314964294\n",
      "Epoch [8/10] , Step [2640/2888] , Loss: 0.2924849987030029\n",
      "Epoch [8/10] , Step [2650/2888] , Loss: 0.4062349200248718\n",
      "Epoch [8/10] , Step [2660/2888] , Loss: 0.7325295209884644\n",
      "Epoch [8/10] , Step [2670/2888] , Loss: 0.6336686611175537\n",
      "Epoch [8/10] , Step [2680/2888] , Loss: 0.2644706368446350\n",
      "Epoch [8/10] , Step [2690/2888] , Loss: 0.5413727164268494\n",
      "Epoch [8/10] , Step [2700/2888] , Loss: 0.2701805830001831\n",
      "Epoch [8/10] , Step [2710/2888] , Loss: 0.4104560911655426\n",
      "Epoch [8/10] , Step [2720/2888] , Loss: 0.5558512806892395\n",
      "Epoch [8/10] , Step [2730/2888] , Loss: 0.3290778994560242\n",
      "Epoch [8/10] , Step [2740/2888] , Loss: 0.4298347234725952\n",
      "Epoch [8/10] , Step [2750/2888] , Loss: 0.5340772271156311\n",
      "Epoch [8/10] , Step [2760/2888] , Loss: 0.5404834151268005\n",
      "Epoch [8/10] , Step [2770/2888] , Loss: 0.4783824086189270\n",
      "Epoch [8/10] , Step [2780/2888] , Loss: 0.2828686833381653\n",
      "Epoch [8/10] , Step [2790/2888] , Loss: 0.4546819329261780\n",
      "Epoch [8/10] , Step [2800/2888] , Loss: 0.5388600826263428\n",
      "Epoch [8/10] , Step [2810/2888] , Loss: 0.5998758673667908\n",
      "Epoch [8/10] , Step [2820/2888] , Loss: 0.5007277131080627\n",
      "Epoch [8/10] , Step [2830/2888] , Loss: 0.3864932060241699\n",
      "Epoch [8/10] , Step [2840/2888] , Loss: 0.5442026853561401\n",
      "Epoch [8/10] , Step [2850/2888] , Loss: 0.6611230969429016\n",
      "Epoch [8/10] , Step [2860/2888] , Loss: 0.4261675477027893\n",
      "Epoch [8/10] , Step [2870/2888] , Loss: 0.2850694656372070\n",
      "Epoch [8/10] , Step [2880/2888] , Loss: 0.5192077159881592\n",
      "Epoch [9/10] , Step [10/2888] , Loss: 0.7085970640182495\n",
      "Epoch [9/10] , Step [20/2888] , Loss: 0.4144172966480255\n",
      "Epoch [9/10] , Step [30/2888] , Loss: 0.5109448432922363\n",
      "Epoch [9/10] , Step [40/2888] , Loss: 0.4139435887336731\n",
      "Epoch [9/10] , Step [50/2888] , Loss: 0.5427046418190002\n",
      "Epoch [9/10] , Step [60/2888] , Loss: 0.4181435704231262\n",
      "Epoch [9/10] , Step [70/2888] , Loss: 0.7451806068420410\n",
      "Epoch [9/10] , Step [80/2888] , Loss: 0.4308080077171326\n",
      "Epoch [9/10] , Step [90/2888] , Loss: 0.3999771773815155\n",
      "Epoch [9/10] , Step [100/2888] , Loss: 0.3605704009532928\n",
      "Epoch [9/10] , Step [110/2888] , Loss: 0.5173786282539368\n",
      "Epoch [9/10] , Step [120/2888] , Loss: 0.3761185109615326\n",
      "Epoch [9/10] , Step [130/2888] , Loss: 0.4541837573051453\n",
      "Epoch [9/10] , Step [140/2888] , Loss: 0.4079289436340332\n",
      "Epoch [9/10] , Step [150/2888] , Loss: 0.5783432126045227\n",
      "Epoch [9/10] , Step [160/2888] , Loss: 0.4551042914390564\n",
      "Epoch [9/10] , Step [170/2888] , Loss: 0.2785310745239258\n",
      "Epoch [9/10] , Step [180/2888] , Loss: 0.4311527907848358\n",
      "Epoch [9/10] , Step [190/2888] , Loss: 0.5307326316833496\n",
      "Epoch [9/10] , Step [200/2888] , Loss: 0.4706739783287048\n",
      "Epoch [9/10] , Step [210/2888] , Loss: 0.3987323343753815\n",
      "Epoch [9/10] , Step [220/2888] , Loss: 0.5704367756843567\n",
      "Epoch [9/10] , Step [230/2888] , Loss: 0.3451271355152130\n",
      "Epoch [9/10] , Step [240/2888] , Loss: 0.4045018553733826\n",
      "Epoch [9/10] , Step [250/2888] , Loss: 0.4833008646965027\n",
      "Epoch [9/10] , Step [260/2888] , Loss: 0.5531969070434570\n",
      "Epoch [9/10] , Step [270/2888] , Loss: 0.4332365393638611\n",
      "Epoch [9/10] , Step [280/2888] , Loss: 0.4669537544250488\n",
      "Epoch [9/10] , Step [290/2888] , Loss: 0.4139455854892731\n",
      "Epoch [9/10] , Step [300/2888] , Loss: 0.2951865494251251\n",
      "Epoch [9/10] , Step [310/2888] , Loss: 0.4412574768066406\n",
      "Epoch [9/10] , Step [320/2888] , Loss: 0.2396659851074219\n",
      "Epoch [9/10] , Step [330/2888] , Loss: 0.3683721423149109\n",
      "Epoch [9/10] , Step [340/2888] , Loss: 0.5644048452377319\n",
      "Epoch [9/10] , Step [350/2888] , Loss: 0.5292420387268066\n",
      "Epoch [9/10] , Step [360/2888] , Loss: 0.5605230927467346\n",
      "Epoch [9/10] , Step [370/2888] , Loss: 0.4815888106822968\n",
      "Epoch [9/10] , Step [380/2888] , Loss: 0.5081866383552551\n",
      "Epoch [9/10] , Step [390/2888] , Loss: 0.4502183496952057\n",
      "Epoch [9/10] , Step [400/2888] , Loss: 0.5276998281478882\n",
      "Epoch [9/10] , Step [410/2888] , Loss: 0.4554267227649689\n",
      "Epoch [9/10] , Step [420/2888] , Loss: 0.4343701601028442\n",
      "Epoch [9/10] , Step [430/2888] , Loss: 0.5813343524932861\n",
      "Epoch [9/10] , Step [440/2888] , Loss: 0.5292462110519409\n",
      "Epoch [9/10] , Step [450/2888] , Loss: 0.5965239405632019\n",
      "Epoch [9/10] , Step [460/2888] , Loss: 0.4522479474544525\n",
      "Epoch [9/10] , Step [470/2888] , Loss: 0.4752888679504395\n",
      "Epoch [9/10] , Step [480/2888] , Loss: 0.3668587803840637\n",
      "Epoch [9/10] , Step [490/2888] , Loss: 0.4038645327091217\n",
      "Epoch [9/10] , Step [500/2888] , Loss: 0.3828604817390442\n",
      "Epoch [9/10] , Step [510/2888] , Loss: 0.4728695154190063\n",
      "Epoch [9/10] , Step [520/2888] , Loss: 0.3995435833930969\n",
      "Epoch [9/10] , Step [530/2888] , Loss: 0.4624179005622864\n",
      "Epoch [9/10] , Step [540/2888] , Loss: 0.2466428726911545\n",
      "Epoch [9/10] , Step [550/2888] , Loss: 0.4562287032604218\n",
      "Epoch [9/10] , Step [560/2888] , Loss: 0.3728933334350586\n",
      "Epoch [9/10] , Step [570/2888] , Loss: 0.2568125724792480\n",
      "Epoch [9/10] , Step [580/2888] , Loss: 0.5119880437850952\n",
      "Epoch [9/10] , Step [590/2888] , Loss: 0.5148295164108276\n",
      "Epoch [9/10] , Step [600/2888] , Loss: 0.1814261674880981\n",
      "Epoch [9/10] , Step [610/2888] , Loss: 0.3102896809577942\n",
      "Epoch [9/10] , Step [620/2888] , Loss: 0.4322440624237061\n",
      "Epoch [9/10] , Step [630/2888] , Loss: 0.4701217114925385\n",
      "Epoch [9/10] , Step [640/2888] , Loss: 0.4629449248313904\n",
      "Epoch [9/10] , Step [650/2888] , Loss: 0.3873987793922424\n",
      "Epoch [9/10] , Step [660/2888] , Loss: 0.6611329913139343\n",
      "Epoch [9/10] , Step [670/2888] , Loss: 0.3861411809921265\n",
      "Epoch [9/10] , Step [680/2888] , Loss: 0.4050948619842529\n",
      "Epoch [9/10] , Step [690/2888] , Loss: 0.4148307442665100\n",
      "Epoch [9/10] , Step [700/2888] , Loss: 0.4951110780239105\n",
      "Epoch [9/10] , Step [710/2888] , Loss: 0.6193864941596985\n",
      "Epoch [9/10] , Step [720/2888] , Loss: 0.4107863903045654\n",
      "Epoch [9/10] , Step [730/2888] , Loss: 0.4539300501346588\n",
      "Epoch [9/10] , Step [740/2888] , Loss: 0.3057167530059814\n",
      "Epoch [9/10] , Step [750/2888] , Loss: 0.5078326463699341\n",
      "Epoch [9/10] , Step [760/2888] , Loss: 0.2861358523368835\n",
      "Epoch [9/10] , Step [770/2888] , Loss: 0.3474858999252319\n",
      "Epoch [9/10] , Step [780/2888] , Loss: 0.2823562920093536\n",
      "Epoch [9/10] , Step [790/2888] , Loss: 0.4523682892322540\n",
      "Epoch [9/10] , Step [800/2888] , Loss: 0.2707573473453522\n",
      "Epoch [9/10] , Step [810/2888] , Loss: 0.5548294186592102\n",
      "Epoch [9/10] , Step [820/2888] , Loss: 0.2705922126770020\n",
      "Epoch [9/10] , Step [830/2888] , Loss: 0.4457995891571045\n",
      "Epoch [9/10] , Step [840/2888] , Loss: 0.3903734982013702\n",
      "Epoch [9/10] , Step [850/2888] , Loss: 0.4268765151500702\n",
      "Epoch [9/10] , Step [860/2888] , Loss: 0.5579954981803894\n",
      "Epoch [9/10] , Step [870/2888] , Loss: 0.5696784257888794\n",
      "Epoch [9/10] , Step [880/2888] , Loss: 0.3411783576011658\n",
      "Epoch [9/10] , Step [890/2888] , Loss: 0.3809432089328766\n",
      "Epoch [9/10] , Step [900/2888] , Loss: 0.4248261153697968\n",
      "Epoch [9/10] , Step [910/2888] , Loss: 0.4090014696121216\n",
      "Epoch [9/10] , Step [920/2888] , Loss: 0.3042336404323578\n",
      "Epoch [9/10] , Step [930/2888] , Loss: 0.5102549791336060\n",
      "Epoch [9/10] , Step [940/2888] , Loss: 0.5240204930305481\n",
      "Epoch [9/10] , Step [950/2888] , Loss: 0.4462479352951050\n",
      "Epoch [9/10] , Step [960/2888] , Loss: 0.3880349695682526\n",
      "Epoch [9/10] , Step [970/2888] , Loss: 0.6290340423583984\n",
      "Epoch [9/10] , Step [980/2888] , Loss: 0.7292351722717285\n",
      "Epoch [9/10] , Step [990/2888] , Loss: 0.4768377840518951\n",
      "Epoch [9/10] , Step [1000/2888] , Loss: 0.6024385094642639\n",
      "Epoch [9/10] , Step [1010/2888] , Loss: 0.3694850206375122\n",
      "Epoch [9/10] , Step [1020/2888] , Loss: 0.2226505428552628\n",
      "Epoch [9/10] , Step [1030/2888] , Loss: 0.3563935458660126\n",
      "Epoch [9/10] , Step [1040/2888] , Loss: 0.5004404187202454\n",
      "Epoch [9/10] , Step [1050/2888] , Loss: 0.3743029236793518\n",
      "Epoch [9/10] , Step [1060/2888] , Loss: 0.4774013757705688\n",
      "Epoch [9/10] , Step [1070/2888] , Loss: 0.1675889045000076\n",
      "Epoch [9/10] , Step [1080/2888] , Loss: 0.5100724697113037\n",
      "Epoch [9/10] , Step [1090/2888] , Loss: 0.4921934008598328\n",
      "Epoch [9/10] , Step [1100/2888] , Loss: 0.3169734179973602\n",
      "Epoch [9/10] , Step [1110/2888] , Loss: 0.5382334589958191\n",
      "Epoch [9/10] , Step [1120/2888] , Loss: 0.3627973496913910\n",
      "Epoch [9/10] , Step [1130/2888] , Loss: 0.4954034984111786\n",
      "Epoch [9/10] , Step [1140/2888] , Loss: 0.4940406680107117\n",
      "Epoch [9/10] , Step [1150/2888] , Loss: 0.5981057286262512\n",
      "Epoch [9/10] , Step [1160/2888] , Loss: 0.3836894333362579\n",
      "Epoch [9/10] , Step [1170/2888] , Loss: 0.3817270398139954\n",
      "Epoch [9/10] , Step [1180/2888] , Loss: 0.5874280929565430\n",
      "Epoch [9/10] , Step [1190/2888] , Loss: 0.5145992040634155\n",
      "Epoch [9/10] , Step [1200/2888] , Loss: 0.7046444416046143\n",
      "Epoch [9/10] , Step [1210/2888] , Loss: 0.2251548618078232\n",
      "Epoch [9/10] , Step [1220/2888] , Loss: 0.5953609943389893\n",
      "Epoch [9/10] , Step [1230/2888] , Loss: 0.3902987837791443\n",
      "Epoch [9/10] , Step [1240/2888] , Loss: 0.3275894224643707\n",
      "Epoch [9/10] , Step [1250/2888] , Loss: 0.6023144721984863\n",
      "Epoch [9/10] , Step [1260/2888] , Loss: 0.6360715031623840\n",
      "Epoch [9/10] , Step [1270/2888] , Loss: 0.5641788244247437\n",
      "Epoch [9/10] , Step [1280/2888] , Loss: 0.3781264722347260\n",
      "Epoch [9/10] , Step [1290/2888] , Loss: 0.5269532203674316\n",
      "Epoch [9/10] , Step [1300/2888] , Loss: 0.6344813704490662\n",
      "Epoch [9/10] , Step [1310/2888] , Loss: 0.5982453823089600\n",
      "Epoch [9/10] , Step [1320/2888] , Loss: 0.5926156044006348\n",
      "Epoch [9/10] , Step [1330/2888] , Loss: 0.5750604271888733\n",
      "Epoch [9/10] , Step [1340/2888] , Loss: 0.4898566603660583\n",
      "Epoch [9/10] , Step [1350/2888] , Loss: 0.6895199418067932\n",
      "Epoch [9/10] , Step [1360/2888] , Loss: 0.5197783708572388\n",
      "Epoch [9/10] , Step [1370/2888] , Loss: 0.3855407834053040\n",
      "Epoch [9/10] , Step [1380/2888] , Loss: 0.6149090528488159\n",
      "Epoch [9/10] , Step [1390/2888] , Loss: 0.2627571821212769\n",
      "Epoch [9/10] , Step [1400/2888] , Loss: 0.2877827286720276\n",
      "Epoch [9/10] , Step [1410/2888] , Loss: 0.5209251046180725\n",
      "Epoch [9/10] , Step [1420/2888] , Loss: 0.3435309231281281\n",
      "Epoch [9/10] , Step [1430/2888] , Loss: 0.5576948523521423\n",
      "Epoch [9/10] , Step [1440/2888] , Loss: 0.3741490840911865\n",
      "Epoch [9/10] , Step [1450/2888] , Loss: 0.3344441950321198\n",
      "Epoch [9/10] , Step [1460/2888] , Loss: 0.4075146615505219\n",
      "Epoch [9/10] , Step [1470/2888] , Loss: 0.4693618416786194\n",
      "Epoch [9/10] , Step [1480/2888] , Loss: 0.3198198378086090\n",
      "Epoch [9/10] , Step [1490/2888] , Loss: 0.6063388586044312\n",
      "Epoch [9/10] , Step [1500/2888] , Loss: 0.2789609432220459\n",
      "Epoch [9/10] , Step [1510/2888] , Loss: 0.8142231702804565\n",
      "Epoch [9/10] , Step [1520/2888] , Loss: 0.4783053994178772\n",
      "Epoch [9/10] , Step [1530/2888] , Loss: 0.7099602222442627\n",
      "Epoch [9/10] , Step [1540/2888] , Loss: 0.5166091918945312\n",
      "Epoch [9/10] , Step [1550/2888] , Loss: 0.3765885233879089\n",
      "Epoch [9/10] , Step [1560/2888] , Loss: 0.2177246510982513\n",
      "Epoch [9/10] , Step [1570/2888] , Loss: 0.4565177261829376\n",
      "Epoch [9/10] , Step [1580/2888] , Loss: 0.4797894954681396\n",
      "Epoch [9/10] , Step [1590/2888] , Loss: 0.4049180746078491\n",
      "Epoch [9/10] , Step [1600/2888] , Loss: 0.6847477555274963\n",
      "Epoch [9/10] , Step [1610/2888] , Loss: 0.2622305154800415\n",
      "Epoch [9/10] , Step [1620/2888] , Loss: 0.5723753571510315\n",
      "Epoch [9/10] , Step [1630/2888] , Loss: 0.4087512493133545\n",
      "Epoch [9/10] , Step [1640/2888] , Loss: 0.4882331490516663\n",
      "Epoch [9/10] , Step [1650/2888] , Loss: 0.5311843752861023\n",
      "Epoch [9/10] , Step [1660/2888] , Loss: 0.2394039928913116\n",
      "Epoch [9/10] , Step [1670/2888] , Loss: 0.5759209394454956\n",
      "Epoch [9/10] , Step [1680/2888] , Loss: 0.4660479724407196\n",
      "Epoch [9/10] , Step [1690/2888] , Loss: 0.5575929284095764\n",
      "Epoch [9/10] , Step [1700/2888] , Loss: 0.4911818206310272\n",
      "Epoch [9/10] , Step [1710/2888] , Loss: 0.6442068815231323\n",
      "Epoch [9/10] , Step [1720/2888] , Loss: 0.5099890828132629\n",
      "Epoch [9/10] , Step [1730/2888] , Loss: 0.3103484511375427\n",
      "Epoch [9/10] , Step [1740/2888] , Loss: 0.3289819955825806\n",
      "Epoch [9/10] , Step [1750/2888] , Loss: 0.3925615549087524\n",
      "Epoch [9/10] , Step [1760/2888] , Loss: 0.5422149896621704\n",
      "Epoch [9/10] , Step [1770/2888] , Loss: 0.2415105402469635\n",
      "Epoch [9/10] , Step [1780/2888] , Loss: 0.4279893040657043\n",
      "Epoch [9/10] , Step [1790/2888] , Loss: 0.4959250092506409\n",
      "Epoch [9/10] , Step [1800/2888] , Loss: 0.2846512794494629\n",
      "Epoch [9/10] , Step [1810/2888] , Loss: 0.2869078218936920\n",
      "Epoch [9/10] , Step [1820/2888] , Loss: 0.2755660414695740\n",
      "Epoch [9/10] , Step [1830/2888] , Loss: 0.5868967771530151\n",
      "Epoch [9/10] , Step [1840/2888] , Loss: 0.4431753754615784\n",
      "Epoch [9/10] , Step [1850/2888] , Loss: 0.3206653892993927\n",
      "Epoch [9/10] , Step [1860/2888] , Loss: 0.5199308991432190\n",
      "Epoch [9/10] , Step [1870/2888] , Loss: 0.5146479606628418\n",
      "Epoch [9/10] , Step [1880/2888] , Loss: 0.6711638569831848\n",
      "Epoch [9/10] , Step [1890/2888] , Loss: 0.5250916481018066\n",
      "Epoch [9/10] , Step [1900/2888] , Loss: 0.5482481122016907\n",
      "Epoch [9/10] , Step [1910/2888] , Loss: 0.5519254207611084\n",
      "Epoch [9/10] , Step [1920/2888] , Loss: 0.6868178844451904\n",
      "Epoch [9/10] , Step [1930/2888] , Loss: 0.5744071006774902\n",
      "Epoch [9/10] , Step [1940/2888] , Loss: 0.4695414900779724\n",
      "Epoch [9/10] , Step [1950/2888] , Loss: 0.5368993282318115\n",
      "Epoch [9/10] , Step [1960/2888] , Loss: 0.4269705414772034\n",
      "Epoch [9/10] , Step [1970/2888] , Loss: 0.6053303480148315\n",
      "Epoch [9/10] , Step [1980/2888] , Loss: 0.7053016424179077\n",
      "Epoch [9/10] , Step [1990/2888] , Loss: 0.6668897271156311\n",
      "Epoch [9/10] , Step [2000/2888] , Loss: 0.5493680834770203\n",
      "Epoch [9/10] , Step [2010/2888] , Loss: 0.5123795270919800\n",
      "Epoch [9/10] , Step [2020/2888] , Loss: 0.4483513534069061\n",
      "Epoch [9/10] , Step [2030/2888] , Loss: 0.5864875316619873\n",
      "Epoch [9/10] , Step [2040/2888] , Loss: 0.5265682339668274\n",
      "Epoch [9/10] , Step [2050/2888] , Loss: 0.2377787530422211\n",
      "Epoch [9/10] , Step [2060/2888] , Loss: 0.5407447814941406\n",
      "Epoch [9/10] , Step [2070/2888] , Loss: 0.4914714097976685\n",
      "Epoch [9/10] , Step [2080/2888] , Loss: 0.4617689847946167\n",
      "Epoch [9/10] , Step [2090/2888] , Loss: 0.7023054361343384\n",
      "Epoch [9/10] , Step [2100/2888] , Loss: 0.6476625204086304\n",
      "Epoch [9/10] , Step [2110/2888] , Loss: 0.3436758518218994\n",
      "Epoch [9/10] , Step [2120/2888] , Loss: 0.2674295008182526\n",
      "Epoch [9/10] , Step [2130/2888] , Loss: 0.3428829610347748\n",
      "Epoch [9/10] , Step [2140/2888] , Loss: 0.4364411532878876\n",
      "Epoch [9/10] , Step [2150/2888] , Loss: 0.4354133605957031\n",
      "Epoch [9/10] , Step [2160/2888] , Loss: 0.3867733478546143\n",
      "Epoch [9/10] , Step [2170/2888] , Loss: 0.1420530527830124\n",
      "Epoch [9/10] , Step [2180/2888] , Loss: 0.4806498289108276\n",
      "Epoch [9/10] , Step [2190/2888] , Loss: 0.4971011281013489\n",
      "Epoch [9/10] , Step [2200/2888] , Loss: 0.4657414853572845\n",
      "Epoch [9/10] , Step [2210/2888] , Loss: 0.4805963039398193\n",
      "Epoch [9/10] , Step [2220/2888] , Loss: 0.4075245261192322\n",
      "Epoch [9/10] , Step [2230/2888] , Loss: 0.4692574739456177\n",
      "Epoch [9/10] , Step [2240/2888] , Loss: 0.2956520915031433\n",
      "Epoch [9/10] , Step [2250/2888] , Loss: 0.5334194898605347\n",
      "Epoch [9/10] , Step [2260/2888] , Loss: 0.2976433336734772\n",
      "Epoch [9/10] , Step [2270/2888] , Loss: 0.6131281852722168\n",
      "Epoch [9/10] , Step [2280/2888] , Loss: 0.3274407982826233\n",
      "Epoch [9/10] , Step [2290/2888] , Loss: 0.4422971010208130\n",
      "Epoch [9/10] , Step [2300/2888] , Loss: 0.5798219442367554\n",
      "Epoch [9/10] , Step [2310/2888] , Loss: 0.5395265817642212\n",
      "Epoch [9/10] , Step [2320/2888] , Loss: 0.4352142810821533\n",
      "Epoch [9/10] , Step [2330/2888] , Loss: 0.5707715749740601\n",
      "Epoch [9/10] , Step [2340/2888] , Loss: 0.6167549490928650\n",
      "Epoch [9/10] , Step [2350/2888] , Loss: 0.2935081720352173\n",
      "Epoch [9/10] , Step [2360/2888] , Loss: 0.4716732501983643\n",
      "Epoch [9/10] , Step [2370/2888] , Loss: 0.5264830589294434\n",
      "Epoch [9/10] , Step [2380/2888] , Loss: 0.6716024875640869\n",
      "Epoch [9/10] , Step [2390/2888] , Loss: 0.6180006265640259\n",
      "Epoch [9/10] , Step [2400/2888] , Loss: 0.6347758173942566\n",
      "Epoch [9/10] , Step [2410/2888] , Loss: 0.5868681669235229\n",
      "Epoch [9/10] , Step [2420/2888] , Loss: 0.4660410284996033\n",
      "Epoch [9/10] , Step [2430/2888] , Loss: 0.5602726936340332\n",
      "Epoch [9/10] , Step [2440/2888] , Loss: 0.5007597208023071\n",
      "Epoch [9/10] , Step [2450/2888] , Loss: 0.3063379526138306\n",
      "Epoch [9/10] , Step [2460/2888] , Loss: 0.3513692319393158\n",
      "Epoch [9/10] , Step [2470/2888] , Loss: 0.7759739756584167\n",
      "Epoch [9/10] , Step [2480/2888] , Loss: 0.5575674176216125\n",
      "Epoch [9/10] , Step [2490/2888] , Loss: 0.4194289743900299\n",
      "Epoch [9/10] , Step [2500/2888] , Loss: 0.5409057140350342\n",
      "Epoch [9/10] , Step [2510/2888] , Loss: 0.1432305872440338\n",
      "Epoch [9/10] , Step [2520/2888] , Loss: 0.4239858388900757\n",
      "Epoch [9/10] , Step [2530/2888] , Loss: 0.6027446985244751\n",
      "Epoch [9/10] , Step [2540/2888] , Loss: 0.4212110936641693\n",
      "Epoch [9/10] , Step [2550/2888] , Loss: 0.6479462981224060\n",
      "Epoch [9/10] , Step [2560/2888] , Loss: 0.5320844054222107\n",
      "Epoch [9/10] , Step [2570/2888] , Loss: 0.3236762881278992\n",
      "Epoch [9/10] , Step [2580/2888] , Loss: 0.3286392092704773\n",
      "Epoch [9/10] , Step [2590/2888] , Loss: 0.2103449702262878\n",
      "Epoch [9/10] , Step [2600/2888] , Loss: 0.2334829419851303\n",
      "Epoch [9/10] , Step [2610/2888] , Loss: 0.6589539647102356\n",
      "Epoch [9/10] , Step [2620/2888] , Loss: 0.2789331972599030\n",
      "Epoch [9/10] , Step [2630/2888] , Loss: 0.5361111760139465\n",
      "Epoch [9/10] , Step [2640/2888] , Loss: 0.4739636480808258\n",
      "Epoch [9/10] , Step [2650/2888] , Loss: 0.4573823809623718\n",
      "Epoch [9/10] , Step [2660/2888] , Loss: 0.6507714986801147\n",
      "Epoch [9/10] , Step [2670/2888] , Loss: 0.4006749987602234\n",
      "Epoch [9/10] , Step [2680/2888] , Loss: 0.4290295839309692\n",
      "Epoch [9/10] , Step [2690/2888] , Loss: 0.3930818438529968\n",
      "Epoch [9/10] , Step [2700/2888] , Loss: 0.4119826555252075\n",
      "Epoch [9/10] , Step [2710/2888] , Loss: 0.6995816230773926\n",
      "Epoch [9/10] , Step [2720/2888] , Loss: 0.4945000708103180\n",
      "Epoch [9/10] , Step [2730/2888] , Loss: 0.4616678953170776\n",
      "Epoch [9/10] , Step [2740/2888] , Loss: 0.3673442006111145\n",
      "Epoch [9/10] , Step [2750/2888] , Loss: 0.5321419835090637\n",
      "Epoch [9/10] , Step [2760/2888] , Loss: 0.6299329996109009\n",
      "Epoch [9/10] , Step [2770/2888] , Loss: 0.4925463199615479\n",
      "Epoch [9/10] , Step [2780/2888] , Loss: 0.3965043425559998\n",
      "Epoch [9/10] , Step [2790/2888] , Loss: 0.4932743608951569\n",
      "Epoch [9/10] , Step [2800/2888] , Loss: 0.5286380648612976\n",
      "Epoch [9/10] , Step [2810/2888] , Loss: 0.1935824155807495\n",
      "Epoch [9/10] , Step [2820/2888] , Loss: 0.3903376460075378\n",
      "Epoch [9/10] , Step [2830/2888] , Loss: 0.6489166617393494\n",
      "Epoch [9/10] , Step [2840/2888] , Loss: 0.4229637980461121\n",
      "Epoch [9/10] , Step [2850/2888] , Loss: 0.8393347859382629\n",
      "Epoch [9/10] , Step [2860/2888] , Loss: 0.4777513742446899\n",
      "Epoch [9/10] , Step [2870/2888] , Loss: 0.2884573638439178\n",
      "Epoch [9/10] , Step [2880/2888] , Loss: 0.5957285165786743\n",
      "Epoch [10/10] , Step [10/2888] , Loss: 0.5274074673652649\n",
      "Epoch [10/10] , Step [20/2888] , Loss: 0.6014275550842285\n",
      "Epoch [10/10] , Step [30/2888] , Loss: 0.3356823027133942\n",
      "Epoch [10/10] , Step [40/2888] , Loss: 0.6676077842712402\n",
      "Epoch [10/10] , Step [50/2888] , Loss: 0.3873874247074127\n",
      "Epoch [10/10] , Step [60/2888] , Loss: 0.3479196429252625\n",
      "Epoch [10/10] , Step [70/2888] , Loss: 0.2077957689762115\n",
      "Epoch [10/10] , Step [80/2888] , Loss: 0.4328258633613586\n",
      "Epoch [10/10] , Step [90/2888] , Loss: 0.4319565594196320\n",
      "Epoch [10/10] , Step [100/2888] , Loss: 0.4977982342243195\n",
      "Epoch [10/10] , Step [110/2888] , Loss: 0.3848913013935089\n",
      "Epoch [10/10] , Step [120/2888] , Loss: 0.4938037097454071\n",
      "Epoch [10/10] , Step [130/2888] , Loss: 0.5416652560234070\n",
      "Epoch [10/10] , Step [140/2888] , Loss: 0.6136537790298462\n",
      "Epoch [10/10] , Step [150/2888] , Loss: 0.5594841241836548\n",
      "Epoch [10/10] , Step [160/2888] , Loss: 0.4142327904701233\n",
      "Epoch [10/10] , Step [170/2888] , Loss: 0.5022186040878296\n",
      "Epoch [10/10] , Step [180/2888] , Loss: 0.6333365440368652\n",
      "Epoch [10/10] , Step [190/2888] , Loss: 0.3213891983032227\n",
      "Epoch [10/10] , Step [200/2888] , Loss: 0.3477788865566254\n",
      "Epoch [10/10] , Step [210/2888] , Loss: 0.4085465371608734\n",
      "Epoch [10/10] , Step [220/2888] , Loss: 0.5084694623947144\n",
      "Epoch [10/10] , Step [230/2888] , Loss: 0.5613571405410767\n",
      "Epoch [10/10] , Step [240/2888] , Loss: 0.3602263927459717\n",
      "Epoch [10/10] , Step [250/2888] , Loss: 0.5964592695236206\n",
      "Epoch [10/10] , Step [260/2888] , Loss: 0.6389094591140747\n",
      "Epoch [10/10] , Step [270/2888] , Loss: 0.4250614345073700\n",
      "Epoch [10/10] , Step [280/2888] , Loss: 0.4539119899272919\n",
      "Epoch [10/10] , Step [290/2888] , Loss: 0.8025223612785339\n",
      "Epoch [10/10] , Step [300/2888] , Loss: 0.4480085372924805\n",
      "Epoch [10/10] , Step [310/2888] , Loss: 0.5529606342315674\n",
      "Epoch [10/10] , Step [320/2888] , Loss: 0.4059345126152039\n",
      "Epoch [10/10] , Step [330/2888] , Loss: 0.2134092003107071\n",
      "Epoch [10/10] , Step [340/2888] , Loss: 0.5358012318611145\n",
      "Epoch [10/10] , Step [350/2888] , Loss: 0.4281531870365143\n",
      "Epoch [10/10] , Step [360/2888] , Loss: 0.2925033569335938\n",
      "Epoch [10/10] , Step [370/2888] , Loss: 0.4009064733982086\n",
      "Epoch [10/10] , Step [380/2888] , Loss: 0.4253110289573669\n",
      "Epoch [10/10] , Step [390/2888] , Loss: 0.6415959000587463\n",
      "Epoch [10/10] , Step [400/2888] , Loss: 0.6682975888252258\n",
      "Epoch [10/10] , Step [410/2888] , Loss: 0.6182089447975159\n",
      "Epoch [10/10] , Step [420/2888] , Loss: 0.2891404628753662\n",
      "Epoch [10/10] , Step [430/2888] , Loss: 0.7829900979995728\n",
      "Epoch [10/10] , Step [440/2888] , Loss: 0.2877861857414246\n",
      "Epoch [10/10] , Step [450/2888] , Loss: 0.4584944844245911\n",
      "Epoch [10/10] , Step [460/2888] , Loss: 0.5024345517158508\n",
      "Epoch [10/10] , Step [470/2888] , Loss: 0.5302731394767761\n",
      "Epoch [10/10] , Step [480/2888] , Loss: 0.5354257225990295\n",
      "Epoch [10/10] , Step [490/2888] , Loss: 0.6273818016052246\n",
      "Epoch [10/10] , Step [500/2888] , Loss: 0.2701909542083740\n",
      "Epoch [10/10] , Step [510/2888] , Loss: 0.6693078875541687\n",
      "Epoch [10/10] , Step [520/2888] , Loss: 0.4279347360134125\n",
      "Epoch [10/10] , Step [530/2888] , Loss: 0.4694753587245941\n",
      "Epoch [10/10] , Step [540/2888] , Loss: 0.5852199196815491\n",
      "Epoch [10/10] , Step [550/2888] , Loss: 0.5053980350494385\n",
      "Epoch [10/10] , Step [560/2888] , Loss: 0.3998423814773560\n",
      "Epoch [10/10] , Step [570/2888] , Loss: 0.4722350239753723\n",
      "Epoch [10/10] , Step [580/2888] , Loss: 0.4370443522930145\n",
      "Epoch [10/10] , Step [590/2888] , Loss: 0.3928073346614838\n",
      "Epoch [10/10] , Step [600/2888] , Loss: 0.5201829671859741\n",
      "Epoch [10/10] , Step [610/2888] , Loss: 0.3929018974304199\n",
      "Epoch [10/10] , Step [620/2888] , Loss: 0.3337897360324860\n",
      "Epoch [10/10] , Step [630/2888] , Loss: 0.5534421205520630\n",
      "Epoch [10/10] , Step [640/2888] , Loss: 0.4717580676078796\n",
      "Epoch [10/10] , Step [650/2888] , Loss: 0.3064267039299011\n",
      "Epoch [10/10] , Step [660/2888] , Loss: 0.3188194930553436\n",
      "Epoch [10/10] , Step [670/2888] , Loss: 0.4353207051753998\n",
      "Epoch [10/10] , Step [680/2888] , Loss: 0.5040805339813232\n",
      "Epoch [10/10] , Step [690/2888] , Loss: 0.3837575316429138\n",
      "Epoch [10/10] , Step [700/2888] , Loss: 0.2856147289276123\n",
      "Epoch [10/10] , Step [710/2888] , Loss: 0.3586077392101288\n",
      "Epoch [10/10] , Step [720/2888] , Loss: 0.5677368640899658\n",
      "Epoch [10/10] , Step [730/2888] , Loss: 0.5261396765708923\n",
      "Epoch [10/10] , Step [740/2888] , Loss: 0.4471821188926697\n",
      "Epoch [10/10] , Step [750/2888] , Loss: 0.5798143148422241\n",
      "Epoch [10/10] , Step [760/2888] , Loss: 0.4397780299186707\n",
      "Epoch [10/10] , Step [770/2888] , Loss: 0.4919211566448212\n",
      "Epoch [10/10] , Step [780/2888] , Loss: 0.5183953642845154\n",
      "Epoch [10/10] , Step [790/2888] , Loss: 0.2661801576614380\n",
      "Epoch [10/10] , Step [800/2888] , Loss: 0.5393899083137512\n",
      "Epoch [10/10] , Step [810/2888] , Loss: 0.4780175387859344\n",
      "Epoch [10/10] , Step [820/2888] , Loss: 0.3351020812988281\n",
      "Epoch [10/10] , Step [830/2888] , Loss: 0.6823692321777344\n",
      "Epoch [10/10] , Step [840/2888] , Loss: 0.2208374589681625\n",
      "Epoch [10/10] , Step [850/2888] , Loss: 0.4151192605495453\n",
      "Epoch [10/10] , Step [860/2888] , Loss: 0.5754765868186951\n",
      "Epoch [10/10] , Step [870/2888] , Loss: 0.3010313808917999\n",
      "Epoch [10/10] , Step [880/2888] , Loss: 0.4308948814868927\n",
      "Epoch [10/10] , Step [890/2888] , Loss: 0.2910479605197906\n",
      "Epoch [10/10] , Step [900/2888] , Loss: 0.2818618118762970\n",
      "Epoch [10/10] , Step [910/2888] , Loss: 0.4411290884017944\n",
      "Epoch [10/10] , Step [920/2888] , Loss: 0.4922613799571991\n",
      "Epoch [10/10] , Step [930/2888] , Loss: 0.5272303223609924\n",
      "Epoch [10/10] , Step [940/2888] , Loss: 0.3814365267753601\n",
      "Epoch [10/10] , Step [950/2888] , Loss: 0.4796541929244995\n",
      "Epoch [10/10] , Step [960/2888] , Loss: 0.3989709615707397\n",
      "Epoch [10/10] , Step [970/2888] , Loss: 0.5562837123870850\n",
      "Epoch [10/10] , Step [980/2888] , Loss: 0.3467709422111511\n",
      "Epoch [10/10] , Step [990/2888] , Loss: 0.6513215899467468\n",
      "Epoch [10/10] , Step [1000/2888] , Loss: 0.5560688972473145\n",
      "Epoch [10/10] , Step [1010/2888] , Loss: 0.5345267057418823\n",
      "Epoch [10/10] , Step [1020/2888] , Loss: 0.3904686868190765\n",
      "Epoch [10/10] , Step [1030/2888] , Loss: 0.2857781648635864\n",
      "Epoch [10/10] , Step [1040/2888] , Loss: 0.3053192794322968\n",
      "Epoch [10/10] , Step [1050/2888] , Loss: 0.5308046340942383\n",
      "Epoch [10/10] , Step [1060/2888] , Loss: 0.5181369781494141\n",
      "Epoch [10/10] , Step [1070/2888] , Loss: 0.4453940093517303\n",
      "Epoch [10/10] , Step [1080/2888] , Loss: 0.4033187627792358\n",
      "Epoch [10/10] , Step [1090/2888] , Loss: 0.7365710735321045\n",
      "Epoch [10/10] , Step [1100/2888] , Loss: 0.3527487516403198\n",
      "Epoch [10/10] , Step [1110/2888] , Loss: 0.4893915355205536\n",
      "Epoch [10/10] , Step [1120/2888] , Loss: 0.6516926884651184\n",
      "Epoch [10/10] , Step [1130/2888] , Loss: 0.4796470999717712\n",
      "Epoch [10/10] , Step [1140/2888] , Loss: 0.5858318209648132\n",
      "Epoch [10/10] , Step [1150/2888] , Loss: 0.6721547842025757\n",
      "Epoch [10/10] , Step [1160/2888] , Loss: 0.3671725690364838\n",
      "Epoch [10/10] , Step [1170/2888] , Loss: 0.4961255788803101\n",
      "Epoch [10/10] , Step [1180/2888] , Loss: 0.4756367206573486\n",
      "Epoch [10/10] , Step [1190/2888] , Loss: 0.3885914683341980\n",
      "Epoch [10/10] , Step [1200/2888] , Loss: 0.4355853497982025\n",
      "Epoch [10/10] , Step [1210/2888] , Loss: 0.5971319079399109\n",
      "Epoch [10/10] , Step [1220/2888] , Loss: 0.5552814602851868\n",
      "Epoch [10/10] , Step [1230/2888] , Loss: 0.4844524562358856\n",
      "Epoch [10/10] , Step [1240/2888] , Loss: 0.4788417220115662\n",
      "Epoch [10/10] , Step [1250/2888] , Loss: 0.3100265264511108\n",
      "Epoch [10/10] , Step [1260/2888] , Loss: 0.4673511385917664\n",
      "Epoch [10/10] , Step [1270/2888] , Loss: 0.4761479496955872\n",
      "Epoch [10/10] , Step [1280/2888] , Loss: 0.4648494124412537\n",
      "Epoch [10/10] , Step [1290/2888] , Loss: 0.5723797082901001\n",
      "Epoch [10/10] , Step [1300/2888] , Loss: 0.5276853442192078\n",
      "Epoch [10/10] , Step [1310/2888] , Loss: 0.4479199051856995\n",
      "Epoch [10/10] , Step [1320/2888] , Loss: 0.3389197289943695\n",
      "Epoch [10/10] , Step [1330/2888] , Loss: 0.2050219476222992\n",
      "Epoch [10/10] , Step [1340/2888] , Loss: 0.5374764204025269\n",
      "Epoch [10/10] , Step [1350/2888] , Loss: 0.6606611609458923\n",
      "Epoch [10/10] , Step [1360/2888] , Loss: 0.3158500790596008\n",
      "Epoch [10/10] , Step [1370/2888] , Loss: 0.5661166906356812\n",
      "Epoch [10/10] , Step [1380/2888] , Loss: 0.5225148200988770\n",
      "Epoch [10/10] , Step [1390/2888] , Loss: 0.2957345247268677\n",
      "Epoch [10/10] , Step [1400/2888] , Loss: 0.3747973442077637\n",
      "Epoch [10/10] , Step [1410/2888] , Loss: 0.3973558545112610\n",
      "Epoch [10/10] , Step [1420/2888] , Loss: 0.3703730106353760\n",
      "Epoch [10/10] , Step [1430/2888] , Loss: 0.3191947937011719\n",
      "Epoch [10/10] , Step [1440/2888] , Loss: 0.6090637445449829\n",
      "Epoch [10/10] , Step [1450/2888] , Loss: 0.3852950036525726\n",
      "Epoch [10/10] , Step [1460/2888] , Loss: 0.5231765508651733\n",
      "Epoch [10/10] , Step [1470/2888] , Loss: 0.7591425180435181\n",
      "Epoch [10/10] , Step [1480/2888] , Loss: 0.2020423114299774\n",
      "Epoch [10/10] , Step [1490/2888] , Loss: 0.5114081501960754\n",
      "Epoch [10/10] , Step [1500/2888] , Loss: 0.4415184259414673\n",
      "Epoch [10/10] , Step [1510/2888] , Loss: 0.5250697731971741\n",
      "Epoch [10/10] , Step [1520/2888] , Loss: 0.4309169948101044\n",
      "Epoch [10/10] , Step [1530/2888] , Loss: 0.2224317193031311\n",
      "Epoch [10/10] , Step [1540/2888] , Loss: 0.4381676316261292\n",
      "Epoch [10/10] , Step [1550/2888] , Loss: 0.3623680174350739\n",
      "Epoch [10/10] , Step [1560/2888] , Loss: 0.4954123497009277\n",
      "Epoch [10/10] , Step [1570/2888] , Loss: 0.6636567115783691\n",
      "Epoch [10/10] , Step [1580/2888] , Loss: 0.4109595715999603\n",
      "Epoch [10/10] , Step [1590/2888] , Loss: 0.3900983333587646\n",
      "Epoch [10/10] , Step [1600/2888] , Loss: 0.4790306687355042\n",
      "Epoch [10/10] , Step [1610/2888] , Loss: 0.5716649293899536\n",
      "Epoch [10/10] , Step [1620/2888] , Loss: 0.5117653608322144\n",
      "Epoch [10/10] , Step [1630/2888] , Loss: 0.6539401412010193\n",
      "Epoch [10/10] , Step [1640/2888] , Loss: 0.3272607922554016\n",
      "Epoch [10/10] , Step [1650/2888] , Loss: 0.3744520843029022\n",
      "Epoch [10/10] , Step [1660/2888] , Loss: 0.3549640774726868\n",
      "Epoch [10/10] , Step [1670/2888] , Loss: 0.4757266044616699\n",
      "Epoch [10/10] , Step [1680/2888] , Loss: 0.6192557811737061\n",
      "Epoch [10/10] , Step [1690/2888] , Loss: 0.7210018634796143\n",
      "Epoch [10/10] , Step [1700/2888] , Loss: 0.3580186069011688\n",
      "Epoch [10/10] , Step [1710/2888] , Loss: 0.5104564428329468\n",
      "Epoch [10/10] , Step [1720/2888] , Loss: 0.2998284101486206\n",
      "Epoch [10/10] , Step [1730/2888] , Loss: 0.4478386640548706\n",
      "Epoch [10/10] , Step [1740/2888] , Loss: 0.5702254772186279\n",
      "Epoch [10/10] , Step [1750/2888] , Loss: 0.5119249820709229\n",
      "Epoch [10/10] , Step [1760/2888] , Loss: 0.3701604008674622\n",
      "Epoch [10/10] , Step [1770/2888] , Loss: 0.3844848573207855\n",
      "Epoch [10/10] , Step [1780/2888] , Loss: 0.3466196060180664\n",
      "Epoch [10/10] , Step [1790/2888] , Loss: 0.3810797929763794\n",
      "Epoch [10/10] , Step [1800/2888] , Loss: 0.5508990287780762\n",
      "Epoch [10/10] , Step [1810/2888] , Loss: 0.4801800251007080\n",
      "Epoch [10/10] , Step [1820/2888] , Loss: 0.4668642878532410\n",
      "Epoch [10/10] , Step [1830/2888] , Loss: 0.4874563217163086\n",
      "Epoch [10/10] , Step [1840/2888] , Loss: 0.5216074585914612\n",
      "Epoch [10/10] , Step [1850/2888] , Loss: 0.3930056989192963\n",
      "Epoch [10/10] , Step [1860/2888] , Loss: 0.4524157047271729\n",
      "Epoch [10/10] , Step [1870/2888] , Loss: 0.5002880692481995\n",
      "Epoch [10/10] , Step [1880/2888] , Loss: 0.4876585602760315\n",
      "Epoch [10/10] , Step [1890/2888] , Loss: 0.3604723513126373\n",
      "Epoch [10/10] , Step [1900/2888] , Loss: 0.4747219681739807\n",
      "Epoch [10/10] , Step [1910/2888] , Loss: 0.5110766887664795\n",
      "Epoch [10/10] , Step [1920/2888] , Loss: 0.2619241476058960\n",
      "Epoch [10/10] , Step [1930/2888] , Loss: 0.3564656376838684\n",
      "Epoch [10/10] , Step [1940/2888] , Loss: 0.5079830288887024\n",
      "Epoch [10/10] , Step [1950/2888] , Loss: 0.6198788881301880\n",
      "Epoch [10/10] , Step [1960/2888] , Loss: 0.5322158336639404\n",
      "Epoch [10/10] , Step [1970/2888] , Loss: 0.3174449205398560\n",
      "Epoch [10/10] , Step [1980/2888] , Loss: 0.2490255981683731\n",
      "Epoch [10/10] , Step [1990/2888] , Loss: 0.4852759838104248\n",
      "Epoch [10/10] , Step [2000/2888] , Loss: 0.5317661166191101\n",
      "Epoch [10/10] , Step [2010/2888] , Loss: 0.5137354731559753\n",
      "Epoch [10/10] , Step [2020/2888] , Loss: 0.4434509873390198\n",
      "Epoch [10/10] , Step [2030/2888] , Loss: 0.3849214911460876\n",
      "Epoch [10/10] , Step [2040/2888] , Loss: 0.4017965793609619\n",
      "Epoch [10/10] , Step [2050/2888] , Loss: 0.3094261586666107\n",
      "Epoch [10/10] , Step [2060/2888] , Loss: 0.3377334177494049\n",
      "Epoch [10/10] , Step [2070/2888] , Loss: 0.3171730041503906\n",
      "Epoch [10/10] , Step [2080/2888] , Loss: 0.4773797392845154\n",
      "Epoch [10/10] , Step [2090/2888] , Loss: 0.4528864920139313\n",
      "Epoch [10/10] , Step [2100/2888] , Loss: 0.3377255499362946\n",
      "Epoch [10/10] , Step [2110/2888] , Loss: 0.5407525897026062\n",
      "Epoch [10/10] , Step [2120/2888] , Loss: 0.6951962709426880\n",
      "Epoch [10/10] , Step [2130/2888] , Loss: 0.4785750210285187\n",
      "Epoch [10/10] , Step [2140/2888] , Loss: 0.2618717551231384\n",
      "Epoch [10/10] , Step [2150/2888] , Loss: 0.3554915487766266\n",
      "Epoch [10/10] , Step [2160/2888] , Loss: 0.6463928818702698\n",
      "Epoch [10/10] , Step [2170/2888] , Loss: 0.4757060408592224\n",
      "Epoch [10/10] , Step [2180/2888] , Loss: 0.4426937699317932\n",
      "Epoch [10/10] , Step [2190/2888] , Loss: 0.5651352405548096\n",
      "Epoch [10/10] , Step [2200/2888] , Loss: 0.2908532619476318\n",
      "Epoch [10/10] , Step [2210/2888] , Loss: 0.5592120289802551\n",
      "Epoch [10/10] , Step [2220/2888] , Loss: 0.4066102802753448\n",
      "Epoch [10/10] , Step [2230/2888] , Loss: 0.3242258429527283\n",
      "Epoch [10/10] , Step [2240/2888] , Loss: 0.4665282666683197\n",
      "Epoch [10/10] , Step [2250/2888] , Loss: 0.4196426570415497\n",
      "Epoch [10/10] , Step [2260/2888] , Loss: 0.4385424852371216\n",
      "Epoch [10/10] , Step [2270/2888] , Loss: 0.5907933712005615\n",
      "Epoch [10/10] , Step [2280/2888] , Loss: 0.4378253817558289\n",
      "Epoch [10/10] , Step [2290/2888] , Loss: 0.6327588558197021\n",
      "Epoch [10/10] , Step [2300/2888] , Loss: 0.5283706188201904\n",
      "Epoch [10/10] , Step [2310/2888] , Loss: 0.3552770614624023\n",
      "Epoch [10/10] , Step [2320/2888] , Loss: 0.5510052442550659\n",
      "Epoch [10/10] , Step [2330/2888] , Loss: 0.3090677261352539\n",
      "Epoch [10/10] , Step [2340/2888] , Loss: 0.3981537222862244\n",
      "Epoch [10/10] , Step [2350/2888] , Loss: 0.5590857267379761\n",
      "Epoch [10/10] , Step [2360/2888] , Loss: 0.2920658290386200\n",
      "Epoch [10/10] , Step [2370/2888] , Loss: 0.4874716103076935\n",
      "Epoch [10/10] , Step [2380/2888] , Loss: 0.3149492442607880\n",
      "Epoch [10/10] , Step [2390/2888] , Loss: 0.4956172704696655\n",
      "Epoch [10/10] , Step [2400/2888] , Loss: 0.3806880712509155\n",
      "Epoch [10/10] , Step [2410/2888] , Loss: 0.4217336773872375\n",
      "Epoch [10/10] , Step [2420/2888] , Loss: 0.4682328999042511\n",
      "Epoch [10/10] , Step [2430/2888] , Loss: 0.3604019880294800\n",
      "Epoch [10/10] , Step [2440/2888] , Loss: 0.5927584171295166\n",
      "Epoch [10/10] , Step [2450/2888] , Loss: 0.6061496138572693\n",
      "Epoch [10/10] , Step [2460/2888] , Loss: 0.6868615746498108\n",
      "Epoch [10/10] , Step [2470/2888] , Loss: 0.3829801380634308\n",
      "Epoch [10/10] , Step [2480/2888] , Loss: 0.4900420904159546\n",
      "Epoch [10/10] , Step [2490/2888] , Loss: 0.5041043758392334\n",
      "Epoch [10/10] , Step [2500/2888] , Loss: 0.3513563573360443\n",
      "Epoch [10/10] , Step [2510/2888] , Loss: 0.4493572711944580\n",
      "Epoch [10/10] , Step [2520/2888] , Loss: 0.5452495813369751\n",
      "Epoch [10/10] , Step [2530/2888] , Loss: 0.5899019241333008\n",
      "Epoch [10/10] , Step [2540/2888] , Loss: 0.4898893833160400\n",
      "Epoch [10/10] , Step [2550/2888] , Loss: 0.3378238379955292\n",
      "Epoch [10/10] , Step [2560/2888] , Loss: 0.3806315958499908\n",
      "Epoch [10/10] , Step [2570/2888] , Loss: 0.2107327133417130\n",
      "Epoch [10/10] , Step [2580/2888] , Loss: 0.4882322847843170\n",
      "Epoch [10/10] , Step [2590/2888] , Loss: 0.4971924126148224\n",
      "Epoch [10/10] , Step [2600/2888] , Loss: 0.4481875300407410\n",
      "Epoch [10/10] , Step [2610/2888] , Loss: 0.4148369431495667\n",
      "Epoch [10/10] , Step [2620/2888] , Loss: 0.4652171134948730\n",
      "Epoch [10/10] , Step [2630/2888] , Loss: 0.5081304311752319\n",
      "Epoch [10/10] , Step [2640/2888] , Loss: 0.4473642110824585\n",
      "Epoch [10/10] , Step [2650/2888] , Loss: 0.5442987084388733\n",
      "Epoch [10/10] , Step [2660/2888] , Loss: 0.3895346224308014\n",
      "Epoch [10/10] , Step [2670/2888] , Loss: 0.5830878019332886\n",
      "Epoch [10/10] , Step [2680/2888] , Loss: 0.6700907945632935\n",
      "Epoch [10/10] , Step [2690/2888] , Loss: 0.3649177551269531\n",
      "Epoch [10/10] , Step [2700/2888] , Loss: 0.4434046745300293\n",
      "Epoch [10/10] , Step [2710/2888] , Loss: 0.4067650735378265\n",
      "Epoch [10/10] , Step [2720/2888] , Loss: 0.5530281662940979\n",
      "Epoch [10/10] , Step [2730/2888] , Loss: 0.1871052682399750\n",
      "Epoch [10/10] , Step [2740/2888] , Loss: 0.2474278062582016\n",
      "Epoch [10/10] , Step [2750/2888] , Loss: 0.5267016291618347\n",
      "Epoch [10/10] , Step [2760/2888] , Loss: 0.6837825775146484\n",
      "Epoch [10/10] , Step [2770/2888] , Loss: 0.4319737851619720\n",
      "Epoch [10/10] , Step [2780/2888] , Loss: 0.4500658810138702\n",
      "Epoch [10/10] , Step [2790/2888] , Loss: 0.3636283874511719\n",
      "Epoch [10/10] , Step [2800/2888] , Loss: 0.6258744001388550\n",
      "Epoch [10/10] , Step [2810/2888] , Loss: 0.5513841509819031\n",
      "Epoch [10/10] , Step [2820/2888] , Loss: 0.5125386118888855\n",
      "Epoch [10/10] , Step [2830/2888] , Loss: 0.6381562948226929\n",
      "Epoch [10/10] , Step [2840/2888] , Loss: 0.4078939557075500\n",
      "Epoch [10/10] , Step [2850/2888] , Loss: 0.4039943516254425\n",
      "Epoch [10/10] , Step [2860/2888] , Loss: 0.3656598627567291\n",
      "Epoch [10/10] , Step [2870/2888] , Loss: 0.4222670197486877\n",
      "Epoch [10/10] , Step [2880/2888] , Loss: 0.3569292724132538\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i , (input_init_conditions,input_x_loc,input_time,Actual_y) in enumerate(train_loader):\n",
    "        input1 = input_init_conditions\n",
    "        input1 = input1.to(device)\n",
    "\n",
    "        input2 = torch.cat((input_x_loc,input_time),-1)\n",
    "        input2 = input2.to(device)\n",
    "\n",
    "        Actual_y = Actual_y.to(device)\n",
    "\n",
    "        Outputs = model(input1,input2)\n",
    "        loss = criterion(Outputs,Actual_y)\n",
    "\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        loss_rec.append(loss.item())\n",
    "\n",
    "        if (i+1) % 10 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoch}] , Step [{i+1}/{total_samples}] , Loss: {loss.item():.16f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_time.size(0)\n",
    "torch.ones(input_time.size(0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1222],\n",
       "        [0.0000, 0.0631],\n",
       "        [0.0000, 0.2255],\n",
       "        [0.0000, 0.0912]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2_BC1 = torch.cat((torch.zeros(input_time.size(0),1),input_time),-1).to(device)\n",
    "input2_BC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_BC1 = torch.zeros(input_time.size(0))\n",
    "target_BC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0050, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_BC1 = model(input1,input2_BC1)\n",
    "# predicted_BC1\n",
    "loss_BC1 = torch.mean((predicted_BC1-target_BC1)**2)\n",
    "loss_BC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_BC_0 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "loss_BC_0 = torch.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_rec)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 41\u001b[0m, in \u001b[0;36mDeepONet.forward\u001b[1;34m(self, branch_input, trunk_input)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Pass inputs through branch and trunk networks\u001b[39;00m\n\u001b[0;32m     40\u001b[0m branch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch_net(branch_input)  \u001b[38;5;66;03m# [batch_size, hidden_dim]\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m trunk_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrunk_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunk_input\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# [batch_size, hidden_dim]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Combine using dot product\u001b[39;00m\n\u001b[0;32m     44\u001b[0m combined_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis_layer(branch_output) \u001b[38;5;241m*\u001b[39m trunk_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch_size]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "model(y,torch.tensor([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_input_1 = torch.tensor(np.random.rand(65,100),dtype=torch.float32).to(device)\n",
    "trial_input_2 = torch.tensor(np.random.rand(65,2),dtype=torch.float32).to(device)\n",
    "model(trial_input_1,trial_input_2).mean()\n",
    "model(trial_input_1,trial_input_2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
