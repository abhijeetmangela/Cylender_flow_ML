{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x281aea7d7f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import h5py\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mu = torch.tensor(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepONet,self).__init__()\n",
    "        self.Branch_L1 = nn.Linear(201,100)\n",
    "        self.Branch_L2 = nn.Linear(100,100)\n",
    "        self.Branch_L3 = nn.Linear(100,100)\n",
    "        self.Branch_L4 = nn.Linear(100,100)\n",
    "        self.Branch_L5 = nn.Linear(100,100)\n",
    "        self.Branch_L6 = nn.Linear(100,100)\n",
    "        self.Branch_L7 = nn.Linear(100,100)\n",
    "\n",
    "        self.Trunk_L1 = nn.Linear(2,100)\n",
    "        self.Trunk_L2 = nn.Linear(100,100)\n",
    "        self.Trunk_L3 = nn.Linear(100,100)\n",
    "        self.Trunk_L4 = nn.Linear(100,100)\n",
    "        self.Trunk_L5 = nn.Linear(100,100)\n",
    "        self.Trunk_L6 = nn.Linear(100,100)\n",
    "        self.Trunk_L7 = nn.Linear(100,100)\n",
    "\n",
    "    def forward(self,y_0,x_loc_and_time):\n",
    "        # Branch\n",
    "        b = F.tanh(self.Branch_L1(y_0))\n",
    "        b = F.tanh(self.Branch_L2(b))\n",
    "        b = F.tanh(self.Branch_L3(b))\n",
    "        b = F.tanh(self.Branch_L4(b))\n",
    "        b = F.tanh(self.Branch_L5(b))\n",
    "        b = F.tanh(self.Branch_L6(b))\n",
    "        b = self.Branch_L7(b)\n",
    "\n",
    "        tr = F.tanh(self.Trunk_L1(x_loc_and_time))\n",
    "        tr = F.tanh(self.Trunk_L2(tr))\n",
    "        tr = F.tanh(self.Trunk_L3(tr))\n",
    "        tr = F.tanh(self.Trunk_L4(tr))\n",
    "        tr = F.tanh(self.Trunk_L5(tr))\n",
    "        tr = F.tanh(self.Trunk_L6(tr))\n",
    "        tr = self.Trunk_L7(tr)\n",
    "\n",
    "        #output = torch.matmul(b,tr.t()).sum(dim=0)\n",
    "        output = torch.sum(b * tr, dim=1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "# model = torch.load(\"model_burgers_1.pt\",weights_only=False)\n",
    "\n",
    "model = DeepONet().to(device)\n",
    "model.load_state_dict(torch.load('model_burgers_5.pt'))\n",
    "# model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0414,  0.0116,  0.0275, -0.0356,  0.0529,  0.0152, -0.0528, -0.0564,\n",
       "         0.0178,  0.0290, -0.0497,  0.0258,  0.0575,  0.0636, -0.0147, -0.0161,\n",
       "         0.0344, -0.0502, -0.0714, -0.0065,  0.0190,  0.0122,  0.0617, -0.0205,\n",
       "        -0.0410,  0.0017,  0.0266,  0.0531,  0.0564, -0.0757,  0.0043,  0.0445,\n",
       "        -0.0174,  0.0285, -0.0090, -0.0364, -0.0269,  0.0297,  0.0676,  0.0548,\n",
       "        -0.0019, -0.0091,  0.0524,  0.0608, -0.0053, -0.0250, -0.0501,  0.0373,\n",
       "        -0.0660,  0.0189, -0.0667,  0.0770, -0.0714, -0.0354, -0.0011, -0.0274,\n",
       "        -0.0123, -0.0438, -0.0218, -0.0433, -0.0685, -0.0711,  0.0527,  0.0061,\n",
       "         0.0673,  0.0165, -0.0337, -0.0076, -0.0704,  0.0742,  0.0354, -0.0423,\n",
       "         0.0258,  0.0469, -0.0318, -0.0458, -0.0498, -0.0798,  0.0709,  0.0047,\n",
       "        -0.0135, -0.0002, -0.0446,  0.0648, -0.0646,  0.0654, -0.0398,  0.0415,\n",
       "        -0.0079, -0.0647,  0.0687,  0.0357,  0.0299,  0.0439, -0.0621,  0.0287,\n",
       "         0.0324,  0.0554, -0.0783,  0.0101], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Branch_L1.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database = pd.read_csv('minus_sin_pix.csv',index_col=0).dropna().to_numpy(dtype='float32')\n",
    "#database = pd.read_pickle(\"test_df.pkl\") #pd.read_csv('minus_sin_pix.csv',index_col=0).dropna().to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database = pd.DataFrame(database).to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"Burgers_generalised_dataset_2.h5\",\"r\") as f:\n",
    "    database = f[\"my_array\"][:]\n",
    "\n",
    "database = database.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,transform=None):\n",
    "        self.initial_conditions = torch.from_numpy(database[:,0:201])#.requires_grad_(True)\n",
    "        self.x_location = torch.from_numpy(database[:,[201]])#.requires_grad_(True)\n",
    "        self.time_vale = torch.from_numpy(database[:,[202]])#.requires_grad_(True)\n",
    "        self.true_y_value = torch.from_numpy(database[:,[203]])#.requires_grad_(True)\n",
    "        self.n_samples = database.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.initial_conditions[index] , self.x_location[index] , self.time_vale[index] , self.true_y_value[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0052],\n",
       "        [-0.0444],\n",
       "        [-0.0843],\n",
       "        ...,\n",
       "        [-0.0133],\n",
       "        [-0.0080],\n",
       "        [-0.0027]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data.true_y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20301000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,_,_,_ = dataset_data.__getitem__(1)\n",
    "#plt.plot(y)\n",
    "#plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6*dataset_data.__len__())\n",
    "test_size = dataset_data.__len__() - train_size\n",
    "\n",
    "batch_size = 25000\n",
    "\n",
    "Burger_train_data , Burger_test_data = torch.utils.data.random_split(Data(),[train_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=Burger_train_data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12180600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "data = data_iter.__next__()\n",
    "Init_val , x_loc, time, y_value = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488 1\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 5000\n",
    "total_samples = len(train_loader)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "print(total_samples,n_iterations)\n",
    "learning_rate = 0.0000001\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=1e-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(outputs,inputs):\n",
    "    return torch.autograd.grad(outputs,inputs,grad_outputs=torch.ones_like(outputs),create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_locations_for_computation = torch.linspace(0,1,300,dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "def Physics_loss_Burgers(init_conditions,time_input_physics,x_locations):\n",
    "    total_temp = torch.tensor(0)\n",
    "    for j in range(len(time_input_physics)):\n",
    "        # Set up the input x locations as a range from 0 to 1\n",
    "        # x_locations = torch.linspace(0,1,300,dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "        # We will calculate gradients on every time given\n",
    "        time_input = time_input_physics[j]*torch.ones_like(x_locations,dtype=torch.float32)\n",
    "\n",
    "        # Taking the slice of the initial conditions associated with that time step. Can be used in future where not just sinx is taken.\n",
    "        input_1_physics = init_conditions[j,:].unsqueeze(0)\n",
    "        input2_physics = torch.cat((x_locations.unsqueeze(-1),time_input.unsqueeze(-1)),-1)\n",
    "\n",
    "        # Getting output \n",
    "        output_physics = model(input_1_physics.expand(len(input2_physics),-1),input2_physics)\n",
    "\n",
    "        # Getting required gradients\n",
    "        du_dt = grad(output_physics,time_input)[0]\n",
    "        du_dx = grad(output_physics,x_locations)[0]\n",
    "        du2_dx2 = grad(du_dx,x_locations)[0]\n",
    "\n",
    "        # Getting the physics loss and summing it up \n",
    "        temp = torch.mean(du_dt + output_physics*du_dx - mu*du2_dx2)\n",
    "        total_temp = total_temp + temp\n",
    "\n",
    "    return total_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_locations = torch.linspace(-1,1,300,dtype=torch.float32).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_input_physics = torch.tensor(0.2)\n",
    "time_input = time_input_physics*torch.ones_like(x_locations,dtype=torch.float32).requires_grad_(True)\n",
    "#print(time_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_locations = torch.linspace(-1,1,300,dtype=torch.float32).requires_grad_(True)\n",
    "input2_physics = torch.cat((x_locations.unsqueeze(-1),time_input.unsqueeze(-1)),-1)\n",
    "#print(input2_physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_1_physics = input1[1,:].unsqueeze(0)\n",
    "#input_1_physics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_physics = model(input_1_physics,input2_physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#du_dt = grad(output_physics,time_input)[0]\n",
    "#du_dx = grad(output_physics,x_locations)[0]\n",
    "#du2_dx2 = grad(du_dx,x_locations)[0]\n",
    "#loss_physics_burgers = torch.mean(du_dt + x_locations*du_dx - mu*du2_dx2)\n",
    "#loss_physics_burgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physics_loss_rec = Physics_loss(input1,input_time[3])\n",
    "#Physics_loss_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000] , Step [10/488] , Loss: 0.0327266380190849 \n",
      "Epoch [1/5000] , Step [20/488] , Loss: 0.0327092371881008 \n",
      "Epoch [1/5000] , Step [30/488] , Loss: 0.0323128737509251 \n",
      "Epoch [1/5000] , Step [40/488] , Loss: 0.0326044224202633 \n",
      "Epoch [1/5000] , Step [50/488] , Loss: 0.0327230878174305 \n",
      "Epoch [1/5000] , Step [60/488] , Loss: 0.0330623798072338 \n",
      "Epoch [1/5000] , Step [70/488] , Loss: 0.0328430719673634 \n",
      "Epoch [1/5000] , Step [80/488] , Loss: 0.0331175513565540 \n",
      "Epoch [1/5000] , Step [90/488] , Loss: 0.0324552692472935 \n",
      "Epoch [1/5000] , Step [100/488] , Loss: 0.0329623781144619 \n",
      "Epoch [1/5000] , Step [110/488] , Loss: 0.0327959917485714 \n",
      "Epoch [1/5000] , Step [120/488] , Loss: 0.0323198363184929 \n",
      "Epoch [1/5000] , Step [130/488] , Loss: 0.0324566289782524 \n",
      "Epoch [1/5000] , Step [140/488] , Loss: 0.0321520976722240 \n",
      "Epoch [1/5000] , Step [150/488] , Loss: 0.0328296311199665 \n",
      "Epoch [1/5000] , Step [160/488] , Loss: 0.0326387360692024 \n",
      "Epoch [1/5000] , Step [170/488] , Loss: 0.0326203368604183 \n",
      "Epoch [1/5000] , Step [180/488] , Loss: 0.0327981300652027 \n",
      "Epoch [1/5000] , Step [190/488] , Loss: 0.0323700681328773 \n",
      "Epoch [1/5000] , Step [200/488] , Loss: 0.0325535200536251 \n",
      "Epoch [1/5000] , Step [210/488] , Loss: 0.0328296683728695 \n",
      "Epoch [1/5000] , Step [220/488] , Loss: 0.0322755724191666 \n",
      "Epoch [1/5000] , Step [230/488] , Loss: 0.0318526960909367 \n",
      "Epoch [1/5000] , Step [240/488] , Loss: 0.0318078324198723 \n",
      "Epoch [1/5000] , Step [250/488] , Loss: 0.0327903814613819 \n",
      "Epoch [1/5000] , Step [260/488] , Loss: 0.0327234007418156 \n",
      "Epoch [1/5000] , Step [270/488] , Loss: 0.0323715992271900 \n",
      "Epoch [1/5000] , Step [280/488] , Loss: 0.0326867923140526 \n",
      "Epoch [1/5000] , Step [290/488] , Loss: 0.0323319211602211 \n",
      "Epoch [1/5000] , Step [300/488] , Loss: 0.0323339328169823 \n",
      "Epoch [1/5000] , Step [310/488] , Loss: 0.0316335782408714 \n",
      "Epoch [1/5000] , Step [320/488] , Loss: 0.0325781702995300 \n",
      "Epoch [1/5000] , Step [330/488] , Loss: 0.0322719998657703 \n",
      "Epoch [1/5000] , Step [340/488] , Loss: 0.0323916822671890 \n",
      "Epoch [1/5000] , Step [350/488] , Loss: 0.0327967628836632 \n",
      "Epoch [1/5000] , Step [360/488] , Loss: 0.0321482643485069 \n",
      "Epoch [1/5000] , Step [370/488] , Loss: 0.0320488698780537 \n",
      "Epoch [1/5000] , Step [380/488] , Loss: 0.0327469222247601 \n",
      "Epoch [1/5000] , Step [390/488] , Loss: 0.0325855612754822 \n",
      "Epoch [1/5000] , Step [400/488] , Loss: 0.0326629243791103 \n",
      "Epoch [1/5000] , Step [410/488] , Loss: 0.0319454669952393 \n",
      "Epoch [1/5000] , Step [420/488] , Loss: 0.0326029397547245 \n",
      "Epoch [1/5000] , Step [430/488] , Loss: 0.0326702930033207 \n",
      "Epoch [1/5000] , Step [440/488] , Loss: 0.0334973447024822 \n",
      "Epoch [1/5000] , Step [450/488] , Loss: 0.0326378606259823 \n",
      "Epoch [1/5000] , Step [460/488] , Loss: 0.0325475148856640 \n",
      "Epoch [1/5000] , Step [470/488] , Loss: 0.0322101935744286 \n",
      "Epoch [1/5000] , Step [480/488] , Loss: 0.0326864048838615 \n",
      "Epoch [2/5000] , Step [10/488] , Loss: 0.0325324982404709 \n",
      "Epoch [2/5000] , Step [20/488] , Loss: 0.0329984761774540 \n",
      "Epoch [2/5000] , Step [30/488] , Loss: 0.0328361801803112 \n",
      "Epoch [2/5000] , Step [40/488] , Loss: 0.0322103276848793 \n",
      "Epoch [2/5000] , Step [50/488] , Loss: 0.0328389331698418 \n",
      "Epoch [2/5000] , Step [60/488] , Loss: 0.0327084623277187 \n",
      "Epoch [2/5000] , Step [70/488] , Loss: 0.0329040363430977 \n",
      "Epoch [2/5000] , Step [80/488] , Loss: 0.0326965078711510 \n",
      "Epoch [2/5000] , Step [90/488] , Loss: 0.0325531922280788 \n",
      "Epoch [2/5000] , Step [100/488] , Loss: 0.0318827256560326 \n",
      "Epoch [2/5000] , Step [110/488] , Loss: 0.0331102088093758 \n",
      "Epoch [2/5000] , Step [120/488] , Loss: 0.0323896445333958 \n",
      "Epoch [2/5000] , Step [130/488] , Loss: 0.0331610627472401 \n",
      "Epoch [2/5000] , Step [140/488] , Loss: 0.0325239486992359 \n",
      "Epoch [2/5000] , Step [150/488] , Loss: 0.0324450545012951 \n",
      "Epoch [2/5000] , Step [160/488] , Loss: 0.0325760506093502 \n",
      "Epoch [2/5000] , Step [170/488] , Loss: 0.0331309251487255 \n",
      "Epoch [2/5000] , Step [180/488] , Loss: 0.0320246517658234 \n",
      "Epoch [2/5000] , Step [190/488] , Loss: 0.0326051935553551 \n",
      "Epoch [2/5000] , Step [200/488] , Loss: 0.0324090234935284 \n",
      "Epoch [2/5000] , Step [210/488] , Loss: 0.0328522920608521 \n",
      "Epoch [2/5000] , Step [220/488] , Loss: 0.0320840068161488 \n",
      "Epoch [2/5000] , Step [230/488] , Loss: 0.0327949710190296 \n",
      "Epoch [2/5000] , Step [240/488] , Loss: 0.0317855849862099 \n",
      "Epoch [2/5000] , Step [250/488] , Loss: 0.0329199321568012 \n",
      "Epoch [2/5000] , Step [260/488] , Loss: 0.0331688039004803 \n",
      "Epoch [2/5000] , Step [270/488] , Loss: 0.0314810015261173 \n",
      "Epoch [2/5000] , Step [280/488] , Loss: 0.0331405550241470 \n",
      "Epoch [2/5000] , Step [290/488] , Loss: 0.0325684696435928 \n",
      "Epoch [2/5000] , Step [300/488] , Loss: 0.0322462841868401 \n",
      "Epoch [2/5000] , Step [310/488] , Loss: 0.0323672443628311 \n",
      "Epoch [2/5000] , Step [320/488] , Loss: 0.0338750481605530 \n",
      "Epoch [2/5000] , Step [330/488] , Loss: 0.0325085259974003 \n",
      "Epoch [2/5000] , Step [340/488] , Loss: 0.0327047258615494 \n",
      "Epoch [2/5000] , Step [350/488] , Loss: 0.0330528020858765 \n",
      "Epoch [2/5000] , Step [360/488] , Loss: 0.0333263650536537 \n",
      "Epoch [2/5000] , Step [370/488] , Loss: 0.0321877039968967 \n",
      "Epoch [2/5000] , Step [380/488] , Loss: 0.0326104126870632 \n",
      "Epoch [2/5000] , Step [390/488] , Loss: 0.0322460681200027 \n",
      "Epoch [2/5000] , Step [400/488] , Loss: 0.0325498469173908 \n",
      "Epoch [2/5000] , Step [410/488] , Loss: 0.0324322059750557 \n",
      "Epoch [2/5000] , Step [420/488] , Loss: 0.0329943560063839 \n",
      "Epoch [2/5000] , Step [430/488] , Loss: 0.0329734422266483 \n",
      "Epoch [2/5000] , Step [440/488] , Loss: 0.0324293971061707 \n",
      "Epoch [2/5000] , Step [450/488] , Loss: 0.0312601476907730 \n",
      "Epoch [2/5000] , Step [460/488] , Loss: 0.0321463607251644 \n",
      "Epoch [2/5000] , Step [470/488] , Loss: 0.0328761450946331 \n",
      "Epoch [2/5000] , Step [480/488] , Loss: 0.0326312482357025 \n",
      "Epoch [3/5000] , Step [10/488] , Loss: 0.0321019627153873 \n",
      "Epoch [3/5000] , Step [20/488] , Loss: 0.0324254892766476 \n",
      "Epoch [3/5000] , Step [30/488] , Loss: 0.0322171337902546 \n",
      "Epoch [3/5000] , Step [40/488] , Loss: 0.0327156856656075 \n",
      "Epoch [3/5000] , Step [50/488] , Loss: 0.0326192975044250 \n",
      "Epoch [3/5000] , Step [60/488] , Loss: 0.0326784849166870 \n",
      "Epoch [3/5000] , Step [70/488] , Loss: 0.0319570265710354 \n",
      "Epoch [3/5000] , Step [80/488] , Loss: 0.0328357927501202 \n",
      "Epoch [3/5000] , Step [90/488] , Loss: 0.0328620709478855 \n",
      "Epoch [3/5000] , Step [100/488] , Loss: 0.0319862477481365 \n",
      "Epoch [3/5000] , Step [110/488] , Loss: 0.0328719615936279 \n",
      "Epoch [3/5000] , Step [120/488] , Loss: 0.0323913767933846 \n",
      "Epoch [3/5000] , Step [130/488] , Loss: 0.0322275869548321 \n",
      "Epoch [3/5000] , Step [140/488] , Loss: 0.0324868075549603 \n",
      "Epoch [3/5000] , Step [150/488] , Loss: 0.0327940434217453 \n",
      "Epoch [3/5000] , Step [160/488] , Loss: 0.0323221907019615 \n",
      "Epoch [3/5000] , Step [170/488] , Loss: 0.0319794192910194 \n",
      "Epoch [3/5000] , Step [180/488] , Loss: 0.0331966839730740 \n",
      "Epoch [3/5000] , Step [190/488] , Loss: 0.0325679481029510 \n",
      "Epoch [3/5000] , Step [200/488] , Loss: 0.0327564068138599 \n",
      "Epoch [3/5000] , Step [210/488] , Loss: 0.0322631485760212 \n",
      "Epoch [3/5000] , Step [220/488] , Loss: 0.0323129780590534 \n",
      "Epoch [3/5000] , Step [230/488] , Loss: 0.0321516394615173 \n",
      "Epoch [3/5000] , Step [240/488] , Loss: 0.0325594022870064 \n",
      "Epoch [3/5000] , Step [250/488] , Loss: 0.0322247780859470 \n",
      "Epoch [3/5000] , Step [260/488] , Loss: 0.0328046120703220 \n",
      "Epoch [3/5000] , Step [270/488] , Loss: 0.0323716774582863 \n",
      "Epoch [3/5000] , Step [280/488] , Loss: 0.0323701351881027 \n",
      "Epoch [3/5000] , Step [290/488] , Loss: 0.0321097411215305 \n",
      "Epoch [3/5000] , Step [300/488] , Loss: 0.0324458554387093 \n",
      "Epoch [3/5000] , Step [310/488] , Loss: 0.0328888259828091 \n",
      "Epoch [3/5000] , Step [320/488] , Loss: 0.0325880348682404 \n",
      "Epoch [3/5000] , Step [330/488] , Loss: 0.0322122760117054 \n",
      "Epoch [3/5000] , Step [340/488] , Loss: 0.0322511233389378 \n",
      "Epoch [3/5000] , Step [350/488] , Loss: 0.0323852226138115 \n",
      "Epoch [3/5000] , Step [360/488] , Loss: 0.0323520898818970 \n",
      "Epoch [3/5000] , Step [370/488] , Loss: 0.0322337821125984 \n",
      "Epoch [3/5000] , Step [380/488] , Loss: 0.0329852253198624 \n",
      "Epoch [3/5000] , Step [390/488] , Loss: 0.0323646999895573 \n",
      "Epoch [3/5000] , Step [400/488] , Loss: 0.0328127406537533 \n",
      "Epoch [3/5000] , Step [410/488] , Loss: 0.0327430181205273 \n",
      "Epoch [3/5000] , Step [420/488] , Loss: 0.0323594287037849 \n",
      "Epoch [3/5000] , Step [430/488] , Loss: 0.0330925323069096 \n",
      "Epoch [3/5000] , Step [440/488] , Loss: 0.0325158983469009 \n",
      "Epoch [3/5000] , Step [450/488] , Loss: 0.0330902300775051 \n",
      "Epoch [3/5000] , Step [460/488] , Loss: 0.0332361757755280 \n",
      "Epoch [3/5000] , Step [470/488] , Loss: 0.0328861065208912 \n",
      "Epoch [3/5000] , Step [480/488] , Loss: 0.0322045497596264 \n",
      "Epoch [4/5000] , Step [10/488] , Loss: 0.0334709845483303 \n",
      "Epoch [4/5000] , Step [20/488] , Loss: 0.0326268784701824 \n",
      "Epoch [4/5000] , Step [30/488] , Loss: 0.0329368896782398 \n",
      "Epoch [4/5000] , Step [40/488] , Loss: 0.0329936817288399 \n",
      "Epoch [4/5000] , Step [50/488] , Loss: 0.0323344841599464 \n",
      "Epoch [4/5000] , Step [60/488] , Loss: 0.0322202332317829 \n",
      "Epoch [4/5000] , Step [70/488] , Loss: 0.0323522165417671 \n",
      "Epoch [4/5000] , Step [80/488] , Loss: 0.0322296395897865 \n",
      "Epoch [4/5000] , Step [90/488] , Loss: 0.0327665209770203 \n",
      "Epoch [4/5000] , Step [100/488] , Loss: 0.0327757187187672 \n",
      "Epoch [4/5000] , Step [110/488] , Loss: 0.0324116647243500 \n",
      "Epoch [4/5000] , Step [120/488] , Loss: 0.0324489250779152 \n",
      "Epoch [4/5000] , Step [130/488] , Loss: 0.0329705588519573 \n",
      "Epoch [4/5000] , Step [140/488] , Loss: 0.0326005034148693 \n",
      "Epoch [4/5000] , Step [150/488] , Loss: 0.0330627933144569 \n",
      "Epoch [4/5000] , Step [160/488] , Loss: 0.0328880138695240 \n",
      "Epoch [4/5000] , Step [170/488] , Loss: 0.0321523658931255 \n",
      "Epoch [4/5000] , Step [180/488] , Loss: 0.0326765999197960 \n",
      "Epoch [4/5000] , Step [190/488] , Loss: 0.0326446555554867 \n",
      "Epoch [4/5000] , Step [200/488] , Loss: 0.0321377925574780 \n",
      "Epoch [4/5000] , Step [210/488] , Loss: 0.0326696857810020 \n",
      "Epoch [4/5000] , Step [220/488] , Loss: 0.0325923338532448 \n",
      "Epoch [4/5000] , Step [230/488] , Loss: 0.0329208970069885 \n",
      "Epoch [4/5000] , Step [240/488] , Loss: 0.0331507958471775 \n",
      "Epoch [4/5000] , Step [250/488] , Loss: 0.0323623195290565 \n",
      "Epoch [4/5000] , Step [260/488] , Loss: 0.0326828770339489 \n",
      "Epoch [4/5000] , Step [270/488] , Loss: 0.0326874218881130 \n",
      "Epoch [4/5000] , Step [280/488] , Loss: 0.0322588272392750 \n",
      "Epoch [4/5000] , Step [290/488] , Loss: 0.0321555174887180 \n",
      "Epoch [4/5000] , Step [300/488] , Loss: 0.0326108224689960 \n",
      "Epoch [4/5000] , Step [310/488] , Loss: 0.0323977842926979 \n",
      "Epoch [4/5000] , Step [320/488] , Loss: 0.0320730395615101 \n",
      "Epoch [4/5000] , Step [330/488] , Loss: 0.0322967246174812 \n",
      "Epoch [4/5000] , Step [340/488] , Loss: 0.0326351299881935 \n",
      "Epoch [4/5000] , Step [350/488] , Loss: 0.0314629450440407 \n",
      "Epoch [4/5000] , Step [360/488] , Loss: 0.0322849228978157 \n",
      "Epoch [4/5000] , Step [370/488] , Loss: 0.0332513265311718 \n",
      "Epoch [4/5000] , Step [380/488] , Loss: 0.0325882509350777 \n",
      "Epoch [4/5000] , Step [390/488] , Loss: 0.0324099920690060 \n",
      "Epoch [4/5000] , Step [400/488] , Loss: 0.0327840261161327 \n",
      "Epoch [4/5000] , Step [410/488] , Loss: 0.0331707112491131 \n",
      "Epoch [4/5000] , Step [420/488] , Loss: 0.0329124592244625 \n",
      "Epoch [4/5000] , Step [430/488] , Loss: 0.0325926132500172 \n",
      "Epoch [4/5000] , Step [440/488] , Loss: 0.0326071009039879 \n",
      "Epoch [4/5000] , Step [450/488] , Loss: 0.0328721217811108 \n",
      "Epoch [4/5000] , Step [460/488] , Loss: 0.0321694985032082 \n",
      "Epoch [4/5000] , Step [470/488] , Loss: 0.0328398384153843 \n",
      "Epoch [4/5000] , Step [480/488] , Loss: 0.0324096828699112 \n",
      "Epoch [5/5000] , Step [10/488] , Loss: 0.0325001664459705 \n",
      "Epoch [5/5000] , Step [20/488] , Loss: 0.0323800072073936 \n",
      "Epoch [5/5000] , Step [30/488] , Loss: 0.0319884568452835 \n",
      "Epoch [5/5000] , Step [40/488] , Loss: 0.0327869169414043 \n",
      "Epoch [5/5000] , Step [50/488] , Loss: 0.0328379385173321 \n",
      "Epoch [5/5000] , Step [60/488] , Loss: 0.0324104130268097 \n",
      "Epoch [5/5000] , Step [70/488] , Loss: 0.0329231619834900 \n",
      "Epoch [5/5000] , Step [80/488] , Loss: 0.0320283547043800 \n",
      "Epoch [5/5000] , Step [90/488] , Loss: 0.0325549617409706 \n",
      "Epoch [5/5000] , Step [100/488] , Loss: 0.0322960279881954 \n",
      "Epoch [5/5000] , Step [110/488] , Loss: 0.0329223759472370 \n",
      "Epoch [5/5000] , Step [120/488] , Loss: 0.0314865186810493 \n",
      "Epoch [5/5000] , Step [130/488] , Loss: 0.0324605256319046 \n",
      "Epoch [5/5000] , Step [140/488] , Loss: 0.0319624617695808 \n",
      "Epoch [5/5000] , Step [150/488] , Loss: 0.0327299274504185 \n",
      "Epoch [5/5000] , Step [160/488] , Loss: 0.0321847312152386 \n",
      "Epoch [5/5000] , Step [170/488] , Loss: 0.0320475064218044 \n",
      "Epoch [5/5000] , Step [180/488] , Loss: 0.0327144376933575 \n",
      "Epoch [5/5000] , Step [190/488] , Loss: 0.0321494899690151 \n",
      "Epoch [5/5000] , Step [200/488] , Loss: 0.0332202911376953 \n",
      "Epoch [5/5000] , Step [210/488] , Loss: 0.0321483910083771 \n",
      "Epoch [5/5000] , Step [220/488] , Loss: 0.0324038267135620 \n",
      "Epoch [5/5000] , Step [230/488] , Loss: 0.0320696197450161 \n",
      "Epoch [5/5000] , Step [240/488] , Loss: 0.0319105163216591 \n",
      "Epoch [5/5000] , Step [250/488] , Loss: 0.0326794050633907 \n",
      "Epoch [5/5000] , Step [260/488] , Loss: 0.0326681248843670 \n",
      "Epoch [5/5000] , Step [270/488] , Loss: 0.0327182039618492 \n",
      "Epoch [5/5000] , Step [280/488] , Loss: 0.0325095020234585 \n",
      "Epoch [5/5000] , Step [290/488] , Loss: 0.0328504107892513 \n",
      "Epoch [5/5000] , Step [300/488] , Loss: 0.0321235060691833 \n",
      "Epoch [5/5000] , Step [310/488] , Loss: 0.0330346375703812 \n",
      "Epoch [5/5000] , Step [320/488] , Loss: 0.0329491980373859 \n",
      "Epoch [5/5000] , Step [330/488] , Loss: 0.0325951352715492 \n",
      "Epoch [5/5000] , Step [340/488] , Loss: 0.0324475355446339 \n",
      "Epoch [5/5000] , Step [350/488] , Loss: 0.0328033454716206 \n",
      "Epoch [5/5000] , Step [360/488] , Loss: 0.0325248762965202 \n",
      "Epoch [5/5000] , Step [370/488] , Loss: 0.0322332270443439 \n",
      "Epoch [5/5000] , Step [380/488] , Loss: 0.0320735014975071 \n",
      "Epoch [5/5000] , Step [390/488] , Loss: 0.0321647264063358 \n",
      "Epoch [5/5000] , Step [400/488] , Loss: 0.0322451367974281 \n",
      "Epoch [5/5000] , Step [410/488] , Loss: 0.0328878685832024 \n",
      "Epoch [5/5000] , Step [420/488] , Loss: 0.0324231870472431 \n",
      "Epoch [5/5000] , Step [430/488] , Loss: 0.0329249426722527 \n",
      "Epoch [5/5000] , Step [440/488] , Loss: 0.0317070446908474 \n",
      "Epoch [5/5000] , Step [450/488] , Loss: 0.0323326885700226 \n",
      "Epoch [5/5000] , Step [460/488] , Loss: 0.0326496288180351 \n",
      "Epoch [5/5000] , Step [470/488] , Loss: 0.0325856953859329 \n",
      "Epoch [5/5000] , Step [480/488] , Loss: 0.0326319597661495 \n",
      "Epoch [6/5000] , Step [10/488] , Loss: 0.0320968069136143 \n",
      "Epoch [6/5000] , Step [20/488] , Loss: 0.0319285430014133 \n",
      "Epoch [6/5000] , Step [30/488] , Loss: 0.0326555967330933 \n",
      "Epoch [6/5000] , Step [40/488] , Loss: 0.0324572324752808 \n",
      "Epoch [6/5000] , Step [50/488] , Loss: 0.0319386646151543 \n",
      "Epoch [6/5000] , Step [60/488] , Loss: 0.0322986468672752 \n",
      "Epoch [6/5000] , Step [70/488] , Loss: 0.0324688479304314 \n",
      "Epoch [6/5000] , Step [80/488] , Loss: 0.0327674634754658 \n",
      "Epoch [6/5000] , Step [90/488] , Loss: 0.0330839939415455 \n",
      "Epoch [6/5000] , Step [100/488] , Loss: 0.0326685719192028 \n",
      "Epoch [6/5000] , Step [110/488] , Loss: 0.0332449488341808 \n",
      "Epoch [6/5000] , Step [120/488] , Loss: 0.0321479104459286 \n",
      "Epoch [6/5000] , Step [130/488] , Loss: 0.0328364223241806 \n",
      "Epoch [6/5000] , Step [140/488] , Loss: 0.0319854803383350 \n",
      "Epoch [6/5000] , Step [150/488] , Loss: 0.0326844900846481 \n",
      "Epoch [6/5000] , Step [160/488] , Loss: 0.0323084257543087 \n",
      "Epoch [6/5000] , Step [170/488] , Loss: 0.0326982252299786 \n",
      "Epoch [6/5000] , Step [180/488] , Loss: 0.0323628224432468 \n",
      "Epoch [6/5000] , Step [190/488] , Loss: 0.0327741131186485 \n",
      "Epoch [6/5000] , Step [200/488] , Loss: 0.0326442606747150 \n",
      "Epoch [6/5000] , Step [210/488] , Loss: 0.0334807001054287 \n",
      "Epoch [6/5000] , Step [220/488] , Loss: 0.0325976684689522 \n",
      "Epoch [6/5000] , Step [230/488] , Loss: 0.0318950489163399 \n",
      "Epoch [6/5000] , Step [240/488] , Loss: 0.0323858335614204 \n",
      "Epoch [6/5000] , Step [250/488] , Loss: 0.0328538939356804 \n",
      "Epoch [6/5000] , Step [260/488] , Loss: 0.0326680578291416 \n",
      "Epoch [6/5000] , Step [270/488] , Loss: 0.0322046577930450 \n",
      "Epoch [6/5000] , Step [280/488] , Loss: 0.0325853452086449 \n",
      "Epoch [6/5000] , Step [290/488] , Loss: 0.0327212661504745 \n",
      "Epoch [6/5000] , Step [300/488] , Loss: 0.0327630676329136 \n",
      "Epoch [6/5000] , Step [310/488] , Loss: 0.0329662598669529 \n",
      "Epoch [6/5000] , Step [320/488] , Loss: 0.0327375605702400 \n",
      "Epoch [6/5000] , Step [330/488] , Loss: 0.0325113832950592 \n",
      "Epoch [6/5000] , Step [340/488] , Loss: 0.0327917374670506 \n",
      "Epoch [6/5000] , Step [350/488] , Loss: 0.0322151258587837 \n",
      "Epoch [6/5000] , Step [360/488] , Loss: 0.0323708839714527 \n",
      "Epoch [6/5000] , Step [370/488] , Loss: 0.0330596752464771 \n",
      "Epoch [6/5000] , Step [380/488] , Loss: 0.0328831300139427 \n",
      "Epoch [6/5000] , Step [390/488] , Loss: 0.0325614623725414 \n",
      "Epoch [6/5000] , Step [400/488] , Loss: 0.0320226140320301 \n",
      "Epoch [6/5000] , Step [410/488] , Loss: 0.0327888876199722 \n",
      "Epoch [6/5000] , Step [420/488] , Loss: 0.0318556278944016 \n",
      "Epoch [6/5000] , Step [430/488] , Loss: 0.0329441390931606 \n",
      "Epoch [6/5000] , Step [440/488] , Loss: 0.0326649658381939 \n",
      "Epoch [6/5000] , Step [450/488] , Loss: 0.0329250879585743 \n",
      "Epoch [6/5000] , Step [460/488] , Loss: 0.0327217914164066 \n",
      "Epoch [6/5000] , Step [470/488] , Loss: 0.0322416312992573 \n",
      "Epoch [6/5000] , Step [480/488] , Loss: 0.0319688655436039 \n",
      "Epoch [7/5000] , Step [10/488] , Loss: 0.0323201976716518 \n",
      "Epoch [7/5000] , Step [20/488] , Loss: 0.0320881865918636 \n",
      "Epoch [7/5000] , Step [30/488] , Loss: 0.0322657637298107 \n",
      "Epoch [7/5000] , Step [40/488] , Loss: 0.0323466137051582 \n",
      "Epoch [7/5000] , Step [50/488] , Loss: 0.0326751917600632 \n",
      "Epoch [7/5000] , Step [60/488] , Loss: 0.0319394432008266 \n",
      "Epoch [7/5000] , Step [70/488] , Loss: 0.0325202420353889 \n",
      "Epoch [7/5000] , Step [80/488] , Loss: 0.0329565741121769 \n",
      "Epoch [7/5000] , Step [90/488] , Loss: 0.0325384512543678 \n",
      "Epoch [7/5000] , Step [100/488] , Loss: 0.0319375619292259 \n",
      "Epoch [7/5000] , Step [110/488] , Loss: 0.0325121283531189 \n",
      "Epoch [7/5000] , Step [120/488] , Loss: 0.0329038575291634 \n",
      "Epoch [7/5000] , Step [130/488] , Loss: 0.0325519628822803 \n",
      "Epoch [7/5000] , Step [140/488] , Loss: 0.0325160659849644 \n",
      "Epoch [7/5000] , Step [150/488] , Loss: 0.0322007760405540 \n",
      "Epoch [7/5000] , Step [160/488] , Loss: 0.0320354737341404 \n",
      "Epoch [7/5000] , Step [170/488] , Loss: 0.0323668494820595 \n",
      "Epoch [7/5000] , Step [180/488] , Loss: 0.0323815681040287 \n",
      "Epoch [7/5000] , Step [190/488] , Loss: 0.0325508601963520 \n",
      "Epoch [7/5000] , Step [200/488] , Loss: 0.0319548137485981 \n",
      "Epoch [7/5000] , Step [210/488] , Loss: 0.0321591086685658 \n",
      "Epoch [7/5000] , Step [220/488] , Loss: 0.0320517942309380 \n",
      "Epoch [7/5000] , Step [230/488] , Loss: 0.0324604287743568 \n",
      "Epoch [7/5000] , Step [240/488] , Loss: 0.0321386381983757 \n",
      "Epoch [7/5000] , Step [250/488] , Loss: 0.0322070978581905 \n",
      "Epoch [7/5000] , Step [260/488] , Loss: 0.0323735959827900 \n",
      "Epoch [7/5000] , Step [270/488] , Loss: 0.0328737050294876 \n",
      "Epoch [7/5000] , Step [280/488] , Loss: 0.0326822586357594 \n",
      "Epoch [7/5000] , Step [290/488] , Loss: 0.0326384790241718 \n",
      "Epoch [7/5000] , Step [300/488] , Loss: 0.0327986702322960 \n",
      "Epoch [7/5000] , Step [310/488] , Loss: 0.0326104946434498 \n",
      "Epoch [7/5000] , Step [320/488] , Loss: 0.0329372249543667 \n",
      "Epoch [7/5000] , Step [330/488] , Loss: 0.0321783348917961 \n",
      "Epoch [7/5000] , Step [340/488] , Loss: 0.0324278883635998 \n",
      "Epoch [7/5000] , Step [350/488] , Loss: 0.0328719653189182 \n",
      "Epoch [7/5000] , Step [360/488] , Loss: 0.0322825722396374 \n",
      "Epoch [7/5000] , Step [370/488] , Loss: 0.0326672159135342 \n",
      "Epoch [7/5000] , Step [380/488] , Loss: 0.0324389599263668 \n",
      "Epoch [7/5000] , Step [390/488] , Loss: 0.0325691886246204 \n",
      "Epoch [7/5000] , Step [400/488] , Loss: 0.0325670428574085 \n",
      "Epoch [7/5000] , Step [410/488] , Loss: 0.0326629206538200 \n",
      "Epoch [7/5000] , Step [420/488] , Loss: 0.0328870341181755 \n",
      "Epoch [7/5000] , Step [430/488] , Loss: 0.0319110862910748 \n",
      "Epoch [7/5000] , Step [440/488] , Loss: 0.0331415608525276 \n",
      "Epoch [7/5000] , Step [450/488] , Loss: 0.0332585722208023 \n",
      "Epoch [7/5000] , Step [460/488] , Loss: 0.0318742319941521 \n",
      "Epoch [7/5000] , Step [470/488] , Loss: 0.0321985594928265 \n",
      "Epoch [7/5000] , Step [480/488] , Loss: 0.0324844792485237 \n",
      "Epoch [8/5000] , Step [10/488] , Loss: 0.0324959009885788 \n",
      "Epoch [8/5000] , Step [20/488] , Loss: 0.0332497172057629 \n",
      "Epoch [8/5000] , Step [30/488] , Loss: 0.0332144312560558 \n",
      "Epoch [8/5000] , Step [40/488] , Loss: 0.0329588875174522 \n",
      "Epoch [8/5000] , Step [50/488] , Loss: 0.0324244610965252 \n",
      "Epoch [8/5000] , Step [60/488] , Loss: 0.0324637554585934 \n",
      "Epoch [8/5000] , Step [70/488] , Loss: 0.0322094634175301 \n",
      "Epoch [8/5000] , Step [80/488] , Loss: 0.0322348959743977 \n",
      "Epoch [8/5000] , Step [90/488] , Loss: 0.0325740166008472 \n",
      "Epoch [8/5000] , Step [100/488] , Loss: 0.0325457714498043 \n",
      "Epoch [8/5000] , Step [110/488] , Loss: 0.0329581052064896 \n",
      "Epoch [8/5000] , Step [120/488] , Loss: 0.0331518501043320 \n",
      "Epoch [8/5000] , Step [130/488] , Loss: 0.0330004580318928 \n",
      "Epoch [8/5000] , Step [140/488] , Loss: 0.0325437784194946 \n",
      "Epoch [8/5000] , Step [150/488] , Loss: 0.0324753746390343 \n",
      "Epoch [8/5000] , Step [160/488] , Loss: 0.0325612984597683 \n",
      "Epoch [8/5000] , Step [170/488] , Loss: 0.0331586673855782 \n",
      "Epoch [8/5000] , Step [180/488] , Loss: 0.0324772819876671 \n",
      "Epoch [8/5000] , Step [190/488] , Loss: 0.0324510112404823 \n",
      "Epoch [8/5000] , Step [200/488] , Loss: 0.0320204421877861 \n",
      "Epoch [8/5000] , Step [210/488] , Loss: 0.0325619280338287 \n",
      "Epoch [8/5000] , Step [220/488] , Loss: 0.0326149314641953 \n",
      "Epoch [8/5000] , Step [230/488] , Loss: 0.0324865505099297 \n",
      "Epoch [8/5000] , Step [240/488] , Loss: 0.0328518822789192 \n",
      "Epoch [8/5000] , Step [250/488] , Loss: 0.0320302397012711 \n",
      "Epoch [8/5000] , Step [260/488] , Loss: 0.0322603732347488 \n",
      "Epoch [8/5000] , Step [270/488] , Loss: 0.0321845114231110 \n",
      "Epoch [8/5000] , Step [280/488] , Loss: 0.0332347638905048 \n",
      "Epoch [8/5000] , Step [290/488] , Loss: 0.0324823707342148 \n",
      "Epoch [8/5000] , Step [300/488] , Loss: 0.0326057933270931 \n",
      "Epoch [8/5000] , Step [310/488] , Loss: 0.0328385382890701 \n",
      "Epoch [8/5000] , Step [320/488] , Loss: 0.0326696187257767 \n",
      "Epoch [8/5000] , Step [330/488] , Loss: 0.0322443991899490 \n",
      "Epoch [8/5000] , Step [340/488] , Loss: 0.0324496924877167 \n",
      "Epoch [8/5000] , Step [350/488] , Loss: 0.0322356894612312 \n",
      "Epoch [8/5000] , Step [360/488] , Loss: 0.0319721624255180 \n",
      "Epoch [8/5000] , Step [370/488] , Loss: 0.0325981602072716 \n",
      "Epoch [8/5000] , Step [380/488] , Loss: 0.0324792340397835 \n",
      "Epoch [8/5000] , Step [390/488] , Loss: 0.0326208584010601 \n",
      "Epoch [8/5000] , Step [400/488] , Loss: 0.0325074121356010 \n",
      "Epoch [8/5000] , Step [410/488] , Loss: 0.0333362370729446 \n",
      "Epoch [8/5000] , Step [420/488] , Loss: 0.0327460914850235 \n",
      "Epoch [8/5000] , Step [430/488] , Loss: 0.0320635698735714 \n",
      "Epoch [8/5000] , Step [440/488] , Loss: 0.0327795445919037 \n",
      "Epoch [8/5000] , Step [450/488] , Loss: 0.0325044877827168 \n",
      "Epoch [8/5000] , Step [460/488] , Loss: 0.0321207717061043 \n",
      "Epoch [8/5000] , Step [470/488] , Loss: 0.0321340374648571 \n",
      "Epoch [8/5000] , Step [480/488] , Loss: 0.0323281474411488 \n",
      "Epoch [9/5000] , Step [10/488] , Loss: 0.0323435552418232 \n",
      "Epoch [9/5000] , Step [20/488] , Loss: 0.0321104973554611 \n",
      "Epoch [9/5000] , Step [30/488] , Loss: 0.0322988256812096 \n",
      "Epoch [9/5000] , Step [40/488] , Loss: 0.0324027650058270 \n",
      "Epoch [9/5000] , Step [50/488] , Loss: 0.0327764526009560 \n",
      "Epoch [9/5000] , Step [60/488] , Loss: 0.0330307185649872 \n",
      "Epoch [9/5000] , Step [70/488] , Loss: 0.0330283865332603 \n",
      "Epoch [9/5000] , Step [80/488] , Loss: 0.0327612496912479 \n",
      "Epoch [9/5000] , Step [90/488] , Loss: 0.0327610373497009 \n",
      "Epoch [9/5000] , Step [100/488] , Loss: 0.0319148488342762 \n",
      "Epoch [9/5000] , Step [110/488] , Loss: 0.0325896516442299 \n",
      "Epoch [9/5000] , Step [120/488] , Loss: 0.0318847149610519 \n",
      "Epoch [9/5000] , Step [130/488] , Loss: 0.0326056964695454 \n",
      "Epoch [9/5000] , Step [140/488] , Loss: 0.0327094234526157 \n",
      "Epoch [9/5000] , Step [150/488] , Loss: 0.0324116647243500 \n",
      "Epoch [9/5000] , Step [160/488] , Loss: 0.0321477390825748 \n",
      "Epoch [9/5000] , Step [170/488] , Loss: 0.0327872261404991 \n",
      "Epoch [9/5000] , Step [180/488] , Loss: 0.0327527076005936 \n",
      "Epoch [9/5000] , Step [190/488] , Loss: 0.0327992849051952 \n",
      "Epoch [9/5000] , Step [200/488] , Loss: 0.0326056629419327 \n",
      "Epoch [9/5000] , Step [210/488] , Loss: 0.0326473638415337 \n",
      "Epoch [9/5000] , Step [220/488] , Loss: 0.0327710993587971 \n",
      "Epoch [9/5000] , Step [230/488] , Loss: 0.0329269319772720 \n",
      "Epoch [9/5000] , Step [240/488] , Loss: 0.0320338793098927 \n",
      "Epoch [9/5000] , Step [250/488] , Loss: 0.0321588553488255 \n",
      "Epoch [9/5000] , Step [260/488] , Loss: 0.0328709594905376 \n",
      "Epoch [9/5000] , Step [270/488] , Loss: 0.0326986089348793 \n",
      "Epoch [9/5000] , Step [280/488] , Loss: 0.0319526270031929 \n",
      "Epoch [9/5000] , Step [290/488] , Loss: 0.0327416509389877 \n",
      "Epoch [9/5000] , Step [300/488] , Loss: 0.0318416990339756 \n",
      "Epoch [9/5000] , Step [310/488] , Loss: 0.0325195118784904 \n",
      "Epoch [9/5000] , Step [320/488] , Loss: 0.0327015295624733 \n",
      "Epoch [9/5000] , Step [330/488] , Loss: 0.0317146033048630 \n",
      "Epoch [9/5000] , Step [340/488] , Loss: 0.0330625921487808 \n",
      "Epoch [9/5000] , Step [350/488] , Loss: 0.0327023081481457 \n",
      "Epoch [9/5000] , Step [360/488] , Loss: 0.0325876399874687 \n",
      "Epoch [9/5000] , Step [370/488] , Loss: 0.0324014574289322 \n",
      "Epoch [9/5000] , Step [380/488] , Loss: 0.0324896611273289 \n",
      "Epoch [9/5000] , Step [390/488] , Loss: 0.0324634872376919 \n",
      "Epoch [9/5000] , Step [400/488] , Loss: 0.0322424359619617 \n",
      "Epoch [9/5000] , Step [410/488] , Loss: 0.0325944088399410 \n",
      "Epoch [9/5000] , Step [420/488] , Loss: 0.0327703468501568 \n",
      "Epoch [9/5000] , Step [430/488] , Loss: 0.0323516279459000 \n",
      "Epoch [9/5000] , Step [440/488] , Loss: 0.0329934284090996 \n",
      "Epoch [9/5000] , Step [450/488] , Loss: 0.0325718000531197 \n",
      "Epoch [9/5000] , Step [460/488] , Loss: 0.0321277379989624 \n",
      "Epoch [9/5000] , Step [470/488] , Loss: 0.0325410626828671 \n",
      "Epoch [9/5000] , Step [480/488] , Loss: 0.0330806225538254 \n",
      "Epoch [10/5000] , Step [10/488] , Loss: 0.0323669165372849 \n",
      "Epoch [10/5000] , Step [20/488] , Loss: 0.0327855274081230 \n",
      "Epoch [10/5000] , Step [30/488] , Loss: 0.0323769636452198 \n",
      "Epoch [10/5000] , Step [40/488] , Loss: 0.0321674421429634 \n",
      "Epoch [10/5000] , Step [50/488] , Loss: 0.0329397432506084 \n",
      "Epoch [10/5000] , Step [60/488] , Loss: 0.0330669283866882 \n",
      "Epoch [10/5000] , Step [70/488] , Loss: 0.0324870385229588 \n",
      "Epoch [10/5000] , Step [80/488] , Loss: 0.0323037989437580 \n",
      "Epoch [10/5000] , Step [90/488] , Loss: 0.0326420515775681 \n",
      "Epoch [10/5000] , Step [100/488] , Loss: 0.0328944958746433 \n",
      "Epoch [10/5000] , Step [110/488] , Loss: 0.0322991535067558 \n",
      "Epoch [10/5000] , Step [120/488] , Loss: 0.0324986577033997 \n",
      "Epoch [10/5000] , Step [130/488] , Loss: 0.0323033034801483 \n",
      "Epoch [10/5000] , Step [140/488] , Loss: 0.0328043997287750 \n",
      "Epoch [10/5000] , Step [150/488] , Loss: 0.0323594659566879 \n",
      "Epoch [10/5000] , Step [160/488] , Loss: 0.0331596359610558 \n",
      "Epoch [10/5000] , Step [170/488] , Loss: 0.0333521701395512 \n",
      "Epoch [10/5000] , Step [180/488] , Loss: 0.0325407087802887 \n",
      "Epoch [10/5000] , Step [190/488] , Loss: 0.0328577421605587 \n",
      "Epoch [10/5000] , Step [200/488] , Loss: 0.0330923274159431 \n",
      "Epoch [10/5000] , Step [210/488] , Loss: 0.0322218500077724 \n",
      "Epoch [10/5000] , Step [220/488] , Loss: 0.0325595028698444 \n",
      "Epoch [10/5000] , Step [230/488] , Loss: 0.0322670713067055 \n",
      "Epoch [10/5000] , Step [240/488] , Loss: 0.0321448519825935 \n",
      "Epoch [10/5000] , Step [250/488] , Loss: 0.0331163592636585 \n",
      "Epoch [10/5000] , Step [260/488] , Loss: 0.0322382301092148 \n",
      "Epoch [10/5000] , Step [270/488] , Loss: 0.0327995307743549 \n",
      "Epoch [10/5000] , Step [280/488] , Loss: 0.0325377285480499 \n",
      "Epoch [10/5000] , Step [290/488] , Loss: 0.0326064340770245 \n",
      "Epoch [10/5000] , Step [300/488] , Loss: 0.0330605953931808 \n",
      "Epoch [10/5000] , Step [310/488] , Loss: 0.0328755863010883 \n",
      "Epoch [10/5000] , Step [320/488] , Loss: 0.0320715717971325 \n",
      "Epoch [10/5000] , Step [330/488] , Loss: 0.0320963338017464 \n",
      "Epoch [10/5000] , Step [340/488] , Loss: 0.0321913622319698 \n",
      "Epoch [10/5000] , Step [350/488] , Loss: 0.0321273058652878 \n",
      "Epoch [10/5000] , Step [360/488] , Loss: 0.0320301689207554 \n",
      "Epoch [10/5000] , Step [370/488] , Loss: 0.0320033058524132 \n",
      "Epoch [10/5000] , Step [380/488] , Loss: 0.0323897227644920 \n",
      "Epoch [10/5000] , Step [390/488] , Loss: 0.0324550680816174 \n",
      "Epoch [10/5000] , Step [400/488] , Loss: 0.0332522317767143 \n",
      "Epoch [10/5000] , Step [410/488] , Loss: 0.0320710465312004 \n",
      "Epoch [10/5000] , Step [420/488] , Loss: 0.0323460400104523 \n",
      "Epoch [10/5000] , Step [430/488] , Loss: 0.0327538214623928 \n",
      "Epoch [10/5000] , Step [440/488] , Loss: 0.0324901901185513 \n",
      "Epoch [10/5000] , Step [450/488] , Loss: 0.0328427031636238 \n",
      "Epoch [10/5000] , Step [460/488] , Loss: 0.0329333841800690 \n",
      "Epoch [10/5000] , Step [470/488] , Loss: 0.0325318984687328 \n",
      "Epoch [10/5000] , Step [480/488] , Loss: 0.0327039323747158 \n",
      "Epoch [11/5000] , Step [10/488] , Loss: 0.0330244675278664 \n",
      "Epoch [11/5000] , Step [20/488] , Loss: 0.0322019681334496 \n",
      "Epoch [11/5000] , Step [30/488] , Loss: 0.0328062362968922 \n",
      "Epoch [11/5000] , Step [40/488] , Loss: 0.0331760495901108 \n",
      "Epoch [11/5000] , Step [50/488] , Loss: 0.0322389379143715 \n",
      "Epoch [11/5000] , Step [60/488] , Loss: 0.0329163745045662 \n",
      "Epoch [11/5000] , Step [70/488] , Loss: 0.0329270884394646 \n",
      "Epoch [11/5000] , Step [80/488] , Loss: 0.0322983339428902 \n",
      "Epoch [11/5000] , Step [90/488] , Loss: 0.0325222276151180 \n",
      "Epoch [11/5000] , Step [100/488] , Loss: 0.0326577015221119 \n",
      "Epoch [11/5000] , Step [110/488] , Loss: 0.0319847166538239 \n",
      "Epoch [11/5000] , Step [120/488] , Loss: 0.0325954407453537 \n",
      "Epoch [11/5000] , Step [130/488] , Loss: 0.0323016457259655 \n",
      "Epoch [11/5000] , Step [140/488] , Loss: 0.0326769128441811 \n",
      "Epoch [11/5000] , Step [150/488] , Loss: 0.0323175191879272 \n",
      "Epoch [11/5000] , Step [160/488] , Loss: 0.0321148186922073 \n",
      "Epoch [11/5000] , Step [170/488] , Loss: 0.0320367589592934 \n",
      "Epoch [11/5000] , Step [180/488] , Loss: 0.0329245589673519 \n",
      "Epoch [11/5000] , Step [190/488] , Loss: 0.0328848250210285 \n",
      "Epoch [11/5000] , Step [200/488] , Loss: 0.0326117761433125 \n",
      "Epoch [11/5000] , Step [210/488] , Loss: 0.0327752567827702 \n",
      "Epoch [11/5000] , Step [220/488] , Loss: 0.0332230962812901 \n",
      "Epoch [11/5000] , Step [230/488] , Loss: 0.0327141992747784 \n",
      "Epoch [11/5000] , Step [240/488] , Loss: 0.0323214344680309 \n",
      "Epoch [11/5000] , Step [250/488] , Loss: 0.0318591408431530 \n",
      "Epoch [11/5000] , Step [260/488] , Loss: 0.0325948335230350 \n",
      "Epoch [11/5000] , Step [270/488] , Loss: 0.0320304520428181 \n",
      "Epoch [11/5000] , Step [280/488] , Loss: 0.0326272696256638 \n",
      "Epoch [11/5000] , Step [290/488] , Loss: 0.0325437262654305 \n",
      "Epoch [11/5000] , Step [300/488] , Loss: 0.0325657427310944 \n",
      "Epoch [11/5000] , Step [310/488] , Loss: 0.0330084040760994 \n",
      "Epoch [11/5000] , Step [320/488] , Loss: 0.0321845710277557 \n",
      "Epoch [11/5000] , Step [330/488] , Loss: 0.0325632207095623 \n",
      "Epoch [11/5000] , Step [340/488] , Loss: 0.0320792905986309 \n",
      "Epoch [11/5000] , Step [350/488] , Loss: 0.0321400463581085 \n",
      "Epoch [11/5000] , Step [360/488] , Loss: 0.0323459729552269 \n",
      "Epoch [11/5000] , Step [370/488] , Loss: 0.0325547009706497 \n",
      "Epoch [11/5000] , Step [380/488] , Loss: 0.0326733812689781 \n",
      "Epoch [11/5000] , Step [390/488] , Loss: 0.0323021262884140 \n",
      "Epoch [11/5000] , Step [400/488] , Loss: 0.0325579792261124 \n",
      "Epoch [11/5000] , Step [410/488] , Loss: 0.0326345711946487 \n",
      "Epoch [11/5000] , Step [420/488] , Loss: 0.0329839698970318 \n",
      "Epoch [11/5000] , Step [430/488] , Loss: 0.0328221246600151 \n",
      "Epoch [11/5000] , Step [440/488] , Loss: 0.0325556583702564 \n",
      "Epoch [11/5000] , Step [450/488] , Loss: 0.0320922061800957 \n",
      "Epoch [11/5000] , Step [460/488] , Loss: 0.0331250689923763 \n",
      "Epoch [11/5000] , Step [470/488] , Loss: 0.0323564335703850 \n",
      "Epoch [11/5000] , Step [480/488] , Loss: 0.0325199551880360 \n",
      "Epoch [12/5000] , Step [10/488] , Loss: 0.0324921086430550 \n",
      "Epoch [12/5000] , Step [20/488] , Loss: 0.0322044417262077 \n",
      "Epoch [12/5000] , Step [30/488] , Loss: 0.0322497412562370 \n",
      "Epoch [12/5000] , Step [40/488] , Loss: 0.0326890572905540 \n",
      "Epoch [12/5000] , Step [50/488] , Loss: 0.0323853008449078 \n",
      "Epoch [12/5000] , Step [60/488] , Loss: 0.0321873426437378 \n",
      "Epoch [12/5000] , Step [70/488] , Loss: 0.0328786410391331 \n",
      "Epoch [12/5000] , Step [80/488] , Loss: 0.0326257981359959 \n",
      "Epoch [12/5000] , Step [90/488] , Loss: 0.0324447117745876 \n",
      "Epoch [12/5000] , Step [100/488] , Loss: 0.0325566530227661 \n",
      "Epoch [12/5000] , Step [110/488] , Loss: 0.0329198315739632 \n",
      "Epoch [12/5000] , Step [120/488] , Loss: 0.0331526957452297 \n",
      "Epoch [12/5000] , Step [130/488] , Loss: 0.0326863601803780 \n",
      "Epoch [12/5000] , Step [140/488] , Loss: 0.0325406678020954 \n",
      "Epoch [12/5000] , Step [150/488] , Loss: 0.0322796106338501 \n",
      "Epoch [12/5000] , Step [160/488] , Loss: 0.0329191721975803 \n",
      "Epoch [12/5000] , Step [170/488] , Loss: 0.0330273732542992 \n",
      "Epoch [12/5000] , Step [180/488] , Loss: 0.0323537625372410 \n",
      "Epoch [12/5000] , Step [190/488] , Loss: 0.0320864021778107 \n",
      "Epoch [12/5000] , Step [200/488] , Loss: 0.0326628684997559 \n",
      "Epoch [12/5000] , Step [210/488] , Loss: 0.0325480625033379 \n",
      "Epoch [12/5000] , Step [220/488] , Loss: 0.0330132097005844 \n",
      "Epoch [12/5000] , Step [230/488] , Loss: 0.0325771719217300 \n",
      "Epoch [12/5000] , Step [240/488] , Loss: 0.0321304760873318 \n",
      "Epoch [12/5000] , Step [250/488] , Loss: 0.0324110053479671 \n",
      "Epoch [12/5000] , Step [260/488] , Loss: 0.0326388478279114 \n",
      "Epoch [12/5000] , Step [270/488] , Loss: 0.0333041660487652 \n",
      "Epoch [12/5000] , Step [280/488] , Loss: 0.0328230373561382 \n",
      "Epoch [12/5000] , Step [290/488] , Loss: 0.0324294157326221 \n",
      "Epoch [12/5000] , Step [300/488] , Loss: 0.0332554690539837 \n",
      "Epoch [12/5000] , Step [310/488] , Loss: 0.0327475368976593 \n",
      "Epoch [12/5000] , Step [320/488] , Loss: 0.0327762849628925 \n",
      "Epoch [12/5000] , Step [330/488] , Loss: 0.0326882675290108 \n",
      "Epoch [12/5000] , Step [340/488] , Loss: 0.0324889309704304 \n",
      "Epoch [12/5000] , Step [350/488] , Loss: 0.0322998724877834 \n",
      "Epoch [12/5000] , Step [360/488] , Loss: 0.0326925031840801 \n",
      "Epoch [12/5000] , Step [370/488] , Loss: 0.0325070731341839 \n",
      "Epoch [12/5000] , Step [380/488] , Loss: 0.0319159701466560 \n",
      "Epoch [12/5000] , Step [390/488] , Loss: 0.0328021124005318 \n",
      "Epoch [12/5000] , Step [400/488] , Loss: 0.0326699204742908 \n",
      "Epoch [12/5000] , Step [410/488] , Loss: 0.0329339504241943 \n",
      "Epoch [12/5000] , Step [420/488] , Loss: 0.0328105688095093 \n",
      "Epoch [12/5000] , Step [430/488] , Loss: 0.0326319970190525 \n",
      "Epoch [12/5000] , Step [440/488] , Loss: 0.0321319773793221 \n",
      "Epoch [12/5000] , Step [450/488] , Loss: 0.0334032960236073 \n",
      "Epoch [12/5000] , Step [460/488] , Loss: 0.0327573046088219 \n",
      "Epoch [12/5000] , Step [470/488] , Loss: 0.0319042503833771 \n",
      "Epoch [12/5000] , Step [480/488] , Loss: 0.0327343828976154 \n",
      "Epoch [13/5000] , Step [10/488] , Loss: 0.0325124561786652 \n",
      "Epoch [13/5000] , Step [20/488] , Loss: 0.0329397208988667 \n",
      "Epoch [13/5000] , Step [30/488] , Loss: 0.0330165363848209 \n",
      "Epoch [13/5000] , Step [40/488] , Loss: 0.0325071178376675 \n",
      "Epoch [13/5000] , Step [50/488] , Loss: 0.0324831418693066 \n",
      "Epoch [13/5000] , Step [60/488] , Loss: 0.0324205607175827 \n",
      "Epoch [13/5000] , Step [70/488] , Loss: 0.0317981615662575 \n",
      "Epoch [13/5000] , Step [80/488] , Loss: 0.0327723026275635 \n",
      "Epoch [13/5000] , Step [90/488] , Loss: 0.0326978899538517 \n",
      "Epoch [13/5000] , Step [100/488] , Loss: 0.0327034704387188 \n",
      "Epoch [13/5000] , Step [110/488] , Loss: 0.0324926450848579 \n",
      "Epoch [13/5000] , Step [120/488] , Loss: 0.0321482233703136 \n",
      "Epoch [13/5000] , Step [130/488] , Loss: 0.0325072631239891 \n",
      "Epoch [13/5000] , Step [140/488] , Loss: 0.0328132994472980 \n",
      "Epoch [13/5000] , Step [150/488] , Loss: 0.0324991047382355 \n",
      "Epoch [13/5000] , Step [160/488] , Loss: 0.0325595512986183 \n",
      "Epoch [13/5000] , Step [170/488] , Loss: 0.0325082950294018 \n",
      "Epoch [13/5000] , Step [180/488] , Loss: 0.0325618386268616 \n",
      "Epoch [13/5000] , Step [190/488] , Loss: 0.0327409133315086 \n",
      "Epoch [13/5000] , Step [200/488] , Loss: 0.0327606983482838 \n",
      "Epoch [13/5000] , Step [210/488] , Loss: 0.0325603708624840 \n",
      "Epoch [13/5000] , Step [220/488] , Loss: 0.0325631126761436 \n",
      "Epoch [13/5000] , Step [230/488] , Loss: 0.0327041447162628 \n",
      "Epoch [13/5000] , Step [240/488] , Loss: 0.0329569093883038 \n",
      "Epoch [13/5000] , Step [250/488] , Loss: 0.0323319882154465 \n",
      "Epoch [13/5000] , Step [260/488] , Loss: 0.0324612669646740 \n",
      "Epoch [13/5000] , Step [270/488] , Loss: 0.0325002595782280 \n",
      "Epoch [13/5000] , Step [280/488] , Loss: 0.0331599600613117 \n",
      "Epoch [13/5000] , Step [290/488] , Loss: 0.0322659797966480 \n",
      "Epoch [13/5000] , Step [300/488] , Loss: 0.0322139821946621 \n",
      "Epoch [13/5000] , Step [310/488] , Loss: 0.0323690325021744 \n",
      "Epoch [13/5000] , Step [320/488] , Loss: 0.0328994393348694 \n",
      "Epoch [13/5000] , Step [330/488] , Loss: 0.0320577025413513 \n",
      "Epoch [13/5000] , Step [340/488] , Loss: 0.0319611243903637 \n",
      "Epoch [13/5000] , Step [350/488] , Loss: 0.0326425321400166 \n",
      "Epoch [13/5000] , Step [360/488] , Loss: 0.0329512432217598 \n",
      "Epoch [13/5000] , Step [370/488] , Loss: 0.0323863290250301 \n",
      "Epoch [13/5000] , Step [380/488] , Loss: 0.0323465578258038 \n",
      "Epoch [13/5000] , Step [390/488] , Loss: 0.0325792022049427 \n",
      "Epoch [13/5000] , Step [400/488] , Loss: 0.0326423346996307 \n",
      "Epoch [13/5000] , Step [410/488] , Loss: 0.0325556099414825 \n",
      "Epoch [13/5000] , Step [420/488] , Loss: 0.0323520824313164 \n",
      "Epoch [13/5000] , Step [430/488] , Loss: 0.0327655151486397 \n",
      "Epoch [13/5000] , Step [440/488] , Loss: 0.0329556055366993 \n",
      "Epoch [13/5000] , Step [450/488] , Loss: 0.0321986451745033 \n",
      "Epoch [13/5000] , Step [460/488] , Loss: 0.0321707352995872 \n",
      "Epoch [13/5000] , Step [470/488] , Loss: 0.0320410504937172 \n",
      "Epoch [13/5000] , Step [480/488] , Loss: 0.0330299846827984 \n",
      "Epoch [14/5000] , Step [10/488] , Loss: 0.0322736948728561 \n",
      "Epoch [14/5000] , Step [20/488] , Loss: 0.0322918146848679 \n",
      "Epoch [14/5000] , Step [30/488] , Loss: 0.0330951586365700 \n",
      "Epoch [14/5000] , Step [40/488] , Loss: 0.0326568074524403 \n",
      "Epoch [14/5000] , Step [50/488] , Loss: 0.0325746461749077 \n",
      "Epoch [14/5000] , Step [60/488] , Loss: 0.0319672077894211 \n",
      "Epoch [14/5000] , Step [70/488] , Loss: 0.0326869711279869 \n",
      "Epoch [14/5000] , Step [80/488] , Loss: 0.0324386656284332 \n",
      "Epoch [14/5000] , Step [90/488] , Loss: 0.0319731496274471 \n",
      "Epoch [14/5000] , Step [100/488] , Loss: 0.0322845205664635 \n",
      "Epoch [14/5000] , Step [110/488] , Loss: 0.0327058024704456 \n",
      "Epoch [14/5000] , Step [120/488] , Loss: 0.0332121998071671 \n",
      "Epoch [14/5000] , Step [130/488] , Loss: 0.0318345874547958 \n",
      "Epoch [14/5000] , Step [140/488] , Loss: 0.0328504629433155 \n",
      "Epoch [14/5000] , Step [150/488] , Loss: 0.0319324098527431 \n",
      "Epoch [14/5000] , Step [160/488] , Loss: 0.0326579958200455 \n",
      "Epoch [14/5000] , Step [170/488] , Loss: 0.0329605303704739 \n",
      "Epoch [14/5000] , Step [180/488] , Loss: 0.0331181623041630 \n",
      "Epoch [14/5000] , Step [190/488] , Loss: 0.0323340632021427 \n",
      "Epoch [14/5000] , Step [200/488] , Loss: 0.0322378017008305 \n",
      "Epoch [14/5000] , Step [210/488] , Loss: 0.0327154584228992 \n",
      "Epoch [14/5000] , Step [220/488] , Loss: 0.0325337499380112 \n",
      "Epoch [14/5000] , Step [230/488] , Loss: 0.0322695299983025 \n",
      "Epoch [14/5000] , Step [240/488] , Loss: 0.0330782793462276 \n",
      "Epoch [14/5000] , Step [250/488] , Loss: 0.0329168066382408 \n",
      "Epoch [14/5000] , Step [260/488] , Loss: 0.0324202105402946 \n",
      "Epoch [14/5000] , Step [270/488] , Loss: 0.0321936234831810 \n",
      "Epoch [14/5000] , Step [280/488] , Loss: 0.0333015322685242 \n",
      "Epoch [14/5000] , Step [290/488] , Loss: 0.0328221134841442 \n",
      "Epoch [14/5000] , Step [300/488] , Loss: 0.0326271764934063 \n",
      "Epoch [14/5000] , Step [310/488] , Loss: 0.0323102548718452 \n",
      "Epoch [14/5000] , Step [320/488] , Loss: 0.0327143408358097 \n",
      "Epoch [14/5000] , Step [330/488] , Loss: 0.0319501422345638 \n",
      "Epoch [14/5000] , Step [340/488] , Loss: 0.0326580516993999 \n",
      "Epoch [14/5000] , Step [350/488] , Loss: 0.0323383063077927 \n",
      "Epoch [14/5000] , Step [360/488] , Loss: 0.0332623571157455 \n",
      "Epoch [14/5000] , Step [370/488] , Loss: 0.0321886204183102 \n",
      "Epoch [14/5000] , Step [380/488] , Loss: 0.0324928797781467 \n",
      "Epoch [14/5000] , Step [390/488] , Loss: 0.0322712734341621 \n",
      "Epoch [14/5000] , Step [400/488] , Loss: 0.0330485329031944 \n",
      "Epoch [14/5000] , Step [410/488] , Loss: 0.0334195792675018 \n",
      "Epoch [14/5000] , Step [420/488] , Loss: 0.0332671292126179 \n",
      "Epoch [14/5000] , Step [430/488] , Loss: 0.0329475365579128 \n",
      "Epoch [14/5000] , Step [440/488] , Loss: 0.0327225439250469 \n",
      "Epoch [14/5000] , Step [450/488] , Loss: 0.0331320501863956 \n",
      "Epoch [14/5000] , Step [460/488] , Loss: 0.0325682088732719 \n",
      "Epoch [14/5000] , Step [470/488] , Loss: 0.0330450683832169 \n",
      "Epoch [14/5000] , Step [480/488] , Loss: 0.0325148850679398 \n",
      "Epoch [15/5000] , Step [10/488] , Loss: 0.0317464917898178 \n",
      "Epoch [15/5000] , Step [20/488] , Loss: 0.0314409285783768 \n",
      "Epoch [15/5000] , Step [30/488] , Loss: 0.0320504978299141 \n",
      "Epoch [15/5000] , Step [40/488] , Loss: 0.0324283279478550 \n",
      "Epoch [15/5000] , Step [50/488] , Loss: 0.0323259010910988 \n",
      "Epoch [15/5000] , Step [60/488] , Loss: 0.0321656726300716 \n",
      "Epoch [15/5000] , Step [70/488] , Loss: 0.0324987620115280 \n",
      "Epoch [15/5000] , Step [80/488] , Loss: 0.0327345952391624 \n",
      "Epoch [15/5000] , Step [90/488] , Loss: 0.0321764051914215 \n",
      "Epoch [15/5000] , Step [100/488] , Loss: 0.0330138280987740 \n",
      "Epoch [15/5000] , Step [110/488] , Loss: 0.0321345776319504 \n",
      "Epoch [15/5000] , Step [120/488] , Loss: 0.0327039547264576 \n",
      "Epoch [15/5000] , Step [130/488] , Loss: 0.0320389866828918 \n",
      "Epoch [15/5000] , Step [140/488] , Loss: 0.0323342904448509 \n",
      "Epoch [15/5000] , Step [150/488] , Loss: 0.0320375151932240 \n",
      "Epoch [15/5000] , Step [160/488] , Loss: 0.0325960069894791 \n",
      "Epoch [15/5000] , Step [170/488] , Loss: 0.0328448414802551 \n",
      "Epoch [15/5000] , Step [180/488] , Loss: 0.0330785736441612 \n",
      "Epoch [15/5000] , Step [190/488] , Loss: 0.0322733372449875 \n",
      "Epoch [15/5000] , Step [200/488] , Loss: 0.0318615958094597 \n",
      "Epoch [15/5000] , Step [210/488] , Loss: 0.0325662381947041 \n",
      "Epoch [15/5000] , Step [220/488] , Loss: 0.0321147665381432 \n",
      "Epoch [15/5000] , Step [230/488] , Loss: 0.0323403440415859 \n",
      "Epoch [15/5000] , Step [240/488] , Loss: 0.0322400815784931 \n",
      "Epoch [15/5000] , Step [250/488] , Loss: 0.0326183848083019 \n",
      "Epoch [15/5000] , Step [260/488] , Loss: 0.0323107056319714 \n",
      "Epoch [15/5000] , Step [270/488] , Loss: 0.0320147909224033 \n",
      "Epoch [15/5000] , Step [280/488] , Loss: 0.0327980816364288 \n",
      "Epoch [15/5000] , Step [290/488] , Loss: 0.0320927128195763 \n",
      "Epoch [15/5000] , Step [300/488] , Loss: 0.0327352806925774 \n",
      "Epoch [15/5000] , Step [310/488] , Loss: 0.0317380018532276 \n",
      "Epoch [15/5000] , Step [320/488] , Loss: 0.0323270522058010 \n",
      "Epoch [15/5000] , Step [330/488] , Loss: 0.0328839197754860 \n",
      "Epoch [15/5000] , Step [340/488] , Loss: 0.0323285944759846 \n",
      "Epoch [15/5000] , Step [350/488] , Loss: 0.0323872454464436 \n",
      "Epoch [15/5000] , Step [360/488] , Loss: 0.0327947735786438 \n",
      "Epoch [15/5000] , Step [370/488] , Loss: 0.0324828810989857 \n",
      "Epoch [15/5000] , Step [380/488] , Loss: 0.0319655276834965 \n",
      "Epoch [15/5000] , Step [390/488] , Loss: 0.0326482690870762 \n",
      "Epoch [15/5000] , Step [400/488] , Loss: 0.0322582609951496 \n",
      "Epoch [15/5000] , Step [410/488] , Loss: 0.0327168777585030 \n",
      "Epoch [15/5000] , Step [420/488] , Loss: 0.0323401317000389 \n",
      "Epoch [15/5000] , Step [430/488] , Loss: 0.0329914242029190 \n",
      "Epoch [15/5000] , Step [440/488] , Loss: 0.0322632007300854 \n",
      "Epoch [15/5000] , Step [450/488] , Loss: 0.0322189480066299 \n",
      "Epoch [15/5000] , Step [460/488] , Loss: 0.0320813991129398 \n",
      "Epoch [15/5000] , Step [470/488] , Loss: 0.0328905172646046 \n",
      "Epoch [15/5000] , Step [480/488] , Loss: 0.0326290428638458 \n",
      "Epoch [16/5000] , Step [10/488] , Loss: 0.0325941778719425 \n",
      "Epoch [16/5000] , Step [20/488] , Loss: 0.0318139865994453 \n",
      "Epoch [16/5000] , Step [30/488] , Loss: 0.0324663035571575 \n",
      "Epoch [16/5000] , Step [40/488] , Loss: 0.0324127711355686 \n",
      "Epoch [16/5000] , Step [50/488] , Loss: 0.0320840217173100 \n",
      "Epoch [16/5000] , Step [60/488] , Loss: 0.0328753404319286 \n",
      "Epoch [16/5000] , Step [70/488] , Loss: 0.0321815945208073 \n",
      "Epoch [16/5000] , Step [80/488] , Loss: 0.0323746502399445 \n",
      "Epoch [16/5000] , Step [90/488] , Loss: 0.0322609990835190 \n",
      "Epoch [16/5000] , Step [100/488] , Loss: 0.0329170078039169 \n",
      "Epoch [16/5000] , Step [110/488] , Loss: 0.0323506444692612 \n",
      "Epoch [16/5000] , Step [120/488] , Loss: 0.0326530523598194 \n",
      "Epoch [16/5000] , Step [130/488] , Loss: 0.0324879586696625 \n",
      "Epoch [16/5000] , Step [140/488] , Loss: 0.0322084240615368 \n",
      "Epoch [16/5000] , Step [150/488] , Loss: 0.0328045785427094 \n",
      "Epoch [16/5000] , Step [160/488] , Loss: 0.0329835154116154 \n",
      "Epoch [16/5000] , Step [170/488] , Loss: 0.0321991406381130 \n",
      "Epoch [16/5000] , Step [180/488] , Loss: 0.0333712883293629 \n",
      "Epoch [16/5000] , Step [190/488] , Loss: 0.0321820266544819 \n",
      "Epoch [16/5000] , Step [200/488] , Loss: 0.0322533212602139 \n",
      "Epoch [16/5000] , Step [210/488] , Loss: 0.0321627259254456 \n",
      "Epoch [16/5000] , Step [220/488] , Loss: 0.0322024747729301 \n",
      "Epoch [16/5000] , Step [230/488] , Loss: 0.0324066840112209 \n",
      "Epoch [16/5000] , Step [240/488] , Loss: 0.0321609638631344 \n",
      "Epoch [16/5000] , Step [250/488] , Loss: 0.0333008617162704 \n",
      "Epoch [16/5000] , Step [260/488] , Loss: 0.0322326719760895 \n",
      "Epoch [16/5000] , Step [270/488] , Loss: 0.0328037738800049 \n",
      "Epoch [16/5000] , Step [280/488] , Loss: 0.0324433930218220 \n",
      "Epoch [16/5000] , Step [290/488] , Loss: 0.0326433628797531 \n",
      "Epoch [16/5000] , Step [300/488] , Loss: 0.0320103466510773 \n",
      "Epoch [16/5000] , Step [310/488] , Loss: 0.0333264134824276 \n",
      "Epoch [16/5000] , Step [320/488] , Loss: 0.0321751981973648 \n",
      "Epoch [16/5000] , Step [330/488] , Loss: 0.0326614640653133 \n",
      "Epoch [16/5000] , Step [340/488] , Loss: 0.0323381870985031 \n",
      "Epoch [16/5000] , Step [350/488] , Loss: 0.0318622402846813 \n",
      "Epoch [16/5000] , Step [360/488] , Loss: 0.0324551202356815 \n",
      "Epoch [16/5000] , Step [370/488] , Loss: 0.0330844484269619 \n",
      "Epoch [16/5000] , Step [380/488] , Loss: 0.0327034890651703 \n",
      "Epoch [16/5000] , Step [390/488] , Loss: 0.0321267955005169 \n",
      "Epoch [16/5000] , Step [400/488] , Loss: 0.0323320291936398 \n",
      "Epoch [16/5000] , Step [410/488] , Loss: 0.0324896275997162 \n",
      "Epoch [16/5000] , Step [420/488] , Loss: 0.0321193188428879 \n",
      "Epoch [16/5000] , Step [430/488] , Loss: 0.0323956832289696 \n",
      "Epoch [16/5000] , Step [440/488] , Loss: 0.0324352532625198 \n",
      "Epoch [16/5000] , Step [450/488] , Loss: 0.0328750610351562 \n",
      "Epoch [16/5000] , Step [460/488] , Loss: 0.0327479392290115 \n",
      "Epoch [16/5000] , Step [470/488] , Loss: 0.0326813831925392 \n",
      "Epoch [16/5000] , Step [480/488] , Loss: 0.0321940593421459 \n",
      "Epoch [17/5000] , Step [10/488] , Loss: 0.0328552052378654 \n",
      "Epoch [17/5000] , Step [20/488] , Loss: 0.0324760749936104 \n",
      "Epoch [17/5000] , Step [30/488] , Loss: 0.0328851453959942 \n",
      "Epoch [17/5000] , Step [40/488] , Loss: 0.0325112827122211 \n",
      "Epoch [17/5000] , Step [50/488] , Loss: 0.0320089273154736 \n",
      "Epoch [17/5000] , Step [60/488] , Loss: 0.0323647372424603 \n",
      "Epoch [17/5000] , Step [70/488] , Loss: 0.0317668542265892 \n",
      "Epoch [17/5000] , Step [80/488] , Loss: 0.0322454720735550 \n",
      "Epoch [17/5000] , Step [90/488] , Loss: 0.0329089649021626 \n",
      "Epoch [17/5000] , Step [100/488] , Loss: 0.0325763188302517 \n",
      "Epoch [17/5000] , Step [110/488] , Loss: 0.0325779467821121 \n",
      "Epoch [17/5000] , Step [120/488] , Loss: 0.0323824733495712 \n",
      "Epoch [17/5000] , Step [130/488] , Loss: 0.0325622074306011 \n",
      "Epoch [17/5000] , Step [140/488] , Loss: 0.0324969999492168 \n",
      "Epoch [17/5000] , Step [150/488] , Loss: 0.0322664529085159 \n",
      "Epoch [17/5000] , Step [160/488] , Loss: 0.0322257466614246 \n",
      "Epoch [17/5000] , Step [170/488] , Loss: 0.0323897786438465 \n",
      "Epoch [17/5000] , Step [180/488] , Loss: 0.0328049808740616 \n",
      "Epoch [17/5000] , Step [190/488] , Loss: 0.0324755273759365 \n",
      "Epoch [17/5000] , Step [200/488] , Loss: 0.0324043296277523 \n",
      "Epoch [17/5000] , Step [210/488] , Loss: 0.0329375229775906 \n",
      "Epoch [17/5000] , Step [220/488] , Loss: 0.0325333550572395 \n",
      "Epoch [17/5000] , Step [230/488] , Loss: 0.0322519838809967 \n",
      "Epoch [17/5000] , Step [240/488] , Loss: 0.0332376472651958 \n",
      "Epoch [17/5000] , Step [250/488] , Loss: 0.0318739563226700 \n",
      "Epoch [17/5000] , Step [260/488] , Loss: 0.0330578014254570 \n",
      "Epoch [17/5000] , Step [270/488] , Loss: 0.0322828069329262 \n",
      "Epoch [17/5000] , Step [280/488] , Loss: 0.0330755785107613 \n",
      "Epoch [17/5000] , Step [290/488] , Loss: 0.0325171165168285 \n",
      "Epoch [17/5000] , Step [300/488] , Loss: 0.0323752425611019 \n",
      "Epoch [17/5000] , Step [310/488] , Loss: 0.0332451760768890 \n",
      "Epoch [17/5000] , Step [320/488] , Loss: 0.0325750857591629 \n",
      "Epoch [17/5000] , Step [330/488] , Loss: 0.0328030809760094 \n",
      "Epoch [17/5000] , Step [340/488] , Loss: 0.0334556549787521 \n",
      "Epoch [17/5000] , Step [350/488] , Loss: 0.0325167849659920 \n",
      "Epoch [17/5000] , Step [360/488] , Loss: 0.0325882993638515 \n",
      "Epoch [17/5000] , Step [370/488] , Loss: 0.0323107354342937 \n",
      "Epoch [17/5000] , Step [380/488] , Loss: 0.0321314409375191 \n",
      "Epoch [17/5000] , Step [390/488] , Loss: 0.0326628684997559 \n",
      "Epoch [17/5000] , Step [400/488] , Loss: 0.0327895097434521 \n",
      "Epoch [17/5000] , Step [410/488] , Loss: 0.0327055528759956 \n",
      "Epoch [17/5000] , Step [420/488] , Loss: 0.0320659577846527 \n",
      "Epoch [17/5000] , Step [430/488] , Loss: 0.0325756669044495 \n",
      "Epoch [17/5000] , Step [440/488] , Loss: 0.0324736610054970 \n",
      "Epoch [17/5000] , Step [450/488] , Loss: 0.0319777727127075 \n",
      "Epoch [17/5000] , Step [460/488] , Loss: 0.0325620807707310 \n",
      "Epoch [17/5000] , Step [470/488] , Loss: 0.0323172025382519 \n",
      "Epoch [17/5000] , Step [480/488] , Loss: 0.0321253910660744 \n",
      "Epoch [18/5000] , Step [10/488] , Loss: 0.0322395302355289 \n",
      "Epoch [18/5000] , Step [20/488] , Loss: 0.0324454195797443 \n",
      "Epoch [18/5000] , Step [30/488] , Loss: 0.0322899259626865 \n",
      "Epoch [18/5000] , Step [40/488] , Loss: 0.0320591554045677 \n",
      "Epoch [18/5000] , Step [50/488] , Loss: 0.0318355299532413 \n",
      "Epoch [18/5000] , Step [60/488] , Loss: 0.0318268612027168 \n",
      "Epoch [18/5000] , Step [70/488] , Loss: 0.0323173142969608 \n",
      "Epoch [18/5000] , Step [80/488] , Loss: 0.0323896445333958 \n",
      "Epoch [18/5000] , Step [90/488] , Loss: 0.0326220467686653 \n",
      "Epoch [18/5000] , Step [100/488] , Loss: 0.0321184396743774 \n",
      "Epoch [18/5000] , Step [110/488] , Loss: 0.0322062745690346 \n",
      "Epoch [18/5000] , Step [120/488] , Loss: 0.0323515236377716 \n",
      "Epoch [18/5000] , Step [130/488] , Loss: 0.0321893431246281 \n",
      "Epoch [18/5000] , Step [140/488] , Loss: 0.0326901637017727 \n",
      "Epoch [18/5000] , Step [150/488] , Loss: 0.0328975468873978 \n",
      "Epoch [18/5000] , Step [160/488] , Loss: 0.0331015735864639 \n",
      "Epoch [18/5000] , Step [170/488] , Loss: 0.0333978906273842 \n",
      "Epoch [18/5000] , Step [180/488] , Loss: 0.0325815230607986 \n",
      "Epoch [18/5000] , Step [190/488] , Loss: 0.0327567644417286 \n",
      "Epoch [18/5000] , Step [200/488] , Loss: 0.0322662778198719 \n",
      "Epoch [18/5000] , Step [210/488] , Loss: 0.0322798341512680 \n",
      "Epoch [18/5000] , Step [220/488] , Loss: 0.0325203128159046 \n",
      "Epoch [18/5000] , Step [230/488] , Loss: 0.0326094441115856 \n",
      "Epoch [18/5000] , Step [240/488] , Loss: 0.0327365137636662 \n",
      "Epoch [18/5000] , Step [250/488] , Loss: 0.0322367623448372 \n",
      "Epoch [18/5000] , Step [260/488] , Loss: 0.0333936214447021 \n",
      "Epoch [18/5000] , Step [270/488] , Loss: 0.0326668508350849 \n",
      "Epoch [18/5000] , Step [280/488] , Loss: 0.0321239158511162 \n",
      "Epoch [18/5000] , Step [290/488] , Loss: 0.0328022092580795 \n",
      "Epoch [18/5000] , Step [300/488] , Loss: 0.0323954820632935 \n",
      "Epoch [18/5000] , Step [310/488] , Loss: 0.0326524712145329 \n",
      "Epoch [18/5000] , Step [320/488] , Loss: 0.0322140678763390 \n",
      "Epoch [18/5000] , Step [330/488] , Loss: 0.0324799194931984 \n",
      "Epoch [18/5000] , Step [340/488] , Loss: 0.0322640053927898 \n",
      "Epoch [18/5000] , Step [350/488] , Loss: 0.0331173799932003 \n",
      "Epoch [18/5000] , Step [360/488] , Loss: 0.0328811630606651 \n",
      "Epoch [18/5000] , Step [370/488] , Loss: 0.0326799787580967 \n",
      "Epoch [18/5000] , Step [380/488] , Loss: 0.0329888574779034 \n",
      "Epoch [18/5000] , Step [390/488] , Loss: 0.0322933830320835 \n",
      "Epoch [18/5000] , Step [400/488] , Loss: 0.0320833623409271 \n",
      "Epoch [18/5000] , Step [410/488] , Loss: 0.0324244461953640 \n",
      "Epoch [18/5000] , Step [420/488] , Loss: 0.0326544418931007 \n",
      "Epoch [18/5000] , Step [430/488] , Loss: 0.0320157296955585 \n",
      "Epoch [18/5000] , Step [440/488] , Loss: 0.0323980785906315 \n",
      "Epoch [18/5000] , Step [450/488] , Loss: 0.0326827429234982 \n",
      "Epoch [18/5000] , Step [460/488] , Loss: 0.0322089456021786 \n",
      "Epoch [18/5000] , Step [470/488] , Loss: 0.0317492261528969 \n",
      "Epoch [18/5000] , Step [480/488] , Loss: 0.0324508175253868 \n",
      "Epoch [19/5000] , Step [10/488] , Loss: 0.0325674079358578 \n",
      "Epoch [19/5000] , Step [20/488] , Loss: 0.0320426896214485 \n",
      "Epoch [19/5000] , Step [30/488] , Loss: 0.0334064923226833 \n",
      "Epoch [19/5000] , Step [40/488] , Loss: 0.0327650420367718 \n",
      "Epoch [19/5000] , Step [50/488] , Loss: 0.0323060937225819 \n",
      "Epoch [19/5000] , Step [60/488] , Loss: 0.0328229330480099 \n",
      "Epoch [19/5000] , Step [70/488] , Loss: 0.0324271954596043 \n",
      "Epoch [19/5000] , Step [80/488] , Loss: 0.0328311100602150 \n",
      "Epoch [19/5000] , Step [90/488] , Loss: 0.0331644974648952 \n",
      "Epoch [19/5000] , Step [100/488] , Loss: 0.0330125130712986 \n",
      "Epoch [19/5000] , Step [110/488] , Loss: 0.0321558900177479 \n",
      "Epoch [19/5000] , Step [120/488] , Loss: 0.0327960141003132 \n",
      "Epoch [19/5000] , Step [130/488] , Loss: 0.0324431210756302 \n",
      "Epoch [19/5000] , Step [140/488] , Loss: 0.0323458351194859 \n",
      "Epoch [19/5000] , Step [150/488] , Loss: 0.0322281606495380 \n",
      "Epoch [19/5000] , Step [160/488] , Loss: 0.0324935615062714 \n",
      "Epoch [19/5000] , Step [170/488] , Loss: 0.0331252925097942 \n",
      "Epoch [19/5000] , Step [180/488] , Loss: 0.0323969461023808 \n",
      "Epoch [19/5000] , Step [190/488] , Loss: 0.0326119996607304 \n",
      "Epoch [19/5000] , Step [200/488] , Loss: 0.0327571816742420 \n",
      "Epoch [19/5000] , Step [210/488] , Loss: 0.0323711521923542 \n",
      "Epoch [19/5000] , Step [220/488] , Loss: 0.0326908044517040 \n",
      "Epoch [19/5000] , Step [230/488] , Loss: 0.0326535962522030 \n",
      "Epoch [19/5000] , Step [240/488] , Loss: 0.0324639268219471 \n",
      "Epoch [19/5000] , Step [250/488] , Loss: 0.0322356894612312 \n",
      "Epoch [19/5000] , Step [260/488] , Loss: 0.0326363071799278 \n",
      "Epoch [19/5000] , Step [270/488] , Loss: 0.0325103178620338 \n",
      "Epoch [19/5000] , Step [280/488] , Loss: 0.0330001562833786 \n",
      "Epoch [19/5000] , Step [290/488] , Loss: 0.0335221216082573 \n",
      "Epoch [19/5000] , Step [300/488] , Loss: 0.0326265133917332 \n",
      "Epoch [19/5000] , Step [310/488] , Loss: 0.0330779589712620 \n",
      "Epoch [19/5000] , Step [320/488] , Loss: 0.0332586802542210 \n",
      "Epoch [19/5000] , Step [330/488] , Loss: 0.0325852520763874 \n",
      "Epoch [19/5000] , Step [340/488] , Loss: 0.0328024663031101 \n",
      "Epoch [19/5000] , Step [350/488] , Loss: 0.0326190441846848 \n",
      "Epoch [19/5000] , Step [360/488] , Loss: 0.0322588719427586 \n",
      "Epoch [19/5000] , Step [370/488] , Loss: 0.0332482494413853 \n",
      "Epoch [19/5000] , Step [380/488] , Loss: 0.0324723795056343 \n",
      "Epoch [19/5000] , Step [390/488] , Loss: 0.0329270474612713 \n",
      "Epoch [19/5000] , Step [400/488] , Loss: 0.0326464511454105 \n",
      "Epoch [19/5000] , Step [410/488] , Loss: 0.0324753932654858 \n",
      "Epoch [19/5000] , Step [420/488] , Loss: 0.0322521477937698 \n",
      "Epoch [19/5000] , Step [430/488] , Loss: 0.0326042771339417 \n",
      "Epoch [19/5000] , Step [440/488] , Loss: 0.0323227904736996 \n",
      "Epoch [19/5000] , Step [450/488] , Loss: 0.0325135849416256 \n",
      "Epoch [19/5000] , Step [460/488] , Loss: 0.0324310138821602 \n",
      "Epoch [19/5000] , Step [470/488] , Loss: 0.0323880948126316 \n",
      "Epoch [19/5000] , Step [480/488] , Loss: 0.0326372981071472 \n",
      "Epoch [20/5000] , Step [10/488] , Loss: 0.0333132669329643 \n",
      "Epoch [20/5000] , Step [20/488] , Loss: 0.0323611274361610 \n",
      "Epoch [20/5000] , Step [30/488] , Loss: 0.0332166440784931 \n",
      "Epoch [20/5000] , Step [40/488] , Loss: 0.0330644659698009 \n",
      "Epoch [20/5000] , Step [50/488] , Loss: 0.0318438410758972 \n",
      "Epoch [20/5000] , Step [60/488] , Loss: 0.0328029096126556 \n",
      "Epoch [20/5000] , Step [70/488] , Loss: 0.0320336110889912 \n",
      "Epoch [20/5000] , Step [80/488] , Loss: 0.0321181565523148 \n",
      "Epoch [20/5000] , Step [90/488] , Loss: 0.0326727926731110 \n",
      "Epoch [20/5000] , Step [100/488] , Loss: 0.0329512991011143 \n",
      "Epoch [20/5000] , Step [110/488] , Loss: 0.0327053889632225 \n",
      "Epoch [20/5000] , Step [120/488] , Loss: 0.0324094034731388 \n",
      "Epoch [20/5000] , Step [130/488] , Loss: 0.0324695445597172 \n",
      "Epoch [20/5000] , Step [140/488] , Loss: 0.0324019342660904 \n",
      "Epoch [20/5000] , Step [150/488] , Loss: 0.0316853858530521 \n",
      "Epoch [20/5000] , Step [160/488] , Loss: 0.0321995764970779 \n",
      "Epoch [20/5000] , Step [170/488] , Loss: 0.0326408557593822 \n",
      "Epoch [20/5000] , Step [180/488] , Loss: 0.0315636582672596 \n",
      "Epoch [20/5000] , Step [190/488] , Loss: 0.0323235020041466 \n",
      "Epoch [20/5000] , Step [200/488] , Loss: 0.0318913906812668 \n",
      "Epoch [20/5000] , Step [210/488] , Loss: 0.0323717072606087 \n",
      "Epoch [20/5000] , Step [220/488] , Loss: 0.0322980768978596 \n",
      "Epoch [20/5000] , Step [230/488] , Loss: 0.0324883125722408 \n",
      "Epoch [20/5000] , Step [240/488] , Loss: 0.0318582281470299 \n",
      "Epoch [20/5000] , Step [250/488] , Loss: 0.0329229049384594 \n",
      "Epoch [20/5000] , Step [260/488] , Loss: 0.0325068309903145 \n",
      "Epoch [20/5000] , Step [270/488] , Loss: 0.0321925617754459 \n",
      "Epoch [20/5000] , Step [280/488] , Loss: 0.0320405960083008 \n",
      "Epoch [20/5000] , Step [290/488] , Loss: 0.0322767831385136 \n",
      "Epoch [20/5000] , Step [300/488] , Loss: 0.0327178426086903 \n",
      "Epoch [20/5000] , Step [310/488] , Loss: 0.0324872359633446 \n",
      "Epoch [20/5000] , Step [320/488] , Loss: 0.0329743027687073 \n",
      "Epoch [20/5000] , Step [330/488] , Loss: 0.0322599485516548 \n",
      "Epoch [20/5000] , Step [340/488] , Loss: 0.0325345546007156 \n",
      "Epoch [20/5000] , Step [350/488] , Loss: 0.0323792695999146 \n",
      "Epoch [20/5000] , Step [360/488] , Loss: 0.0332747735083103 \n",
      "Epoch [20/5000] , Step [370/488] , Loss: 0.0330301299691200 \n",
      "Epoch [20/5000] , Step [380/488] , Loss: 0.0329329296946526 \n",
      "Epoch [20/5000] , Step [390/488] , Loss: 0.0328474752604961 \n",
      "Epoch [20/5000] , Step [400/488] , Loss: 0.0328202694654465 \n",
      "Epoch [20/5000] , Step [410/488] , Loss: 0.0327858440577984 \n",
      "Epoch [20/5000] , Step [420/488] , Loss: 0.0321569889783859 \n",
      "Epoch [20/5000] , Step [430/488] , Loss: 0.0324079282581806 \n",
      "Epoch [20/5000] , Step [440/488] , Loss: 0.0324238725006580 \n",
      "Epoch [20/5000] , Step [450/488] , Loss: 0.0319010391831398 \n",
      "Epoch [20/5000] , Step [460/488] , Loss: 0.0326949656009674 \n",
      "Epoch [20/5000] , Step [470/488] , Loss: 0.0321593433618546 \n",
      "Epoch [20/5000] , Step [480/488] , Loss: 0.0328114219009876 \n",
      "Epoch [21/5000] , Step [10/488] , Loss: 0.0324933491647243 \n",
      "Epoch [21/5000] , Step [20/488] , Loss: 0.0330349206924438 \n",
      "Epoch [21/5000] , Step [30/488] , Loss: 0.0333046242594719 \n",
      "Epoch [21/5000] , Step [40/488] , Loss: 0.0325141511857510 \n",
      "Epoch [21/5000] , Step [50/488] , Loss: 0.0327268354594707 \n",
      "Epoch [21/5000] , Step [60/488] , Loss: 0.0322606600821018 \n",
      "Epoch [21/5000] , Step [70/488] , Loss: 0.0325779877603054 \n",
      "Epoch [21/5000] , Step [80/488] , Loss: 0.0325667150318623 \n",
      "Epoch [21/5000] , Step [90/488] , Loss: 0.0322056934237480 \n",
      "Epoch [21/5000] , Step [100/488] , Loss: 0.0328075103461742 \n",
      "Epoch [21/5000] , Step [110/488] , Loss: 0.0325737111270428 \n",
      "Epoch [21/5000] , Step [120/488] , Loss: 0.0321925468742847 \n",
      "Epoch [21/5000] , Step [130/488] , Loss: 0.0331926718354225 \n",
      "Epoch [21/5000] , Step [140/488] , Loss: 0.0321448184549809 \n",
      "Epoch [21/5000] , Step [150/488] , Loss: 0.0325726978480816 \n",
      "Epoch [21/5000] , Step [160/488] , Loss: 0.0324298031628132 \n",
      "Epoch [21/5000] , Step [170/488] , Loss: 0.0331130437552929 \n",
      "Epoch [21/5000] , Step [180/488] , Loss: 0.0325617454946041 \n",
      "Epoch [21/5000] , Step [190/488] , Loss: 0.0331594124436378 \n",
      "Epoch [21/5000] , Step [200/488] , Loss: 0.0323696732521057 \n",
      "Epoch [21/5000] , Step [210/488] , Loss: 0.0321472510695457 \n",
      "Epoch [21/5000] , Step [220/488] , Loss: 0.0327560864388943 \n",
      "Epoch [21/5000] , Step [230/488] , Loss: 0.0321884714066982 \n",
      "Epoch [21/5000] , Step [240/488] , Loss: 0.0320637896656990 \n",
      "Epoch [21/5000] , Step [250/488] , Loss: 0.0323770195245743 \n",
      "Epoch [21/5000] , Step [260/488] , Loss: 0.0326736010611057 \n",
      "Epoch [21/5000] , Step [270/488] , Loss: 0.0317018143832684 \n",
      "Epoch [21/5000] , Step [280/488] , Loss: 0.0334826894104481 \n",
      "Epoch [21/5000] , Step [290/488] , Loss: 0.0316301956772804 \n",
      "Epoch [21/5000] , Step [300/488] , Loss: 0.0325164608657360 \n",
      "Epoch [21/5000] , Step [310/488] , Loss: 0.0333812609314919 \n",
      "Epoch [21/5000] , Step [320/488] , Loss: 0.0323133990168571 \n",
      "Epoch [21/5000] , Step [330/488] , Loss: 0.0319364741444588 \n",
      "Epoch [21/5000] , Step [340/488] , Loss: 0.0322899632155895 \n",
      "Epoch [21/5000] , Step [350/488] , Loss: 0.0327963680028915 \n",
      "Epoch [21/5000] , Step [360/488] , Loss: 0.0323143489658833 \n",
      "Epoch [21/5000] , Step [370/488] , Loss: 0.0320822745561600 \n",
      "Epoch [21/5000] , Step [380/488] , Loss: 0.0321456566452980 \n",
      "Epoch [21/5000] , Step [390/488] , Loss: 0.0324915237724781 \n",
      "Epoch [21/5000] , Step [400/488] , Loss: 0.0320304036140442 \n",
      "Epoch [21/5000] , Step [410/488] , Loss: 0.0322682373225689 \n",
      "Epoch [21/5000] , Step [420/488] , Loss: 0.0327424146234989 \n",
      "Epoch [21/5000] , Step [430/488] , Loss: 0.0330851301550865 \n",
      "Epoch [21/5000] , Step [440/488] , Loss: 0.0312574245035648 \n",
      "Epoch [21/5000] , Step [450/488] , Loss: 0.0319933257997036 \n",
      "Epoch [21/5000] , Step [460/488] , Loss: 0.0327726565301418 \n",
      "Epoch [21/5000] , Step [470/488] , Loss: 0.0327065847814083 \n",
      "Epoch [21/5000] , Step [480/488] , Loss: 0.0329282395541668 \n",
      "Epoch [22/5000] , Step [10/488] , Loss: 0.0315662994980812 \n",
      "Epoch [22/5000] , Step [20/488] , Loss: 0.0328505374491215 \n",
      "Epoch [22/5000] , Step [30/488] , Loss: 0.0325860604643822 \n",
      "Epoch [22/5000] , Step [40/488] , Loss: 0.0327494144439697 \n",
      "Epoch [22/5000] , Step [50/488] , Loss: 0.0323713980615139 \n",
      "Epoch [22/5000] , Step [60/488] , Loss: 0.0335164964199066 \n",
      "Epoch [22/5000] , Step [70/488] , Loss: 0.0321308933198452 \n",
      "Epoch [22/5000] , Step [80/488] , Loss: 0.0320871211588383 \n",
      "Epoch [22/5000] , Step [90/488] , Loss: 0.0323423817753792 \n",
      "Epoch [22/5000] , Step [100/488] , Loss: 0.0323912613093853 \n",
      "Epoch [22/5000] , Step [110/488] , Loss: 0.0327849276363850 \n",
      "Epoch [22/5000] , Step [120/488] , Loss: 0.0327328778803349 \n",
      "Epoch [22/5000] , Step [130/488] , Loss: 0.0321415513753891 \n",
      "Epoch [22/5000] , Step [140/488] , Loss: 0.0325601845979691 \n",
      "Epoch [22/5000] , Step [150/488] , Loss: 0.0325267612934113 \n",
      "Epoch [22/5000] , Step [160/488] , Loss: 0.0324743539094925 \n",
      "Epoch [22/5000] , Step [170/488] , Loss: 0.0329974927008152 \n",
      "Epoch [22/5000] , Step [180/488] , Loss: 0.0318528302013874 \n",
      "Epoch [22/5000] , Step [190/488] , Loss: 0.0327020511031151 \n",
      "Epoch [22/5000] , Step [200/488] , Loss: 0.0325387492775917 \n",
      "Epoch [22/5000] , Step [210/488] , Loss: 0.0332202427089214 \n",
      "Epoch [22/5000] , Step [220/488] , Loss: 0.0329113565385342 \n",
      "Epoch [22/5000] , Step [230/488] , Loss: 0.0326899662613869 \n",
      "Epoch [22/5000] , Step [240/488] , Loss: 0.0323737487196922 \n",
      "Epoch [22/5000] , Step [250/488] , Loss: 0.0326788797974586 \n",
      "Epoch [22/5000] , Step [260/488] , Loss: 0.0319679044187069 \n",
      "Epoch [22/5000] , Step [270/488] , Loss: 0.0331439487636089 \n",
      "Epoch [22/5000] , Step [280/488] , Loss: 0.0327090173959732 \n",
      "Epoch [22/5000] , Step [290/488] , Loss: 0.0326384529471397 \n",
      "Epoch [22/5000] , Step [300/488] , Loss: 0.0330480858683586 \n",
      "Epoch [22/5000] , Step [310/488] , Loss: 0.0324458256363869 \n",
      "Epoch [22/5000] , Step [320/488] , Loss: 0.0323228202760220 \n",
      "Epoch [22/5000] , Step [330/488] , Loss: 0.0323907956480980 \n",
      "Epoch [22/5000] , Step [340/488] , Loss: 0.0320903733372688 \n",
      "Epoch [22/5000] , Step [350/488] , Loss: 0.0326903909444809 \n",
      "Epoch [22/5000] , Step [360/488] , Loss: 0.0329273901879787 \n",
      "Epoch [22/5000] , Step [370/488] , Loss: 0.0323594287037849 \n",
      "Epoch [22/5000] , Step [380/488] , Loss: 0.0330190658569336 \n",
      "Epoch [22/5000] , Step [390/488] , Loss: 0.0322175249457359 \n",
      "Epoch [22/5000] , Step [400/488] , Loss: 0.0319537520408630 \n",
      "Epoch [22/5000] , Step [410/488] , Loss: 0.0329703986644745 \n",
      "Epoch [22/5000] , Step [420/488] , Loss: 0.0323903858661652 \n",
      "Epoch [22/5000] , Step [430/488] , Loss: 0.0330435857176781 \n",
      "Epoch [22/5000] , Step [440/488] , Loss: 0.0325452983379364 \n",
      "Epoch [22/5000] , Step [450/488] , Loss: 0.0318860821425915 \n",
      "Epoch [22/5000] , Step [460/488] , Loss: 0.0321080125868320 \n",
      "Epoch [22/5000] , Step [470/488] , Loss: 0.0326739698648453 \n",
      "Epoch [22/5000] , Step [480/488] , Loss: 0.0325341969728470 \n",
      "Epoch [23/5000] , Step [10/488] , Loss: 0.0323499552905560 \n",
      "Epoch [23/5000] , Step [20/488] , Loss: 0.0322403684258461 \n",
      "Epoch [23/5000] , Step [30/488] , Loss: 0.0330243073403835 \n",
      "Epoch [23/5000] , Step [40/488] , Loss: 0.0319401696324348 \n",
      "Epoch [23/5000] , Step [50/488] , Loss: 0.0321087986230850 \n",
      "Epoch [23/5000] , Step [60/488] , Loss: 0.0318406373262405 \n",
      "Epoch [23/5000] , Step [70/488] , Loss: 0.0320587866008282 \n",
      "Epoch [23/5000] , Step [80/488] , Loss: 0.0321215093135834 \n",
      "Epoch [23/5000] , Step [90/488] , Loss: 0.0332393869757652 \n",
      "Epoch [23/5000] , Step [100/488] , Loss: 0.0324172489345074 \n",
      "Epoch [23/5000] , Step [110/488] , Loss: 0.0323162972927094 \n",
      "Epoch [23/5000] , Step [120/488] , Loss: 0.0329962894320488 \n",
      "Epoch [23/5000] , Step [130/488] , Loss: 0.0321601927280426 \n",
      "Epoch [23/5000] , Step [140/488] , Loss: 0.0323028601706028 \n",
      "Epoch [23/5000] , Step [150/488] , Loss: 0.0324480086565018 \n",
      "Epoch [23/5000] , Step [160/488] , Loss: 0.0327571332454681 \n",
      "Epoch [23/5000] , Step [170/488] , Loss: 0.0326579622924328 \n",
      "Epoch [23/5000] , Step [180/488] , Loss: 0.0324151627719402 \n",
      "Epoch [23/5000] , Step [190/488] , Loss: 0.0324841141700745 \n",
      "Epoch [23/5000] , Step [200/488] , Loss: 0.0328927040100098 \n",
      "Epoch [23/5000] , Step [210/488] , Loss: 0.0329737402498722 \n",
      "Epoch [23/5000] , Step [220/488] , Loss: 0.0330080613493919 \n",
      "Epoch [23/5000] , Step [230/488] , Loss: 0.0323326438665390 \n",
      "Epoch [23/5000] , Step [240/488] , Loss: 0.0325376167893410 \n",
      "Epoch [23/5000] , Step [250/488] , Loss: 0.0321291796863079 \n",
      "Epoch [23/5000] , Step [260/488] , Loss: 0.0324508324265480 \n",
      "Epoch [23/5000] , Step [270/488] , Loss: 0.0322477817535400 \n",
      "Epoch [23/5000] , Step [280/488] , Loss: 0.0326180942356586 \n",
      "Epoch [23/5000] , Step [290/488] , Loss: 0.0319974608719349 \n",
      "Epoch [23/5000] , Step [300/488] , Loss: 0.0321405157446861 \n",
      "Epoch [23/5000] , Step [310/488] , Loss: 0.0329019799828529 \n",
      "Epoch [23/5000] , Step [320/488] , Loss: 0.0325833335518837 \n",
      "Epoch [23/5000] , Step [330/488] , Loss: 0.0325137823820114 \n",
      "Epoch [23/5000] , Step [340/488] , Loss: 0.0330596379935741 \n",
      "Epoch [23/5000] , Step [350/488] , Loss: 0.0327468216419220 \n",
      "Epoch [23/5000] , Step [360/488] , Loss: 0.0327012762427330 \n",
      "Epoch [23/5000] , Step [370/488] , Loss: 0.0322609841823578 \n",
      "Epoch [23/5000] , Step [380/488] , Loss: 0.0325753688812256 \n",
      "Epoch [23/5000] , Step [390/488] , Loss: 0.0321663506329060 \n",
      "Epoch [23/5000] , Step [400/488] , Loss: 0.0319277122616768 \n",
      "Epoch [23/5000] , Step [410/488] , Loss: 0.0324388183653355 \n",
      "Epoch [23/5000] , Step [420/488] , Loss: 0.0323224887251854 \n",
      "Epoch [23/5000] , Step [430/488] , Loss: 0.0335571095347404 \n",
      "Epoch [23/5000] , Step [440/488] , Loss: 0.0314591117203236 \n",
      "Epoch [23/5000] , Step [450/488] , Loss: 0.0323970317840576 \n",
      "Epoch [23/5000] , Step [460/488] , Loss: 0.0324807651340961 \n",
      "Epoch [23/5000] , Step [470/488] , Loss: 0.0321483872830868 \n",
      "Epoch [23/5000] , Step [480/488] , Loss: 0.0322513654828072 \n",
      "Epoch [24/5000] , Step [10/488] , Loss: 0.0327984951436520 \n",
      "Epoch [24/5000] , Step [20/488] , Loss: 0.0321766212582588 \n",
      "Epoch [24/5000] , Step [30/488] , Loss: 0.0324016921222210 \n",
      "Epoch [24/5000] , Step [40/488] , Loss: 0.0322019234299660 \n",
      "Epoch [24/5000] , Step [50/488] , Loss: 0.0327921323478222 \n",
      "Epoch [24/5000] , Step [60/488] , Loss: 0.0318979620933533 \n",
      "Epoch [24/5000] , Step [70/488] , Loss: 0.0325932651758194 \n",
      "Epoch [24/5000] , Step [80/488] , Loss: 0.0328749157488346 \n",
      "Epoch [24/5000] , Step [90/488] , Loss: 0.0322767235338688 \n",
      "Epoch [24/5000] , Step [100/488] , Loss: 0.0323760397732258 \n",
      "Epoch [24/5000] , Step [110/488] , Loss: 0.0318938121199608 \n",
      "Epoch [24/5000] , Step [120/488] , Loss: 0.0320227891206741 \n",
      "Epoch [24/5000] , Step [130/488] , Loss: 0.0326212942600250 \n",
      "Epoch [24/5000] , Step [140/488] , Loss: 0.0330049395561218 \n",
      "Epoch [24/5000] , Step [150/488] , Loss: 0.0325630493462086 \n",
      "Epoch [24/5000] , Step [160/488] , Loss: 0.0325529053807259 \n",
      "Epoch [24/5000] , Step [170/488] , Loss: 0.0314674973487854 \n",
      "Epoch [24/5000] , Step [180/488] , Loss: 0.0325732566416264 \n",
      "Epoch [24/5000] , Step [190/488] , Loss: 0.0327611081302166 \n",
      "Epoch [24/5000] , Step [200/488] , Loss: 0.0330628715455532 \n",
      "Epoch [24/5000] , Step [210/488] , Loss: 0.0327137336134911 \n",
      "Epoch [24/5000] , Step [220/488] , Loss: 0.0322600901126862 \n",
      "Epoch [24/5000] , Step [230/488] , Loss: 0.0322585180401802 \n",
      "Epoch [24/5000] , Step [240/488] , Loss: 0.0320727862417698 \n",
      "Epoch [24/5000] , Step [250/488] , Loss: 0.0325318723917007 \n",
      "Epoch [24/5000] , Step [260/488] , Loss: 0.0325224585831165 \n",
      "Epoch [24/5000] , Step [270/488] , Loss: 0.0327605009078979 \n",
      "Epoch [24/5000] , Step [280/488] , Loss: 0.0326518826186657 \n",
      "Epoch [24/5000] , Step [290/488] , Loss: 0.0320627838373184 \n",
      "Epoch [24/5000] , Step [300/488] , Loss: 0.0329320617020130 \n",
      "Epoch [24/5000] , Step [310/488] , Loss: 0.0324737019836903 \n",
      "Epoch [24/5000] , Step [320/488] , Loss: 0.0325205363333225 \n",
      "Epoch [24/5000] , Step [330/488] , Loss: 0.0324121043086052 \n",
      "Epoch [24/5000] , Step [340/488] , Loss: 0.0325957089662552 \n",
      "Epoch [24/5000] , Step [350/488] , Loss: 0.0332835987210274 \n",
      "Epoch [24/5000] , Step [360/488] , Loss: 0.0326475389301777 \n",
      "Epoch [24/5000] , Step [370/488] , Loss: 0.0323662385344505 \n",
      "Epoch [24/5000] , Step [380/488] , Loss: 0.0324180983006954 \n",
      "Epoch [24/5000] , Step [390/488] , Loss: 0.0327368564903736 \n",
      "Epoch [24/5000] , Step [400/488] , Loss: 0.0326747074723244 \n",
      "Epoch [24/5000] , Step [410/488] , Loss: 0.0328988060355186 \n",
      "Epoch [24/5000] , Step [420/488] , Loss: 0.0323475860059261 \n",
      "Epoch [24/5000] , Step [430/488] , Loss: 0.0331124402582645 \n",
      "Epoch [24/5000] , Step [440/488] , Loss: 0.0316581018269062 \n",
      "Epoch [24/5000] , Step [450/488] , Loss: 0.0325629003345966 \n",
      "Epoch [24/5000] , Step [460/488] , Loss: 0.0321358777582645 \n",
      "Epoch [24/5000] , Step [470/488] , Loss: 0.0329343266785145 \n",
      "Epoch [24/5000] , Step [480/488] , Loss: 0.0326561033725739 \n",
      "Epoch [25/5000] , Step [10/488] , Loss: 0.0324762202799320 \n",
      "Epoch [25/5000] , Step [20/488] , Loss: 0.0323819629848003 \n",
      "Epoch [25/5000] , Step [30/488] , Loss: 0.0318878591060638 \n",
      "Epoch [25/5000] , Step [40/488] , Loss: 0.0328522436320782 \n",
      "Epoch [25/5000] , Step [50/488] , Loss: 0.0322419218719006 \n",
      "Epoch [25/5000] , Step [60/488] , Loss: 0.0326423868536949 \n",
      "Epoch [25/5000] , Step [70/488] , Loss: 0.0325497873127460 \n",
      "Epoch [25/5000] , Step [80/488] , Loss: 0.0323241017758846 \n",
      "Epoch [25/5000] , Step [90/488] , Loss: 0.0324568338692188 \n",
      "Epoch [25/5000] , Step [100/488] , Loss: 0.0326988250017166 \n",
      "Epoch [25/5000] , Step [110/488] , Loss: 0.0326469801366329 \n",
      "Epoch [25/5000] , Step [120/488] , Loss: 0.0319854766130447 \n",
      "Epoch [25/5000] , Step [130/488] , Loss: 0.0329446531832218 \n",
      "Epoch [25/5000] , Step [140/488] , Loss: 0.0322854183614254 \n",
      "Epoch [25/5000] , Step [150/488] , Loss: 0.0325218997895718 \n",
      "Epoch [25/5000] , Step [160/488] , Loss: 0.0321135409176350 \n",
      "Epoch [25/5000] , Step [170/488] , Loss: 0.0325415953993797 \n",
      "Epoch [25/5000] , Step [180/488] , Loss: 0.0329235717654228 \n",
      "Epoch [25/5000] , Step [190/488] , Loss: 0.0325124934315681 \n",
      "Epoch [25/5000] , Step [200/488] , Loss: 0.0320407077670097 \n",
      "Epoch [25/5000] , Step [210/488] , Loss: 0.0326973721385002 \n",
      "Epoch [25/5000] , Step [220/488] , Loss: 0.0334344096481800 \n",
      "Epoch [25/5000] , Step [230/488] , Loss: 0.0326730348169804 \n",
      "Epoch [25/5000] , Step [240/488] , Loss: 0.0320139601826668 \n",
      "Epoch [25/5000] , Step [250/488] , Loss: 0.0324915386736393 \n",
      "Epoch [25/5000] , Step [260/488] , Loss: 0.0322067216038704 \n",
      "Epoch [25/5000] , Step [270/488] , Loss: 0.0322308242321014 \n",
      "Epoch [25/5000] , Step [280/488] , Loss: 0.0330599583685398 \n",
      "Epoch [25/5000] , Step [290/488] , Loss: 0.0328131131827831 \n",
      "Epoch [25/5000] , Step [300/488] , Loss: 0.0321182310581207 \n",
      "Epoch [25/5000] , Step [310/488] , Loss: 0.0324002131819725 \n",
      "Epoch [25/5000] , Step [320/488] , Loss: 0.0322827324271202 \n",
      "Epoch [25/5000] , Step [330/488] , Loss: 0.0323520563542843 \n",
      "Epoch [25/5000] , Step [340/488] , Loss: 0.0328661501407623 \n",
      "Epoch [25/5000] , Step [350/488] , Loss: 0.0326090306043625 \n",
      "Epoch [25/5000] , Step [360/488] , Loss: 0.0319971181452274 \n",
      "Epoch [25/5000] , Step [370/488] , Loss: 0.0325475670397282 \n",
      "Epoch [25/5000] , Step [380/488] , Loss: 0.0327160693705082 \n",
      "Epoch [25/5000] , Step [390/488] , Loss: 0.0326009467244148 \n",
      "Epoch [25/5000] , Step [400/488] , Loss: 0.0325968563556671 \n",
      "Epoch [25/5000] , Step [410/488] , Loss: 0.0327343456447124 \n",
      "Epoch [25/5000] , Step [420/488] , Loss: 0.0329887308180332 \n",
      "Epoch [25/5000] , Step [430/488] , Loss: 0.0325138568878174 \n",
      "Epoch [25/5000] , Step [440/488] , Loss: 0.0323078446090221 \n",
      "Epoch [25/5000] , Step [450/488] , Loss: 0.0319815315306187 \n",
      "Epoch [25/5000] , Step [460/488] , Loss: 0.0323623754084110 \n",
      "Epoch [25/5000] , Step [470/488] , Loss: 0.0323261618614197 \n",
      "Epoch [25/5000] , Step [480/488] , Loss: 0.0328054390847683 \n",
      "Epoch [26/5000] , Step [10/488] , Loss: 0.0322882086038589 \n",
      "Epoch [26/5000] , Step [20/488] , Loss: 0.0325621999800205 \n",
      "Epoch [26/5000] , Step [30/488] , Loss: 0.0329425558447838 \n",
      "Epoch [26/5000] , Step [40/488] , Loss: 0.0322278961539268 \n",
      "Epoch [26/5000] , Step [50/488] , Loss: 0.0325609259307384 \n",
      "Epoch [26/5000] , Step [60/488] , Loss: 0.0331444703042507 \n",
      "Epoch [26/5000] , Step [70/488] , Loss: 0.0327215045690536 \n",
      "Epoch [26/5000] , Step [80/488] , Loss: 0.0324995368719101 \n",
      "Epoch [26/5000] , Step [90/488] , Loss: 0.0325538478791714 \n",
      "Epoch [26/5000] , Step [100/488] , Loss: 0.0327669195830822 \n",
      "Epoch [26/5000] , Step [110/488] , Loss: 0.0324356891214848 \n",
      "Epoch [26/5000] , Step [120/488] , Loss: 0.0316018201410770 \n",
      "Epoch [26/5000] , Step [130/488] , Loss: 0.0320076085627079 \n",
      "Epoch [26/5000] , Step [140/488] , Loss: 0.0322711654007435 \n",
      "Epoch [26/5000] , Step [150/488] , Loss: 0.0331220999360085 \n",
      "Epoch [26/5000] , Step [160/488] , Loss: 0.0328635983169079 \n",
      "Epoch [26/5000] , Step [170/488] , Loss: 0.0332066901028156 \n",
      "Epoch [26/5000] , Step [180/488] , Loss: 0.0324549451470375 \n",
      "Epoch [26/5000] , Step [190/488] , Loss: 0.0327834412455559 \n",
      "Epoch [26/5000] , Step [200/488] , Loss: 0.0322504453361034 \n",
      "Epoch [26/5000] , Step [210/488] , Loss: 0.0321156568825245 \n",
      "Epoch [26/5000] , Step [220/488] , Loss: 0.0327167809009552 \n",
      "Epoch [26/5000] , Step [230/488] , Loss: 0.0325780138373375 \n",
      "Epoch [26/5000] , Step [240/488] , Loss: 0.0327901095151901 \n",
      "Epoch [26/5000] , Step [250/488] , Loss: 0.0327948592603207 \n",
      "Epoch [26/5000] , Step [260/488] , Loss: 0.0322790257632732 \n",
      "Epoch [26/5000] , Step [270/488] , Loss: 0.0322882235050201 \n",
      "Epoch [26/5000] , Step [280/488] , Loss: 0.0327703505754471 \n",
      "Epoch [26/5000] , Step [290/488] , Loss: 0.0321087464690208 \n",
      "Epoch [26/5000] , Step [300/488] , Loss: 0.0329595319926739 \n",
      "Epoch [26/5000] , Step [310/488] , Loss: 0.0321819819509983 \n",
      "Epoch [26/5000] , Step [320/488] , Loss: 0.0325316973030567 \n",
      "Epoch [26/5000] , Step [330/488] , Loss: 0.0324496813118458 \n",
      "Epoch [26/5000] , Step [340/488] , Loss: 0.0324678011238575 \n",
      "Epoch [26/5000] , Step [350/488] , Loss: 0.0323545597493649 \n",
      "Epoch [26/5000] , Step [360/488] , Loss: 0.0318931229412556 \n",
      "Epoch [26/5000] , Step [370/488] , Loss: 0.0332015901803970 \n",
      "Epoch [26/5000] , Step [380/488] , Loss: 0.0323213711380959 \n",
      "Epoch [26/5000] , Step [390/488] , Loss: 0.0326695926487446 \n",
      "Epoch [26/5000] , Step [400/488] , Loss: 0.0324111655354500 \n",
      "Epoch [26/5000] , Step [410/488] , Loss: 0.0319117642939091 \n",
      "Epoch [26/5000] , Step [420/488] , Loss: 0.0319950617849827 \n",
      "Epoch [26/5000] , Step [430/488] , Loss: 0.0325283706188202 \n",
      "Epoch [26/5000] , Step [440/488] , Loss: 0.0330016203224659 \n",
      "Epoch [26/5000] , Step [450/488] , Loss: 0.0322854965925217 \n",
      "Epoch [26/5000] , Step [460/488] , Loss: 0.0322352871298790 \n",
      "Epoch [26/5000] , Step [470/488] , Loss: 0.0327517576515675 \n",
      "Epoch [26/5000] , Step [480/488] , Loss: 0.0336774289608002 \n",
      "Epoch [27/5000] , Step [10/488] , Loss: 0.0321368277072906 \n",
      "Epoch [27/5000] , Step [20/488] , Loss: 0.0327163040637970 \n",
      "Epoch [27/5000] , Step [30/488] , Loss: 0.0322894901037216 \n",
      "Epoch [27/5000] , Step [40/488] , Loss: 0.0319684594869614 \n",
      "Epoch [27/5000] , Step [50/488] , Loss: 0.0325129181146622 \n",
      "Epoch [27/5000] , Step [60/488] , Loss: 0.0325453765690327 \n",
      "Epoch [27/5000] , Step [70/488] , Loss: 0.0329175107181072 \n",
      "Epoch [27/5000] , Step [80/488] , Loss: 0.0327454283833504 \n",
      "Epoch [27/5000] , Step [90/488] , Loss: 0.0325256288051605 \n",
      "Epoch [27/5000] , Step [100/488] , Loss: 0.0319752842187881 \n",
      "Epoch [27/5000] , Step [110/488] , Loss: 0.0322548113763332 \n",
      "Epoch [27/5000] , Step [120/488] , Loss: 0.0323731005191803 \n",
      "Epoch [27/5000] , Step [130/488] , Loss: 0.0320407561957836 \n",
      "Epoch [27/5000] , Step [140/488] , Loss: 0.0322744436562061 \n",
      "Epoch [27/5000] , Step [150/488] , Loss: 0.0330638624727726 \n",
      "Epoch [27/5000] , Step [160/488] , Loss: 0.0329449959099293 \n",
      "Epoch [27/5000] , Step [170/488] , Loss: 0.0326177887618542 \n",
      "Epoch [27/5000] , Step [180/488] , Loss: 0.0327354036271572 \n",
      "Epoch [27/5000] , Step [190/488] , Loss: 0.0328264832496643 \n",
      "Epoch [27/5000] , Step [200/488] , Loss: 0.0321373976767063 \n",
      "Epoch [27/5000] , Step [210/488] , Loss: 0.0319258682429790 \n",
      "Epoch [27/5000] , Step [220/488] , Loss: 0.0329026058316231 \n",
      "Epoch [27/5000] , Step [230/488] , Loss: 0.0324895791709423 \n",
      "Epoch [27/5000] , Step [240/488] , Loss: 0.0326389335095882 \n",
      "Epoch [27/5000] , Step [250/488] , Loss: 0.0330870151519775 \n",
      "Epoch [27/5000] , Step [260/488] , Loss: 0.0331177450716496 \n",
      "Epoch [27/5000] , Step [270/488] , Loss: 0.0325276665389538 \n",
      "Epoch [27/5000] , Step [280/488] , Loss: 0.0329121500253677 \n",
      "Epoch [27/5000] , Step [290/488] , Loss: 0.0328213647007942 \n",
      "Epoch [27/5000] , Step [300/488] , Loss: 0.0324366576969624 \n",
      "Epoch [27/5000] , Step [310/488] , Loss: 0.0322690047323704 \n",
      "Epoch [27/5000] , Step [320/488] , Loss: 0.0326015390455723 \n",
      "Epoch [27/5000] , Step [330/488] , Loss: 0.0325114913284779 \n",
      "Epoch [27/5000] , Step [340/488] , Loss: 0.0331859588623047 \n",
      "Epoch [27/5000] , Step [350/488] , Loss: 0.0323806181550026 \n",
      "Epoch [27/5000] , Step [360/488] , Loss: 0.0327519029378891 \n",
      "Epoch [27/5000] , Step [370/488] , Loss: 0.0324592143297195 \n",
      "Epoch [27/5000] , Step [380/488] , Loss: 0.0324104279279709 \n",
      "Epoch [27/5000] , Step [390/488] , Loss: 0.0318466238677502 \n",
      "Epoch [27/5000] , Step [400/488] , Loss: 0.0325944237411022 \n",
      "Epoch [27/5000] , Step [410/488] , Loss: 0.0320238843560219 \n",
      "Epoch [27/5000] , Step [420/488] , Loss: 0.0318804681301117 \n",
      "Epoch [27/5000] , Step [430/488] , Loss: 0.0319157056510448 \n",
      "Epoch [27/5000] , Step [440/488] , Loss: 0.0327783636748791 \n",
      "Epoch [27/5000] , Step [450/488] , Loss: 0.0327926129102707 \n",
      "Epoch [27/5000] , Step [460/488] , Loss: 0.0325454473495483 \n",
      "Epoch [27/5000] , Step [470/488] , Loss: 0.0326844789087772 \n",
      "Epoch [27/5000] , Step [480/488] , Loss: 0.0328761674463749 \n",
      "Epoch [28/5000] , Step [10/488] , Loss: 0.0321630164980888 \n",
      "Epoch [28/5000] , Step [20/488] , Loss: 0.0320145078003407 \n",
      "Epoch [28/5000] , Step [30/488] , Loss: 0.0327047631144524 \n",
      "Epoch [28/5000] , Step [40/488] , Loss: 0.0327047593891621 \n",
      "Epoch [28/5000] , Step [50/488] , Loss: 0.0326502472162247 \n",
      "Epoch [28/5000] , Step [60/488] , Loss: 0.0329538844525814 \n",
      "Epoch [28/5000] , Step [70/488] , Loss: 0.0323006734251976 \n",
      "Epoch [28/5000] , Step [80/488] , Loss: 0.0328848958015442 \n",
      "Epoch [28/5000] , Step [90/488] , Loss: 0.0325324758887291 \n",
      "Epoch [28/5000] , Step [100/488] , Loss: 0.0321375168859959 \n",
      "Epoch [28/5000] , Step [110/488] , Loss: 0.0330585278570652 \n",
      "Epoch [28/5000] , Step [120/488] , Loss: 0.0321373343467712 \n",
      "Epoch [28/5000] , Step [130/488] , Loss: 0.0322426743805408 \n",
      "Epoch [28/5000] , Step [140/488] , Loss: 0.0325789526104927 \n",
      "Epoch [28/5000] , Step [150/488] , Loss: 0.0323534645140171 \n",
      "Epoch [28/5000] , Step [160/488] , Loss: 0.0323080345988274 \n",
      "Epoch [28/5000] , Step [170/488] , Loss: 0.0322836600244045 \n",
      "Epoch [28/5000] , Step [180/488] , Loss: 0.0335162505507469 \n",
      "Epoch [28/5000] , Step [190/488] , Loss: 0.0316270515322685 \n",
      "Epoch [28/5000] , Step [200/488] , Loss: 0.0324198864400387 \n",
      "Epoch [28/5000] , Step [210/488] , Loss: 0.0324233286082745 \n",
      "Epoch [28/5000] , Step [220/488] , Loss: 0.0326877199113369 \n",
      "Epoch [28/5000] , Step [230/488] , Loss: 0.0323131531476974 \n",
      "Epoch [28/5000] , Step [240/488] , Loss: 0.0323861613869667 \n",
      "Epoch [28/5000] , Step [250/488] , Loss: 0.0324189625680447 \n",
      "Epoch [28/5000] , Step [260/488] , Loss: 0.0326261483132839 \n",
      "Epoch [28/5000] , Step [270/488] , Loss: 0.0330093614757061 \n",
      "Epoch [28/5000] , Step [280/488] , Loss: 0.0330485291779041 \n",
      "Epoch [28/5000] , Step [290/488] , Loss: 0.0329536944627762 \n",
      "Epoch [28/5000] , Step [300/488] , Loss: 0.0325827039778233 \n",
      "Epoch [28/5000] , Step [310/488] , Loss: 0.0329323820769787 \n",
      "Epoch [28/5000] , Step [320/488] , Loss: 0.0324226729571819 \n",
      "Epoch [28/5000] , Step [330/488] , Loss: 0.0324359312653542 \n",
      "Epoch [28/5000] , Step [340/488] , Loss: 0.0326297245919704 \n",
      "Epoch [28/5000] , Step [350/488] , Loss: 0.0326628834009171 \n",
      "Epoch [28/5000] , Step [360/488] , Loss: 0.0329518988728523 \n",
      "Epoch [28/5000] , Step [370/488] , Loss: 0.0323037914931774 \n",
      "Epoch [28/5000] , Step [380/488] , Loss: 0.0326236858963966 \n",
      "Epoch [28/5000] , Step [390/488] , Loss: 0.0324164144694805 \n",
      "Epoch [28/5000] , Step [400/488] , Loss: 0.0322545431554317 \n",
      "Epoch [28/5000] , Step [410/488] , Loss: 0.0324785076081753 \n",
      "Epoch [28/5000] , Step [420/488] , Loss: 0.0323517583310604 \n",
      "Epoch [28/5000] , Step [430/488] , Loss: 0.0321518853306770 \n",
      "Epoch [28/5000] , Step [440/488] , Loss: 0.0326967351138592 \n",
      "Epoch [28/5000] , Step [450/488] , Loss: 0.0329992286860943 \n",
      "Epoch [28/5000] , Step [460/488] , Loss: 0.0328831002116203 \n",
      "Epoch [28/5000] , Step [470/488] , Loss: 0.0323260836303234 \n",
      "Epoch [28/5000] , Step [480/488] , Loss: 0.0331205017864704 \n",
      "Epoch [29/5000] , Step [10/488] , Loss: 0.0322523042559624 \n",
      "Epoch [29/5000] , Step [20/488] , Loss: 0.0321021787822247 \n",
      "Epoch [29/5000] , Step [30/488] , Loss: 0.0330725461244583 \n",
      "Epoch [29/5000] , Step [40/488] , Loss: 0.0327333062887192 \n",
      "Epoch [29/5000] , Step [50/488] , Loss: 0.0316875837743282 \n",
      "Epoch [29/5000] , Step [60/488] , Loss: 0.0323993675410748 \n",
      "Epoch [29/5000] , Step [70/488] , Loss: 0.0327907986938953 \n",
      "Epoch [29/5000] , Step [80/488] , Loss: 0.0328431986272335 \n",
      "Epoch [29/5000] , Step [90/488] , Loss: 0.0320290029048920 \n",
      "Epoch [29/5000] , Step [100/488] , Loss: 0.0322796627879143 \n",
      "Epoch [29/5000] , Step [110/488] , Loss: 0.0323645994067192 \n",
      "Epoch [29/5000] , Step [120/488] , Loss: 0.0323670171201229 \n",
      "Epoch [29/5000] , Step [130/488] , Loss: 0.0327627584338188 \n",
      "Epoch [29/5000] , Step [140/488] , Loss: 0.0323980562388897 \n",
      "Epoch [29/5000] , Step [150/488] , Loss: 0.0322834253311157 \n",
      "Epoch [29/5000] , Step [160/488] , Loss: 0.0324409753084183 \n",
      "Epoch [29/5000] , Step [170/488] , Loss: 0.0323978215456009 \n",
      "Epoch [29/5000] , Step [180/488] , Loss: 0.0330443456768990 \n",
      "Epoch [29/5000] , Step [190/488] , Loss: 0.0322583578526974 \n",
      "Epoch [29/5000] , Step [200/488] , Loss: 0.0325264334678650 \n",
      "Epoch [29/5000] , Step [210/488] , Loss: 0.0324738174676895 \n",
      "Epoch [29/5000] , Step [220/488] , Loss: 0.0328063555061817 \n",
      "Epoch [29/5000] , Step [230/488] , Loss: 0.0326634757220745 \n",
      "Epoch [29/5000] , Step [240/488] , Loss: 0.0329577103257179 \n",
      "Epoch [29/5000] , Step [250/488] , Loss: 0.0328237265348434 \n",
      "Epoch [29/5000] , Step [260/488] , Loss: 0.0325077474117279 \n",
      "Epoch [29/5000] , Step [270/488] , Loss: 0.0326471775770187 \n",
      "Epoch [29/5000] , Step [280/488] , Loss: 0.0325760319828987 \n",
      "Epoch [29/5000] , Step [290/488] , Loss: 0.0325443334877491 \n",
      "Epoch [29/5000] , Step [300/488] , Loss: 0.0325699150562286 \n",
      "Epoch [29/5000] , Step [310/488] , Loss: 0.0328350551426411 \n",
      "Epoch [29/5000] , Step [320/488] , Loss: 0.0323382839560509 \n",
      "Epoch [29/5000] , Step [330/488] , Loss: 0.0323514528572559 \n",
      "Epoch [29/5000] , Step [340/488] , Loss: 0.0324417278170586 \n",
      "Epoch [29/5000] , Step [350/488] , Loss: 0.0326613523066044 \n",
      "Epoch [29/5000] , Step [360/488] , Loss: 0.0322391241788864 \n",
      "Epoch [29/5000] , Step [370/488] , Loss: 0.0323269478976727 \n",
      "Epoch [29/5000] , Step [380/488] , Loss: 0.0326786302030087 \n",
      "Epoch [29/5000] , Step [390/488] , Loss: 0.0323952697217464 \n",
      "Epoch [29/5000] , Step [400/488] , Loss: 0.0325732342898846 \n",
      "Epoch [29/5000] , Step [410/488] , Loss: 0.0321522168815136 \n",
      "Epoch [29/5000] , Step [420/488] , Loss: 0.0325732417404652 \n",
      "Epoch [29/5000] , Step [430/488] , Loss: 0.0329529792070389 \n",
      "Epoch [29/5000] , Step [440/488] , Loss: 0.0324725955724716 \n",
      "Epoch [29/5000] , Step [450/488] , Loss: 0.0328715741634369 \n",
      "Epoch [29/5000] , Step [460/488] , Loss: 0.0331227630376816 \n",
      "Epoch [29/5000] , Step [470/488] , Loss: 0.0323645509779453 \n",
      "Epoch [29/5000] , Step [480/488] , Loss: 0.0326756425201893 \n",
      "Epoch [30/5000] , Step [10/488] , Loss: 0.0325340293347836 \n",
      "Epoch [30/5000] , Step [20/488] , Loss: 0.0317198298871517 \n",
      "Epoch [30/5000] , Step [30/488] , Loss: 0.0329195298254490 \n",
      "Epoch [30/5000] , Step [40/488] , Loss: 0.0328773371875286 \n",
      "Epoch [30/5000] , Step [50/488] , Loss: 0.0321076475083828 \n",
      "Epoch [30/5000] , Step [60/488] , Loss: 0.0322485752403736 \n",
      "Epoch [30/5000] , Step [70/488] , Loss: 0.0323401466012001 \n",
      "Epoch [30/5000] , Step [80/488] , Loss: 0.0325941219925880 \n",
      "Epoch [30/5000] , Step [90/488] , Loss: 0.0328429751098156 \n",
      "Epoch [30/5000] , Step [100/488] , Loss: 0.0328943915665150 \n",
      "Epoch [30/5000] , Step [110/488] , Loss: 0.0328922420740128 \n",
      "Epoch [30/5000] , Step [120/488] , Loss: 0.0328486375510693 \n",
      "Epoch [30/5000] , Step [130/488] , Loss: 0.0331531353294849 \n",
      "Epoch [30/5000] , Step [140/488] , Loss: 0.0327619016170502 \n",
      "Epoch [30/5000] , Step [150/488] , Loss: 0.0327985286712646 \n",
      "Epoch [30/5000] , Step [160/488] , Loss: 0.0320584662258625 \n",
      "Epoch [30/5000] , Step [170/488] , Loss: 0.0327207632362843 \n",
      "Epoch [30/5000] , Step [180/488] , Loss: 0.0325432009994984 \n",
      "Epoch [30/5000] , Step [190/488] , Loss: 0.0321823395788670 \n",
      "Epoch [30/5000] , Step [200/488] , Loss: 0.0323192775249481 \n",
      "Epoch [30/5000] , Step [210/488] , Loss: 0.0324946641921997 \n",
      "Epoch [30/5000] , Step [220/488] , Loss: 0.0321614854037762 \n",
      "Epoch [30/5000] , Step [230/488] , Loss: 0.0328203216195107 \n",
      "Epoch [30/5000] , Step [240/488] , Loss: 0.0325032211840153 \n",
      "Epoch [30/5000] , Step [250/488] , Loss: 0.0324273034930229 \n",
      "Epoch [30/5000] , Step [260/488] , Loss: 0.0324402302503586 \n",
      "Epoch [30/5000] , Step [270/488] , Loss: 0.0326508469879627 \n",
      "Epoch [30/5000] , Step [280/488] , Loss: 0.0323677510023117 \n",
      "Epoch [30/5000] , Step [290/488] , Loss: 0.0322204194962978 \n",
      "Epoch [30/5000] , Step [300/488] , Loss: 0.0326502919197083 \n",
      "Epoch [30/5000] , Step [310/488] , Loss: 0.0331433042883873 \n",
      "Epoch [30/5000] , Step [320/488] , Loss: 0.0324778668582439 \n",
      "Epoch [30/5000] , Step [330/488] , Loss: 0.0321759432554245 \n",
      "Epoch [30/5000] , Step [340/488] , Loss: 0.0326046682894230 \n",
      "Epoch [30/5000] , Step [350/488] , Loss: 0.0335318148136139 \n",
      "Epoch [30/5000] , Step [360/488] , Loss: 0.0319313555955887 \n",
      "Epoch [30/5000] , Step [370/488] , Loss: 0.0327116250991821 \n",
      "Epoch [30/5000] , Step [380/488] , Loss: 0.0317293889820576 \n",
      "Epoch [30/5000] , Step [390/488] , Loss: 0.0323785208165646 \n",
      "Epoch [30/5000] , Step [400/488] , Loss: 0.0330554805696011 \n",
      "Epoch [30/5000] , Step [410/488] , Loss: 0.0323751457035542 \n",
      "Epoch [30/5000] , Step [420/488] , Loss: 0.0320384129881859 \n",
      "Epoch [30/5000] , Step [430/488] , Loss: 0.0319453887641430 \n",
      "Epoch [30/5000] , Step [440/488] , Loss: 0.0325950980186462 \n",
      "Epoch [30/5000] , Step [450/488] , Loss: 0.0328500419855118 \n",
      "Epoch [30/5000] , Step [460/488] , Loss: 0.0322106257081032 \n",
      "Epoch [30/5000] , Step [470/488] , Loss: 0.0321128591895103 \n",
      "Epoch [30/5000] , Step [480/488] , Loss: 0.0325651802122593 \n",
      "Epoch [31/5000] , Step [10/488] , Loss: 0.0324801765382290 \n",
      "Epoch [31/5000] , Step [20/488] , Loss: 0.0322100184857845 \n",
      "Epoch [31/5000] , Step [30/488] , Loss: 0.0324889719486237 \n",
      "Epoch [31/5000] , Step [40/488] , Loss: 0.0326545648276806 \n",
      "Epoch [31/5000] , Step [50/488] , Loss: 0.0329591743648052 \n",
      "Epoch [31/5000] , Step [60/488] , Loss: 0.0324014537036419 \n",
      "Epoch [31/5000] , Step [70/488] , Loss: 0.0324855856597424 \n",
      "Epoch [31/5000] , Step [80/488] , Loss: 0.0328837707638741 \n",
      "Epoch [31/5000] , Step [90/488] , Loss: 0.0326032713055611 \n",
      "Epoch [31/5000] , Step [100/488] , Loss: 0.0322704687714577 \n",
      "Epoch [31/5000] , Step [110/488] , Loss: 0.0323097296059132 \n",
      "Epoch [31/5000] , Step [120/488] , Loss: 0.0327151790261269 \n",
      "Epoch [31/5000] , Step [130/488] , Loss: 0.0327550880610943 \n",
      "Epoch [31/5000] , Step [140/488] , Loss: 0.0327342040836811 \n",
      "Epoch [31/5000] , Step [150/488] , Loss: 0.0326958149671555 \n",
      "Epoch [31/5000] , Step [160/488] , Loss: 0.0328218266367912 \n",
      "Epoch [31/5000] , Step [170/488] , Loss: 0.0321302488446236 \n",
      "Epoch [31/5000] , Step [180/488] , Loss: 0.0325305946171284 \n",
      "Epoch [31/5000] , Step [190/488] , Loss: 0.0325999632477760 \n",
      "Epoch [31/5000] , Step [200/488] , Loss: 0.0326400026679039 \n",
      "Epoch [31/5000] , Step [210/488] , Loss: 0.0321668051183224 \n",
      "Epoch [31/5000] , Step [220/488] , Loss: 0.0320747196674347 \n",
      "Epoch [31/5000] , Step [230/488] , Loss: 0.0322379581630230 \n",
      "Epoch [31/5000] , Step [240/488] , Loss: 0.0327529571950436 \n",
      "Epoch [31/5000] , Step [250/488] , Loss: 0.0325863622128963 \n",
      "Epoch [31/5000] , Step [260/488] , Loss: 0.0322155952453613 \n",
      "Epoch [31/5000] , Step [270/488] , Loss: 0.0324339903891087 \n",
      "Epoch [31/5000] , Step [280/488] , Loss: 0.0329440571367741 \n",
      "Epoch [31/5000] , Step [290/488] , Loss: 0.0330232121050358 \n",
      "Epoch [31/5000] , Step [300/488] , Loss: 0.0323649309575558 \n",
      "Epoch [31/5000] , Step [310/488] , Loss: 0.0330546312034130 \n",
      "Epoch [31/5000] , Step [320/488] , Loss: 0.0321453399956226 \n",
      "Epoch [31/5000] , Step [330/488] , Loss: 0.0325209945440292 \n",
      "Epoch [31/5000] , Step [340/488] , Loss: 0.0320717804133892 \n",
      "Epoch [31/5000] , Step [350/488] , Loss: 0.0330366380512714 \n",
      "Epoch [31/5000] , Step [360/488] , Loss: 0.0323003195226192 \n",
      "Epoch [31/5000] , Step [370/488] , Loss: 0.0329517312347889 \n",
      "Epoch [31/5000] , Step [380/488] , Loss: 0.0323355793952942 \n",
      "Epoch [31/5000] , Step [390/488] , Loss: 0.0325983725488186 \n",
      "Epoch [31/5000] , Step [400/488] , Loss: 0.0325668416917324 \n",
      "Epoch [31/5000] , Step [410/488] , Loss: 0.0321934372186661 \n",
      "Epoch [31/5000] , Step [420/488] , Loss: 0.0324126780033112 \n",
      "Epoch [31/5000] , Step [430/488] , Loss: 0.0324668176472187 \n",
      "Epoch [31/5000] , Step [440/488] , Loss: 0.0324543081223965 \n",
      "Epoch [31/5000] , Step [450/488] , Loss: 0.0322660356760025 \n",
      "Epoch [31/5000] , Step [460/488] , Loss: 0.0327431038022041 \n",
      "Epoch [31/5000] , Step [470/488] , Loss: 0.0324122421443462 \n",
      "Epoch [31/5000] , Step [480/488] , Loss: 0.0329421684145927 \n",
      "Epoch [32/5000] , Step [10/488] , Loss: 0.0319605283439159 \n",
      "Epoch [32/5000] , Step [20/488] , Loss: 0.0326719954609871 \n",
      "Epoch [32/5000] , Step [30/488] , Loss: 0.0325041003525257 \n",
      "Epoch [32/5000] , Step [40/488] , Loss: 0.0328563824295998 \n",
      "Epoch [32/5000] , Step [50/488] , Loss: 0.0323106087744236 \n",
      "Epoch [32/5000] , Step [60/488] , Loss: 0.0325999855995178 \n",
      "Epoch [32/5000] , Step [70/488] , Loss: 0.0320453494787216 \n",
      "Epoch [32/5000] , Step [80/488] , Loss: 0.0320223569869995 \n",
      "Epoch [32/5000] , Step [90/488] , Loss: 0.0327329710125923 \n",
      "Epoch [32/5000] , Step [100/488] , Loss: 0.0329190678894520 \n",
      "Epoch [32/5000] , Step [110/488] , Loss: 0.0331473127007484 \n",
      "Epoch [32/5000] , Step [120/488] , Loss: 0.0324377827346325 \n",
      "Epoch [32/5000] , Step [130/488] , Loss: 0.0323386676609516 \n",
      "Epoch [32/5000] , Step [140/488] , Loss: 0.0322816148400307 \n",
      "Epoch [32/5000] , Step [150/488] , Loss: 0.0324031636118889 \n",
      "Epoch [32/5000] , Step [160/488] , Loss: 0.0323019772768021 \n",
      "Epoch [32/5000] , Step [170/488] , Loss: 0.0327482335269451 \n",
      "Epoch [32/5000] , Step [180/488] , Loss: 0.0323833152651787 \n",
      "Epoch [32/5000] , Step [190/488] , Loss: 0.0325903333723545 \n",
      "Epoch [32/5000] , Step [200/488] , Loss: 0.0326105765998363 \n",
      "Epoch [32/5000] , Step [210/488] , Loss: 0.0325672291219234 \n",
      "Epoch [32/5000] , Step [220/488] , Loss: 0.0324850268661976 \n",
      "Epoch [32/5000] , Step [230/488] , Loss: 0.0329609438776970 \n",
      "Epoch [32/5000] , Step [240/488] , Loss: 0.0331406891345978 \n",
      "Epoch [32/5000] , Step [250/488] , Loss: 0.0321581475436687 \n",
      "Epoch [32/5000] , Step [260/488] , Loss: 0.0334779731929302 \n",
      "Epoch [32/5000] , Step [270/488] , Loss: 0.0329052098095417 \n",
      "Epoch [32/5000] , Step [280/488] , Loss: 0.0321805216372013 \n",
      "Epoch [32/5000] , Step [290/488] , Loss: 0.0320673324167728 \n",
      "Epoch [32/5000] , Step [300/488] , Loss: 0.0324641019105911 \n",
      "Epoch [32/5000] , Step [310/488] , Loss: 0.0314604714512825 \n",
      "Epoch [32/5000] , Step [320/488] , Loss: 0.0325108878314495 \n",
      "Epoch [32/5000] , Step [330/488] , Loss: 0.0323078893125057 \n",
      "Epoch [32/5000] , Step [340/488] , Loss: 0.0325232073664665 \n",
      "Epoch [32/5000] , Step [350/488] , Loss: 0.0329490453004837 \n",
      "Epoch [32/5000] , Step [360/488] , Loss: 0.0330939255654812 \n",
      "Epoch [32/5000] , Step [370/488] , Loss: 0.0322455354034901 \n",
      "Epoch [32/5000] , Step [380/488] , Loss: 0.0322374179959297 \n",
      "Epoch [32/5000] , Step [390/488] , Loss: 0.0331700965762138 \n",
      "Epoch [32/5000] , Step [400/488] , Loss: 0.0325247347354889 \n",
      "Epoch [32/5000] , Step [410/488] , Loss: 0.0324159301817417 \n",
      "Epoch [32/5000] , Step [420/488] , Loss: 0.0314944833517075 \n",
      "Epoch [32/5000] , Step [430/488] , Loss: 0.0326654203236103 \n",
      "Epoch [32/5000] , Step [440/488] , Loss: 0.0326092019677162 \n",
      "Epoch [32/5000] , Step [450/488] , Loss: 0.0326201058924198 \n",
      "Epoch [32/5000] , Step [460/488] , Loss: 0.0321170091629028 \n",
      "Epoch [32/5000] , Step [470/488] , Loss: 0.0330602191388607 \n",
      "Epoch [32/5000] , Step [480/488] , Loss: 0.0319845750927925 \n",
      "Epoch [33/5000] , Step [10/488] , Loss: 0.0327539592981339 \n",
      "Epoch [33/5000] , Step [20/488] , Loss: 0.0326571427285671 \n",
      "Epoch [33/5000] , Step [30/488] , Loss: 0.0323108471930027 \n",
      "Epoch [33/5000] , Step [40/488] , Loss: 0.0324902571737766 \n",
      "Epoch [33/5000] , Step [50/488] , Loss: 0.0322308279573917 \n",
      "Epoch [33/5000] , Step [60/488] , Loss: 0.0323071219027042 \n",
      "Epoch [33/5000] , Step [70/488] , Loss: 0.0331269539892673 \n",
      "Epoch [33/5000] , Step [80/488] , Loss: 0.0329547002911568 \n",
      "Epoch [33/5000] , Step [90/488] , Loss: 0.0325717665255070 \n",
      "Epoch [33/5000] , Step [100/488] , Loss: 0.0316821038722992 \n",
      "Epoch [33/5000] , Step [110/488] , Loss: 0.0332326926290989 \n",
      "Epoch [33/5000] , Step [120/488] , Loss: 0.0321595408022404 \n",
      "Epoch [33/5000] , Step [130/488] , Loss: 0.0319865383207798 \n",
      "Epoch [33/5000] , Step [140/488] , Loss: 0.0321865566074848 \n",
      "Epoch [33/5000] , Step [150/488] , Loss: 0.0328016094863415 \n",
      "Epoch [33/5000] , Step [160/488] , Loss: 0.0330419577658176 \n",
      "Epoch [33/5000] , Step [170/488] , Loss: 0.0328008159995079 \n",
      "Epoch [33/5000] , Step [180/488] , Loss: 0.0322061106562614 \n",
      "Epoch [33/5000] , Step [190/488] , Loss: 0.0326900742948055 \n",
      "Epoch [33/5000] , Step [200/488] , Loss: 0.0330642238259315 \n",
      "Epoch [33/5000] , Step [210/488] , Loss: 0.0322785377502441 \n",
      "Epoch [33/5000] , Step [220/488] , Loss: 0.0332235321402550 \n",
      "Epoch [33/5000] , Step [230/488] , Loss: 0.0328124612569809 \n",
      "Epoch [33/5000] , Step [240/488] , Loss: 0.0328892618417740 \n",
      "Epoch [33/5000] , Step [250/488] , Loss: 0.0332161858677864 \n",
      "Epoch [33/5000] , Step [260/488] , Loss: 0.0321663133800030 \n",
      "Epoch [33/5000] , Step [270/488] , Loss: 0.0326739996671677 \n",
      "Epoch [33/5000] , Step [280/488] , Loss: 0.0332965403795242 \n",
      "Epoch [33/5000] , Step [290/488] , Loss: 0.0327364839613438 \n",
      "Epoch [33/5000] , Step [300/488] , Loss: 0.0328499227762222 \n",
      "Epoch [33/5000] , Step [310/488] , Loss: 0.0327370464801788 \n",
      "Epoch [33/5000] , Step [320/488] , Loss: 0.0324394516646862 \n",
      "Epoch [33/5000] , Step [330/488] , Loss: 0.0323544368147850 \n",
      "Epoch [33/5000] , Step [340/488] , Loss: 0.0326164215803146 \n",
      "Epoch [33/5000] , Step [350/488] , Loss: 0.0325728468596935 \n",
      "Epoch [33/5000] , Step [360/488] , Loss: 0.0322284065186977 \n",
      "Epoch [33/5000] , Step [370/488] , Loss: 0.0317510142922401 \n",
      "Epoch [33/5000] , Step [380/488] , Loss: 0.0324553847312927 \n",
      "Epoch [33/5000] , Step [390/488] , Loss: 0.0322287604212761 \n",
      "Epoch [33/5000] , Step [400/488] , Loss: 0.0326414406299591 \n",
      "Epoch [33/5000] , Step [410/488] , Loss: 0.0327002964913845 \n",
      "Epoch [33/5000] , Step [420/488] , Loss: 0.0327014289796352 \n",
      "Epoch [33/5000] , Step [430/488] , Loss: 0.0322118736803532 \n",
      "Epoch [33/5000] , Step [440/488] , Loss: 0.0327437184751034 \n",
      "Epoch [33/5000] , Step [450/488] , Loss: 0.0328941866755486 \n",
      "Epoch [33/5000] , Step [460/488] , Loss: 0.0323975756764412 \n",
      "Epoch [33/5000] , Step [470/488] , Loss: 0.0325787961483002 \n",
      "Epoch [33/5000] , Step [480/488] , Loss: 0.0324953608214855 \n",
      "Epoch [34/5000] , Step [10/488] , Loss: 0.0325856693089008 \n",
      "Epoch [34/5000] , Step [20/488] , Loss: 0.0316610932350159 \n",
      "Epoch [34/5000] , Step [30/488] , Loss: 0.0325828455388546 \n",
      "Epoch [34/5000] , Step [40/488] , Loss: 0.0326337218284607 \n",
      "Epoch [34/5000] , Step [50/488] , Loss: 0.0320606306195259 \n",
      "Epoch [34/5000] , Step [60/488] , Loss: 0.0323785431683064 \n",
      "Epoch [34/5000] , Step [70/488] , Loss: 0.0325112044811249 \n",
      "Epoch [34/5000] , Step [80/488] , Loss: 0.0320969410240650 \n",
      "Epoch [34/5000] , Step [90/488] , Loss: 0.0322638191282749 \n",
      "Epoch [34/5000] , Step [100/488] , Loss: 0.0327120497822762 \n",
      "Epoch [34/5000] , Step [110/488] , Loss: 0.0326123349368572 \n",
      "Epoch [34/5000] , Step [120/488] , Loss: 0.0328516736626625 \n",
      "Epoch [34/5000] , Step [130/488] , Loss: 0.0327415429055691 \n",
      "Epoch [34/5000] , Step [140/488] , Loss: 0.0324528366327286 \n",
      "Epoch [34/5000] , Step [150/488] , Loss: 0.0319453738629818 \n",
      "Epoch [34/5000] , Step [160/488] , Loss: 0.0329006500542164 \n",
      "Epoch [34/5000] , Step [170/488] , Loss: 0.0316743850708008 \n",
      "Epoch [34/5000] , Step [180/488] , Loss: 0.0325222760438919 \n",
      "Epoch [34/5000] , Step [190/488] , Loss: 0.0326430425047874 \n",
      "Epoch [34/5000] , Step [200/488] , Loss: 0.0321376733481884 \n",
      "Epoch [34/5000] , Step [210/488] , Loss: 0.0323562361299992 \n",
      "Epoch [34/5000] , Step [220/488] , Loss: 0.0325258970260620 \n",
      "Epoch [34/5000] , Step [230/488] , Loss: 0.0331304296851158 \n",
      "Epoch [34/5000] , Step [240/488] , Loss: 0.0327701829373837 \n",
      "Epoch [34/5000] , Step [250/488] , Loss: 0.0320108905434608 \n",
      "Epoch [34/5000] , Step [260/488] , Loss: 0.0318443402647972 \n",
      "Epoch [34/5000] , Step [270/488] , Loss: 0.0318894125521183 \n",
      "Epoch [34/5000] , Step [280/488] , Loss: 0.0328542217612267 \n",
      "Epoch [34/5000] , Step [290/488] , Loss: 0.0319182649254799 \n",
      "Epoch [34/5000] , Step [300/488] , Loss: 0.0329310595989227 \n",
      "Epoch [34/5000] , Step [310/488] , Loss: 0.0326846726238728 \n",
      "Epoch [34/5000] , Step [320/488] , Loss: 0.0323974862694740 \n",
      "Epoch [34/5000] , Step [330/488] , Loss: 0.0325605124235153 \n",
      "Epoch [34/5000] , Step [340/488] , Loss: 0.0324776060879230 \n",
      "Epoch [34/5000] , Step [350/488] , Loss: 0.0329090021550655 \n",
      "Epoch [34/5000] , Step [360/488] , Loss: 0.0326614119112492 \n",
      "Epoch [34/5000] , Step [370/488] , Loss: 0.0322459861636162 \n",
      "Epoch [34/5000] , Step [380/488] , Loss: 0.0327585488557816 \n",
      "Epoch [34/5000] , Step [390/488] , Loss: 0.0326106883585453 \n",
      "Epoch [34/5000] , Step [400/488] , Loss: 0.0325547270476818 \n",
      "Epoch [34/5000] , Step [410/488] , Loss: 0.0317142084240913 \n",
      "Epoch [34/5000] , Step [420/488] , Loss: 0.0326062552630901 \n",
      "Epoch [34/5000] , Step [430/488] , Loss: 0.0327400229871273 \n",
      "Epoch [34/5000] , Step [440/488] , Loss: 0.0330149605870247 \n",
      "Epoch [34/5000] , Step [450/488] , Loss: 0.0327929668128490 \n",
      "Epoch [34/5000] , Step [460/488] , Loss: 0.0319447517395020 \n",
      "Epoch [34/5000] , Step [470/488] , Loss: 0.0324961170554161 \n",
      "Epoch [34/5000] , Step [480/488] , Loss: 0.0330602787435055 \n",
      "Epoch [35/5000] , Step [10/488] , Loss: 0.0326574370265007 \n",
      "Epoch [35/5000] , Step [20/488] , Loss: 0.0325127728283405 \n",
      "Epoch [35/5000] , Step [30/488] , Loss: 0.0330384559929371 \n",
      "Epoch [35/5000] , Step [40/488] , Loss: 0.0331907160580158 \n",
      "Epoch [35/5000] , Step [50/488] , Loss: 0.0329751819372177 \n",
      "Epoch [35/5000] , Step [60/488] , Loss: 0.0323065333068371 \n",
      "Epoch [35/5000] , Step [70/488] , Loss: 0.0320500582456589 \n",
      "Epoch [35/5000] , Step [80/488] , Loss: 0.0325801819562912 \n",
      "Epoch [35/5000] , Step [90/488] , Loss: 0.0329727903008461 \n",
      "Epoch [35/5000] , Step [100/488] , Loss: 0.0322396531701088 \n",
      "Epoch [35/5000] , Step [110/488] , Loss: 0.0325607955455780 \n",
      "Epoch [35/5000] , Step [120/488] , Loss: 0.0325419828295708 \n",
      "Epoch [35/5000] , Step [130/488] , Loss: 0.0325824096798897 \n",
      "Epoch [35/5000] , Step [140/488] , Loss: 0.0328663140535355 \n",
      "Epoch [35/5000] , Step [150/488] , Loss: 0.0324225425720215 \n",
      "Epoch [35/5000] , Step [160/488] , Loss: 0.0324994474649429 \n",
      "Epoch [35/5000] , Step [170/488] , Loss: 0.0324691347777843 \n",
      "Epoch [35/5000] , Step [180/488] , Loss: 0.0325832813978195 \n",
      "Epoch [35/5000] , Step [190/488] , Loss: 0.0330422297120094 \n",
      "Epoch [35/5000] , Step [200/488] , Loss: 0.0321407206356525 \n",
      "Epoch [35/5000] , Step [210/488] , Loss: 0.0326209403574467 \n",
      "Epoch [35/5000] , Step [220/488] , Loss: 0.0327144749462605 \n",
      "Epoch [35/5000] , Step [230/488] , Loss: 0.0334752351045609 \n",
      "Epoch [35/5000] , Step [240/488] , Loss: 0.0323891900479794 \n",
      "Epoch [35/5000] , Step [250/488] , Loss: 0.0326359644532204 \n",
      "Epoch [35/5000] , Step [260/488] , Loss: 0.0319961234927177 \n",
      "Epoch [35/5000] , Step [270/488] , Loss: 0.0328508913516998 \n",
      "Epoch [35/5000] , Step [280/488] , Loss: 0.0322621874511242 \n",
      "Epoch [35/5000] , Step [290/488] , Loss: 0.0323394872248173 \n",
      "Epoch [35/5000] , Step [300/488] , Loss: 0.0326801203191280 \n",
      "Epoch [35/5000] , Step [310/488] , Loss: 0.0322736203670502 \n",
      "Epoch [35/5000] , Step [320/488] , Loss: 0.0324542261660099 \n",
      "Epoch [35/5000] , Step [330/488] , Loss: 0.0326956063508987 \n",
      "Epoch [35/5000] , Step [340/488] , Loss: 0.0331506282091141 \n",
      "Epoch [35/5000] , Step [350/488] , Loss: 0.0320153459906578 \n",
      "Epoch [35/5000] , Step [360/488] , Loss: 0.0327224880456924 \n",
      "Epoch [35/5000] , Step [370/488] , Loss: 0.0328630544245243 \n",
      "Epoch [35/5000] , Step [380/488] , Loss: 0.0327540673315525 \n",
      "Epoch [35/5000] , Step [390/488] , Loss: 0.0328741967678070 \n",
      "Epoch [35/5000] , Step [400/488] , Loss: 0.0326345488429070 \n",
      "Epoch [35/5000] , Step [410/488] , Loss: 0.0327152125537395 \n",
      "Epoch [35/5000] , Step [420/488] , Loss: 0.0321774110198021 \n",
      "Epoch [35/5000] , Step [430/488] , Loss: 0.0324010960757732 \n",
      "Epoch [35/5000] , Step [440/488] , Loss: 0.0324535407125950 \n",
      "Epoch [35/5000] , Step [450/488] , Loss: 0.0326495878398418 \n",
      "Epoch [35/5000] , Step [460/488] , Loss: 0.0323937162756920 \n",
      "Epoch [35/5000] , Step [470/488] , Loss: 0.0329554006457329 \n",
      "Epoch [35/5000] , Step [480/488] , Loss: 0.0333080813288689 \n",
      "Epoch [36/5000] , Step [10/488] , Loss: 0.0324449501931667 \n",
      "Epoch [36/5000] , Step [20/488] , Loss: 0.0325362309813499 \n",
      "Epoch [36/5000] , Step [30/488] , Loss: 0.0320126526057720 \n",
      "Epoch [36/5000] , Step [40/488] , Loss: 0.0324537046253681 \n",
      "Epoch [36/5000] , Step [50/488] , Loss: 0.0324217639863491 \n",
      "Epoch [36/5000] , Step [60/488] , Loss: 0.0326683036983013 \n",
      "Epoch [36/5000] , Step [70/488] , Loss: 0.0325525626540184 \n",
      "Epoch [36/5000] , Step [80/488] , Loss: 0.0324841141700745 \n",
      "Epoch [36/5000] , Step [90/488] , Loss: 0.0328175984323025 \n",
      "Epoch [36/5000] , Step [100/488] , Loss: 0.0326940752565861 \n",
      "Epoch [36/5000] , Step [110/488] , Loss: 0.0322964042425156 \n",
      "Epoch [36/5000] , Step [120/488] , Loss: 0.0311638265848160 \n",
      "Epoch [36/5000] , Step [130/488] , Loss: 0.0325211100280285 \n",
      "Epoch [36/5000] , Step [140/488] , Loss: 0.0324036888778210 \n",
      "Epoch [36/5000] , Step [150/488] , Loss: 0.0320829935371876 \n",
      "Epoch [36/5000] , Step [160/488] , Loss: 0.0322318747639656 \n",
      "Epoch [36/5000] , Step [170/488] , Loss: 0.0324096344411373 \n",
      "Epoch [36/5000] , Step [180/488] , Loss: 0.0328635536134243 \n",
      "Epoch [36/5000] , Step [190/488] , Loss: 0.0315045528113842 \n",
      "Epoch [36/5000] , Step [200/488] , Loss: 0.0318729542195797 \n",
      "Epoch [36/5000] , Step [210/488] , Loss: 0.0324430800974369 \n",
      "Epoch [36/5000] , Step [220/488] , Loss: 0.0321466475725174 \n",
      "Epoch [36/5000] , Step [230/488] , Loss: 0.0319324955344200 \n",
      "Epoch [36/5000] , Step [240/488] , Loss: 0.0325181521475315 \n",
      "Epoch [36/5000] , Step [250/488] , Loss: 0.0325389951467514 \n",
      "Epoch [36/5000] , Step [260/488] , Loss: 0.0326121337711811 \n",
      "Epoch [36/5000] , Step [270/488] , Loss: 0.0319721847772598 \n",
      "Epoch [36/5000] , Step [280/488] , Loss: 0.0331391654908657 \n",
      "Epoch [36/5000] , Step [290/488] , Loss: 0.0329300127923489 \n",
      "Epoch [36/5000] , Step [300/488] , Loss: 0.0320696197450161 \n",
      "Epoch [36/5000] , Step [310/488] , Loss: 0.0320256575942039 \n",
      "Epoch [36/5000] , Step [320/488] , Loss: 0.0318167582154274 \n",
      "Epoch [36/5000] , Step [330/488] , Loss: 0.0324121639132500 \n",
      "Epoch [36/5000] , Step [340/488] , Loss: 0.0327238291501999 \n",
      "Epoch [36/5000] , Step [350/488] , Loss: 0.0328590609133244 \n",
      "Epoch [36/5000] , Step [360/488] , Loss: 0.0325417853891850 \n",
      "Epoch [36/5000] , Step [370/488] , Loss: 0.0321806967258453 \n",
      "Epoch [36/5000] , Step [380/488] , Loss: 0.0328532382845879 \n",
      "Epoch [36/5000] , Step [390/488] , Loss: 0.0325807407498360 \n",
      "Epoch [36/5000] , Step [400/488] , Loss: 0.0322088226675987 \n",
      "Epoch [36/5000] , Step [410/488] , Loss: 0.0330383777618408 \n",
      "Epoch [36/5000] , Step [420/488] , Loss: 0.0318199023604393 \n",
      "Epoch [36/5000] , Step [430/488] , Loss: 0.0333454236388206 \n",
      "Epoch [36/5000] , Step [440/488] , Loss: 0.0320999510586262 \n",
      "Epoch [36/5000] , Step [450/488] , Loss: 0.0324132181704044 \n",
      "Epoch [36/5000] , Step [460/488] , Loss: 0.0328907445073128 \n",
      "Epoch [36/5000] , Step [470/488] , Loss: 0.0335587449371815 \n",
      "Epoch [36/5000] , Step [480/488] , Loss: 0.0326796993613243 \n",
      "Epoch [37/5000] , Step [10/488] , Loss: 0.0324585884809494 \n",
      "Epoch [37/5000] , Step [20/488] , Loss: 0.0325139015913010 \n",
      "Epoch [37/5000] , Step [30/488] , Loss: 0.0324841290712357 \n",
      "Epoch [37/5000] , Step [40/488] , Loss: 0.0324492678046227 \n",
      "Epoch [37/5000] , Step [50/488] , Loss: 0.0322850458323956 \n",
      "Epoch [37/5000] , Step [60/488] , Loss: 0.0319316610693932 \n",
      "Epoch [37/5000] , Step [70/488] , Loss: 0.0323941409587860 \n",
      "Epoch [37/5000] , Step [80/488] , Loss: 0.0332640744745731 \n",
      "Epoch [37/5000] , Step [90/488] , Loss: 0.0323692560195923 \n",
      "Epoch [37/5000] , Step [100/488] , Loss: 0.0323056988418102 \n",
      "Epoch [37/5000] , Step [110/488] , Loss: 0.0326959788799286 \n",
      "Epoch [37/5000] , Step [120/488] , Loss: 0.0325470566749573 \n",
      "Epoch [37/5000] , Step [130/488] , Loss: 0.0330194644629955 \n",
      "Epoch [37/5000] , Step [140/488] , Loss: 0.0329328328371048 \n",
      "Epoch [37/5000] , Step [150/488] , Loss: 0.0325777232646942 \n",
      "Epoch [37/5000] , Step [160/488] , Loss: 0.0323316827416420 \n",
      "Epoch [37/5000] , Step [170/488] , Loss: 0.0325743593275547 \n",
      "Epoch [37/5000] , Step [180/488] , Loss: 0.0329611413180828 \n",
      "Epoch [37/5000] , Step [190/488] , Loss: 0.0328890271484852 \n",
      "Epoch [37/5000] , Step [200/488] , Loss: 0.0329943224787712 \n",
      "Epoch [37/5000] , Step [210/488] , Loss: 0.0322386994957924 \n",
      "Epoch [37/5000] , Step [220/488] , Loss: 0.0331065207719803 \n",
      "Epoch [37/5000] , Step [230/488] , Loss: 0.0320226065814495 \n",
      "Epoch [37/5000] , Step [240/488] , Loss: 0.0328024588525295 \n",
      "Epoch [37/5000] , Step [250/488] , Loss: 0.0321940854191780 \n",
      "Epoch [37/5000] , Step [260/488] , Loss: 0.0325559452176094 \n",
      "Epoch [37/5000] , Step [270/488] , Loss: 0.0319260470569134 \n",
      "Epoch [37/5000] , Step [280/488] , Loss: 0.0323097370564938 \n",
      "Epoch [37/5000] , Step [290/488] , Loss: 0.0326755121350288 \n",
      "Epoch [37/5000] , Step [300/488] , Loss: 0.0324879586696625 \n",
      "Epoch [37/5000] , Step [310/488] , Loss: 0.0321739576756954 \n",
      "Epoch [37/5000] , Step [320/488] , Loss: 0.0326017774641514 \n",
      "Epoch [37/5000] , Step [330/488] , Loss: 0.0325396284461021 \n",
      "Epoch [37/5000] , Step [340/488] , Loss: 0.0324344933032990 \n",
      "Epoch [37/5000] , Step [350/488] , Loss: 0.0322139635682106 \n",
      "Epoch [37/5000] , Step [360/488] , Loss: 0.0324661917984486 \n",
      "Epoch [37/5000] , Step [370/488] , Loss: 0.0318470150232315 \n",
      "Epoch [37/5000] , Step [380/488] , Loss: 0.0328549742698669 \n",
      "Epoch [37/5000] , Step [390/488] , Loss: 0.0325549766421318 \n",
      "Epoch [37/5000] , Step [400/488] , Loss: 0.0320668630301952 \n",
      "Epoch [37/5000] , Step [410/488] , Loss: 0.0330772213637829 \n",
      "Epoch [37/5000] , Step [420/488] , Loss: 0.0322701595723629 \n",
      "Epoch [37/5000] , Step [430/488] , Loss: 0.0323179475963116 \n",
      "Epoch [37/5000] , Step [440/488] , Loss: 0.0324086062610149 \n",
      "Epoch [37/5000] , Step [450/488] , Loss: 0.0321717001497746 \n",
      "Epoch [37/5000] , Step [460/488] , Loss: 0.0324807465076447 \n",
      "Epoch [37/5000] , Step [470/488] , Loss: 0.0322825089097023 \n",
      "Epoch [37/5000] , Step [480/488] , Loss: 0.0321059077978134 \n",
      "Epoch [38/5000] , Step [10/488] , Loss: 0.0321568548679352 \n",
      "Epoch [38/5000] , Step [20/488] , Loss: 0.0328346192836761 \n",
      "Epoch [38/5000] , Step [30/488] , Loss: 0.0332607105374336 \n",
      "Epoch [38/5000] , Step [40/488] , Loss: 0.0318518280982971 \n",
      "Epoch [38/5000] , Step [50/488] , Loss: 0.0318480022251606 \n",
      "Epoch [38/5000] , Step [60/488] , Loss: 0.0324997007846832 \n",
      "Epoch [38/5000] , Step [70/488] , Loss: 0.0323834009468555 \n",
      "Epoch [38/5000] , Step [80/488] , Loss: 0.0325922369956970 \n",
      "Epoch [38/5000] , Step [90/488] , Loss: 0.0326418653130531 \n",
      "Epoch [38/5000] , Step [100/488] , Loss: 0.0327312238514423 \n",
      "Epoch [38/5000] , Step [110/488] , Loss: 0.0321313627064228 \n",
      "Epoch [38/5000] , Step [120/488] , Loss: 0.0328274741768837 \n",
      "Epoch [38/5000] , Step [130/488] , Loss: 0.0326053388416767 \n",
      "Epoch [38/5000] , Step [140/488] , Loss: 0.0328486263751984 \n",
      "Epoch [38/5000] , Step [150/488] , Loss: 0.0328341946005821 \n",
      "Epoch [38/5000] , Step [160/488] , Loss: 0.0327468663454056 \n",
      "Epoch [38/5000] , Step [170/488] , Loss: 0.0324864089488983 \n",
      "Epoch [38/5000] , Step [180/488] , Loss: 0.0317906402051449 \n",
      "Epoch [38/5000] , Step [190/488] , Loss: 0.0317912474274635 \n",
      "Epoch [38/5000] , Step [200/488] , Loss: 0.0323446579277515 \n",
      "Epoch [38/5000] , Step [210/488] , Loss: 0.0318692438304424 \n",
      "Epoch [38/5000] , Step [220/488] , Loss: 0.0327171236276627 \n",
      "Epoch [38/5000] , Step [230/488] , Loss: 0.0329245328903198 \n",
      "Epoch [38/5000] , Step [240/488] , Loss: 0.0324188396334648 \n",
      "Epoch [38/5000] , Step [250/488] , Loss: 0.0326741486787796 \n",
      "Epoch [38/5000] , Step [260/488] , Loss: 0.0320150293409824 \n",
      "Epoch [38/5000] , Step [270/488] , Loss: 0.0325367264449596 \n",
      "Epoch [38/5000] , Step [280/488] , Loss: 0.0324134565889835 \n",
      "Epoch [38/5000] , Step [290/488] , Loss: 0.0320804826915264 \n",
      "Epoch [38/5000] , Step [300/488] , Loss: 0.0332950428128242 \n",
      "Epoch [38/5000] , Step [310/488] , Loss: 0.0325503833591938 \n",
      "Epoch [38/5000] , Step [320/488] , Loss: 0.0327591262757778 \n",
      "Epoch [38/5000] , Step [330/488] , Loss: 0.0327635593712330 \n",
      "Epoch [38/5000] , Step [340/488] , Loss: 0.0323821119964123 \n",
      "Epoch [38/5000] , Step [350/488] , Loss: 0.0326516143977642 \n",
      "Epoch [38/5000] , Step [360/488] , Loss: 0.0326739624142647 \n",
      "Epoch [38/5000] , Step [370/488] , Loss: 0.0327915288507938 \n",
      "Epoch [38/5000] , Step [380/488] , Loss: 0.0328878983855247 \n",
      "Epoch [38/5000] , Step [390/488] , Loss: 0.0329608544707298 \n",
      "Epoch [38/5000] , Step [400/488] , Loss: 0.0322315357625484 \n",
      "Epoch [38/5000] , Step [410/488] , Loss: 0.0325152985751629 \n",
      "Epoch [38/5000] , Step [420/488] , Loss: 0.0328800752758980 \n",
      "Epoch [38/5000] , Step [430/488] , Loss: 0.0326846502721310 \n",
      "Epoch [38/5000] , Step [440/488] , Loss: 0.0328326597809792 \n",
      "Epoch [38/5000] , Step [450/488] , Loss: 0.0322999954223633 \n",
      "Epoch [38/5000] , Step [460/488] , Loss: 0.0320302769541740 \n",
      "Epoch [38/5000] , Step [470/488] , Loss: 0.0318896584212780 \n",
      "Epoch [38/5000] , Step [480/488] , Loss: 0.0323160067200661 \n",
      "Epoch [39/5000] , Step [10/488] , Loss: 0.0325247980654240 \n",
      "Epoch [39/5000] , Step [20/488] , Loss: 0.0334310866892338 \n",
      "Epoch [39/5000] , Step [30/488] , Loss: 0.0329277180135250 \n",
      "Epoch [39/5000] , Step [40/488] , Loss: 0.0322398543357849 \n",
      "Epoch [39/5000] , Step [50/488] , Loss: 0.0326733998954296 \n",
      "Epoch [39/5000] , Step [60/488] , Loss: 0.0321779437363148 \n",
      "Epoch [39/5000] , Step [70/488] , Loss: 0.0325806587934494 \n",
      "Epoch [39/5000] , Step [80/488] , Loss: 0.0317908935248852 \n",
      "Epoch [39/5000] , Step [90/488] , Loss: 0.0324483178555965 \n",
      "Epoch [39/5000] , Step [100/488] , Loss: 0.0324393920600414 \n",
      "Epoch [39/5000] , Step [110/488] , Loss: 0.0324557758867741 \n",
      "Epoch [39/5000] , Step [120/488] , Loss: 0.0319781824946404 \n",
      "Epoch [39/5000] , Step [130/488] , Loss: 0.0329413898289204 \n",
      "Epoch [39/5000] , Step [140/488] , Loss: 0.0326372832059860 \n",
      "Epoch [39/5000] , Step [150/488] , Loss: 0.0320070534944534 \n",
      "Epoch [39/5000] , Step [160/488] , Loss: 0.0322963632643223 \n",
      "Epoch [39/5000] , Step [170/488] , Loss: 0.0324958115816116 \n",
      "Epoch [39/5000] , Step [180/488] , Loss: 0.0330154672265053 \n",
      "Epoch [39/5000] , Step [190/488] , Loss: 0.0325899608433247 \n",
      "Epoch [39/5000] , Step [200/488] , Loss: 0.0327187441289425 \n",
      "Epoch [39/5000] , Step [210/488] , Loss: 0.0329226069152355 \n",
      "Epoch [39/5000] , Step [220/488] , Loss: 0.0318423733115196 \n",
      "Epoch [39/5000] , Step [230/488] , Loss: 0.0327297076582909 \n",
      "Epoch [39/5000] , Step [240/488] , Loss: 0.0326659977436066 \n",
      "Epoch [39/5000] , Step [250/488] , Loss: 0.0321173854172230 \n",
      "Epoch [39/5000] , Step [260/488] , Loss: 0.0325040966272354 \n",
      "Epoch [39/5000] , Step [270/488] , Loss: 0.0329264663159847 \n",
      "Epoch [39/5000] , Step [280/488] , Loss: 0.0324244648218155 \n",
      "Epoch [39/5000] , Step [290/488] , Loss: 0.0317826233804226 \n",
      "Epoch [39/5000] , Step [300/488] , Loss: 0.0333281420171261 \n",
      "Epoch [39/5000] , Step [310/488] , Loss: 0.0322708748281002 \n",
      "Epoch [39/5000] , Step [320/488] , Loss: 0.0325055047869682 \n",
      "Epoch [39/5000] , Step [330/488] , Loss: 0.0326137728989124 \n",
      "Epoch [39/5000] , Step [340/488] , Loss: 0.0327900797128677 \n",
      "Epoch [39/5000] , Step [350/488] , Loss: 0.0327999740839005 \n",
      "Epoch [39/5000] , Step [360/488] , Loss: 0.0328416936099529 \n",
      "Epoch [39/5000] , Step [370/488] , Loss: 0.0323919132351875 \n",
      "Epoch [39/5000] , Step [380/488] , Loss: 0.0323493592441082 \n",
      "Epoch [39/5000] , Step [390/488] , Loss: 0.0323787406086922 \n",
      "Epoch [39/5000] , Step [400/488] , Loss: 0.0326892770826817 \n",
      "Epoch [39/5000] , Step [410/488] , Loss: 0.0322301872074604 \n",
      "Epoch [39/5000] , Step [420/488] , Loss: 0.0322925448417664 \n",
      "Epoch [39/5000] , Step [430/488] , Loss: 0.0325023047626019 \n",
      "Epoch [39/5000] , Step [440/488] , Loss: 0.0331973880529404 \n",
      "Epoch [39/5000] , Step [450/488] , Loss: 0.0324907749891281 \n",
      "Epoch [39/5000] , Step [460/488] , Loss: 0.0322113037109375 \n",
      "Epoch [39/5000] , Step [470/488] , Loss: 0.0327523723244667 \n",
      "Epoch [39/5000] , Step [480/488] , Loss: 0.0326900705695152 \n",
      "Epoch [40/5000] , Step [10/488] , Loss: 0.0324038714170456 \n",
      "Epoch [40/5000] , Step [20/488] , Loss: 0.0326423309743404 \n",
      "Epoch [40/5000] , Step [30/488] , Loss: 0.0327221788465977 \n",
      "Epoch [40/5000] , Step [40/488] , Loss: 0.0324458628892899 \n",
      "Epoch [40/5000] , Step [50/488] , Loss: 0.0327292270958424 \n",
      "Epoch [40/5000] , Step [60/488] , Loss: 0.0324930176138878 \n",
      "Epoch [40/5000] , Step [70/488] , Loss: 0.0323636531829834 \n",
      "Epoch [40/5000] , Step [80/488] , Loss: 0.0332057029008865 \n",
      "Epoch [40/5000] , Step [90/488] , Loss: 0.0322904139757156 \n",
      "Epoch [40/5000] , Step [100/488] , Loss: 0.0322074368596077 \n",
      "Epoch [40/5000] , Step [110/488] , Loss: 0.0320962816476822 \n",
      "Epoch [40/5000] , Step [120/488] , Loss: 0.0321519784629345 \n",
      "Epoch [40/5000] , Step [130/488] , Loss: 0.0329404547810555 \n",
      "Epoch [40/5000] , Step [140/488] , Loss: 0.0329553671181202 \n",
      "Epoch [40/5000] , Step [150/488] , Loss: 0.0322243459522724 \n",
      "Epoch [40/5000] , Step [160/488] , Loss: 0.0320017524063587 \n",
      "Epoch [40/5000] , Step [170/488] , Loss: 0.0318157412111759 \n",
      "Epoch [40/5000] , Step [180/488] , Loss: 0.0322440899908543 \n",
      "Epoch [40/5000] , Step [190/488] , Loss: 0.0324593447148800 \n",
      "Epoch [40/5000] , Step [200/488] , Loss: 0.0326388031244278 \n",
      "Epoch [40/5000] , Step [210/488] , Loss: 0.0324129685759544 \n",
      "Epoch [40/5000] , Step [220/488] , Loss: 0.0317439138889313 \n",
      "Epoch [40/5000] , Step [230/488] , Loss: 0.0319687984883785 \n",
      "Epoch [40/5000] , Step [240/488] , Loss: 0.0325525365769863 \n",
      "Epoch [40/5000] , Step [250/488] , Loss: 0.0328342169523239 \n",
      "Epoch [40/5000] , Step [260/488] , Loss: 0.0327865183353424 \n",
      "Epoch [40/5000] , Step [270/488] , Loss: 0.0325710400938988 \n",
      "Epoch [40/5000] , Step [280/488] , Loss: 0.0325334332883358 \n",
      "Epoch [40/5000] , Step [290/488] , Loss: 0.0325132720172405 \n",
      "Epoch [40/5000] , Step [300/488] , Loss: 0.0328183099627495 \n",
      "Epoch [40/5000] , Step [310/488] , Loss: 0.0322341397404671 \n",
      "Epoch [40/5000] , Step [320/488] , Loss: 0.0325113907456398 \n",
      "Epoch [40/5000] , Step [330/488] , Loss: 0.0325912795960903 \n",
      "Epoch [40/5000] , Step [340/488] , Loss: 0.0321870408952236 \n",
      "Epoch [40/5000] , Step [350/488] , Loss: 0.0330310426652431 \n",
      "Epoch [40/5000] , Step [360/488] , Loss: 0.0327110327780247 \n",
      "Epoch [40/5000] , Step [370/488] , Loss: 0.0324637889862061 \n",
      "Epoch [40/5000] , Step [380/488] , Loss: 0.0321831814944744 \n",
      "Epoch [40/5000] , Step [390/488] , Loss: 0.0324023030698299 \n",
      "Epoch [40/5000] , Step [400/488] , Loss: 0.0328802764415741 \n",
      "Epoch [40/5000] , Step [410/488] , Loss: 0.0335119999945164 \n",
      "Epoch [40/5000] , Step [420/488] , Loss: 0.0325397662818432 \n",
      "Epoch [40/5000] , Step [430/488] , Loss: 0.0327444709837437 \n",
      "Epoch [40/5000] , Step [440/488] , Loss: 0.0327080525457859 \n",
      "Epoch [40/5000] , Step [450/488] , Loss: 0.0319185033440590 \n",
      "Epoch [40/5000] , Step [460/488] , Loss: 0.0322683490812778 \n",
      "Epoch [40/5000] , Step [470/488] , Loss: 0.0330562107264996 \n",
      "Epoch [40/5000] , Step [480/488] , Loss: 0.0324884727597237 \n",
      "Epoch [41/5000] , Step [10/488] , Loss: 0.0326256528496742 \n",
      "Epoch [41/5000] , Step [20/488] , Loss: 0.0323871597647667 \n",
      "Epoch [41/5000] , Step [30/488] , Loss: 0.0324735306203365 \n",
      "Epoch [41/5000] , Step [40/488] , Loss: 0.0325966365635395 \n",
      "Epoch [41/5000] , Step [50/488] , Loss: 0.0330354087054729 \n",
      "Epoch [41/5000] , Step [60/488] , Loss: 0.0324139259755611 \n",
      "Epoch [41/5000] , Step [70/488] , Loss: 0.0329255275428295 \n",
      "Epoch [41/5000] , Step [80/488] , Loss: 0.0327667146921158 \n",
      "Epoch [41/5000] , Step [90/488] , Loss: 0.0328143872320652 \n",
      "Epoch [41/5000] , Step [100/488] , Loss: 0.0322577282786369 \n",
      "Epoch [41/5000] , Step [110/488] , Loss: 0.0323382914066315 \n",
      "Epoch [41/5000] , Step [120/488] , Loss: 0.0328159146010876 \n",
      "Epoch [41/5000] , Step [130/488] , Loss: 0.0322647802531719 \n",
      "Epoch [41/5000] , Step [140/488] , Loss: 0.0324085913598537 \n",
      "Epoch [41/5000] , Step [150/488] , Loss: 0.0325023718178272 \n",
      "Epoch [41/5000] , Step [160/488] , Loss: 0.0325589701533318 \n",
      "Epoch [41/5000] , Step [170/488] , Loss: 0.0330261811614037 \n",
      "Epoch [41/5000] , Step [180/488] , Loss: 0.0326594971120358 \n",
      "Epoch [41/5000] , Step [190/488] , Loss: 0.0325757190585136 \n",
      "Epoch [41/5000] , Step [200/488] , Loss: 0.0322117023169994 \n",
      "Epoch [41/5000] , Step [210/488] , Loss: 0.0329597368836403 \n",
      "Epoch [41/5000] , Step [220/488] , Loss: 0.0326564162969589 \n",
      "Epoch [41/5000] , Step [230/488] , Loss: 0.0324260741472244 \n",
      "Epoch [41/5000] , Step [240/488] , Loss: 0.0328957885503769 \n",
      "Epoch [41/5000] , Step [250/488] , Loss: 0.0326141119003296 \n",
      "Epoch [41/5000] , Step [260/488] , Loss: 0.0329816974699497 \n",
      "Epoch [41/5000] , Step [270/488] , Loss: 0.0326350294053555 \n",
      "Epoch [41/5000] , Step [280/488] , Loss: 0.0326137021183968 \n",
      "Epoch [41/5000] , Step [290/488] , Loss: 0.0328318588435650 \n",
      "Epoch [41/5000] , Step [300/488] , Loss: 0.0325566865503788 \n",
      "Epoch [41/5000] , Step [310/488] , Loss: 0.0324517749249935 \n",
      "Epoch [41/5000] , Step [320/488] , Loss: 0.0323286205530167 \n",
      "Epoch [41/5000] , Step [330/488] , Loss: 0.0328374169766903 \n",
      "Epoch [41/5000] , Step [340/488] , Loss: 0.0322111360728741 \n",
      "Epoch [41/5000] , Step [350/488] , Loss: 0.0334058254957199 \n",
      "Epoch [41/5000] , Step [360/488] , Loss: 0.0323703587055206 \n",
      "Epoch [41/5000] , Step [370/488] , Loss: 0.0326024107635021 \n",
      "Epoch [41/5000] , Step [380/488] , Loss: 0.0327124446630478 \n",
      "Epoch [41/5000] , Step [390/488] , Loss: 0.0323896668851376 \n",
      "Epoch [41/5000] , Step [400/488] , Loss: 0.0325212255120277 \n",
      "Epoch [41/5000] , Step [410/488] , Loss: 0.0327141210436821 \n",
      "Epoch [41/5000] , Step [420/488] , Loss: 0.0320953205227852 \n",
      "Epoch [41/5000] , Step [430/488] , Loss: 0.0325323678553104 \n",
      "Epoch [41/5000] , Step [440/488] , Loss: 0.0323943048715591 \n",
      "Epoch [41/5000] , Step [450/488] , Loss: 0.0329876430332661 \n",
      "Epoch [41/5000] , Step [460/488] , Loss: 0.0325458683073521 \n",
      "Epoch [41/5000] , Step [470/488] , Loss: 0.0327501706779003 \n",
      "Epoch [41/5000] , Step [480/488] , Loss: 0.0328641012310982 \n",
      "Epoch [42/5000] , Step [10/488] , Loss: 0.0317000001668930 \n",
      "Epoch [42/5000] , Step [20/488] , Loss: 0.0333933494985104 \n",
      "Epoch [42/5000] , Step [30/488] , Loss: 0.0327572077512741 \n",
      "Epoch [42/5000] , Step [40/488] , Loss: 0.0323128476738930 \n",
      "Epoch [42/5000] , Step [50/488] , Loss: 0.0324241891503334 \n",
      "Epoch [42/5000] , Step [60/488] , Loss: 0.0324971899390221 \n",
      "Epoch [42/5000] , Step [70/488] , Loss: 0.0330233797430992 \n",
      "Epoch [42/5000] , Step [80/488] , Loss: 0.0322073437273502 \n",
      "Epoch [42/5000] , Step [90/488] , Loss: 0.0324081927537918 \n",
      "Epoch [42/5000] , Step [100/488] , Loss: 0.0321559384465218 \n",
      "Epoch [42/5000] , Step [110/488] , Loss: 0.0330195687711239 \n",
      "Epoch [42/5000] , Step [120/488] , Loss: 0.0321879610419273 \n",
      "Epoch [42/5000] , Step [130/488] , Loss: 0.0323847420513630 \n",
      "Epoch [42/5000] , Step [140/488] , Loss: 0.0319974012672901 \n",
      "Epoch [42/5000] , Step [150/488] , Loss: 0.0327081866562366 \n",
      "Epoch [42/5000] , Step [160/488] , Loss: 0.0326541922986507 \n",
      "Epoch [42/5000] , Step [170/488] , Loss: 0.0323944836854935 \n",
      "Epoch [42/5000] , Step [180/488] , Loss: 0.0322116874158382 \n",
      "Epoch [42/5000] , Step [190/488] , Loss: 0.0326685383915901 \n",
      "Epoch [42/5000] , Step [200/488] , Loss: 0.0320422798395157 \n",
      "Epoch [42/5000] , Step [210/488] , Loss: 0.0327910892665386 \n",
      "Epoch [42/5000] , Step [220/488] , Loss: 0.0324853211641312 \n",
      "Epoch [42/5000] , Step [230/488] , Loss: 0.0320460014045238 \n",
      "Epoch [42/5000] , Step [240/488] , Loss: 0.0325393751263618 \n",
      "Epoch [42/5000] , Step [250/488] , Loss: 0.0323433056473732 \n",
      "Epoch [42/5000] , Step [260/488] , Loss: 0.0326127484440804 \n",
      "Epoch [42/5000] , Step [270/488] , Loss: 0.0321880541741848 \n",
      "Epoch [42/5000] , Step [280/488] , Loss: 0.0321373529732227 \n",
      "Epoch [42/5000] , Step [290/488] , Loss: 0.0324191190302372 \n",
      "Epoch [42/5000] , Step [300/488] , Loss: 0.0327938012778759 \n",
      "Epoch [42/5000] , Step [310/488] , Loss: 0.0322493091225624 \n",
      "Epoch [42/5000] , Step [320/488] , Loss: 0.0327379181981087 \n",
      "Epoch [42/5000] , Step [330/488] , Loss: 0.0329969339072704 \n",
      "Epoch [42/5000] , Step [340/488] , Loss: 0.0324226655066013 \n",
      "Epoch [42/5000] , Step [350/488] , Loss: 0.0328255556523800 \n",
      "Epoch [42/5000] , Step [360/488] , Loss: 0.0321139805018902 \n",
      "Epoch [42/5000] , Step [370/488] , Loss: 0.0325882211327553 \n",
      "Epoch [42/5000] , Step [380/488] , Loss: 0.0332159921526909 \n",
      "Epoch [42/5000] , Step [390/488] , Loss: 0.0322262383997440 \n",
      "Epoch [42/5000] , Step [400/488] , Loss: 0.0329706557095051 \n",
      "Epoch [42/5000] , Step [410/488] , Loss: 0.0329044833779335 \n",
      "Epoch [42/5000] , Step [420/488] , Loss: 0.0328738614916801 \n",
      "Epoch [42/5000] , Step [430/488] , Loss: 0.0330044738948345 \n",
      "Epoch [42/5000] , Step [440/488] , Loss: 0.0319597572088242 \n",
      "Epoch [42/5000] , Step [450/488] , Loss: 0.0325505770742893 \n",
      "Epoch [42/5000] , Step [460/488] , Loss: 0.0320698395371437 \n",
      "Epoch [42/5000] , Step [470/488] , Loss: 0.0325810909271240 \n",
      "Epoch [42/5000] , Step [480/488] , Loss: 0.0327153950929642 \n",
      "Epoch [43/5000] , Step [10/488] , Loss: 0.0331205129623413 \n",
      "Epoch [43/5000] , Step [20/488] , Loss: 0.0329134650528431 \n",
      "Epoch [43/5000] , Step [30/488] , Loss: 0.0327917262911797 \n",
      "Epoch [43/5000] , Step [40/488] , Loss: 0.0321300588548183 \n",
      "Epoch [43/5000] , Step [50/488] , Loss: 0.0325827486813068 \n",
      "Epoch [43/5000] , Step [60/488] , Loss: 0.0327536575496197 \n",
      "Epoch [43/5000] , Step [70/488] , Loss: 0.0328429490327835 \n",
      "Epoch [43/5000] , Step [80/488] , Loss: 0.0322345979511738 \n",
      "Epoch [43/5000] , Step [90/488] , Loss: 0.0326703786849976 \n",
      "Epoch [43/5000] , Step [100/488] , Loss: 0.0328948535025120 \n",
      "Epoch [43/5000] , Step [110/488] , Loss: 0.0325940996408463 \n",
      "Epoch [43/5000] , Step [120/488] , Loss: 0.0320226065814495 \n",
      "Epoch [43/5000] , Step [130/488] , Loss: 0.0319058969616890 \n",
      "Epoch [43/5000] , Step [140/488] , Loss: 0.0325108580291271 \n",
      "Epoch [43/5000] , Step [150/488] , Loss: 0.0324843898415565 \n",
      "Epoch [43/5000] , Step [160/488] , Loss: 0.0327896215021610 \n",
      "Epoch [43/5000] , Step [170/488] , Loss: 0.0320626050233841 \n",
      "Epoch [43/5000] , Step [180/488] , Loss: 0.0323023311793804 \n",
      "Epoch [43/5000] , Step [190/488] , Loss: 0.0322408825159073 \n",
      "Epoch [43/5000] , Step [200/488] , Loss: 0.0320210754871368 \n",
      "Epoch [43/5000] , Step [210/488] , Loss: 0.0324647016823292 \n",
      "Epoch [43/5000] , Step [220/488] , Loss: 0.0328093357384205 \n",
      "Epoch [43/5000] , Step [230/488] , Loss: 0.0322859808802605 \n",
      "Epoch [43/5000] , Step [240/488] , Loss: 0.0321912914514542 \n",
      "Epoch [43/5000] , Step [250/488] , Loss: 0.0323754958808422 \n",
      "Epoch [43/5000] , Step [260/488] , Loss: 0.0323745273053646 \n",
      "Epoch [43/5000] , Step [270/488] , Loss: 0.0325050726532936 \n",
      "Epoch [43/5000] , Step [280/488] , Loss: 0.0324867852032185 \n",
      "Epoch [43/5000] , Step [290/488] , Loss: 0.0329541526734829 \n",
      "Epoch [43/5000] , Step [300/488] , Loss: 0.0323585867881775 \n",
      "Epoch [43/5000] , Step [310/488] , Loss: 0.0324571654200554 \n",
      "Epoch [43/5000] , Step [320/488] , Loss: 0.0327845029532909 \n",
      "Epoch [43/5000] , Step [330/488] , Loss: 0.0329516753554344 \n",
      "Epoch [43/5000] , Step [340/488] , Loss: 0.0324208363890648 \n",
      "Epoch [43/5000] , Step [350/488] , Loss: 0.0326026305556297 \n",
      "Epoch [43/5000] , Step [360/488] , Loss: 0.0328311547636986 \n",
      "Epoch [43/5000] , Step [370/488] , Loss: 0.0320562645792961 \n",
      "Epoch [43/5000] , Step [380/488] , Loss: 0.0324770398437977 \n",
      "Epoch [43/5000] , Step [390/488] , Loss: 0.0323991775512695 \n",
      "Epoch [43/5000] , Step [400/488] , Loss: 0.0324326641857624 \n",
      "Epoch [43/5000] , Step [410/488] , Loss: 0.0323299206793308 \n",
      "Epoch [43/5000] , Step [420/488] , Loss: 0.0321272201836109 \n",
      "Epoch [43/5000] , Step [430/488] , Loss: 0.0326318852603436 \n",
      "Epoch [43/5000] , Step [440/488] , Loss: 0.0327920727431774 \n",
      "Epoch [43/5000] , Step [450/488] , Loss: 0.0332529954612255 \n",
      "Epoch [43/5000] , Step [460/488] , Loss: 0.0329887457191944 \n",
      "Epoch [43/5000] , Step [470/488] , Loss: 0.0328086018562317 \n",
      "Epoch [43/5000] , Step [480/488] , Loss: 0.0329871810972691 \n",
      "Epoch [44/5000] , Step [10/488] , Loss: 0.0321936234831810 \n",
      "Epoch [44/5000] , Step [20/488] , Loss: 0.0325463414192200 \n",
      "Epoch [44/5000] , Step [30/488] , Loss: 0.0321240611374378 \n",
      "Epoch [44/5000] , Step [40/488] , Loss: 0.0325094908475876 \n",
      "Epoch [44/5000] , Step [50/488] , Loss: 0.0329884104430676 \n",
      "Epoch [44/5000] , Step [60/488] , Loss: 0.0319917760789394 \n",
      "Epoch [44/5000] , Step [70/488] , Loss: 0.0327567383646965 \n",
      "Epoch [44/5000] , Step [80/488] , Loss: 0.0321398787200451 \n",
      "Epoch [44/5000] , Step [90/488] , Loss: 0.0322737470269203 \n",
      "Epoch [44/5000] , Step [100/488] , Loss: 0.0322214700281620 \n",
      "Epoch [44/5000] , Step [110/488] , Loss: 0.0323967225849628 \n",
      "Epoch [44/5000] , Step [120/488] , Loss: 0.0326131060719490 \n",
      "Epoch [44/5000] , Step [130/488] , Loss: 0.0327244475483894 \n",
      "Epoch [44/5000] , Step [140/488] , Loss: 0.0323044173419476 \n",
      "Epoch [44/5000] , Step [150/488] , Loss: 0.0324886329472065 \n",
      "Epoch [44/5000] , Step [160/488] , Loss: 0.0324228815734386 \n",
      "Epoch [44/5000] , Step [170/488] , Loss: 0.0323619283735752 \n",
      "Epoch [44/5000] , Step [180/488] , Loss: 0.0329072922468185 \n",
      "Epoch [44/5000] , Step [190/488] , Loss: 0.0332589559257030 \n",
      "Epoch [44/5000] , Step [200/488] , Loss: 0.0325831621885300 \n",
      "Epoch [44/5000] , Step [210/488] , Loss: 0.0322657376527786 \n",
      "Epoch [44/5000] , Step [220/488] , Loss: 0.0321906246244907 \n",
      "Epoch [44/5000] , Step [230/488] , Loss: 0.0323398001492023 \n",
      "Epoch [44/5000] , Step [240/488] , Loss: 0.0325619541108608 \n",
      "Epoch [44/5000] , Step [250/488] , Loss: 0.0323823764920235 \n",
      "Epoch [44/5000] , Step [260/488] , Loss: 0.0325394757091999 \n",
      "Epoch [44/5000] , Step [270/488] , Loss: 0.0328860916197300 \n",
      "Epoch [44/5000] , Step [280/488] , Loss: 0.0324739515781403 \n",
      "Epoch [44/5000] , Step [290/488] , Loss: 0.0327973999083042 \n",
      "Epoch [44/5000] , Step [300/488] , Loss: 0.0331997647881508 \n",
      "Epoch [44/5000] , Step [310/488] , Loss: 0.0324860215187073 \n",
      "Epoch [44/5000] , Step [320/488] , Loss: 0.0332911387085915 \n",
      "Epoch [44/5000] , Step [330/488] , Loss: 0.0324959717690945 \n",
      "Epoch [44/5000] , Step [340/488] , Loss: 0.0323919504880905 \n",
      "Epoch [44/5000] , Step [350/488] , Loss: 0.0323480963706970 \n",
      "Epoch [44/5000] , Step [360/488] , Loss: 0.0331280305981636 \n",
      "Epoch [44/5000] , Step [370/488] , Loss: 0.0325068123638630 \n",
      "Epoch [44/5000] , Step [380/488] , Loss: 0.0324939675629139 \n",
      "Epoch [44/5000] , Step [390/488] , Loss: 0.0320818312466145 \n",
      "Epoch [44/5000] , Step [400/488] , Loss: 0.0328240618109703 \n",
      "Epoch [44/5000] , Step [410/488] , Loss: 0.0321906097233295 \n",
      "Epoch [44/5000] , Step [420/488] , Loss: 0.0327708646655083 \n",
      "Epoch [44/5000] , Step [430/488] , Loss: 0.0324794240295887 \n",
      "Epoch [44/5000] , Step [440/488] , Loss: 0.0332162380218506 \n",
      "Epoch [44/5000] , Step [450/488] , Loss: 0.0329994782805443 \n",
      "Epoch [44/5000] , Step [460/488] , Loss: 0.0326571725308895 \n",
      "Epoch [44/5000] , Step [470/488] , Loss: 0.0324625708162785 \n",
      "Epoch [44/5000] , Step [480/488] , Loss: 0.0318690612912178 \n",
      "Epoch [45/5000] , Step [10/488] , Loss: 0.0324816256761551 \n",
      "Epoch [45/5000] , Step [20/488] , Loss: 0.0324184298515320 \n",
      "Epoch [45/5000] , Step [30/488] , Loss: 0.0321713760495186 \n",
      "Epoch [45/5000] , Step [40/488] , Loss: 0.0324629582464695 \n",
      "Epoch [45/5000] , Step [50/488] , Loss: 0.0334390066564083 \n",
      "Epoch [45/5000] , Step [60/488] , Loss: 0.0323593206703663 \n",
      "Epoch [45/5000] , Step [70/488] , Loss: 0.0325837396085262 \n",
      "Epoch [45/5000] , Step [80/488] , Loss: 0.0326783619821072 \n",
      "Epoch [45/5000] , Step [90/488] , Loss: 0.0324717648327351 \n",
      "Epoch [45/5000] , Step [100/488] , Loss: 0.0328485891222954 \n",
      "Epoch [45/5000] , Step [110/488] , Loss: 0.0329568870365620 \n",
      "Epoch [45/5000] , Step [120/488] , Loss: 0.0322695076465607 \n",
      "Epoch [45/5000] , Step [130/488] , Loss: 0.0329458862543106 \n",
      "Epoch [45/5000] , Step [140/488] , Loss: 0.0326004549860954 \n",
      "Epoch [45/5000] , Step [150/488] , Loss: 0.0323764979839325 \n",
      "Epoch [45/5000] , Step [160/488] , Loss: 0.0332149863243103 \n",
      "Epoch [45/5000] , Step [170/488] , Loss: 0.0323370099067688 \n",
      "Epoch [45/5000] , Step [180/488] , Loss: 0.0329256914556026 \n",
      "Epoch [45/5000] , Step [190/488] , Loss: 0.0329344011843204 \n",
      "Epoch [45/5000] , Step [200/488] , Loss: 0.0323454253375530 \n",
      "Epoch [45/5000] , Step [210/488] , Loss: 0.0323857255280018 \n",
      "Epoch [45/5000] , Step [220/488] , Loss: 0.0325752571225166 \n",
      "Epoch [45/5000] , Step [230/488] , Loss: 0.0325069464743137 \n",
      "Epoch [45/5000] , Step [240/488] , Loss: 0.0328083261847496 \n",
      "Epoch [45/5000] , Step [250/488] , Loss: 0.0326141119003296 \n",
      "Epoch [45/5000] , Step [260/488] , Loss: 0.0324366539716721 \n",
      "Epoch [45/5000] , Step [270/488] , Loss: 0.0326552763581276 \n",
      "Epoch [45/5000] , Step [280/488] , Loss: 0.0329887159168720 \n",
      "Epoch [45/5000] , Step [290/488] , Loss: 0.0327423512935638 \n",
      "Epoch [45/5000] , Step [300/488] , Loss: 0.0322558172047138 \n",
      "Epoch [45/5000] , Step [310/488] , Loss: 0.0318966545164585 \n",
      "Epoch [45/5000] , Step [320/488] , Loss: 0.0323904827237129 \n",
      "Epoch [45/5000] , Step [330/488] , Loss: 0.0325732752680779 \n",
      "Epoch [45/5000] , Step [340/488] , Loss: 0.0319812260568142 \n",
      "Epoch [45/5000] , Step [350/488] , Loss: 0.0326187834143639 \n",
      "Epoch [45/5000] , Step [360/488] , Loss: 0.0323316827416420 \n",
      "Epoch [45/5000] , Step [370/488] , Loss: 0.0324222929775715 \n",
      "Epoch [45/5000] , Step [380/488] , Loss: 0.0326204150915146 \n",
      "Epoch [45/5000] , Step [390/488] , Loss: 0.0326262563467026 \n",
      "Epoch [45/5000] , Step [400/488] , Loss: 0.0323219075798988 \n",
      "Epoch [45/5000] , Step [410/488] , Loss: 0.0325554981827736 \n",
      "Epoch [45/5000] , Step [420/488] , Loss: 0.0318950638175011 \n",
      "Epoch [45/5000] , Step [430/488] , Loss: 0.0330397412180901 \n",
      "Epoch [45/5000] , Step [440/488] , Loss: 0.0331991948187351 \n",
      "Epoch [45/5000] , Step [450/488] , Loss: 0.0325219817459583 \n",
      "Epoch [45/5000] , Step [460/488] , Loss: 0.0330685637891293 \n",
      "Epoch [45/5000] , Step [470/488] , Loss: 0.0328717231750488 \n",
      "Epoch [45/5000] , Step [480/488] , Loss: 0.0316757857799530 \n",
      "Epoch [46/5000] , Step [10/488] , Loss: 0.0328912287950516 \n",
      "Epoch [46/5000] , Step [20/488] , Loss: 0.0330368056893349 \n",
      "Epoch [46/5000] , Step [30/488] , Loss: 0.0329727642238140 \n",
      "Epoch [46/5000] , Step [40/488] , Loss: 0.0323905125260353 \n",
      "Epoch [46/5000] , Step [50/488] , Loss: 0.0329132936894894 \n",
      "Epoch [46/5000] , Step [60/488] , Loss: 0.0330662019550800 \n",
      "Epoch [46/5000] , Step [70/488] , Loss: 0.0321433059871197 \n",
      "Epoch [46/5000] , Step [80/488] , Loss: 0.0321015305817127 \n",
      "Epoch [46/5000] , Step [90/488] , Loss: 0.0324163846671581 \n",
      "Epoch [46/5000] , Step [100/488] , Loss: 0.0324926786124706 \n",
      "Epoch [46/5000] , Step [110/488] , Loss: 0.0321124494075775 \n",
      "Epoch [46/5000] , Step [120/488] , Loss: 0.0328493900597095 \n",
      "Epoch [46/5000] , Step [130/488] , Loss: 0.0323769710958004 \n",
      "Epoch [46/5000] , Step [140/488] , Loss: 0.0328480638563633 \n",
      "Epoch [46/5000] , Step [150/488] , Loss: 0.0331384614109993 \n",
      "Epoch [46/5000] , Step [160/488] , Loss: 0.0325252078473568 \n",
      "Epoch [46/5000] , Step [170/488] , Loss: 0.0323199406266212 \n",
      "Epoch [46/5000] , Step [180/488] , Loss: 0.0326841697096825 \n",
      "Epoch [46/5000] , Step [190/488] , Loss: 0.0326226912438869 \n",
      "Epoch [46/5000] , Step [200/488] , Loss: 0.0323601067066193 \n",
      "Epoch [46/5000] , Step [210/488] , Loss: 0.0324911475181580 \n",
      "Epoch [46/5000] , Step [220/488] , Loss: 0.0319578908383846 \n",
      "Epoch [46/5000] , Step [230/488] , Loss: 0.0325699597597122 \n",
      "Epoch [46/5000] , Step [240/488] , Loss: 0.0322557128965855 \n",
      "Epoch [46/5000] , Step [250/488] , Loss: 0.0318236313760281 \n",
      "Epoch [46/5000] , Step [260/488] , Loss: 0.0326045788824558 \n",
      "Epoch [46/5000] , Step [270/488] , Loss: 0.0326573178172112 \n",
      "Epoch [46/5000] , Step [280/488] , Loss: 0.0320498943328857 \n",
      "Epoch [46/5000] , Step [290/488] , Loss: 0.0326141677796841 \n",
      "Epoch [46/5000] , Step [300/488] , Loss: 0.0322392173111439 \n",
      "Epoch [46/5000] , Step [310/488] , Loss: 0.0323862507939339 \n",
      "Epoch [46/5000] , Step [320/488] , Loss: 0.0329640135169029 \n",
      "Epoch [46/5000] , Step [330/488] , Loss: 0.0317589528858662 \n",
      "Epoch [46/5000] , Step [340/488] , Loss: 0.0326354466378689 \n",
      "Epoch [46/5000] , Step [350/488] , Loss: 0.0327501296997070 \n",
      "Epoch [46/5000] , Step [360/488] , Loss: 0.0329974293708801 \n",
      "Epoch [46/5000] , Step [370/488] , Loss: 0.0329912677407265 \n",
      "Epoch [46/5000] , Step [380/488] , Loss: 0.0324123911559582 \n",
      "Epoch [46/5000] , Step [390/488] , Loss: 0.0323150232434273 \n",
      "Epoch [46/5000] , Step [400/488] , Loss: 0.0325527414679527 \n",
      "Epoch [46/5000] , Step [410/488] , Loss: 0.0324386879801750 \n",
      "Epoch [46/5000] , Step [420/488] , Loss: 0.0324262455105782 \n",
      "Epoch [46/5000] , Step [430/488] , Loss: 0.0323598049581051 \n",
      "Epoch [46/5000] , Step [440/488] , Loss: 0.0325248539447784 \n",
      "Epoch [46/5000] , Step [450/488] , Loss: 0.0326861813664436 \n",
      "Epoch [46/5000] , Step [460/488] , Loss: 0.0319534800946712 \n",
      "Epoch [46/5000] , Step [470/488] , Loss: 0.0333754345774651 \n",
      "Epoch [46/5000] , Step [480/488] , Loss: 0.0332634374499321 \n",
      "Epoch [47/5000] , Step [10/488] , Loss: 0.0327284559607506 \n",
      "Epoch [47/5000] , Step [20/488] , Loss: 0.0334733575582504 \n",
      "Epoch [47/5000] , Step [30/488] , Loss: 0.0317531228065491 \n",
      "Epoch [47/5000] , Step [40/488] , Loss: 0.0320410430431366 \n",
      "Epoch [47/5000] , Step [50/488] , Loss: 0.0326984785497189 \n",
      "Epoch [47/5000] , Step [60/488] , Loss: 0.0327905789017677 \n",
      "Epoch [47/5000] , Step [70/488] , Loss: 0.0324441269040108 \n",
      "Epoch [47/5000] , Step [80/488] , Loss: 0.0326063968241215 \n",
      "Epoch [47/5000] , Step [90/488] , Loss: 0.0319245345890522 \n",
      "Epoch [47/5000] , Step [100/488] , Loss: 0.0315996296703815 \n",
      "Epoch [47/5000] , Step [110/488] , Loss: 0.0322776734828949 \n",
      "Epoch [47/5000] , Step [120/488] , Loss: 0.0320961400866508 \n",
      "Epoch [47/5000] , Step [130/488] , Loss: 0.0319864749908447 \n",
      "Epoch [47/5000] , Step [140/488] , Loss: 0.0324049741029739 \n",
      "Epoch [47/5000] , Step [150/488] , Loss: 0.0325080230832100 \n",
      "Epoch [47/5000] , Step [160/488] , Loss: 0.0330401659011841 \n",
      "Epoch [47/5000] , Step [170/488] , Loss: 0.0327419415116310 \n",
      "Epoch [47/5000] , Step [180/488] , Loss: 0.0328952856361866 \n",
      "Epoch [47/5000] , Step [190/488] , Loss: 0.0327495485544205 \n",
      "Epoch [47/5000] , Step [200/488] , Loss: 0.0324245952069759 \n",
      "Epoch [47/5000] , Step [210/488] , Loss: 0.0332283452153206 \n",
      "Epoch [47/5000] , Step [220/488] , Loss: 0.0324169322848320 \n",
      "Epoch [47/5000] , Step [230/488] , Loss: 0.0322851352393627 \n",
      "Epoch [47/5000] , Step [240/488] , Loss: 0.0326484031975269 \n",
      "Epoch [47/5000] , Step [250/488] , Loss: 0.0324685424566269 \n",
      "Epoch [47/5000] , Step [260/488] , Loss: 0.0325051732361317 \n",
      "Epoch [47/5000] , Step [270/488] , Loss: 0.0319490097463131 \n",
      "Epoch [47/5000] , Step [280/488] , Loss: 0.0326300077140331 \n",
      "Epoch [47/5000] , Step [290/488] , Loss: 0.0324176326394081 \n",
      "Epoch [47/5000] , Step [300/488] , Loss: 0.0323087498545647 \n",
      "Epoch [47/5000] , Step [310/488] , Loss: 0.0322263315320015 \n",
      "Epoch [47/5000] , Step [320/488] , Loss: 0.0326658859848976 \n",
      "Epoch [47/5000] , Step [330/488] , Loss: 0.0327692180871964 \n",
      "Epoch [47/5000] , Step [340/488] , Loss: 0.0329371020197868 \n",
      "Epoch [47/5000] , Step [350/488] , Loss: 0.0321282409131527 \n",
      "Epoch [47/5000] , Step [360/488] , Loss: 0.0326157286763191 \n",
      "Epoch [47/5000] , Step [370/488] , Loss: 0.0327012278139591 \n",
      "Epoch [47/5000] , Step [380/488] , Loss: 0.0323733128607273 \n",
      "Epoch [47/5000] , Step [390/488] , Loss: 0.0327401570975780 \n",
      "Epoch [47/5000] , Step [400/488] , Loss: 0.0325028225779533 \n",
      "Epoch [47/5000] , Step [410/488] , Loss: 0.0327665805816650 \n",
      "Epoch [47/5000] , Step [420/488] , Loss: 0.0334114022552967 \n",
      "Epoch [47/5000] , Step [430/488] , Loss: 0.0329359471797943 \n",
      "Epoch [47/5000] , Step [440/488] , Loss: 0.0314630568027496 \n",
      "Epoch [47/5000] , Step [450/488] , Loss: 0.0325005091726780 \n",
      "Epoch [47/5000] , Step [460/488] , Loss: 0.0330318920314312 \n",
      "Epoch [47/5000] , Step [470/488] , Loss: 0.0320142172276974 \n",
      "Epoch [47/5000] , Step [480/488] , Loss: 0.0320096053183079 \n",
      "Epoch [48/5000] , Step [10/488] , Loss: 0.0322129912674427 \n",
      "Epoch [48/5000] , Step [20/488] , Loss: 0.0324175432324409 \n",
      "Epoch [48/5000] , Step [30/488] , Loss: 0.0320743583142757 \n",
      "Epoch [48/5000] , Step [40/488] , Loss: 0.0325478836894035 \n",
      "Epoch [48/5000] , Step [50/488] , Loss: 0.0329911783337593 \n",
      "Epoch [48/5000] , Step [60/488] , Loss: 0.0323988385498524 \n",
      "Epoch [48/5000] , Step [70/488] , Loss: 0.0325534902513027 \n",
      "Epoch [48/5000] , Step [80/488] , Loss: 0.0325885750353336 \n",
      "Epoch [48/5000] , Step [90/488] , Loss: 0.0324532203376293 \n",
      "Epoch [48/5000] , Step [100/488] , Loss: 0.0323651246726513 \n",
      "Epoch [48/5000] , Step [110/488] , Loss: 0.0323244668543339 \n",
      "Epoch [48/5000] , Step [120/488] , Loss: 0.0319735333323479 \n",
      "Epoch [48/5000] , Step [130/488] , Loss: 0.0325120687484741 \n",
      "Epoch [48/5000] , Step [140/488] , Loss: 0.0326577350497246 \n",
      "Epoch [48/5000] , Step [150/488] , Loss: 0.0321909412741661 \n",
      "Epoch [48/5000] , Step [160/488] , Loss: 0.0322735309600830 \n",
      "Epoch [48/5000] , Step [170/488] , Loss: 0.0322329662740231 \n",
      "Epoch [48/5000] , Step [180/488] , Loss: 0.0331118255853653 \n",
      "Epoch [48/5000] , Step [190/488] , Loss: 0.0327017195522785 \n",
      "Epoch [48/5000] , Step [200/488] , Loss: 0.0326665565371513 \n",
      "Epoch [48/5000] , Step [210/488] , Loss: 0.0325973331928253 \n",
      "Epoch [48/5000] , Step [220/488] , Loss: 0.0322086624801159 \n",
      "Epoch [48/5000] , Step [230/488] , Loss: 0.0330254584550858 \n",
      "Epoch [48/5000] , Step [240/488] , Loss: 0.0324862152338028 \n",
      "Epoch [48/5000] , Step [250/488] , Loss: 0.0330245606601238 \n",
      "Epoch [48/5000] , Step [260/488] , Loss: 0.0322629921138287 \n",
      "Epoch [48/5000] , Step [270/488] , Loss: 0.0325260944664478 \n",
      "Epoch [48/5000] , Step [280/488] , Loss: 0.0322681218385696 \n",
      "Epoch [48/5000] , Step [290/488] , Loss: 0.0328794047236443 \n",
      "Epoch [48/5000] , Step [300/488] , Loss: 0.0322116725146770 \n",
      "Epoch [48/5000] , Step [310/488] , Loss: 0.0319284163415432 \n",
      "Epoch [48/5000] , Step [320/488] , Loss: 0.0326353684067726 \n",
      "Epoch [48/5000] , Step [330/488] , Loss: 0.0328365527093410 \n",
      "Epoch [48/5000] , Step [340/488] , Loss: 0.0326985828578472 \n",
      "Epoch [48/5000] , Step [350/488] , Loss: 0.0324065461754799 \n",
      "Epoch [48/5000] , Step [360/488] , Loss: 0.0330096930265427 \n",
      "Epoch [48/5000] , Step [370/488] , Loss: 0.0324610993266106 \n",
      "Epoch [48/5000] , Step [380/488] , Loss: 0.0330202840268612 \n",
      "Epoch [48/5000] , Step [390/488] , Loss: 0.0326613672077656 \n",
      "Epoch [48/5000] , Step [400/488] , Loss: 0.0322763137519360 \n",
      "Epoch [48/5000] , Step [410/488] , Loss: 0.0316826365888119 \n",
      "Epoch [48/5000] , Step [420/488] , Loss: 0.0327483043074608 \n",
      "Epoch [48/5000] , Step [430/488] , Loss: 0.0328740142285824 \n",
      "Epoch [48/5000] , Step [440/488] , Loss: 0.0321736969053745 \n",
      "Epoch [48/5000] , Step [450/488] , Loss: 0.0328875780105591 \n",
      "Epoch [48/5000] , Step [460/488] , Loss: 0.0321007221937180 \n",
      "Epoch [48/5000] , Step [470/488] , Loss: 0.0332313366234303 \n",
      "Epoch [48/5000] , Step [480/488] , Loss: 0.0329167507588863 \n",
      "Epoch [49/5000] , Step [10/488] , Loss: 0.0318801403045654 \n",
      "Epoch [49/5000] , Step [20/488] , Loss: 0.0324771367013454 \n",
      "Epoch [49/5000] , Step [30/488] , Loss: 0.0326815396547318 \n",
      "Epoch [49/5000] , Step [40/488] , Loss: 0.0329789258539677 \n",
      "Epoch [49/5000] , Step [50/488] , Loss: 0.0329056978225708 \n",
      "Epoch [49/5000] , Step [60/488] , Loss: 0.0324062891304493 \n",
      "Epoch [49/5000] , Step [70/488] , Loss: 0.0323531962931156 \n",
      "Epoch [49/5000] , Step [80/488] , Loss: 0.0320454426109791 \n",
      "Epoch [49/5000] , Step [90/488] , Loss: 0.0321210548281670 \n",
      "Epoch [49/5000] , Step [100/488] , Loss: 0.0327956713736057 \n",
      "Epoch [49/5000] , Step [110/488] , Loss: 0.0323927141726017 \n",
      "Epoch [49/5000] , Step [120/488] , Loss: 0.0323462709784508 \n",
      "Epoch [49/5000] , Step [130/488] , Loss: 0.0325366742908955 \n",
      "Epoch [49/5000] , Step [140/488] , Loss: 0.0329633541405201 \n",
      "Epoch [49/5000] , Step [150/488] , Loss: 0.0332283452153206 \n",
      "Epoch [49/5000] , Step [160/488] , Loss: 0.0326518826186657 \n",
      "Epoch [49/5000] , Step [170/488] , Loss: 0.0330242663621902 \n",
      "Epoch [49/5000] , Step [180/488] , Loss: 0.0323767103254795 \n",
      "Epoch [49/5000] , Step [190/488] , Loss: 0.0322679691016674 \n",
      "Epoch [49/5000] , Step [200/488] , Loss: 0.0325246341526508 \n",
      "Epoch [49/5000] , Step [210/488] , Loss: 0.0321421734988689 \n",
      "Epoch [49/5000] , Step [220/488] , Loss: 0.0321699641644955 \n",
      "Epoch [49/5000] , Step [230/488] , Loss: 0.0327213183045387 \n",
      "Epoch [49/5000] , Step [240/488] , Loss: 0.0319482162594795 \n",
      "Epoch [49/5000] , Step [250/488] , Loss: 0.0332382395863533 \n",
      "Epoch [49/5000] , Step [260/488] , Loss: 0.0324603840708733 \n",
      "Epoch [49/5000] , Step [270/488] , Loss: 0.0319408886134624 \n",
      "Epoch [49/5000] , Step [280/488] , Loss: 0.0322520658373833 \n",
      "Epoch [49/5000] , Step [290/488] , Loss: 0.0318927317857742 \n",
      "Epoch [49/5000] , Step [300/488] , Loss: 0.0319257788360119 \n",
      "Epoch [49/5000] , Step [310/488] , Loss: 0.0327645242214203 \n",
      "Epoch [49/5000] , Step [320/488] , Loss: 0.0329219661653042 \n",
      "Epoch [49/5000] , Step [330/488] , Loss: 0.0327470898628235 \n",
      "Epoch [49/5000] , Step [340/488] , Loss: 0.0328535474836826 \n",
      "Epoch [49/5000] , Step [350/488] , Loss: 0.0328942313790321 \n",
      "Epoch [49/5000] , Step [360/488] , Loss: 0.0323096849024296 \n",
      "Epoch [49/5000] , Step [370/488] , Loss: 0.0329537540674210 \n",
      "Epoch [49/5000] , Step [380/488] , Loss: 0.0318960547447205 \n",
      "Epoch [49/5000] , Step [390/488] , Loss: 0.0322063639760017 \n",
      "Epoch [49/5000] , Step [400/488] , Loss: 0.0323250778019428 \n",
      "Epoch [49/5000] , Step [410/488] , Loss: 0.0317395143210888 \n",
      "Epoch [49/5000] , Step [420/488] , Loss: 0.0326839871704578 \n",
      "Epoch [49/5000] , Step [430/488] , Loss: 0.0318014658987522 \n",
      "Epoch [49/5000] , Step [440/488] , Loss: 0.0334153734147549 \n",
      "Epoch [49/5000] , Step [450/488] , Loss: 0.0330895483493805 \n",
      "Epoch [49/5000] , Step [460/488] , Loss: 0.0321173220872879 \n",
      "Epoch [49/5000] , Step [470/488] , Loss: 0.0323926396667957 \n",
      "Epoch [49/5000] , Step [480/488] , Loss: 0.0322442762553692 \n",
      "Epoch [50/5000] , Step [10/488] , Loss: 0.0324772074818611 \n",
      "Epoch [50/5000] , Step [20/488] , Loss: 0.0326111949980259 \n",
      "Epoch [50/5000] , Step [30/488] , Loss: 0.0319808423519135 \n",
      "Epoch [50/5000] , Step [40/488] , Loss: 0.0321876518428326 \n",
      "Epoch [50/5000] , Step [50/488] , Loss: 0.0330343581736088 \n",
      "Epoch [50/5000] , Step [60/488] , Loss: 0.0319460481405258 \n",
      "Epoch [50/5000] , Step [70/488] , Loss: 0.0325409211218357 \n",
      "Epoch [50/5000] , Step [80/488] , Loss: 0.0326852425932884 \n",
      "Epoch [50/5000] , Step [90/488] , Loss: 0.0328233353793621 \n",
      "Epoch [50/5000] , Step [100/488] , Loss: 0.0322346761822701 \n",
      "Epoch [50/5000] , Step [110/488] , Loss: 0.0332813113927841 \n",
      "Epoch [50/5000] , Step [120/488] , Loss: 0.0325197391211987 \n",
      "Epoch [50/5000] , Step [130/488] , Loss: 0.0327926091849804 \n",
      "Epoch [50/5000] , Step [140/488] , Loss: 0.0326481498777866 \n",
      "Epoch [50/5000] , Step [150/488] , Loss: 0.0324071198701859 \n",
      "Epoch [50/5000] , Step [160/488] , Loss: 0.0323457866907120 \n",
      "Epoch [50/5000] , Step [170/488] , Loss: 0.0320390947163105 \n",
      "Epoch [50/5000] , Step [180/488] , Loss: 0.0327393338084221 \n",
      "Epoch [50/5000] , Step [190/488] , Loss: 0.0326516553759575 \n",
      "Epoch [50/5000] , Step [200/488] , Loss: 0.0324191898107529 \n",
      "Epoch [50/5000] , Step [210/488] , Loss: 0.0331025123596191 \n",
      "Epoch [50/5000] , Step [220/488] , Loss: 0.0327278152108192 \n",
      "Epoch [50/5000] , Step [230/488] , Loss: 0.0329930596053600 \n",
      "Epoch [50/5000] , Step [240/488] , Loss: 0.0326468385756016 \n",
      "Epoch [50/5000] , Step [250/488] , Loss: 0.0327724441885948 \n",
      "Epoch [50/5000] , Step [260/488] , Loss: 0.0325731448829174 \n",
      "Epoch [50/5000] , Step [270/488] , Loss: 0.0325163789093494 \n",
      "Epoch [50/5000] , Step [280/488] , Loss: 0.0321687869727612 \n",
      "Epoch [50/5000] , Step [290/488] , Loss: 0.0322802253067493 \n",
      "Epoch [50/5000] , Step [300/488] , Loss: 0.0332132615149021 \n",
      "Epoch [50/5000] , Step [310/488] , Loss: 0.0325985625386238 \n",
      "Epoch [50/5000] , Step [320/488] , Loss: 0.0319275893270969 \n",
      "Epoch [50/5000] , Step [330/488] , Loss: 0.0321406796574593 \n",
      "Epoch [50/5000] , Step [340/488] , Loss: 0.0326702632009983 \n",
      "Epoch [50/5000] , Step [350/488] , Loss: 0.0328933037817478 \n",
      "Epoch [50/5000] , Step [360/488] , Loss: 0.0327605232596397 \n",
      "Epoch [50/5000] , Step [370/488] , Loss: 0.0325687676668167 \n",
      "Epoch [50/5000] , Step [380/488] , Loss: 0.0322768911719322 \n",
      "Epoch [50/5000] , Step [390/488] , Loss: 0.0317436940968037 \n",
      "Epoch [50/5000] , Step [400/488] , Loss: 0.0322477705776691 \n",
      "Epoch [50/5000] , Step [410/488] , Loss: 0.0324193537235260 \n",
      "Epoch [50/5000] , Step [420/488] , Loss: 0.0326863452792168 \n",
      "Epoch [50/5000] , Step [430/488] , Loss: 0.0324071981012821 \n",
      "Epoch [50/5000] , Step [440/488] , Loss: 0.0319460593163967 \n",
      "Epoch [50/5000] , Step [450/488] , Loss: 0.0321435928344727 \n",
      "Epoch [50/5000] , Step [460/488] , Loss: 0.0324424766004086 \n",
      "Epoch [50/5000] , Step [470/488] , Loss: 0.0326478220522404 \n",
      "Epoch [50/5000] , Step [480/488] , Loss: 0.0324368104338646 \n",
      "Epoch [51/5000] , Step [10/488] , Loss: 0.0322149060666561 \n",
      "Epoch [51/5000] , Step [20/488] , Loss: 0.0319777727127075 \n",
      "Epoch [51/5000] , Step [30/488] , Loss: 0.0328207276761532 \n",
      "Epoch [51/5000] , Step [40/488] , Loss: 0.0316894948482513 \n",
      "Epoch [51/5000] , Step [50/488] , Loss: 0.0325045697391033 \n",
      "Epoch [51/5000] , Step [60/488] , Loss: 0.0327917821705341 \n",
      "Epoch [51/5000] , Step [70/488] , Loss: 0.0320269241929054 \n",
      "Epoch [51/5000] , Step [80/488] , Loss: 0.0333313085138798 \n",
      "Epoch [51/5000] , Step [90/488] , Loss: 0.0321503803133965 \n",
      "Epoch [51/5000] , Step [100/488] , Loss: 0.0323205031454563 \n",
      "Epoch [51/5000] , Step [110/488] , Loss: 0.0325420349836349 \n",
      "Epoch [51/5000] , Step [120/488] , Loss: 0.0332454480230808 \n",
      "Epoch [51/5000] , Step [130/488] , Loss: 0.0326871201395988 \n",
      "Epoch [51/5000] , Step [140/488] , Loss: 0.0324095487594604 \n",
      "Epoch [51/5000] , Step [150/488] , Loss: 0.0324335731565952 \n",
      "Epoch [51/5000] , Step [160/488] , Loss: 0.0329883210361004 \n",
      "Epoch [51/5000] , Step [170/488] , Loss: 0.0322237536311150 \n",
      "Epoch [51/5000] , Step [180/488] , Loss: 0.0329388938844204 \n",
      "Epoch [51/5000] , Step [190/488] , Loss: 0.0328626856207848 \n",
      "Epoch [51/5000] , Step [200/488] , Loss: 0.0323088802397251 \n",
      "Epoch [51/5000] , Step [210/488] , Loss: 0.0319967828691006 \n",
      "Epoch [51/5000] , Step [220/488] , Loss: 0.0325055271387100 \n",
      "Epoch [51/5000] , Step [230/488] , Loss: 0.0330136194825172 \n",
      "Epoch [51/5000] , Step [240/488] , Loss: 0.0324981771409512 \n",
      "Epoch [51/5000] , Step [250/488] , Loss: 0.0327429696917534 \n",
      "Epoch [51/5000] , Step [260/488] , Loss: 0.0321147665381432 \n",
      "Epoch [51/5000] , Step [270/488] , Loss: 0.0325629338622093 \n",
      "Epoch [51/5000] , Step [280/488] , Loss: 0.0322736017405987 \n",
      "Epoch [51/5000] , Step [290/488] , Loss: 0.0322516821324825 \n",
      "Epoch [51/5000] , Step [300/488] , Loss: 0.0320083908736706 \n",
      "Epoch [51/5000] , Step [310/488] , Loss: 0.0328437201678753 \n",
      "Epoch [51/5000] , Step [320/488] , Loss: 0.0326436460018158 \n",
      "Epoch [51/5000] , Step [330/488] , Loss: 0.0329665280878544 \n",
      "Epoch [51/5000] , Step [340/488] , Loss: 0.0323178246617317 \n",
      "Epoch [51/5000] , Step [350/488] , Loss: 0.0321963652968407 \n",
      "Epoch [51/5000] , Step [360/488] , Loss: 0.0319968201220036 \n",
      "Epoch [51/5000] , Step [370/488] , Loss: 0.0325036011636257 \n",
      "Epoch [51/5000] , Step [380/488] , Loss: 0.0329195968806744 \n",
      "Epoch [51/5000] , Step [390/488] , Loss: 0.0323307551443577 \n",
      "Epoch [51/5000] , Step [400/488] , Loss: 0.0326290316879749 \n",
      "Epoch [51/5000] , Step [410/488] , Loss: 0.0325358137488365 \n",
      "Epoch [51/5000] , Step [420/488] , Loss: 0.0321511141955853 \n",
      "Epoch [51/5000] , Step [430/488] , Loss: 0.0321822613477707 \n",
      "Epoch [51/5000] , Step [440/488] , Loss: 0.0323387943208218 \n",
      "Epoch [51/5000] , Step [450/488] , Loss: 0.0320014916360378 \n",
      "Epoch [51/5000] , Step [460/488] , Loss: 0.0322642587125301 \n",
      "Epoch [51/5000] , Step [470/488] , Loss: 0.0328046008944511 \n",
      "Epoch [51/5000] , Step [480/488] , Loss: 0.0321497991681099 \n",
      "Epoch [52/5000] , Step [10/488] , Loss: 0.0321136452257633 \n",
      "Epoch [52/5000] , Step [20/488] , Loss: 0.0330796018242836 \n",
      "Epoch [52/5000] , Step [30/488] , Loss: 0.0320779122412205 \n",
      "Epoch [52/5000] , Step [40/488] , Loss: 0.0333180390298367 \n",
      "Epoch [52/5000] , Step [50/488] , Loss: 0.0321565121412277 \n",
      "Epoch [52/5000] , Step [60/488] , Loss: 0.0322509407997131 \n",
      "Epoch [52/5000] , Step [70/488] , Loss: 0.0321145020425320 \n",
      "Epoch [52/5000] , Step [80/488] , Loss: 0.0324265994131565 \n",
      "Epoch [52/5000] , Step [90/488] , Loss: 0.0322608575224876 \n",
      "Epoch [52/5000] , Step [100/488] , Loss: 0.0325033105909824 \n",
      "Epoch [52/5000] , Step [110/488] , Loss: 0.0324739255011082 \n",
      "Epoch [52/5000] , Step [120/488] , Loss: 0.0325382016599178 \n",
      "Epoch [52/5000] , Step [130/488] , Loss: 0.0331147760152817 \n",
      "Epoch [52/5000] , Step [140/488] , Loss: 0.0322059653699398 \n",
      "Epoch [52/5000] , Step [150/488] , Loss: 0.0322445109486580 \n",
      "Epoch [52/5000] , Step [160/488] , Loss: 0.0320871807634830 \n",
      "Epoch [52/5000] , Step [170/488] , Loss: 0.0323929935693741 \n",
      "Epoch [52/5000] , Step [180/488] , Loss: 0.0325777642428875 \n",
      "Epoch [52/5000] , Step [190/488] , Loss: 0.0324914678931236 \n",
      "Epoch [52/5000] , Step [200/488] , Loss: 0.0328812897205353 \n",
      "Epoch [52/5000] , Step [210/488] , Loss: 0.0322390347719193 \n",
      "Epoch [52/5000] , Step [220/488] , Loss: 0.0324695110321045 \n",
      "Epoch [52/5000] , Step [230/488] , Loss: 0.0325762182474136 \n",
      "Epoch [52/5000] , Step [240/488] , Loss: 0.0322601646184921 \n",
      "Epoch [52/5000] , Step [250/488] , Loss: 0.0324001722037792 \n",
      "Epoch [52/5000] , Step [260/488] , Loss: 0.0323384106159210 \n",
      "Epoch [52/5000] , Step [270/488] , Loss: 0.0324920304119587 \n",
      "Epoch [52/5000] , Step [280/488] , Loss: 0.0326673761010170 \n",
      "Epoch [52/5000] , Step [290/488] , Loss: 0.0319837108254433 \n",
      "Epoch [52/5000] , Step [300/488] , Loss: 0.0323857814073563 \n",
      "Epoch [52/5000] , Step [310/488] , Loss: 0.0325706712901592 \n",
      "Epoch [52/5000] , Step [320/488] , Loss: 0.0322904437780380 \n",
      "Epoch [52/5000] , Step [330/488] , Loss: 0.0329785495996475 \n",
      "Epoch [52/5000] , Step [340/488] , Loss: 0.0318559408187866 \n",
      "Epoch [52/5000] , Step [350/488] , Loss: 0.0332742184400558 \n",
      "Epoch [52/5000] , Step [360/488] , Loss: 0.0329729616641998 \n",
      "Epoch [52/5000] , Step [370/488] , Loss: 0.0323853008449078 \n",
      "Epoch [52/5000] , Step [380/488] , Loss: 0.0320629067718983 \n",
      "Epoch [52/5000] , Step [390/488] , Loss: 0.0325427576899529 \n",
      "Epoch [52/5000] , Step [400/488] , Loss: 0.0326213091611862 \n",
      "Epoch [52/5000] , Step [410/488] , Loss: 0.0323096551001072 \n",
      "Epoch [52/5000] , Step [420/488] , Loss: 0.0326600894331932 \n",
      "Epoch [52/5000] , Step [430/488] , Loss: 0.0319948121905327 \n",
      "Epoch [52/5000] , Step [440/488] , Loss: 0.0326509587466717 \n",
      "Epoch [52/5000] , Step [450/488] , Loss: 0.0329380594193935 \n",
      "Epoch [52/5000] , Step [460/488] , Loss: 0.0324545092880726 \n",
      "Epoch [52/5000] , Step [470/488] , Loss: 0.0322800762951374 \n",
      "Epoch [52/5000] , Step [480/488] , Loss: 0.0327075794339180 \n",
      "Epoch [53/5000] , Step [10/488] , Loss: 0.0322845913469791 \n",
      "Epoch [53/5000] , Step [20/488] , Loss: 0.0322883129119873 \n",
      "Epoch [53/5000] , Step [30/488] , Loss: 0.0330205559730530 \n",
      "Epoch [53/5000] , Step [40/488] , Loss: 0.0333237089216709 \n",
      "Epoch [53/5000] , Step [50/488] , Loss: 0.0323131233453751 \n",
      "Epoch [53/5000] , Step [60/488] , Loss: 0.0323467366397381 \n",
      "Epoch [53/5000] , Step [70/488] , Loss: 0.0328435152769089 \n",
      "Epoch [53/5000] , Step [80/488] , Loss: 0.0334791429340839 \n",
      "Epoch [53/5000] , Step [90/488] , Loss: 0.0326022766530514 \n",
      "Epoch [53/5000] , Step [100/488] , Loss: 0.0329229682683945 \n",
      "Epoch [53/5000] , Step [110/488] , Loss: 0.0329166986048222 \n",
      "Epoch [53/5000] , Step [120/488] , Loss: 0.0328480377793312 \n",
      "Epoch [53/5000] , Step [130/488] , Loss: 0.0318943262100220 \n",
      "Epoch [53/5000] , Step [140/488] , Loss: 0.0330972485244274 \n",
      "Epoch [53/5000] , Step [150/488] , Loss: 0.0328427404165268 \n",
      "Epoch [53/5000] , Step [160/488] , Loss: 0.0324033163487911 \n",
      "Epoch [53/5000] , Step [170/488] , Loss: 0.0324624069035053 \n",
      "Epoch [53/5000] , Step [180/488] , Loss: 0.0325002521276474 \n",
      "Epoch [53/5000] , Step [190/488] , Loss: 0.0323583446443081 \n",
      "Epoch [53/5000] , Step [200/488] , Loss: 0.0324749276041985 \n",
      "Epoch [53/5000] , Step [210/488] , Loss: 0.0321815647184849 \n",
      "Epoch [53/5000] , Step [220/488] , Loss: 0.0325191915035248 \n",
      "Epoch [53/5000] , Step [230/488] , Loss: 0.0325208380818367 \n",
      "Epoch [53/5000] , Step [240/488] , Loss: 0.0333164818584919 \n",
      "Epoch [53/5000] , Step [250/488] , Loss: 0.0322959944605827 \n",
      "Epoch [53/5000] , Step [260/488] , Loss: 0.0330586731433868 \n",
      "Epoch [53/5000] , Step [270/488] , Loss: 0.0327985100448132 \n",
      "Epoch [53/5000] , Step [280/488] , Loss: 0.0320291146636009 \n",
      "Epoch [53/5000] , Step [290/488] , Loss: 0.0324859619140625 \n",
      "Epoch [53/5000] , Step [300/488] , Loss: 0.0323662795126438 \n",
      "Epoch [53/5000] , Step [310/488] , Loss: 0.0327406674623489 \n",
      "Epoch [53/5000] , Step [320/488] , Loss: 0.0325822681188583 \n",
      "Epoch [53/5000] , Step [330/488] , Loss: 0.0326776988804340 \n",
      "Epoch [53/5000] , Step [340/488] , Loss: 0.0315296575427055 \n",
      "Epoch [53/5000] , Step [350/488] , Loss: 0.0326419807970524 \n",
      "Epoch [53/5000] , Step [360/488] , Loss: 0.0321530699729919 \n",
      "Epoch [53/5000] , Step [370/488] , Loss: 0.0331226848065853 \n",
      "Epoch [53/5000] , Step [380/488] , Loss: 0.0323475636541843 \n",
      "Epoch [53/5000] , Step [390/488] , Loss: 0.0321387425065041 \n",
      "Epoch [53/5000] , Step [400/488] , Loss: 0.0329269021749496 \n",
      "Epoch [53/5000] , Step [410/488] , Loss: 0.0328495539724827 \n",
      "Epoch [53/5000] , Step [420/488] , Loss: 0.0323659293353558 \n",
      "Epoch [53/5000] , Step [430/488] , Loss: 0.0326091051101685 \n",
      "Epoch [53/5000] , Step [440/488] , Loss: 0.0320293605327606 \n",
      "Epoch [53/5000] , Step [450/488] , Loss: 0.0327786505222321 \n",
      "Epoch [53/5000] , Step [460/488] , Loss: 0.0326171070337296 \n",
      "Epoch [53/5000] , Step [470/488] , Loss: 0.0330885387957096 \n",
      "Epoch [53/5000] , Step [480/488] , Loss: 0.0321044810116291 \n",
      "Epoch [54/5000] , Step [10/488] , Loss: 0.0322303995490074 \n",
      "Epoch [54/5000] , Step [20/488] , Loss: 0.0323754511773586 \n",
      "Epoch [54/5000] , Step [30/488] , Loss: 0.0329391658306122 \n",
      "Epoch [54/5000] , Step [40/488] , Loss: 0.0326438955962658 \n",
      "Epoch [54/5000] , Step [50/488] , Loss: 0.0319255404174328 \n",
      "Epoch [54/5000] , Step [60/488] , Loss: 0.0317980609834194 \n",
      "Epoch [54/5000] , Step [70/488] , Loss: 0.0324331745505333 \n",
      "Epoch [54/5000] , Step [80/488] , Loss: 0.0324075296521187 \n",
      "Epoch [54/5000] , Step [90/488] , Loss: 0.0329423025250435 \n",
      "Epoch [54/5000] , Step [100/488] , Loss: 0.0327393114566803 \n",
      "Epoch [54/5000] , Step [110/488] , Loss: 0.0328508689999580 \n",
      "Epoch [54/5000] , Step [120/488] , Loss: 0.0328905023634434 \n",
      "Epoch [54/5000] , Step [130/488] , Loss: 0.0322991199791431 \n",
      "Epoch [54/5000] , Step [140/488] , Loss: 0.0326823480427265 \n",
      "Epoch [54/5000] , Step [150/488] , Loss: 0.0328642800450325 \n",
      "Epoch [54/5000] , Step [160/488] , Loss: 0.0329331867396832 \n",
      "Epoch [54/5000] , Step [170/488] , Loss: 0.0323108993470669 \n",
      "Epoch [54/5000] , Step [180/488] , Loss: 0.0320765338838100 \n",
      "Epoch [54/5000] , Step [190/488] , Loss: 0.0329184383153915 \n",
      "Epoch [54/5000] , Step [200/488] , Loss: 0.0325111262500286 \n",
      "Epoch [54/5000] , Step [210/488] , Loss: 0.0326428115367889 \n",
      "Epoch [54/5000] , Step [220/488] , Loss: 0.0327631197869778 \n",
      "Epoch [54/5000] , Step [230/488] , Loss: 0.0326537750661373 \n",
      "Epoch [54/5000] , Step [240/488] , Loss: 0.0330424793064594 \n",
      "Epoch [54/5000] , Step [250/488] , Loss: 0.0324054844677448 \n",
      "Epoch [54/5000] , Step [260/488] , Loss: 0.0318351686000824 \n",
      "Epoch [54/5000] , Step [270/488] , Loss: 0.0320708788931370 \n",
      "Epoch [54/5000] , Step [280/488] , Loss: 0.0317755453288555 \n",
      "Epoch [54/5000] , Step [290/488] , Loss: 0.0321026407182217 \n",
      "Epoch [54/5000] , Step [300/488] , Loss: 0.0326890610158443 \n",
      "Epoch [54/5000] , Step [310/488] , Loss: 0.0320344865322113 \n",
      "Epoch [54/5000] , Step [320/488] , Loss: 0.0321194753050804 \n",
      "Epoch [54/5000] , Step [330/488] , Loss: 0.0328964926302433 \n",
      "Epoch [54/5000] , Step [340/488] , Loss: 0.0328302085399628 \n",
      "Epoch [54/5000] , Step [350/488] , Loss: 0.0324656181037426 \n",
      "Epoch [54/5000] , Step [360/488] , Loss: 0.0329104103147984 \n",
      "Epoch [54/5000] , Step [370/488] , Loss: 0.0323863960802555 \n",
      "Epoch [54/5000] , Step [380/488] , Loss: 0.0330482162535191 \n",
      "Epoch [54/5000] , Step [390/488] , Loss: 0.0325194709002972 \n",
      "Epoch [54/5000] , Step [400/488] , Loss: 0.0332712456583977 \n",
      "Epoch [54/5000] , Step [410/488] , Loss: 0.0326563157141209 \n",
      "Epoch [54/5000] , Step [420/488] , Loss: 0.0326277092099190 \n",
      "Epoch [54/5000] , Step [430/488] , Loss: 0.0318453982472420 \n",
      "Epoch [54/5000] , Step [440/488] , Loss: 0.0320797935128212 \n",
      "Epoch [54/5000] , Step [450/488] , Loss: 0.0328465700149536 \n",
      "Epoch [54/5000] , Step [460/488] , Loss: 0.0325414575636387 \n",
      "Epoch [54/5000] , Step [470/488] , Loss: 0.0333345457911491 \n",
      "Epoch [54/5000] , Step [480/488] , Loss: 0.0326310433447361 \n",
      "Epoch [55/5000] , Step [10/488] , Loss: 0.0327541120350361 \n",
      "Epoch [55/5000] , Step [20/488] , Loss: 0.0325293578207493 \n",
      "Epoch [55/5000] , Step [30/488] , Loss: 0.0325493738055229 \n",
      "Epoch [55/5000] , Step [40/488] , Loss: 0.0320036374032497 \n",
      "Epoch [55/5000] , Step [50/488] , Loss: 0.0317939557135105 \n",
      "Epoch [55/5000] , Step [60/488] , Loss: 0.0323582887649536 \n",
      "Epoch [55/5000] , Step [70/488] , Loss: 0.0331363566219807 \n",
      "Epoch [55/5000] , Step [80/488] , Loss: 0.0325397327542305 \n",
      "Epoch [55/5000] , Step [90/488] , Loss: 0.0325119718909264 \n",
      "Epoch [55/5000] , Step [100/488] , Loss: 0.0327167995274067 \n",
      "Epoch [55/5000] , Step [110/488] , Loss: 0.0322160497307777 \n",
      "Epoch [55/5000] , Step [120/488] , Loss: 0.0325306840240955 \n",
      "Epoch [55/5000] , Step [130/488] , Loss: 0.0327174030244350 \n",
      "Epoch [55/5000] , Step [140/488] , Loss: 0.0318038389086723 \n",
      "Epoch [55/5000] , Step [150/488] , Loss: 0.0330220684409142 \n",
      "Epoch [55/5000] , Step [160/488] , Loss: 0.0331900492310524 \n",
      "Epoch [55/5000] , Step [170/488] , Loss: 0.0330616384744644 \n",
      "Epoch [55/5000] , Step [180/488] , Loss: 0.0322412848472595 \n",
      "Epoch [55/5000] , Step [190/488] , Loss: 0.0323502495884895 \n",
      "Epoch [55/5000] , Step [200/488] , Loss: 0.0323520265519619 \n",
      "Epoch [55/5000] , Step [210/488] , Loss: 0.0331189632415771 \n",
      "Epoch [55/5000] , Step [220/488] , Loss: 0.0324142426252365 \n",
      "Epoch [55/5000] , Step [230/488] , Loss: 0.0321698971092701 \n",
      "Epoch [55/5000] , Step [240/488] , Loss: 0.0322946906089783 \n",
      "Epoch [55/5000] , Step [250/488] , Loss: 0.0324815027415752 \n",
      "Epoch [55/5000] , Step [260/488] , Loss: 0.0318726748228073 \n",
      "Epoch [55/5000] , Step [270/488] , Loss: 0.0330234728753567 \n",
      "Epoch [55/5000] , Step [280/488] , Loss: 0.0325768738985062 \n",
      "Epoch [55/5000] , Step [290/488] , Loss: 0.0324107669293880 \n",
      "Epoch [55/5000] , Step [300/488] , Loss: 0.0328261069953442 \n",
      "Epoch [55/5000] , Step [310/488] , Loss: 0.0326275192201138 \n",
      "Epoch [55/5000] , Step [320/488] , Loss: 0.0326895192265511 \n",
      "Epoch [55/5000] , Step [330/488] , Loss: 0.0327441915869713 \n",
      "Epoch [55/5000] , Step [340/488] , Loss: 0.0328969024121761 \n",
      "Epoch [55/5000] , Step [350/488] , Loss: 0.0323697030544281 \n",
      "Epoch [55/5000] , Step [360/488] , Loss: 0.0327802225947380 \n",
      "Epoch [55/5000] , Step [370/488] , Loss: 0.0319202393293381 \n",
      "Epoch [55/5000] , Step [380/488] , Loss: 0.0321906916797161 \n",
      "Epoch [55/5000] , Step [390/488] , Loss: 0.0321937836706638 \n",
      "Epoch [55/5000] , Step [400/488] , Loss: 0.0321363918483257 \n",
      "Epoch [55/5000] , Step [410/488] , Loss: 0.0321499109268188 \n",
      "Epoch [55/5000] , Step [420/488] , Loss: 0.0326812453567982 \n",
      "Epoch [55/5000] , Step [430/488] , Loss: 0.0324298962950706 \n",
      "Epoch [55/5000] , Step [440/488] , Loss: 0.0329279638826847 \n",
      "Epoch [55/5000] , Step [450/488] , Loss: 0.0328651033341885 \n",
      "Epoch [55/5000] , Step [460/488] , Loss: 0.0324570462107658 \n",
      "Epoch [55/5000] , Step [470/488] , Loss: 0.0321182273328304 \n",
      "Epoch [55/5000] , Step [480/488] , Loss: 0.0323028638958931 \n",
      "Epoch [56/5000] , Step [10/488] , Loss: 0.0327893048524857 \n",
      "Epoch [56/5000] , Step [20/488] , Loss: 0.0327132493257523 \n",
      "Epoch [56/5000] , Step [30/488] , Loss: 0.0321214087307453 \n",
      "Epoch [56/5000] , Step [40/488] , Loss: 0.0331319831311703 \n",
      "Epoch [56/5000] , Step [50/488] , Loss: 0.0326485671103001 \n",
      "Epoch [56/5000] , Step [60/488] , Loss: 0.0321178622543812 \n",
      "Epoch [56/5000] , Step [70/488] , Loss: 0.0326372608542442 \n",
      "Epoch [56/5000] , Step [80/488] , Loss: 0.0323168560862541 \n",
      "Epoch [56/5000] , Step [90/488] , Loss: 0.0326981768012047 \n",
      "Epoch [56/5000] , Step [100/488] , Loss: 0.0323746949434280 \n",
      "Epoch [56/5000] , Step [110/488] , Loss: 0.0320800133049488 \n",
      "Epoch [56/5000] , Step [120/488] , Loss: 0.0329486429691315 \n",
      "Epoch [56/5000] , Step [130/488] , Loss: 0.0328581593930721 \n",
      "Epoch [56/5000] , Step [140/488] , Loss: 0.0324080549180508 \n",
      "Epoch [56/5000] , Step [150/488] , Loss: 0.0331010967493057 \n",
      "Epoch [56/5000] , Step [160/488] , Loss: 0.0328314118087292 \n",
      "Epoch [56/5000] , Step [170/488] , Loss: 0.0331949144601822 \n",
      "Epoch [56/5000] , Step [180/488] , Loss: 0.0324668660759926 \n",
      "Epoch [56/5000] , Step [190/488] , Loss: 0.0324262268841267 \n",
      "Epoch [56/5000] , Step [200/488] , Loss: 0.0324082560837269 \n",
      "Epoch [56/5000] , Step [210/488] , Loss: 0.0329789184033871 \n",
      "Epoch [56/5000] , Step [220/488] , Loss: 0.0326286889612675 \n",
      "Epoch [56/5000] , Step [230/488] , Loss: 0.0322264842689037 \n",
      "Epoch [56/5000] , Step [240/488] , Loss: 0.0329241529107094 \n",
      "Epoch [56/5000] , Step [250/488] , Loss: 0.0325276292860508 \n",
      "Epoch [56/5000] , Step [260/488] , Loss: 0.0318034328520298 \n",
      "Epoch [56/5000] , Step [270/488] , Loss: 0.0324635542929173 \n",
      "Epoch [56/5000] , Step [280/488] , Loss: 0.0323416367173195 \n",
      "Epoch [56/5000] , Step [290/488] , Loss: 0.0317363515496254 \n",
      "Epoch [56/5000] , Step [300/488] , Loss: 0.0330138728022575 \n",
      "Epoch [56/5000] , Step [310/488] , Loss: 0.0327982604503632 \n",
      "Epoch [56/5000] , Step [320/488] , Loss: 0.0317272469401360 \n",
      "Epoch [56/5000] , Step [330/488] , Loss: 0.0324028953909874 \n",
      "Epoch [56/5000] , Step [340/488] , Loss: 0.0328663922846317 \n",
      "Epoch [56/5000] , Step [350/488] , Loss: 0.0330724753439426 \n",
      "Epoch [56/5000] , Step [360/488] , Loss: 0.0326861031353474 \n",
      "Epoch [56/5000] , Step [370/488] , Loss: 0.0329509973526001 \n",
      "Epoch [56/5000] , Step [380/488] , Loss: 0.0323322489857674 \n",
      "Epoch [56/5000] , Step [390/488] , Loss: 0.0321766324341297 \n",
      "Epoch [56/5000] , Step [400/488] , Loss: 0.0324863307178020 \n",
      "Epoch [56/5000] , Step [410/488] , Loss: 0.0323681347072124 \n",
      "Epoch [56/5000] , Step [420/488] , Loss: 0.0328115187585354 \n",
      "Epoch [56/5000] , Step [430/488] , Loss: 0.0325678810477257 \n",
      "Epoch [56/5000] , Step [440/488] , Loss: 0.0320536829531193 \n",
      "Epoch [56/5000] , Step [450/488] , Loss: 0.0314202420413494 \n",
      "Epoch [56/5000] , Step [460/488] , Loss: 0.0323315188288689 \n",
      "Epoch [56/5000] , Step [470/488] , Loss: 0.0321904420852661 \n",
      "Epoch [56/5000] , Step [480/488] , Loss: 0.0322874560952187 \n",
      "Epoch [57/5000] , Step [10/488] , Loss: 0.0323188453912735 \n",
      "Epoch [57/5000] , Step [20/488] , Loss: 0.0326018705964088 \n",
      "Epoch [57/5000] , Step [30/488] , Loss: 0.0328056141734123 \n",
      "Epoch [57/5000] , Step [40/488] , Loss: 0.0325903110206127 \n",
      "Epoch [57/5000] , Step [50/488] , Loss: 0.0327568054199219 \n",
      "Epoch [57/5000] , Step [60/488] , Loss: 0.0321229398250580 \n",
      "Epoch [57/5000] , Step [70/488] , Loss: 0.0322204157710075 \n",
      "Epoch [57/5000] , Step [80/488] , Loss: 0.0325459949672222 \n",
      "Epoch [57/5000] , Step [90/488] , Loss: 0.0326976925134659 \n",
      "Epoch [57/5000] , Step [100/488] , Loss: 0.0329334326088428 \n",
      "Epoch [57/5000] , Step [110/488] , Loss: 0.0322665721178055 \n",
      "Epoch [57/5000] , Step [120/488] , Loss: 0.0330826565623283 \n",
      "Epoch [57/5000] , Step [130/488] , Loss: 0.0326319858431816 \n",
      "Epoch [57/5000] , Step [140/488] , Loss: 0.0326036997139454 \n",
      "Epoch [57/5000] , Step [150/488] , Loss: 0.0331213995814323 \n",
      "Epoch [57/5000] , Step [160/488] , Loss: 0.0326345264911652 \n",
      "Epoch [57/5000] , Step [170/488] , Loss: 0.0328671149909496 \n",
      "Epoch [57/5000] , Step [180/488] , Loss: 0.0336857810616493 \n",
      "Epoch [57/5000] , Step [190/488] , Loss: 0.0334742330014706 \n",
      "Epoch [57/5000] , Step [200/488] , Loss: 0.0325834862887859 \n",
      "Epoch [57/5000] , Step [210/488] , Loss: 0.0326099954545498 \n",
      "Epoch [57/5000] , Step [220/488] , Loss: 0.0332323387265205 \n",
      "Epoch [57/5000] , Step [230/488] , Loss: 0.0328468084335327 \n",
      "Epoch [57/5000] , Step [240/488] , Loss: 0.0321574918925762 \n",
      "Epoch [57/5000] , Step [250/488] , Loss: 0.0328075885772705 \n",
      "Epoch [57/5000] , Step [260/488] , Loss: 0.0328861474990845 \n",
      "Epoch [57/5000] , Step [270/488] , Loss: 0.0325110591948032 \n",
      "Epoch [57/5000] , Step [280/488] , Loss: 0.0328507572412491 \n",
      "Epoch [57/5000] , Step [290/488] , Loss: 0.0325464867055416 \n",
      "Epoch [57/5000] , Step [300/488] , Loss: 0.0327528193593025 \n",
      "Epoch [57/5000] , Step [310/488] , Loss: 0.0327300913631916 \n",
      "Epoch [57/5000] , Step [320/488] , Loss: 0.0326537340879440 \n",
      "Epoch [57/5000] , Step [330/488] , Loss: 0.0322742275893688 \n",
      "Epoch [57/5000] , Step [340/488] , Loss: 0.0323261208832264 \n",
      "Epoch [57/5000] , Step [350/488] , Loss: 0.0326198302209377 \n",
      "Epoch [57/5000] , Step [360/488] , Loss: 0.0335043705999851 \n",
      "Epoch [57/5000] , Step [370/488] , Loss: 0.0324571691453457 \n",
      "Epoch [57/5000] , Step [380/488] , Loss: 0.0327477678656578 \n",
      "Epoch [57/5000] , Step [390/488] , Loss: 0.0324841141700745 \n",
      "Epoch [57/5000] , Step [400/488] , Loss: 0.0333054326474667 \n",
      "Epoch [57/5000] , Step [410/488] , Loss: 0.0328641980886459 \n",
      "Epoch [57/5000] , Step [420/488] , Loss: 0.0327210649847984 \n",
      "Epoch [57/5000] , Step [430/488] , Loss: 0.0323145203292370 \n",
      "Epoch [57/5000] , Step [440/488] , Loss: 0.0329025201499462 \n",
      "Epoch [57/5000] , Step [450/488] , Loss: 0.0323422290384769 \n",
      "Epoch [57/5000] , Step [460/488] , Loss: 0.0321392118930817 \n",
      "Epoch [57/5000] , Step [470/488] , Loss: 0.0325753688812256 \n",
      "Epoch [57/5000] , Step [480/488] , Loss: 0.0324285887181759 \n",
      "Epoch [58/5000] , Step [10/488] , Loss: 0.0331487916409969 \n",
      "Epoch [58/5000] , Step [20/488] , Loss: 0.0322159677743912 \n",
      "Epoch [58/5000] , Step [30/488] , Loss: 0.0322044268250465 \n",
      "Epoch [58/5000] , Step [40/488] , Loss: 0.0327771902084351 \n",
      "Epoch [58/5000] , Step [50/488] , Loss: 0.0331146940588951 \n",
      "Epoch [58/5000] , Step [60/488] , Loss: 0.0322370044887066 \n",
      "Epoch [58/5000] , Step [70/488] , Loss: 0.0320029221475124 \n",
      "Epoch [58/5000] , Step [80/488] , Loss: 0.0320233590900898 \n",
      "Epoch [58/5000] , Step [90/488] , Loss: 0.0324706323444843 \n",
      "Epoch [58/5000] , Step [100/488] , Loss: 0.0318959504365921 \n",
      "Epoch [58/5000] , Step [110/488] , Loss: 0.0322640314698219 \n",
      "Epoch [58/5000] , Step [120/488] , Loss: 0.0329510383307934 \n",
      "Epoch [58/5000] , Step [130/488] , Loss: 0.0327376909554005 \n",
      "Epoch [58/5000] , Step [140/488] , Loss: 0.0328461229801178 \n",
      "Epoch [58/5000] , Step [150/488] , Loss: 0.0325467102229595 \n",
      "Epoch [58/5000] , Step [160/488] , Loss: 0.0322060398757458 \n",
      "Epoch [58/5000] , Step [170/488] , Loss: 0.0326894186437130 \n",
      "Epoch [58/5000] , Step [180/488] , Loss: 0.0325016267597675 \n",
      "Epoch [58/5000] , Step [190/488] , Loss: 0.0328767672181129 \n",
      "Epoch [58/5000] , Step [200/488] , Loss: 0.0328636802732944 \n",
      "Epoch [58/5000] , Step [210/488] , Loss: 0.0325840152800083 \n",
      "Epoch [58/5000] , Step [220/488] , Loss: 0.0323301814496517 \n",
      "Epoch [58/5000] , Step [230/488] , Loss: 0.0332979932427406 \n",
      "Epoch [58/5000] , Step [240/488] , Loss: 0.0326279327273369 \n",
      "Epoch [58/5000] , Step [250/488] , Loss: 0.0326521955430508 \n",
      "Epoch [58/5000] , Step [260/488] , Loss: 0.0320720188319683 \n",
      "Epoch [58/5000] , Step [270/488] , Loss: 0.0326309762895107 \n",
      "Epoch [58/5000] , Step [280/488] , Loss: 0.0326369069516659 \n",
      "Epoch [58/5000] , Step [290/488] , Loss: 0.0320009775459766 \n",
      "Epoch [58/5000] , Step [300/488] , Loss: 0.0321591049432755 \n",
      "Epoch [58/5000] , Step [310/488] , Loss: 0.0328667797148228 \n",
      "Epoch [58/5000] , Step [320/488] , Loss: 0.0329172238707542 \n",
      "Epoch [58/5000] , Step [330/488] , Loss: 0.0327515825629234 \n",
      "Epoch [58/5000] , Step [340/488] , Loss: 0.0327302441000938 \n",
      "Epoch [58/5000] , Step [350/488] , Loss: 0.0326720066368580 \n",
      "Epoch [58/5000] , Step [360/488] , Loss: 0.0328148491680622 \n",
      "Epoch [58/5000] , Step [370/488] , Loss: 0.0327107273042202 \n",
      "Epoch [58/5000] , Step [380/488] , Loss: 0.0325781106948853 \n",
      "Epoch [58/5000] , Step [390/488] , Loss: 0.0323708057403564 \n",
      "Epoch [58/5000] , Step [400/488] , Loss: 0.0327850915491581 \n",
      "Epoch [58/5000] , Step [410/488] , Loss: 0.0325259864330292 \n",
      "Epoch [58/5000] , Step [420/488] , Loss: 0.0323401317000389 \n",
      "Epoch [58/5000] , Step [430/488] , Loss: 0.0322723761200905 \n",
      "Epoch [58/5000] , Step [440/488] , Loss: 0.0327664650976658 \n",
      "Epoch [58/5000] , Step [450/488] , Loss: 0.0322557576000690 \n",
      "Epoch [58/5000] , Step [460/488] , Loss: 0.0323139503598213 \n",
      "Epoch [58/5000] , Step [470/488] , Loss: 0.0337424166500568 \n",
      "Epoch [58/5000] , Step [480/488] , Loss: 0.0328766554594040 \n",
      "Epoch [59/5000] , Step [10/488] , Loss: 0.0322176478803158 \n",
      "Epoch [59/5000] , Step [20/488] , Loss: 0.0324817970395088 \n",
      "Epoch [59/5000] , Step [30/488] , Loss: 0.0326787531375885 \n",
      "Epoch [59/5000] , Step [40/488] , Loss: 0.0320306643843651 \n",
      "Epoch [59/5000] , Step [50/488] , Loss: 0.0324269197881222 \n",
      "Epoch [59/5000] , Step [60/488] , Loss: 0.0323579721152782 \n",
      "Epoch [59/5000] , Step [70/488] , Loss: 0.0326544418931007 \n",
      "Epoch [59/5000] , Step [80/488] , Loss: 0.0316851772367954 \n",
      "Epoch [59/5000] , Step [90/488] , Loss: 0.0325457677245140 \n",
      "Epoch [59/5000] , Step [100/488] , Loss: 0.0323712825775146 \n",
      "Epoch [59/5000] , Step [110/488] , Loss: 0.0321111120283604 \n",
      "Epoch [59/5000] , Step [120/488] , Loss: 0.0321801267564297 \n",
      "Epoch [59/5000] , Step [130/488] , Loss: 0.0325398854911327 \n",
      "Epoch [59/5000] , Step [140/488] , Loss: 0.0325652882456779 \n",
      "Epoch [59/5000] , Step [150/488] , Loss: 0.0327094569802284 \n",
      "Epoch [59/5000] , Step [160/488] , Loss: 0.0328934229910374 \n",
      "Epoch [59/5000] , Step [170/488] , Loss: 0.0325111038982868 \n",
      "Epoch [59/5000] , Step [180/488] , Loss: 0.0322943627834320 \n",
      "Epoch [59/5000] , Step [190/488] , Loss: 0.0321654267609119 \n",
      "Epoch [59/5000] , Step [200/488] , Loss: 0.0326082222163677 \n",
      "Epoch [59/5000] , Step [210/488] , Loss: 0.0324927978217602 \n",
      "Epoch [59/5000] , Step [220/488] , Loss: 0.0326590873301029 \n",
      "Epoch [59/5000] , Step [230/488] , Loss: 0.0329612195491791 \n",
      "Epoch [59/5000] , Step [240/488] , Loss: 0.0327862016856670 \n",
      "Epoch [59/5000] , Step [250/488] , Loss: 0.0325249545276165 \n",
      "Epoch [59/5000] , Step [260/488] , Loss: 0.0324850082397461 \n",
      "Epoch [59/5000] , Step [270/488] , Loss: 0.0326321534812450 \n",
      "Epoch [59/5000] , Step [280/488] , Loss: 0.0328122563660145 \n",
      "Epoch [59/5000] , Step [290/488] , Loss: 0.0330290086567402 \n",
      "Epoch [59/5000] , Step [300/488] , Loss: 0.0324174016714096 \n",
      "Epoch [59/5000] , Step [310/488] , Loss: 0.0320095568895340 \n",
      "Epoch [59/5000] , Step [320/488] , Loss: 0.0330741517245770 \n",
      "Epoch [59/5000] , Step [330/488] , Loss: 0.0326972790062428 \n",
      "Epoch [59/5000] , Step [340/488] , Loss: 0.0319161117076874 \n",
      "Epoch [59/5000] , Step [350/488] , Loss: 0.0325028076767921 \n",
      "Epoch [59/5000] , Step [360/488] , Loss: 0.0334568545222282 \n",
      "Epoch [59/5000] , Step [370/488] , Loss: 0.0327106155455112 \n",
      "Epoch [59/5000] , Step [380/488] , Loss: 0.0324866250157356 \n",
      "Epoch [59/5000] , Step [390/488] , Loss: 0.0324991717934608 \n",
      "Epoch [59/5000] , Step [400/488] , Loss: 0.0329181626439095 \n",
      "Epoch [59/5000] , Step [410/488] , Loss: 0.0324014201760292 \n",
      "Epoch [59/5000] , Step [420/488] , Loss: 0.0325867831707001 \n",
      "Epoch [59/5000] , Step [430/488] , Loss: 0.0336214713752270 \n",
      "Epoch [59/5000] , Step [440/488] , Loss: 0.0323329083621502 \n",
      "Epoch [59/5000] , Step [450/488] , Loss: 0.0321080163121223 \n",
      "Epoch [59/5000] , Step [460/488] , Loss: 0.0321858972311020 \n",
      "Epoch [59/5000] , Step [470/488] , Loss: 0.0325705893337727 \n",
      "Epoch [59/5000] , Step [480/488] , Loss: 0.0322614014148712 \n",
      "Epoch [60/5000] , Step [10/488] , Loss: 0.0328981764614582 \n",
      "Epoch [60/5000] , Step [20/488] , Loss: 0.0321462973952293 \n",
      "Epoch [60/5000] , Step [30/488] , Loss: 0.0326152518391609 \n",
      "Epoch [60/5000] , Step [40/488] , Loss: 0.0323861278593540 \n",
      "Epoch [60/5000] , Step [50/488] , Loss: 0.0323996394872665 \n",
      "Epoch [60/5000] , Step [60/488] , Loss: 0.0321364738047123 \n",
      "Epoch [60/5000] , Step [70/488] , Loss: 0.0326272025704384 \n",
      "Epoch [60/5000] , Step [80/488] , Loss: 0.0324221216142178 \n",
      "Epoch [60/5000] , Step [90/488] , Loss: 0.0325777418911457 \n",
      "Epoch [60/5000] , Step [100/488] , Loss: 0.0326784849166870 \n",
      "Epoch [60/5000] , Step [110/488] , Loss: 0.0326500758528709 \n",
      "Epoch [60/5000] , Step [120/488] , Loss: 0.0323965549468994 \n",
      "Epoch [60/5000] , Step [130/488] , Loss: 0.0325997807085514 \n",
      "Epoch [60/5000] , Step [140/488] , Loss: 0.0328494831919670 \n",
      "Epoch [60/5000] , Step [150/488] , Loss: 0.0323593206703663 \n",
      "Epoch [60/5000] , Step [160/488] , Loss: 0.0325931981205940 \n",
      "Epoch [60/5000] , Step [170/488] , Loss: 0.0319588705897331 \n",
      "Epoch [60/5000] , Step [180/488] , Loss: 0.0318784862756729 \n",
      "Epoch [60/5000] , Step [190/488] , Loss: 0.0321433357894421 \n",
      "Epoch [60/5000] , Step [200/488] , Loss: 0.0333460345864296 \n",
      "Epoch [60/5000] , Step [210/488] , Loss: 0.0323223806917667 \n",
      "Epoch [60/5000] , Step [220/488] , Loss: 0.0326507017016411 \n",
      "Epoch [60/5000] , Step [230/488] , Loss: 0.0322711430490017 \n",
      "Epoch [60/5000] , Step [240/488] , Loss: 0.0326004102826118 \n",
      "Epoch [60/5000] , Step [250/488] , Loss: 0.0321328006684780 \n",
      "Epoch [60/5000] , Step [260/488] , Loss: 0.0326266996562481 \n",
      "Epoch [60/5000] , Step [270/488] , Loss: 0.0329132936894894 \n",
      "Epoch [60/5000] , Step [280/488] , Loss: 0.0327896922826767 \n",
      "Epoch [60/5000] , Step [290/488] , Loss: 0.0326891653239727 \n",
      "Epoch [60/5000] , Step [300/488] , Loss: 0.0324514731764793 \n",
      "Epoch [60/5000] , Step [310/488] , Loss: 0.0337135531008244 \n",
      "Epoch [60/5000] , Step [320/488] , Loss: 0.0326787531375885 \n",
      "Epoch [60/5000] , Step [330/488] , Loss: 0.0324375182390213 \n",
      "Epoch [60/5000] , Step [340/488] , Loss: 0.0321310386061668 \n",
      "Epoch [60/5000] , Step [350/488] , Loss: 0.0324389114975929 \n",
      "Epoch [60/5000] , Step [360/488] , Loss: 0.0328597836196423 \n",
      "Epoch [60/5000] , Step [370/488] , Loss: 0.0327015146613121 \n",
      "Epoch [60/5000] , Step [380/488] , Loss: 0.0327902399003506 \n",
      "Epoch [60/5000] , Step [390/488] , Loss: 0.0322082787752151 \n",
      "Epoch [60/5000] , Step [400/488] , Loss: 0.0329945273697376 \n",
      "Epoch [60/5000] , Step [410/488] , Loss: 0.0330092199146748 \n",
      "Epoch [60/5000] , Step [420/488] , Loss: 0.0331203490495682 \n",
      "Epoch [60/5000] , Step [430/488] , Loss: 0.0325216278433800 \n",
      "Epoch [60/5000] , Step [440/488] , Loss: 0.0326676741242409 \n",
      "Epoch [60/5000] , Step [450/488] , Loss: 0.0323302038013935 \n",
      "Epoch [60/5000] , Step [460/488] , Loss: 0.0326970592141151 \n",
      "Epoch [60/5000] , Step [470/488] , Loss: 0.0320519022643566 \n",
      "Epoch [60/5000] , Step [480/488] , Loss: 0.0326634086668491 \n",
      "Epoch [61/5000] , Step [10/488] , Loss: 0.0326970070600510 \n",
      "Epoch [61/5000] , Step [20/488] , Loss: 0.0325711332261562 \n",
      "Epoch [61/5000] , Step [30/488] , Loss: 0.0328143201768398 \n",
      "Epoch [61/5000] , Step [40/488] , Loss: 0.0327941365540028 \n",
      "Epoch [61/5000] , Step [50/488] , Loss: 0.0317032672464848 \n",
      "Epoch [61/5000] , Step [60/488] , Loss: 0.0327079929411411 \n",
      "Epoch [61/5000] , Step [70/488] , Loss: 0.0325450077652931 \n",
      "Epoch [61/5000] , Step [80/488] , Loss: 0.0322869271039963 \n",
      "Epoch [61/5000] , Step [90/488] , Loss: 0.0330106392502785 \n",
      "Epoch [61/5000] , Step [100/488] , Loss: 0.0322377793490887 \n",
      "Epoch [61/5000] , Step [110/488] , Loss: 0.0321704857051373 \n",
      "Epoch [61/5000] , Step [120/488] , Loss: 0.0327331200242043 \n",
      "Epoch [61/5000] , Step [130/488] , Loss: 0.0327066257596016 \n",
      "Epoch [61/5000] , Step [140/488] , Loss: 0.0321414135396481 \n",
      "Epoch [61/5000] , Step [150/488] , Loss: 0.0327359922230244 \n",
      "Epoch [61/5000] , Step [160/488] , Loss: 0.0326583459973335 \n",
      "Epoch [61/5000] , Step [170/488] , Loss: 0.0323672108352184 \n",
      "Epoch [61/5000] , Step [180/488] , Loss: 0.0323692262172699 \n",
      "Epoch [61/5000] , Step [190/488] , Loss: 0.0321205109357834 \n",
      "Epoch [61/5000] , Step [200/488] , Loss: 0.0319116525352001 \n",
      "Epoch [61/5000] , Step [210/488] , Loss: 0.0323202423751354 \n",
      "Epoch [61/5000] , Step [220/488] , Loss: 0.0325241796672344 \n",
      "Epoch [61/5000] , Step [230/488] , Loss: 0.0324834026396275 \n",
      "Epoch [61/5000] , Step [240/488] , Loss: 0.0330217145383358 \n",
      "Epoch [61/5000] , Step [250/488] , Loss: 0.0321976132690907 \n",
      "Epoch [61/5000] , Step [260/488] , Loss: 0.0324532054364681 \n",
      "Epoch [61/5000] , Step [270/488] , Loss: 0.0323299691081047 \n",
      "Epoch [61/5000] , Step [280/488] , Loss: 0.0329065211117268 \n",
      "Epoch [61/5000] , Step [290/488] , Loss: 0.0329192355275154 \n",
      "Epoch [61/5000] , Step [300/488] , Loss: 0.0320075936615467 \n",
      "Epoch [61/5000] , Step [310/488] , Loss: 0.0324388481676579 \n",
      "Epoch [61/5000] , Step [320/488] , Loss: 0.0326197259128094 \n",
      "Epoch [61/5000] , Step [330/488] , Loss: 0.0325306057929993 \n",
      "Epoch [61/5000] , Step [340/488] , Loss: 0.0329420827329159 \n",
      "Epoch [61/5000] , Step [350/488] , Loss: 0.0320978686213493 \n",
      "Epoch [61/5000] , Step [360/488] , Loss: 0.0329276025295258 \n",
      "Epoch [61/5000] , Step [370/488] , Loss: 0.0324103645980358 \n",
      "Epoch [61/5000] , Step [380/488] , Loss: 0.0323579572141171 \n",
      "Epoch [61/5000] , Step [390/488] , Loss: 0.0323636159300804 \n",
      "Epoch [61/5000] , Step [400/488] , Loss: 0.0327347852289677 \n",
      "Epoch [61/5000] , Step [410/488] , Loss: 0.0327020622789860 \n",
      "Epoch [61/5000] , Step [420/488] , Loss: 0.0323268026113510 \n",
      "Epoch [61/5000] , Step [430/488] , Loss: 0.0325733199715614 \n",
      "Epoch [61/5000] , Step [440/488] , Loss: 0.0326342508196831 \n",
      "Epoch [61/5000] , Step [450/488] , Loss: 0.0326929390430450 \n",
      "Epoch [61/5000] , Step [460/488] , Loss: 0.0325992815196514 \n",
      "Epoch [61/5000] , Step [470/488] , Loss: 0.0328776463866234 \n",
      "Epoch [61/5000] , Step [480/488] , Loss: 0.0319662094116211 \n",
      "Epoch [62/5000] , Step [10/488] , Loss: 0.0325541086494923 \n",
      "Epoch [62/5000] , Step [20/488] , Loss: 0.0325065925717354 \n",
      "Epoch [62/5000] , Step [30/488] , Loss: 0.0323804989457130 \n",
      "Epoch [62/5000] , Step [40/488] , Loss: 0.0324493348598480 \n",
      "Epoch [62/5000] , Step [50/488] , Loss: 0.0327976420521736 \n",
      "Epoch [62/5000] , Step [60/488] , Loss: 0.0328418724238873 \n",
      "Epoch [62/5000] , Step [70/488] , Loss: 0.0322494655847549 \n",
      "Epoch [62/5000] , Step [80/488] , Loss: 0.0327311120927334 \n",
      "Epoch [62/5000] , Step [90/488] , Loss: 0.0321187041699886 \n",
      "Epoch [62/5000] , Step [100/488] , Loss: 0.0328578315675259 \n",
      "Epoch [62/5000] , Step [110/488] , Loss: 0.0321809686720371 \n",
      "Epoch [62/5000] , Step [120/488] , Loss: 0.0324959270656109 \n",
      "Epoch [62/5000] , Step [130/488] , Loss: 0.0326006300747395 \n",
      "Epoch [62/5000] , Step [140/488] , Loss: 0.0326750241219997 \n",
      "Epoch [62/5000] , Step [150/488] , Loss: 0.0330127775669098 \n",
      "Epoch [62/5000] , Step [160/488] , Loss: 0.0332523100078106 \n",
      "Epoch [62/5000] , Step [170/488] , Loss: 0.0327170901000500 \n",
      "Epoch [62/5000] , Step [180/488] , Loss: 0.0322119183838367 \n",
      "Epoch [62/5000] , Step [190/488] , Loss: 0.0332291796803474 \n",
      "Epoch [62/5000] , Step [200/488] , Loss: 0.0333021320402622 \n",
      "Epoch [62/5000] , Step [210/488] , Loss: 0.0329771488904953 \n",
      "Epoch [62/5000] , Step [220/488] , Loss: 0.0326001942157745 \n",
      "Epoch [62/5000] , Step [230/488] , Loss: 0.0325632616877556 \n",
      "Epoch [62/5000] , Step [240/488] , Loss: 0.0322517342865467 \n",
      "Epoch [62/5000] , Step [250/488] , Loss: 0.0319556370377541 \n",
      "Epoch [62/5000] , Step [260/488] , Loss: 0.0329146906733513 \n",
      "Epoch [62/5000] , Step [270/488] , Loss: 0.0321325771510601 \n",
      "Epoch [62/5000] , Step [280/488] , Loss: 0.0324671268463135 \n",
      "Epoch [62/5000] , Step [290/488] , Loss: 0.0324064195156097 \n",
      "Epoch [62/5000] , Step [300/488] , Loss: 0.0324776992201805 \n",
      "Epoch [62/5000] , Step [310/488] , Loss: 0.0321142040193081 \n",
      "Epoch [62/5000] , Step [320/488] , Loss: 0.0328112542629242 \n",
      "Epoch [62/5000] , Step [330/488] , Loss: 0.0329720005393028 \n",
      "Epoch [62/5000] , Step [340/488] , Loss: 0.0329661816358566 \n",
      "Epoch [62/5000] , Step [350/488] , Loss: 0.0329977646470070 \n",
      "Epoch [62/5000] , Step [360/488] , Loss: 0.0322340093553066 \n",
      "Epoch [62/5000] , Step [370/488] , Loss: 0.0321427099406719 \n",
      "Epoch [62/5000] , Step [380/488] , Loss: 0.0323173329234123 \n",
      "Epoch [62/5000] , Step [390/488] , Loss: 0.0323996469378471 \n",
      "Epoch [62/5000] , Step [400/488] , Loss: 0.0324043706059456 \n",
      "Epoch [62/5000] , Step [410/488] , Loss: 0.0323310829699039 \n",
      "Epoch [62/5000] , Step [420/488] , Loss: 0.0323531366884708 \n",
      "Epoch [62/5000] , Step [430/488] , Loss: 0.0318626463413239 \n",
      "Epoch [62/5000] , Step [440/488] , Loss: 0.0327695123851299 \n",
      "Epoch [62/5000] , Step [450/488] , Loss: 0.0324685685336590 \n",
      "Epoch [62/5000] , Step [460/488] , Loss: 0.0325040891766548 \n",
      "Epoch [62/5000] , Step [470/488] , Loss: 0.0326090194284916 \n",
      "Epoch [62/5000] , Step [480/488] , Loss: 0.0326185673475266 \n",
      "Epoch [63/5000] , Step [10/488] , Loss: 0.0325843840837479 \n",
      "Epoch [63/5000] , Step [20/488] , Loss: 0.0325257331132889 \n",
      "Epoch [63/5000] , Step [30/488] , Loss: 0.0323856100440025 \n",
      "Epoch [63/5000] , Step [40/488] , Loss: 0.0324657000601292 \n",
      "Epoch [63/5000] , Step [50/488] , Loss: 0.0324872508645058 \n",
      "Epoch [63/5000] , Step [60/488] , Loss: 0.0325249880552292 \n",
      "Epoch [63/5000] , Step [70/488] , Loss: 0.0324748642742634 \n",
      "Epoch [63/5000] , Step [80/488] , Loss: 0.0324886217713356 \n",
      "Epoch [63/5000] , Step [90/488] , Loss: 0.0320491045713425 \n",
      "Epoch [63/5000] , Step [100/488] , Loss: 0.0327691324055195 \n",
      "Epoch [63/5000] , Step [110/488] , Loss: 0.0328373163938522 \n",
      "Epoch [63/5000] , Step [120/488] , Loss: 0.0326548628509045 \n",
      "Epoch [63/5000] , Step [130/488] , Loss: 0.0323840156197548 \n",
      "Epoch [63/5000] , Step [140/488] , Loss: 0.0329214334487915 \n",
      "Epoch [63/5000] , Step [150/488] , Loss: 0.0322471149265766 \n",
      "Epoch [63/5000] , Step [160/488] , Loss: 0.0322582498192787 \n",
      "Epoch [63/5000] , Step [170/488] , Loss: 0.0326637290418148 \n",
      "Epoch [63/5000] , Step [180/488] , Loss: 0.0318942442536354 \n",
      "Epoch [63/5000] , Step [190/488] , Loss: 0.0325820818543434 \n",
      "Epoch [63/5000] , Step [200/488] , Loss: 0.0326940305531025 \n",
      "Epoch [63/5000] , Step [210/488] , Loss: 0.0330024175345898 \n",
      "Epoch [63/5000] , Step [220/488] , Loss: 0.0325183570384979 \n",
      "Epoch [63/5000] , Step [230/488] , Loss: 0.0326982140541077 \n",
      "Epoch [63/5000] , Step [240/488] , Loss: 0.0323795340955257 \n",
      "Epoch [63/5000] , Step [250/488] , Loss: 0.0319802239537239 \n",
      "Epoch [63/5000] , Step [260/488] , Loss: 0.0322362072765827 \n",
      "Epoch [63/5000] , Step [270/488] , Loss: 0.0325988084077835 \n",
      "Epoch [63/5000] , Step [280/488] , Loss: 0.0323323197662830 \n",
      "Epoch [63/5000] , Step [290/488] , Loss: 0.0322502963244915 \n",
      "Epoch [63/5000] , Step [300/488] , Loss: 0.0330994948744774 \n",
      "Epoch [63/5000] , Step [310/488] , Loss: 0.0329648740589619 \n",
      "Epoch [63/5000] , Step [320/488] , Loss: 0.0325399860739708 \n",
      "Epoch [63/5000] , Step [330/488] , Loss: 0.0328887216746807 \n",
      "Epoch [63/5000] , Step [340/488] , Loss: 0.0330659672617912 \n",
      "Epoch [63/5000] , Step [350/488] , Loss: 0.0319106541574001 \n",
      "Epoch [63/5000] , Step [360/488] , Loss: 0.0322959870100021 \n",
      "Epoch [63/5000] , Step [370/488] , Loss: 0.0327824130654335 \n",
      "Epoch [63/5000] , Step [380/488] , Loss: 0.0321940667927265 \n",
      "Epoch [63/5000] , Step [390/488] , Loss: 0.0316455438733101 \n",
      "Epoch [63/5000] , Step [400/488] , Loss: 0.0329171344637871 \n",
      "Epoch [63/5000] , Step [410/488] , Loss: 0.0326340012252331 \n",
      "Epoch [63/5000] , Step [420/488] , Loss: 0.0328018218278885 \n",
      "Epoch [63/5000] , Step [430/488] , Loss: 0.0329269804060459 \n",
      "Epoch [63/5000] , Step [440/488] , Loss: 0.0323625020682812 \n",
      "Epoch [63/5000] , Step [450/488] , Loss: 0.0329942554235458 \n",
      "Epoch [63/5000] , Step [460/488] , Loss: 0.0322513654828072 \n",
      "Epoch [63/5000] , Step [470/488] , Loss: 0.0324369296431541 \n",
      "Epoch [63/5000] , Step [480/488] , Loss: 0.0321066677570343 \n",
      "Epoch [64/5000] , Step [10/488] , Loss: 0.0316758491098881 \n",
      "Epoch [64/5000] , Step [20/488] , Loss: 0.0322776213288307 \n",
      "Epoch [64/5000] , Step [30/488] , Loss: 0.0322342850267887 \n",
      "Epoch [64/5000] , Step [40/488] , Loss: 0.0326204150915146 \n",
      "Epoch [64/5000] , Step [50/488] , Loss: 0.0324351452291012 \n",
      "Epoch [64/5000] , Step [60/488] , Loss: 0.0319169834256172 \n",
      "Epoch [64/5000] , Step [70/488] , Loss: 0.0329141169786453 \n",
      "Epoch [64/5000] , Step [80/488] , Loss: 0.0321220681071281 \n",
      "Epoch [64/5000] , Step [90/488] , Loss: 0.0328137613832951 \n",
      "Epoch [64/5000] , Step [100/488] , Loss: 0.0326813906431198 \n",
      "Epoch [64/5000] , Step [110/488] , Loss: 0.0324175246059895 \n",
      "Epoch [64/5000] , Step [120/488] , Loss: 0.0316787138581276 \n",
      "Epoch [64/5000] , Step [130/488] , Loss: 0.0323446281254292 \n",
      "Epoch [64/5000] , Step [140/488] , Loss: 0.0327701903879642 \n",
      "Epoch [64/5000] , Step [150/488] , Loss: 0.0326092801988125 \n",
      "Epoch [64/5000] , Step [160/488] , Loss: 0.0326569080352783 \n",
      "Epoch [64/5000] , Step [170/488] , Loss: 0.0330080725252628 \n",
      "Epoch [64/5000] , Step [180/488] , Loss: 0.0325445756316185 \n",
      "Epoch [64/5000] , Step [190/488] , Loss: 0.0321634262800217 \n",
      "Epoch [64/5000] , Step [200/488] , Loss: 0.0327949263155460 \n",
      "Epoch [64/5000] , Step [210/488] , Loss: 0.0328536480665207 \n",
      "Epoch [64/5000] , Step [220/488] , Loss: 0.0321539044380188 \n",
      "Epoch [64/5000] , Step [230/488] , Loss: 0.0317216701805592 \n",
      "Epoch [64/5000] , Step [240/488] , Loss: 0.0323252007365227 \n",
      "Epoch [64/5000] , Step [250/488] , Loss: 0.0329680107533932 \n",
      "Epoch [64/5000] , Step [260/488] , Loss: 0.0330725274980068 \n",
      "Epoch [64/5000] , Step [270/488] , Loss: 0.0321112684905529 \n",
      "Epoch [64/5000] , Step [280/488] , Loss: 0.0321747250854969 \n",
      "Epoch [64/5000] , Step [290/488] , Loss: 0.0332994461059570 \n",
      "Epoch [64/5000] , Step [300/488] , Loss: 0.0326153524219990 \n",
      "Epoch [64/5000] , Step [310/488] , Loss: 0.0325415097177029 \n",
      "Epoch [64/5000] , Step [320/488] , Loss: 0.0328393951058388 \n",
      "Epoch [64/5000] , Step [330/488] , Loss: 0.0327833145856857 \n",
      "Epoch [64/5000] , Step [340/488] , Loss: 0.0324371717870235 \n",
      "Epoch [64/5000] , Step [350/488] , Loss: 0.0326540395617485 \n",
      "Epoch [64/5000] , Step [360/488] , Loss: 0.0327671766281128 \n",
      "Epoch [64/5000] , Step [370/488] , Loss: 0.0331855155527592 \n",
      "Epoch [64/5000] , Step [380/488] , Loss: 0.0324589610099792 \n",
      "Epoch [64/5000] , Step [390/488] , Loss: 0.0328441560268402 \n",
      "Epoch [64/5000] , Step [400/488] , Loss: 0.0332676246762276 \n",
      "Epoch [64/5000] , Step [410/488] , Loss: 0.0326158665120602 \n",
      "Epoch [64/5000] , Step [420/488] , Loss: 0.0325280837714672 \n",
      "Epoch [64/5000] , Step [430/488] , Loss: 0.0317617729306221 \n",
      "Epoch [64/5000] , Step [440/488] , Loss: 0.0324998423457146 \n",
      "Epoch [64/5000] , Step [450/488] , Loss: 0.0323939360678196 \n",
      "Epoch [64/5000] , Step [460/488] , Loss: 0.0322285480797291 \n",
      "Epoch [64/5000] , Step [470/488] , Loss: 0.0324573665857315 \n",
      "Epoch [64/5000] , Step [480/488] , Loss: 0.0319397933781147 \n",
      "Epoch [65/5000] , Step [10/488] , Loss: 0.0322407111525536 \n",
      "Epoch [65/5000] , Step [20/488] , Loss: 0.0324299745261669 \n",
      "Epoch [65/5000] , Step [30/488] , Loss: 0.0325041674077511 \n",
      "Epoch [65/5000] , Step [40/488] , Loss: 0.0327480882406235 \n",
      "Epoch [65/5000] , Step [50/488] , Loss: 0.0327276550233364 \n",
      "Epoch [65/5000] , Step [60/488] , Loss: 0.0324775204062462 \n",
      "Epoch [65/5000] , Step [70/488] , Loss: 0.0327071100473404 \n",
      "Epoch [65/5000] , Step [80/488] , Loss: 0.0325621664524078 \n",
      "Epoch [65/5000] , Step [90/488] , Loss: 0.0326856635510921 \n",
      "Epoch [65/5000] , Step [100/488] , Loss: 0.0329842232167721 \n",
      "Epoch [65/5000] , Step [110/488] , Loss: 0.0323039852082729 \n",
      "Epoch [65/5000] , Step [120/488] , Loss: 0.0324670486152172 \n",
      "Epoch [65/5000] , Step [130/488] , Loss: 0.0318570956587791 \n",
      "Epoch [65/5000] , Step [140/488] , Loss: 0.0328051373362541 \n",
      "Epoch [65/5000] , Step [150/488] , Loss: 0.0325506553053856 \n",
      "Epoch [65/5000] , Step [160/488] , Loss: 0.0330118536949158 \n",
      "Epoch [65/5000] , Step [170/488] , Loss: 0.0322285518050194 \n",
      "Epoch [65/5000] , Step [180/488] , Loss: 0.0323062688112259 \n",
      "Epoch [65/5000] , Step [190/488] , Loss: 0.0323185734450817 \n",
      "Epoch [65/5000] , Step [200/488] , Loss: 0.0327632986009121 \n",
      "Epoch [65/5000] , Step [210/488] , Loss: 0.0326969586312771 \n",
      "Epoch [65/5000] , Step [220/488] , Loss: 0.0328148268163204 \n",
      "Epoch [65/5000] , Step [230/488] , Loss: 0.0331823602318764 \n",
      "Epoch [65/5000] , Step [240/488] , Loss: 0.0320035703480244 \n",
      "Epoch [65/5000] , Step [250/488] , Loss: 0.0329652540385723 \n",
      "Epoch [65/5000] , Step [260/488] , Loss: 0.0326165072619915 \n",
      "Epoch [65/5000] , Step [270/488] , Loss: 0.0325713083148003 \n",
      "Epoch [65/5000] , Step [280/488] , Loss: 0.0318100377917290 \n",
      "Epoch [65/5000] , Step [290/488] , Loss: 0.0321476794779301 \n",
      "Epoch [65/5000] , Step [300/488] , Loss: 0.0322866626083851 \n",
      "Epoch [65/5000] , Step [310/488] , Loss: 0.0325387753546238 \n",
      "Epoch [65/5000] , Step [320/488] , Loss: 0.0328005850315094 \n",
      "Epoch [65/5000] , Step [330/488] , Loss: 0.0321871861815453 \n",
      "Epoch [65/5000] , Step [340/488] , Loss: 0.0323252938687801 \n",
      "Epoch [65/5000] , Step [350/488] , Loss: 0.0327856354415417 \n",
      "Epoch [65/5000] , Step [360/488] , Loss: 0.0325272865593433 \n",
      "Epoch [65/5000] , Step [370/488] , Loss: 0.0326352044939995 \n",
      "Epoch [65/5000] , Step [380/488] , Loss: 0.0318943969905376 \n",
      "Epoch [65/5000] , Step [390/488] , Loss: 0.0326398462057114 \n",
      "Epoch [65/5000] , Step [400/488] , Loss: 0.0324803739786148 \n",
      "Epoch [65/5000] , Step [410/488] , Loss: 0.0319798290729523 \n",
      "Epoch [65/5000] , Step [420/488] , Loss: 0.0327347777783871 \n",
      "Epoch [65/5000] , Step [430/488] , Loss: 0.0324336625635624 \n",
      "Epoch [65/5000] , Step [440/488] , Loss: 0.0327560678124428 \n",
      "Epoch [65/5000] , Step [450/488] , Loss: 0.0332535430788994 \n",
      "Epoch [65/5000] , Step [460/488] , Loss: 0.0326568149030209 \n",
      "Epoch [65/5000] , Step [470/488] , Loss: 0.0324455164372921 \n",
      "Epoch [65/5000] , Step [480/488] , Loss: 0.0322645939886570 \n",
      "Epoch [66/5000] , Step [10/488] , Loss: 0.0320891737937927 \n",
      "Epoch [66/5000] , Step [20/488] , Loss: 0.0321599394083023 \n",
      "Epoch [66/5000] , Step [30/488] , Loss: 0.0329989455640316 \n",
      "Epoch [66/5000] , Step [40/488] , Loss: 0.0326488465070724 \n",
      "Epoch [66/5000] , Step [50/488] , Loss: 0.0327075049281120 \n",
      "Epoch [66/5000] , Step [60/488] , Loss: 0.0319305621087551 \n",
      "Epoch [66/5000] , Step [70/488] , Loss: 0.0326927974820137 \n",
      "Epoch [66/5000] , Step [80/488] , Loss: 0.0318414941430092 \n",
      "Epoch [66/5000] , Step [90/488] , Loss: 0.0325556918978691 \n",
      "Epoch [66/5000] , Step [100/488] , Loss: 0.0327371284365654 \n",
      "Epoch [66/5000] , Step [110/488] , Loss: 0.0319439657032490 \n",
      "Epoch [66/5000] , Step [120/488] , Loss: 0.0321468487381935 \n",
      "Epoch [66/5000] , Step [130/488] , Loss: 0.0327660590410233 \n",
      "Epoch [66/5000] , Step [140/488] , Loss: 0.0325270444154739 \n",
      "Epoch [66/5000] , Step [150/488] , Loss: 0.0324089042842388 \n",
      "Epoch [66/5000] , Step [160/488] , Loss: 0.0324268490076065 \n",
      "Epoch [66/5000] , Step [170/488] , Loss: 0.0330291241407394 \n",
      "Epoch [66/5000] , Step [180/488] , Loss: 0.0328792519867420 \n",
      "Epoch [66/5000] , Step [190/488] , Loss: 0.0325617827475071 \n",
      "Epoch [66/5000] , Step [200/488] , Loss: 0.0328438431024551 \n",
      "Epoch [66/5000] , Step [210/488] , Loss: 0.0321876555681229 \n",
      "Epoch [66/5000] , Step [220/488] , Loss: 0.0326885581016541 \n",
      "Epoch [66/5000] , Step [230/488] , Loss: 0.0326221771538258 \n",
      "Epoch [66/5000] , Step [240/488] , Loss: 0.0320671163499355 \n",
      "Epoch [66/5000] , Step [250/488] , Loss: 0.0320220589637756 \n",
      "Epoch [66/5000] , Step [260/488] , Loss: 0.0330974683165550 \n",
      "Epoch [66/5000] , Step [270/488] , Loss: 0.0326391793787479 \n",
      "Epoch [66/5000] , Step [280/488] , Loss: 0.0324285887181759 \n",
      "Epoch [66/5000] , Step [290/488] , Loss: 0.0320815667510033 \n",
      "Epoch [66/5000] , Step [300/488] , Loss: 0.0328717343509197 \n",
      "Epoch [66/5000] , Step [310/488] , Loss: 0.0335229001939297 \n",
      "Epoch [66/5000] , Step [320/488] , Loss: 0.0326407961547375 \n",
      "Epoch [66/5000] , Step [330/488] , Loss: 0.0323288403451443 \n",
      "Epoch [66/5000] , Step [340/488] , Loss: 0.0329020395874977 \n",
      "Epoch [66/5000] , Step [350/488] , Loss: 0.0327667631208897 \n",
      "Epoch [66/5000] , Step [360/488] , Loss: 0.0324276313185692 \n",
      "Epoch [66/5000] , Step [370/488] , Loss: 0.0321784578263760 \n",
      "Epoch [66/5000] , Step [380/488] , Loss: 0.0328135155141354 \n",
      "Epoch [66/5000] , Step [390/488] , Loss: 0.0314468406140804 \n",
      "Epoch [66/5000] , Step [400/488] , Loss: 0.0326872467994690 \n",
      "Epoch [66/5000] , Step [410/488] , Loss: 0.0326362401247025 \n",
      "Epoch [66/5000] , Step [420/488] , Loss: 0.0330404751002789 \n",
      "Epoch [66/5000] , Step [430/488] , Loss: 0.0321883223950863 \n",
      "Epoch [66/5000] , Step [440/488] , Loss: 0.0323620885610580 \n",
      "Epoch [66/5000] , Step [450/488] , Loss: 0.0333932042121887 \n",
      "Epoch [66/5000] , Step [460/488] , Loss: 0.0321390517055988 \n",
      "Epoch [66/5000] , Step [470/488] , Loss: 0.0321780405938625 \n",
      "Epoch [66/5000] , Step [480/488] , Loss: 0.0325032696127892 \n",
      "Epoch [67/5000] , Step [10/488] , Loss: 0.0326165258884430 \n",
      "Epoch [67/5000] , Step [20/488] , Loss: 0.0318297073245049 \n",
      "Epoch [67/5000] , Step [30/488] , Loss: 0.0319826714694500 \n",
      "Epoch [67/5000] , Step [40/488] , Loss: 0.0330602005124092 \n",
      "Epoch [67/5000] , Step [50/488] , Loss: 0.0324866585433483 \n",
      "Epoch [67/5000] , Step [60/488] , Loss: 0.0323537699878216 \n",
      "Epoch [67/5000] , Step [70/488] , Loss: 0.0328106842935085 \n",
      "Epoch [67/5000] , Step [80/488] , Loss: 0.0325595177710056 \n",
      "Epoch [67/5000] , Step [90/488] , Loss: 0.0332089364528656 \n",
      "Epoch [67/5000] , Step [100/488] , Loss: 0.0321409106254578 \n",
      "Epoch [67/5000] , Step [110/488] , Loss: 0.0324765257537365 \n",
      "Epoch [67/5000] , Step [120/488] , Loss: 0.0318191386759281 \n",
      "Epoch [67/5000] , Step [130/488] , Loss: 0.0322985611855984 \n",
      "Epoch [67/5000] , Step [140/488] , Loss: 0.0328724980354309 \n",
      "Epoch [67/5000] , Step [150/488] , Loss: 0.0326078496873379 \n",
      "Epoch [67/5000] , Step [160/488] , Loss: 0.0321395359933376 \n",
      "Epoch [67/5000] , Step [170/488] , Loss: 0.0325073078274727 \n",
      "Epoch [67/5000] , Step [180/488] , Loss: 0.0325671620666981 \n",
      "Epoch [67/5000] , Step [190/488] , Loss: 0.0329535491764545 \n",
      "Epoch [67/5000] , Step [200/488] , Loss: 0.0329270772635937 \n",
      "Epoch [67/5000] , Step [210/488] , Loss: 0.0329422652721405 \n",
      "Epoch [67/5000] , Step [220/488] , Loss: 0.0321078598499298 \n",
      "Epoch [67/5000] , Step [230/488] , Loss: 0.0330297723412514 \n",
      "Epoch [67/5000] , Step [240/488] , Loss: 0.0324287675321102 \n",
      "Epoch [67/5000] , Step [250/488] , Loss: 0.0333185233175755 \n",
      "Epoch [67/5000] , Step [260/488] , Loss: 0.0322841480374336 \n",
      "Epoch [67/5000] , Step [270/488] , Loss: 0.0325963571667671 \n",
      "Epoch [67/5000] , Step [280/488] , Loss: 0.0326713994145393 \n",
      "Epoch [67/5000] , Step [290/488] , Loss: 0.0326387584209442 \n",
      "Epoch [67/5000] , Step [300/488] , Loss: 0.0326540134847164 \n",
      "Epoch [67/5000] , Step [310/488] , Loss: 0.0327264890074730 \n",
      "Epoch [67/5000] , Step [320/488] , Loss: 0.0326052270829678 \n",
      "Epoch [67/5000] , Step [330/488] , Loss: 0.0323827005922794 \n",
      "Epoch [67/5000] , Step [340/488] , Loss: 0.0320939533412457 \n",
      "Epoch [67/5000] , Step [350/488] , Loss: 0.0325202234089375 \n",
      "Epoch [67/5000] , Step [360/488] , Loss: 0.0325136259198189 \n",
      "Epoch [67/5000] , Step [370/488] , Loss: 0.0329940505325794 \n",
      "Epoch [67/5000] , Step [380/488] , Loss: 0.0319329202175140 \n",
      "Epoch [67/5000] , Step [390/488] , Loss: 0.0329725593328476 \n",
      "Epoch [67/5000] , Step [400/488] , Loss: 0.0324264355003834 \n",
      "Epoch [67/5000] , Step [410/488] , Loss: 0.0325986482203007 \n",
      "Epoch [67/5000] , Step [420/488] , Loss: 0.0325145646929741 \n",
      "Epoch [67/5000] , Step [430/488] , Loss: 0.0328156054019928 \n",
      "Epoch [67/5000] , Step [440/488] , Loss: 0.0324426256120205 \n",
      "Epoch [67/5000] , Step [450/488] , Loss: 0.0335625298321247 \n",
      "Epoch [67/5000] , Step [460/488] , Loss: 0.0326661914587021 \n",
      "Epoch [67/5000] , Step [470/488] , Loss: 0.0317138023674488 \n",
      "Epoch [67/5000] , Step [480/488] , Loss: 0.0329875871539116 \n",
      "Epoch [68/5000] , Step [10/488] , Loss: 0.0326369144022465 \n",
      "Epoch [68/5000] , Step [20/488] , Loss: 0.0327416732907295 \n",
      "Epoch [68/5000] , Step [30/488] , Loss: 0.0324836261570454 \n",
      "Epoch [68/5000] , Step [40/488] , Loss: 0.0321577712893486 \n",
      "Epoch [68/5000] , Step [50/488] , Loss: 0.0329760722815990 \n",
      "Epoch [68/5000] , Step [60/488] , Loss: 0.0325966365635395 \n",
      "Epoch [68/5000] , Step [70/488] , Loss: 0.0328914597630501 \n",
      "Epoch [68/5000] , Step [80/488] , Loss: 0.0331714488565922 \n",
      "Epoch [68/5000] , Step [90/488] , Loss: 0.0327342115342617 \n",
      "Epoch [68/5000] , Step [100/488] , Loss: 0.0324860624969006 \n",
      "Epoch [68/5000] , Step [110/488] , Loss: 0.0321943238377571 \n",
      "Epoch [68/5000] , Step [120/488] , Loss: 0.0325472876429558 \n",
      "Epoch [68/5000] , Step [130/488] , Loss: 0.0320122763514519 \n",
      "Epoch [68/5000] , Step [140/488] , Loss: 0.0328391864895821 \n",
      "Epoch [68/5000] , Step [150/488] , Loss: 0.0324541404843330 \n",
      "Epoch [68/5000] , Step [160/488] , Loss: 0.0331641025841236 \n",
      "Epoch [68/5000] , Step [170/488] , Loss: 0.0329900979995728 \n",
      "Epoch [68/5000] , Step [180/488] , Loss: 0.0327391251921654 \n",
      "Epoch [68/5000] , Step [190/488] , Loss: 0.0331381745636463 \n",
      "Epoch [68/5000] , Step [200/488] , Loss: 0.0328038148581982 \n",
      "Epoch [68/5000] , Step [210/488] , Loss: 0.0324465781450272 \n",
      "Epoch [68/5000] , Step [220/488] , Loss: 0.0321760624647141 \n",
      "Epoch [68/5000] , Step [230/488] , Loss: 0.0326295755803585 \n",
      "Epoch [68/5000] , Step [240/488] , Loss: 0.0320732444524765 \n",
      "Epoch [68/5000] , Step [250/488] , Loss: 0.0332677029073238 \n",
      "Epoch [68/5000] , Step [260/488] , Loss: 0.0333819352090359 \n",
      "Epoch [68/5000] , Step [270/488] , Loss: 0.0329516716301441 \n",
      "Epoch [68/5000] , Step [280/488] , Loss: 0.0326311700046062 \n",
      "Epoch [68/5000] , Step [290/488] , Loss: 0.0329567454755306 \n",
      "Epoch [68/5000] , Step [300/488] , Loss: 0.0324334725737572 \n",
      "Epoch [68/5000] , Step [310/488] , Loss: 0.0330149345099926 \n",
      "Epoch [68/5000] , Step [320/488] , Loss: 0.0329346731305122 \n",
      "Epoch [68/5000] , Step [330/488] , Loss: 0.0326857604086399 \n",
      "Epoch [68/5000] , Step [340/488] , Loss: 0.0320408195257187 \n",
      "Epoch [68/5000] , Step [350/488] , Loss: 0.0318827815353870 \n",
      "Epoch [68/5000] , Step [360/488] , Loss: 0.0322306677699089 \n",
      "Epoch [68/5000] , Step [370/488] , Loss: 0.0322008840739727 \n",
      "Epoch [68/5000] , Step [380/488] , Loss: 0.0327281765639782 \n",
      "Epoch [68/5000] , Step [390/488] , Loss: 0.0324718877673149 \n",
      "Epoch [68/5000] , Step [400/488] , Loss: 0.0327334403991699 \n",
      "Epoch [68/5000] , Step [410/488] , Loss: 0.0326274931430817 \n",
      "Epoch [68/5000] , Step [420/488] , Loss: 0.0325668603181839 \n",
      "Epoch [68/5000] , Step [430/488] , Loss: 0.0324256345629692 \n",
      "Epoch [68/5000] , Step [440/488] , Loss: 0.0321672223508358 \n",
      "Epoch [68/5000] , Step [450/488] , Loss: 0.0321841537952423 \n",
      "Epoch [68/5000] , Step [460/488] , Loss: 0.0327928811311722 \n",
      "Epoch [68/5000] , Step [470/488] , Loss: 0.0318760871887207 \n",
      "Epoch [68/5000] , Step [480/488] , Loss: 0.0328359641134739 \n",
      "Epoch [69/5000] , Step [10/488] , Loss: 0.0320995263755322 \n",
      "Epoch [69/5000] , Step [20/488] , Loss: 0.0326458252966404 \n",
      "Epoch [69/5000] , Step [30/488] , Loss: 0.0322408601641655 \n",
      "Epoch [69/5000] , Step [40/488] , Loss: 0.0325224772095680 \n",
      "Epoch [69/5000] , Step [50/488] , Loss: 0.0326191000640392 \n",
      "Epoch [69/5000] , Step [60/488] , Loss: 0.0318581499159336 \n",
      "Epoch [69/5000] , Step [70/488] , Loss: 0.0321308635175228 \n",
      "Epoch [69/5000] , Step [80/488] , Loss: 0.0330968163907528 \n",
      "Epoch [69/5000] , Step [90/488] , Loss: 0.0331961140036583 \n",
      "Epoch [69/5000] , Step [100/488] , Loss: 0.0327288396656513 \n",
      "Epoch [69/5000] , Step [110/488] , Loss: 0.0323817953467369 \n",
      "Epoch [69/5000] , Step [120/488] , Loss: 0.0323492400348186 \n",
      "Epoch [69/5000] , Step [130/488] , Loss: 0.0327500477433205 \n",
      "Epoch [69/5000] , Step [140/488] , Loss: 0.0328271873295307 \n",
      "Epoch [69/5000] , Step [150/488] , Loss: 0.0318017341196537 \n",
      "Epoch [69/5000] , Step [160/488] , Loss: 0.0331061407923698 \n",
      "Epoch [69/5000] , Step [170/488] , Loss: 0.0321135669946671 \n",
      "Epoch [69/5000] , Step [180/488] , Loss: 0.0324659049510956 \n",
      "Epoch [69/5000] , Step [190/488] , Loss: 0.0320861227810383 \n",
      "Epoch [69/5000] , Step [200/488] , Loss: 0.0328881628811359 \n",
      "Epoch [69/5000] , Step [210/488] , Loss: 0.0327701605856419 \n",
      "Epoch [69/5000] , Step [220/488] , Loss: 0.0327427498996258 \n",
      "Epoch [69/5000] , Step [230/488] , Loss: 0.0323670692741871 \n",
      "Epoch [69/5000] , Step [240/488] , Loss: 0.0324310101568699 \n",
      "Epoch [69/5000] , Step [250/488] , Loss: 0.0329253599047661 \n",
      "Epoch [69/5000] , Step [260/488] , Loss: 0.0326345786452293 \n",
      "Epoch [69/5000] , Step [270/488] , Loss: 0.0330143384635448 \n",
      "Epoch [69/5000] , Step [280/488] , Loss: 0.0326507985591888 \n",
      "Epoch [69/5000] , Step [290/488] , Loss: 0.0326865240931511 \n",
      "Epoch [69/5000] , Step [300/488] , Loss: 0.0321055613458157 \n",
      "Epoch [69/5000] , Step [310/488] , Loss: 0.0317080356180668 \n",
      "Epoch [69/5000] , Step [320/488] , Loss: 0.0326742790639400 \n",
      "Epoch [69/5000] , Step [330/488] , Loss: 0.0330900959670544 \n",
      "Epoch [69/5000] , Step [340/488] , Loss: 0.0327772684395313 \n",
      "Epoch [69/5000] , Step [350/488] , Loss: 0.0321099050343037 \n",
      "Epoch [69/5000] , Step [360/488] , Loss: 0.0318797156214714 \n",
      "Epoch [69/5000] , Step [370/488] , Loss: 0.0325014926493168 \n",
      "Epoch [69/5000] , Step [380/488] , Loss: 0.0320306383073330 \n",
      "Epoch [69/5000] , Step [390/488] , Loss: 0.0324194096028805 \n",
      "Epoch [69/5000] , Step [400/488] , Loss: 0.0326942503452301 \n",
      "Epoch [69/5000] , Step [410/488] , Loss: 0.0328041315078735 \n",
      "Epoch [69/5000] , Step [420/488] , Loss: 0.0329696536064148 \n",
      "Epoch [69/5000] , Step [430/488] , Loss: 0.0326789021492004 \n",
      "Epoch [69/5000] , Step [440/488] , Loss: 0.0325162820518017 \n",
      "Epoch [69/5000] , Step [450/488] , Loss: 0.0321227610111237 \n",
      "Epoch [69/5000] , Step [460/488] , Loss: 0.0325739569962025 \n",
      "Epoch [69/5000] , Step [470/488] , Loss: 0.0323530174791813 \n",
      "Epoch [69/5000] , Step [480/488] , Loss: 0.0325381346046925 \n",
      "Epoch [70/5000] , Step [10/488] , Loss: 0.0325472652912140 \n",
      "Epoch [70/5000] , Step [20/488] , Loss: 0.0324209816753864 \n",
      "Epoch [70/5000] , Step [30/488] , Loss: 0.0325019657611847 \n",
      "Epoch [70/5000] , Step [40/488] , Loss: 0.0327871702611446 \n",
      "Epoch [70/5000] , Step [50/488] , Loss: 0.0320154987275600 \n",
      "Epoch [70/5000] , Step [60/488] , Loss: 0.0323230177164078 \n",
      "Epoch [70/5000] , Step [70/488] , Loss: 0.0319118164479733 \n",
      "Epoch [70/5000] , Step [80/488] , Loss: 0.0326151773333549 \n",
      "Epoch [70/5000] , Step [90/488] , Loss: 0.0326563268899918 \n",
      "Epoch [70/5000] , Step [100/488] , Loss: 0.0327250584959984 \n",
      "Epoch [70/5000] , Step [110/488] , Loss: 0.0327541902661324 \n",
      "Epoch [70/5000] , Step [120/488] , Loss: 0.0320416726171970 \n",
      "Epoch [70/5000] , Step [130/488] , Loss: 0.0320797562599182 \n",
      "Epoch [70/5000] , Step [140/488] , Loss: 0.0326982401311398 \n",
      "Epoch [70/5000] , Step [150/488] , Loss: 0.0319209285080433 \n",
      "Epoch [70/5000] , Step [160/488] , Loss: 0.0327631980180740 \n",
      "Epoch [70/5000] , Step [170/488] , Loss: 0.0325547568500042 \n",
      "Epoch [70/5000] , Step [180/488] , Loss: 0.0325697436928749 \n",
      "Epoch [70/5000] , Step [190/488] , Loss: 0.0326616875827312 \n",
      "Epoch [70/5000] , Step [200/488] , Loss: 0.0327245295047760 \n",
      "Epoch [70/5000] , Step [210/488] , Loss: 0.0320688709616661 \n",
      "Epoch [70/5000] , Step [220/488] , Loss: 0.0330375395715237 \n",
      "Epoch [70/5000] , Step [230/488] , Loss: 0.0319547839462757 \n",
      "Epoch [70/5000] , Step [240/488] , Loss: 0.0326684713363647 \n",
      "Epoch [70/5000] , Step [250/488] , Loss: 0.0326803699135780 \n",
      "Epoch [70/5000] , Step [260/488] , Loss: 0.0324180126190186 \n",
      "Epoch [70/5000] , Step [270/488] , Loss: 0.0326405204832554 \n",
      "Epoch [70/5000] , Step [280/488] , Loss: 0.0326178111135960 \n",
      "Epoch [70/5000] , Step [290/488] , Loss: 0.0325142703950405 \n",
      "Epoch [70/5000] , Step [300/488] , Loss: 0.0332700759172440 \n",
      "Epoch [70/5000] , Step [310/488] , Loss: 0.0318308696150780 \n",
      "Epoch [70/5000] , Step [320/488] , Loss: 0.0334684327244759 \n",
      "Epoch [70/5000] , Step [330/488] , Loss: 0.0321653671562672 \n",
      "Epoch [70/5000] , Step [340/488] , Loss: 0.0329601392149925 \n",
      "Epoch [70/5000] , Step [350/488] , Loss: 0.0317856632173061 \n",
      "Epoch [70/5000] , Step [360/488] , Loss: 0.0319577082991600 \n",
      "Epoch [70/5000] , Step [370/488] , Loss: 0.0323299169540405 \n",
      "Epoch [70/5000] , Step [380/488] , Loss: 0.0323025174438953 \n",
      "Epoch [70/5000] , Step [390/488] , Loss: 0.0325537510216236 \n",
      "Epoch [70/5000] , Step [400/488] , Loss: 0.0321025587618351 \n",
      "Epoch [70/5000] , Step [410/488] , Loss: 0.0324231684207916 \n",
      "Epoch [70/5000] , Step [420/488] , Loss: 0.0326189994812012 \n",
      "Epoch [70/5000] , Step [430/488] , Loss: 0.0326307080686092 \n",
      "Epoch [70/5000] , Step [440/488] , Loss: 0.0319615676999092 \n",
      "Epoch [70/5000] , Step [450/488] , Loss: 0.0325522944331169 \n",
      "Epoch [70/5000] , Step [460/488] , Loss: 0.0328056588768959 \n",
      "Epoch [70/5000] , Step [470/488] , Loss: 0.0324486233294010 \n",
      "Epoch [70/5000] , Step [480/488] , Loss: 0.0331806205213070 \n",
      "Epoch [71/5000] , Step [10/488] , Loss: 0.0320247337222099 \n",
      "Epoch [71/5000] , Step [20/488] , Loss: 0.0326251909136772 \n",
      "Epoch [71/5000] , Step [30/488] , Loss: 0.0323742814362049 \n",
      "Epoch [71/5000] , Step [40/488] , Loss: 0.0320986770093441 \n",
      "Epoch [71/5000] , Step [50/488] , Loss: 0.0324079133570194 \n",
      "Epoch [71/5000] , Step [60/488] , Loss: 0.0328647792339325 \n",
      "Epoch [71/5000] , Step [70/488] , Loss: 0.0325739607214928 \n",
      "Epoch [71/5000] , Step [80/488] , Loss: 0.0316277444362640 \n",
      "Epoch [71/5000] , Step [90/488] , Loss: 0.0327844955027103 \n",
      "Epoch [71/5000] , Step [100/488] , Loss: 0.0326510891318321 \n",
      "Epoch [71/5000] , Step [110/488] , Loss: 0.0325687639415264 \n",
      "Epoch [71/5000] , Step [120/488] , Loss: 0.0329038351774216 \n",
      "Epoch [71/5000] , Step [130/488] , Loss: 0.0324833579361439 \n",
      "Epoch [71/5000] , Step [140/488] , Loss: 0.0322182327508926 \n",
      "Epoch [71/5000] , Step [150/488] , Loss: 0.0326439999043941 \n",
      "Epoch [71/5000] , Step [160/488] , Loss: 0.0332046486437321 \n",
      "Epoch [71/5000] , Step [170/488] , Loss: 0.0328295715153217 \n",
      "Epoch [71/5000] , Step [180/488] , Loss: 0.0328154340386391 \n",
      "Epoch [71/5000] , Step [190/488] , Loss: 0.0332737602293491 \n",
      "Epoch [71/5000] , Step [200/488] , Loss: 0.0322898365557194 \n",
      "Epoch [71/5000] , Step [210/488] , Loss: 0.0320163890719414 \n",
      "Epoch [71/5000] , Step [220/488] , Loss: 0.0319712534546852 \n",
      "Epoch [71/5000] , Step [230/488] , Loss: 0.0333114266395569 \n",
      "Epoch [71/5000] , Step [240/488] , Loss: 0.0322759523987770 \n",
      "Epoch [71/5000] , Step [250/488] , Loss: 0.0328288264572620 \n",
      "Epoch [71/5000] , Step [260/488] , Loss: 0.0327574200928211 \n",
      "Epoch [71/5000] , Step [270/488] , Loss: 0.0327766723930836 \n",
      "Epoch [71/5000] , Step [280/488] , Loss: 0.0327838212251663 \n",
      "Epoch [71/5000] , Step [290/488] , Loss: 0.0325067788362503 \n",
      "Epoch [71/5000] , Step [300/488] , Loss: 0.0322674103081226 \n",
      "Epoch [71/5000] , Step [310/488] , Loss: 0.0324923433363438 \n",
      "Epoch [71/5000] , Step [320/488] , Loss: 0.0323347933590412 \n",
      "Epoch [71/5000] , Step [330/488] , Loss: 0.0322440080344677 \n",
      "Epoch [71/5000] , Step [340/488] , Loss: 0.0321723222732544 \n",
      "Epoch [71/5000] , Step [350/488] , Loss: 0.0326393544673920 \n",
      "Epoch [71/5000] , Step [360/488] , Loss: 0.0319021977484226 \n",
      "Epoch [71/5000] , Step [370/488] , Loss: 0.0324238501489162 \n",
      "Epoch [71/5000] , Step [380/488] , Loss: 0.0322919003665447 \n",
      "Epoch [71/5000] , Step [390/488] , Loss: 0.0324208401143551 \n",
      "Epoch [71/5000] , Step [400/488] , Loss: 0.0332522541284561 \n",
      "Epoch [71/5000] , Step [410/488] , Loss: 0.0326442644000053 \n",
      "Epoch [71/5000] , Step [420/488] , Loss: 0.0316834039986134 \n",
      "Epoch [71/5000] , Step [430/488] , Loss: 0.0318582989275455 \n",
      "Epoch [71/5000] , Step [440/488] , Loss: 0.0332469344139099 \n",
      "Epoch [71/5000] , Step [450/488] , Loss: 0.0328942909836769 \n",
      "Epoch [71/5000] , Step [460/488] , Loss: 0.0325662568211555 \n",
      "Epoch [71/5000] , Step [470/488] , Loss: 0.0326369181275368 \n",
      "Epoch [71/5000] , Step [480/488] , Loss: 0.0320695899426937 \n",
      "Epoch [72/5000] , Step [10/488] , Loss: 0.0323627032339573 \n",
      "Epoch [72/5000] , Step [20/488] , Loss: 0.0326994732022285 \n",
      "Epoch [72/5000] , Step [30/488] , Loss: 0.0332224369049072 \n",
      "Epoch [72/5000] , Step [40/488] , Loss: 0.0321804434061050 \n",
      "Epoch [72/5000] , Step [50/488] , Loss: 0.0324956327676773 \n",
      "Epoch [72/5000] , Step [60/488] , Loss: 0.0327547490596771 \n",
      "Epoch [72/5000] , Step [70/488] , Loss: 0.0322687514126301 \n",
      "Epoch [72/5000] , Step [80/488] , Loss: 0.0331400521099567 \n",
      "Epoch [72/5000] , Step [90/488] , Loss: 0.0326716862618923 \n",
      "Epoch [72/5000] , Step [100/488] , Loss: 0.0322565734386444 \n",
      "Epoch [72/5000] , Step [110/488] , Loss: 0.0324119254946709 \n",
      "Epoch [72/5000] , Step [120/488] , Loss: 0.0325236618518829 \n",
      "Epoch [72/5000] , Step [130/488] , Loss: 0.0323501713573933 \n",
      "Epoch [72/5000] , Step [140/488] , Loss: 0.0322192274034023 \n",
      "Epoch [72/5000] , Step [150/488] , Loss: 0.0328930132091045 \n",
      "Epoch [72/5000] , Step [160/488] , Loss: 0.0326106064021587 \n",
      "Epoch [72/5000] , Step [170/488] , Loss: 0.0321839079260826 \n",
      "Epoch [72/5000] , Step [180/488] , Loss: 0.0325287990272045 \n",
      "Epoch [72/5000] , Step [190/488] , Loss: 0.0327008739113808 \n",
      "Epoch [72/5000] , Step [200/488] , Loss: 0.0322521440684795 \n",
      "Epoch [72/5000] , Step [210/488] , Loss: 0.0324168317019939 \n",
      "Epoch [72/5000] , Step [220/488] , Loss: 0.0320237651467323 \n",
      "Epoch [72/5000] , Step [230/488] , Loss: 0.0324191339313984 \n",
      "Epoch [72/5000] , Step [240/488] , Loss: 0.0321797057986259 \n",
      "Epoch [72/5000] , Step [250/488] , Loss: 0.0326951071619987 \n",
      "Epoch [72/5000] , Step [260/488] , Loss: 0.0325669273734093 \n",
      "Epoch [72/5000] , Step [270/488] , Loss: 0.0323855504393578 \n",
      "Epoch [72/5000] , Step [280/488] , Loss: 0.0326234586536884 \n",
      "Epoch [72/5000] , Step [290/488] , Loss: 0.0329095646739006 \n",
      "Epoch [72/5000] , Step [300/488] , Loss: 0.0318656563758850 \n",
      "Epoch [72/5000] , Step [310/488] , Loss: 0.0319440141320229 \n",
      "Epoch [72/5000] , Step [320/488] , Loss: 0.0326516442000866 \n",
      "Epoch [72/5000] , Step [330/488] , Loss: 0.0318569317460060 \n",
      "Epoch [72/5000] , Step [340/488] , Loss: 0.0325314402580261 \n",
      "Epoch [72/5000] , Step [350/488] , Loss: 0.0325316004455090 \n",
      "Epoch [72/5000] , Step [360/488] , Loss: 0.0328101217746735 \n",
      "Epoch [72/5000] , Step [370/488] , Loss: 0.0325919091701508 \n",
      "Epoch [72/5000] , Step [380/488] , Loss: 0.0324860550463200 \n",
      "Epoch [72/5000] , Step [390/488] , Loss: 0.0321983620524406 \n",
      "Epoch [72/5000] , Step [400/488] , Loss: 0.0329422242939472 \n",
      "Epoch [72/5000] , Step [410/488] , Loss: 0.0321555100381374 \n",
      "Epoch [72/5000] , Step [420/488] , Loss: 0.0326608158648014 \n",
      "Epoch [72/5000] , Step [430/488] , Loss: 0.0329998023808002 \n",
      "Epoch [72/5000] , Step [440/488] , Loss: 0.0323648713529110 \n",
      "Epoch [72/5000] , Step [450/488] , Loss: 0.0326874591410160 \n",
      "Epoch [72/5000] , Step [460/488] , Loss: 0.0330584235489368 \n",
      "Epoch [72/5000] , Step [470/488] , Loss: 0.0323066301643848 \n",
      "Epoch [72/5000] , Step [480/488] , Loss: 0.0326363071799278 \n",
      "Epoch [73/5000] , Step [10/488] , Loss: 0.0330801121890545 \n",
      "Epoch [73/5000] , Step [20/488] , Loss: 0.0330666601657867 \n",
      "Epoch [73/5000] , Step [30/488] , Loss: 0.0328641310334206 \n",
      "Epoch [73/5000] , Step [40/488] , Loss: 0.0326952636241913 \n",
      "Epoch [73/5000] , Step [50/488] , Loss: 0.0318736359477043 \n",
      "Epoch [73/5000] , Step [60/488] , Loss: 0.0324738621711731 \n",
      "Epoch [73/5000] , Step [70/488] , Loss: 0.0323145687580109 \n",
      "Epoch [73/5000] , Step [80/488] , Loss: 0.0326809361577034 \n",
      "Epoch [73/5000] , Step [90/488] , Loss: 0.0328241139650345 \n",
      "Epoch [73/5000] , Step [100/488] , Loss: 0.0319797731935978 \n",
      "Epoch [73/5000] , Step [110/488] , Loss: 0.0322402454912663 \n",
      "Epoch [73/5000] , Step [120/488] , Loss: 0.0329798534512520 \n",
      "Epoch [73/5000] , Step [130/488] , Loss: 0.0325598604977131 \n",
      "Epoch [73/5000] , Step [140/488] , Loss: 0.0322612971067429 \n",
      "Epoch [73/5000] , Step [150/488] , Loss: 0.0321473032236099 \n",
      "Epoch [73/5000] , Step [160/488] , Loss: 0.0323903933167458 \n",
      "Epoch [73/5000] , Step [170/488] , Loss: 0.0322553664445877 \n",
      "Epoch [73/5000] , Step [180/488] , Loss: 0.0328837744891644 \n",
      "Epoch [73/5000] , Step [190/488] , Loss: 0.0323112495243549 \n",
      "Epoch [73/5000] , Step [200/488] , Loss: 0.0328491292893887 \n",
      "Epoch [73/5000] , Step [210/488] , Loss: 0.0325500071048737 \n",
      "Epoch [73/5000] , Step [220/488] , Loss: 0.0322327874600887 \n",
      "Epoch [73/5000] , Step [230/488] , Loss: 0.0331619754433632 \n",
      "Epoch [73/5000] , Step [240/488] , Loss: 0.0329385101795197 \n",
      "Epoch [73/5000] , Step [250/488] , Loss: 0.0326505377888680 \n",
      "Epoch [73/5000] , Step [260/488] , Loss: 0.0316873341798782 \n",
      "Epoch [73/5000] , Step [270/488] , Loss: 0.0328177623450756 \n",
      "Epoch [73/5000] , Step [280/488] , Loss: 0.0333733484148979 \n",
      "Epoch [73/5000] , Step [290/488] , Loss: 0.0325889922678471 \n",
      "Epoch [73/5000] , Step [300/488] , Loss: 0.0327195785939693 \n",
      "Epoch [73/5000] , Step [310/488] , Loss: 0.0330599658191204 \n",
      "Epoch [73/5000] , Step [320/488] , Loss: 0.0328109636902809 \n",
      "Epoch [73/5000] , Step [330/488] , Loss: 0.0326698273420334 \n",
      "Epoch [73/5000] , Step [340/488] , Loss: 0.0325660631060600 \n",
      "Epoch [73/5000] , Step [350/488] , Loss: 0.0327258706092834 \n",
      "Epoch [73/5000] , Step [360/488] , Loss: 0.0320849530398846 \n",
      "Epoch [73/5000] , Step [370/488] , Loss: 0.0323410257697105 \n",
      "Epoch [73/5000] , Step [380/488] , Loss: 0.0323710404336452 \n",
      "Epoch [73/5000] , Step [390/488] , Loss: 0.0325831137597561 \n",
      "Epoch [73/5000] , Step [400/488] , Loss: 0.0325819663703442 \n",
      "Epoch [73/5000] , Step [410/488] , Loss: 0.0320216156542301 \n",
      "Epoch [73/5000] , Step [420/488] , Loss: 0.0326963216066360 \n",
      "Epoch [73/5000] , Step [430/488] , Loss: 0.0327649004757404 \n",
      "Epoch [73/5000] , Step [440/488] , Loss: 0.0328848846256733 \n",
      "Epoch [73/5000] , Step [450/488] , Loss: 0.0324409529566765 \n",
      "Epoch [73/5000] , Step [460/488] , Loss: 0.0322971418499947 \n",
      "Epoch [73/5000] , Step [470/488] , Loss: 0.0325215794146061 \n",
      "Epoch [73/5000] , Step [480/488] , Loss: 0.0327594056725502 \n",
      "Epoch [74/5000] , Step [10/488] , Loss: 0.0316999927163124 \n",
      "Epoch [74/5000] , Step [20/488] , Loss: 0.0323808975517750 \n",
      "Epoch [74/5000] , Step [30/488] , Loss: 0.0324360691010952 \n",
      "Epoch [74/5000] , Step [40/488] , Loss: 0.0325091779232025 \n",
      "Epoch [74/5000] , Step [50/488] , Loss: 0.0327108241617680 \n",
      "Epoch [74/5000] , Step [60/488] , Loss: 0.0325829200446606 \n",
      "Epoch [74/5000] , Step [70/488] , Loss: 0.0326110757887363 \n",
      "Epoch [74/5000] , Step [80/488] , Loss: 0.0334013551473618 \n",
      "Epoch [74/5000] , Step [90/488] , Loss: 0.0322961322963238 \n",
      "Epoch [74/5000] , Step [100/488] , Loss: 0.0327051877975464 \n",
      "Epoch [74/5000] , Step [110/488] , Loss: 0.0328142754733562 \n",
      "Epoch [74/5000] , Step [120/488] , Loss: 0.0320436693727970 \n",
      "Epoch [74/5000] , Step [130/488] , Loss: 0.0333812832832336 \n",
      "Epoch [74/5000] , Step [140/488] , Loss: 0.0326515510678291 \n",
      "Epoch [74/5000] , Step [150/488] , Loss: 0.0325409807264805 \n",
      "Epoch [74/5000] , Step [160/488] , Loss: 0.0326250009238720 \n",
      "Epoch [74/5000] , Step [170/488] , Loss: 0.0325870588421822 \n",
      "Epoch [74/5000] , Step [180/488] , Loss: 0.0324948765337467 \n",
      "Epoch [74/5000] , Step [190/488] , Loss: 0.0328471623361111 \n",
      "Epoch [74/5000] , Step [200/488] , Loss: 0.0323840081691742 \n",
      "Epoch [74/5000] , Step [210/488] , Loss: 0.0322955548763275 \n",
      "Epoch [74/5000] , Step [220/488] , Loss: 0.0326088182628155 \n",
      "Epoch [74/5000] , Step [230/488] , Loss: 0.0329801030457020 \n",
      "Epoch [74/5000] , Step [240/488] , Loss: 0.0322272256016731 \n",
      "Epoch [74/5000] , Step [250/488] , Loss: 0.0327979400753975 \n",
      "Epoch [74/5000] , Step [260/488] , Loss: 0.0324563123285770 \n",
      "Epoch [74/5000] , Step [270/488] , Loss: 0.0330436304211617 \n",
      "Epoch [74/5000] , Step [280/488] , Loss: 0.0326759256422520 \n",
      "Epoch [74/5000] , Step [290/488] , Loss: 0.0327747315168381 \n",
      "Epoch [74/5000] , Step [300/488] , Loss: 0.0326392799615860 \n",
      "Epoch [74/5000] , Step [310/488] , Loss: 0.0322051681578159 \n",
      "Epoch [74/5000] , Step [320/488] , Loss: 0.0328422598540783 \n",
      "Epoch [74/5000] , Step [330/488] , Loss: 0.0323966629803181 \n",
      "Epoch [74/5000] , Step [340/488] , Loss: 0.0322637148201466 \n",
      "Epoch [74/5000] , Step [350/488] , Loss: 0.0324393361806870 \n",
      "Epoch [74/5000] , Step [360/488] , Loss: 0.0323636941611767 \n",
      "Epoch [74/5000] , Step [370/488] , Loss: 0.0323366336524487 \n",
      "Epoch [74/5000] , Step [380/488] , Loss: 0.0328847058117390 \n",
      "Epoch [74/5000] , Step [390/488] , Loss: 0.0324570387601852 \n",
      "Epoch [74/5000] , Step [400/488] , Loss: 0.0326340124011040 \n",
      "Epoch [74/5000] , Step [410/488] , Loss: 0.0332251340150833 \n",
      "Epoch [74/5000] , Step [420/488] , Loss: 0.0326065123081207 \n",
      "Epoch [74/5000] , Step [430/488] , Loss: 0.0322895534336567 \n",
      "Epoch [74/5000] , Step [440/488] , Loss: 0.0321732498705387 \n",
      "Epoch [74/5000] , Step [450/488] , Loss: 0.0326620563864708 \n",
      "Epoch [74/5000] , Step [460/488] , Loss: 0.0320822559297085 \n",
      "Epoch [74/5000] , Step [470/488] , Loss: 0.0330045260488987 \n",
      "Epoch [74/5000] , Step [480/488] , Loss: 0.0323461666703224 \n",
      "Epoch [75/5000] , Step [10/488] , Loss: 0.0320510752499104 \n",
      "Epoch [75/5000] , Step [20/488] , Loss: 0.0325223393738270 \n",
      "Epoch [75/5000] , Step [30/488] , Loss: 0.0326202437281609 \n",
      "Epoch [75/5000] , Step [40/488] , Loss: 0.0316841267049313 \n",
      "Epoch [75/5000] , Step [50/488] , Loss: 0.0320802144706249 \n",
      "Epoch [75/5000] , Step [60/488] , Loss: 0.0324150100350380 \n",
      "Epoch [75/5000] , Step [70/488] , Loss: 0.0325139090418816 \n",
      "Epoch [75/5000] , Step [80/488] , Loss: 0.0332476310431957 \n",
      "Epoch [75/5000] , Step [90/488] , Loss: 0.0326252505183220 \n",
      "Epoch [75/5000] , Step [100/488] , Loss: 0.0325666889548302 \n",
      "Epoch [75/5000] , Step [110/488] , Loss: 0.0325646959245205 \n",
      "Epoch [75/5000] , Step [120/488] , Loss: 0.0325993411242962 \n",
      "Epoch [75/5000] , Step [130/488] , Loss: 0.0322523526847363 \n",
      "Epoch [75/5000] , Step [140/488] , Loss: 0.0328696481883526 \n",
      "Epoch [75/5000] , Step [150/488] , Loss: 0.0330710113048553 \n",
      "Epoch [75/5000] , Step [160/488] , Loss: 0.0326581597328186 \n",
      "Epoch [75/5000] , Step [170/488] , Loss: 0.0324188619852066 \n",
      "Epoch [75/5000] , Step [180/488] , Loss: 0.0329823046922684 \n",
      "Epoch [75/5000] , Step [190/488] , Loss: 0.0322645828127861 \n",
      "Epoch [75/5000] , Step [200/488] , Loss: 0.0324542038142681 \n",
      "Epoch [75/5000] , Step [210/488] , Loss: 0.0328827723860741 \n",
      "Epoch [75/5000] , Step [220/488] , Loss: 0.0323989987373352 \n",
      "Epoch [75/5000] , Step [230/488] , Loss: 0.0325459241867065 \n",
      "Epoch [75/5000] , Step [240/488] , Loss: 0.0320759378373623 \n",
      "Epoch [75/5000] , Step [250/488] , Loss: 0.0323816575109959 \n",
      "Epoch [75/5000] , Step [260/488] , Loss: 0.0324476286768913 \n",
      "Epoch [75/5000] , Step [270/488] , Loss: 0.0324655398726463 \n",
      "Epoch [75/5000] , Step [280/488] , Loss: 0.0323619432747364 \n",
      "Epoch [75/5000] , Step [290/488] , Loss: 0.0322623737156391 \n",
      "Epoch [75/5000] , Step [300/488] , Loss: 0.0325639694929123 \n",
      "Epoch [75/5000] , Step [310/488] , Loss: 0.0329765416681767 \n",
      "Epoch [75/5000] , Step [320/488] , Loss: 0.0320139788091183 \n",
      "Epoch [75/5000] , Step [330/488] , Loss: 0.0319856964051723 \n",
      "Epoch [75/5000] , Step [340/488] , Loss: 0.0327963717281818 \n",
      "Epoch [75/5000] , Step [350/488] , Loss: 0.0326703935861588 \n",
      "Epoch [75/5000] , Step [360/488] , Loss: 0.0324019677937031 \n",
      "Epoch [75/5000] , Step [370/488] , Loss: 0.0325437188148499 \n",
      "Epoch [75/5000] , Step [380/488] , Loss: 0.0316550023853779 \n",
      "Epoch [75/5000] , Step [390/488] , Loss: 0.0326644927263260 \n",
      "Epoch [75/5000] , Step [400/488] , Loss: 0.0323967225849628 \n",
      "Epoch [75/5000] , Step [410/488] , Loss: 0.0325565040111542 \n",
      "Epoch [75/5000] , Step [420/488] , Loss: 0.0328532829880714 \n",
      "Epoch [75/5000] , Step [430/488] , Loss: 0.0323761850595474 \n",
      "Epoch [75/5000] , Step [440/488] , Loss: 0.0326044298708439 \n",
      "Epoch [75/5000] , Step [450/488] , Loss: 0.0325659029185772 \n",
      "Epoch [75/5000] , Step [460/488] , Loss: 0.0319197252392769 \n",
      "Epoch [75/5000] , Step [470/488] , Loss: 0.0322880856692791 \n",
      "Epoch [75/5000] , Step [480/488] , Loss: 0.0320705845952034 \n",
      "Epoch [76/5000] , Step [10/488] , Loss: 0.0324910245835781 \n",
      "Epoch [76/5000] , Step [20/488] , Loss: 0.0322665311396122 \n",
      "Epoch [76/5000] , Step [30/488] , Loss: 0.0331693924963474 \n",
      "Epoch [76/5000] , Step [40/488] , Loss: 0.0320836864411831 \n",
      "Epoch [76/5000] , Step [50/488] , Loss: 0.0324432998895645 \n",
      "Epoch [76/5000] , Step [60/488] , Loss: 0.0324360653758049 \n",
      "Epoch [76/5000] , Step [70/488] , Loss: 0.0320003442466259 \n",
      "Epoch [76/5000] , Step [80/488] , Loss: 0.0319870747625828 \n",
      "Epoch [76/5000] , Step [90/488] , Loss: 0.0325487963855267 \n",
      "Epoch [76/5000] , Step [100/488] , Loss: 0.0326977558434010 \n",
      "Epoch [76/5000] , Step [110/488] , Loss: 0.0323194488883018 \n",
      "Epoch [76/5000] , Step [120/488] , Loss: 0.0324556045234203 \n",
      "Epoch [76/5000] , Step [130/488] , Loss: 0.0320440568029881 \n",
      "Epoch [76/5000] , Step [140/488] , Loss: 0.0325441546738148 \n",
      "Epoch [76/5000] , Step [150/488] , Loss: 0.0325431674718857 \n",
      "Epoch [76/5000] , Step [160/488] , Loss: 0.0322610773146152 \n",
      "Epoch [76/5000] , Step [170/488] , Loss: 0.0322248153388500 \n",
      "Epoch [76/5000] , Step [180/488] , Loss: 0.0325957946479321 \n",
      "Epoch [76/5000] , Step [190/488] , Loss: 0.0332068055868149 \n",
      "Epoch [76/5000] , Step [200/488] , Loss: 0.0316440872848034 \n",
      "Epoch [76/5000] , Step [210/488] , Loss: 0.0324737131595612 \n",
      "Epoch [76/5000] , Step [220/488] , Loss: 0.0329660885035992 \n",
      "Epoch [76/5000] , Step [230/488] , Loss: 0.0332010649144650 \n",
      "Epoch [76/5000] , Step [240/488] , Loss: 0.0318134501576424 \n",
      "Epoch [76/5000] , Step [250/488] , Loss: 0.0321388170123100 \n",
      "Epoch [76/5000] , Step [260/488] , Loss: 0.0322781503200531 \n",
      "Epoch [76/5000] , Step [270/488] , Loss: 0.0328931771218777 \n",
      "Epoch [76/5000] , Step [280/488] , Loss: 0.0315355248749256 \n",
      "Epoch [76/5000] , Step [290/488] , Loss: 0.0326074808835983 \n",
      "Epoch [76/5000] , Step [300/488] , Loss: 0.0332345515489578 \n",
      "Epoch [76/5000] , Step [310/488] , Loss: 0.0326208136975765 \n",
      "Epoch [76/5000] , Step [320/488] , Loss: 0.0324695073068142 \n",
      "Epoch [76/5000] , Step [330/488] , Loss: 0.0330551788210869 \n",
      "Epoch [76/5000] , Step [340/488] , Loss: 0.0327891968190670 \n",
      "Epoch [76/5000] , Step [350/488] , Loss: 0.0330300331115723 \n",
      "Epoch [76/5000] , Step [360/488] , Loss: 0.0326419658958912 \n",
      "Epoch [76/5000] , Step [370/488] , Loss: 0.0325479321181774 \n",
      "Epoch [76/5000] , Step [380/488] , Loss: 0.0326067321002483 \n",
      "Epoch [76/5000] , Step [390/488] , Loss: 0.0325750187039375 \n",
      "Epoch [76/5000] , Step [400/488] , Loss: 0.0330484956502914 \n",
      "Epoch [76/5000] , Step [410/488] , Loss: 0.0319192633032799 \n",
      "Epoch [76/5000] , Step [420/488] , Loss: 0.0323930233716965 \n",
      "Epoch [76/5000] , Step [430/488] , Loss: 0.0322327688336372 \n",
      "Epoch [76/5000] , Step [440/488] , Loss: 0.0325944572687149 \n",
      "Epoch [76/5000] , Step [450/488] , Loss: 0.0331339091062546 \n",
      "Epoch [76/5000] , Step [460/488] , Loss: 0.0324915014207363 \n",
      "Epoch [76/5000] , Step [470/488] , Loss: 0.0322257764637470 \n",
      "Epoch [76/5000] , Step [480/488] , Loss: 0.0324515029788017 \n",
      "Epoch [77/5000] , Step [10/488] , Loss: 0.0317840874195099 \n",
      "Epoch [77/5000] , Step [20/488] , Loss: 0.0325314365327358 \n",
      "Epoch [77/5000] , Step [30/488] , Loss: 0.0330680683255196 \n",
      "Epoch [77/5000] , Step [40/488] , Loss: 0.0316786877810955 \n",
      "Epoch [77/5000] , Step [50/488] , Loss: 0.0331964939832687 \n",
      "Epoch [77/5000] , Step [60/488] , Loss: 0.0322722196578979 \n",
      "Epoch [77/5000] , Step [70/488] , Loss: 0.0323441587388515 \n",
      "Epoch [77/5000] , Step [80/488] , Loss: 0.0325434431433678 \n",
      "Epoch [77/5000] , Step [90/488] , Loss: 0.0320558920502663 \n",
      "Epoch [77/5000] , Step [100/488] , Loss: 0.0325627885758877 \n",
      "Epoch [77/5000] , Step [110/488] , Loss: 0.0331403799355030 \n",
      "Epoch [77/5000] , Step [120/488] , Loss: 0.0321079604327679 \n",
      "Epoch [77/5000] , Step [130/488] , Loss: 0.0325931347906590 \n",
      "Epoch [77/5000] , Step [140/488] , Loss: 0.0326073691248894 \n",
      "Epoch [77/5000] , Step [150/488] , Loss: 0.0331850051879883 \n",
      "Epoch [77/5000] , Step [160/488] , Loss: 0.0321468263864517 \n",
      "Epoch [77/5000] , Step [170/488] , Loss: 0.0326173231005669 \n",
      "Epoch [77/5000] , Step [180/488] , Loss: 0.0328214801847935 \n",
      "Epoch [77/5000] , Step [190/488] , Loss: 0.0322235338389874 \n",
      "Epoch [77/5000] , Step [200/488] , Loss: 0.0328041166067123 \n",
      "Epoch [77/5000] , Step [210/488] , Loss: 0.0314778946340084 \n",
      "Epoch [77/5000] , Step [220/488] , Loss: 0.0327661521732807 \n",
      "Epoch [77/5000] , Step [230/488] , Loss: 0.0322396457195282 \n",
      "Epoch [77/5000] , Step [240/488] , Loss: 0.0321886800229549 \n",
      "Epoch [77/5000] , Step [250/488] , Loss: 0.0322115421295166 \n",
      "Epoch [77/5000] , Step [260/488] , Loss: 0.0327544137835503 \n",
      "Epoch [77/5000] , Step [270/488] , Loss: 0.0320817269384861 \n",
      "Epoch [77/5000] , Step [280/488] , Loss: 0.0329367332160473 \n",
      "Epoch [77/5000] , Step [290/488] , Loss: 0.0323765836656094 \n",
      "Epoch [77/5000] , Step [300/488] , Loss: 0.0317067801952362 \n",
      "Epoch [77/5000] , Step [310/488] , Loss: 0.0321207381784916 \n",
      "Epoch [77/5000] , Step [320/488] , Loss: 0.0329429022967815 \n",
      "Epoch [77/5000] , Step [330/488] , Loss: 0.0321688242256641 \n",
      "Epoch [77/5000] , Step [340/488] , Loss: 0.0325246490538120 \n",
      "Epoch [77/5000] , Step [350/488] , Loss: 0.0325211957097054 \n",
      "Epoch [77/5000] , Step [360/488] , Loss: 0.0322577729821205 \n",
      "Epoch [77/5000] , Step [370/488] , Loss: 0.0323783680796623 \n",
      "Epoch [77/5000] , Step [380/488] , Loss: 0.0324723422527313 \n",
      "Epoch [77/5000] , Step [390/488] , Loss: 0.0319952033460140 \n",
      "Epoch [77/5000] , Step [400/488] , Loss: 0.0330505222082138 \n",
      "Epoch [77/5000] , Step [410/488] , Loss: 0.0325887352228165 \n",
      "Epoch [77/5000] , Step [420/488] , Loss: 0.0330543741583824 \n",
      "Epoch [77/5000] , Step [430/488] , Loss: 0.0331915505230427 \n",
      "Epoch [77/5000] , Step [440/488] , Loss: 0.0320653468370438 \n",
      "Epoch [77/5000] , Step [450/488] , Loss: 0.0326873362064362 \n",
      "Epoch [77/5000] , Step [460/488] , Loss: 0.0326279923319817 \n",
      "Epoch [77/5000] , Step [470/488] , Loss: 0.0329992994666100 \n",
      "Epoch [77/5000] , Step [480/488] , Loss: 0.0322193987667561 \n",
      "Epoch [78/5000] , Step [10/488] , Loss: 0.0325980894267559 \n",
      "Epoch [78/5000] , Step [20/488] , Loss: 0.0337133929133415 \n",
      "Epoch [78/5000] , Step [30/488] , Loss: 0.0330158099532127 \n",
      "Epoch [78/5000] , Step [40/488] , Loss: 0.0324730761349201 \n",
      "Epoch [78/5000] , Step [50/488] , Loss: 0.0327011793851852 \n",
      "Epoch [78/5000] , Step [60/488] , Loss: 0.0330230034887791 \n",
      "Epoch [78/5000] , Step [70/488] , Loss: 0.0327255278825760 \n",
      "Epoch [78/5000] , Step [80/488] , Loss: 0.0327119342982769 \n",
      "Epoch [78/5000] , Step [90/488] , Loss: 0.0327376648783684 \n",
      "Epoch [78/5000] , Step [100/488] , Loss: 0.0323273390531540 \n",
      "Epoch [78/5000] , Step [110/488] , Loss: 0.0327897369861603 \n",
      "Epoch [78/5000] , Step [120/488] , Loss: 0.0326259769499302 \n",
      "Epoch [78/5000] , Step [130/488] , Loss: 0.0321185849606991 \n",
      "Epoch [78/5000] , Step [140/488] , Loss: 0.0321082770824432 \n",
      "Epoch [78/5000] , Step [150/488] , Loss: 0.0331705324351788 \n",
      "Epoch [78/5000] , Step [160/488] , Loss: 0.0331070683896542 \n",
      "Epoch [78/5000] , Step [170/488] , Loss: 0.0326591655611992 \n",
      "Epoch [78/5000] , Step [180/488] , Loss: 0.0326009206473827 \n",
      "Epoch [78/5000] , Step [190/488] , Loss: 0.0323690064251423 \n",
      "Epoch [78/5000] , Step [200/488] , Loss: 0.0326206013560295 \n",
      "Epoch [78/5000] , Step [210/488] , Loss: 0.0328475907444954 \n",
      "Epoch [78/5000] , Step [220/488] , Loss: 0.0325425975024700 \n",
      "Epoch [78/5000] , Step [230/488] , Loss: 0.0327614881098270 \n",
      "Epoch [78/5000] , Step [240/488] , Loss: 0.0325202681124210 \n",
      "Epoch [78/5000] , Step [250/488] , Loss: 0.0324080698192120 \n",
      "Epoch [78/5000] , Step [260/488] , Loss: 0.0322673097252846 \n",
      "Epoch [78/5000] , Step [270/488] , Loss: 0.0324160866439342 \n",
      "Epoch [78/5000] , Step [280/488] , Loss: 0.0323900133371353 \n",
      "Epoch [78/5000] , Step [290/488] , Loss: 0.0325806513428688 \n",
      "Epoch [78/5000] , Step [300/488] , Loss: 0.0333396121859550 \n",
      "Epoch [78/5000] , Step [310/488] , Loss: 0.0331695005297661 \n",
      "Epoch [78/5000] , Step [320/488] , Loss: 0.0320841781795025 \n",
      "Epoch [78/5000] , Step [330/488] , Loss: 0.0323518775403500 \n",
      "Epoch [78/5000] , Step [340/488] , Loss: 0.0327563211321831 \n",
      "Epoch [78/5000] , Step [350/488] , Loss: 0.0324932113289833 \n",
      "Epoch [78/5000] , Step [360/488] , Loss: 0.0323518142104149 \n",
      "Epoch [78/5000] , Step [370/488] , Loss: 0.0333755761384964 \n",
      "Epoch [78/5000] , Step [380/488] , Loss: 0.0330858640372753 \n",
      "Epoch [78/5000] , Step [390/488] , Loss: 0.0325699821114540 \n",
      "Epoch [78/5000] , Step [400/488] , Loss: 0.0321916826069355 \n",
      "Epoch [78/5000] , Step [410/488] , Loss: 0.0321888253092766 \n",
      "Epoch [78/5000] , Step [420/488] , Loss: 0.0327854007482529 \n",
      "Epoch [78/5000] , Step [430/488] , Loss: 0.0323308035731316 \n",
      "Epoch [78/5000] , Step [440/488] , Loss: 0.0318532735109329 \n",
      "Epoch [78/5000] , Step [450/488] , Loss: 0.0321168564260006 \n",
      "Epoch [78/5000] , Step [460/488] , Loss: 0.0327430032193661 \n",
      "Epoch [78/5000] , Step [470/488] , Loss: 0.0321358777582645 \n",
      "Epoch [78/5000] , Step [480/488] , Loss: 0.0327258966863155 \n",
      "Epoch [79/5000] , Step [10/488] , Loss: 0.0323905907571316 \n",
      "Epoch [79/5000] , Step [20/488] , Loss: 0.0327886790037155 \n",
      "Epoch [79/5000] , Step [30/488] , Loss: 0.0321778021752834 \n",
      "Epoch [79/5000] , Step [40/488] , Loss: 0.0329024903476238 \n",
      "Epoch [79/5000] , Step [50/488] , Loss: 0.0327246673405170 \n",
      "Epoch [79/5000] , Step [60/488] , Loss: 0.0333140417933464 \n",
      "Epoch [79/5000] , Step [70/488] , Loss: 0.0323675014078617 \n",
      "Epoch [79/5000] , Step [80/488] , Loss: 0.0320898368954659 \n",
      "Epoch [79/5000] , Step [90/488] , Loss: 0.0324792116880417 \n",
      "Epoch [79/5000] , Step [100/488] , Loss: 0.0326558724045753 \n",
      "Epoch [79/5000] , Step [110/488] , Loss: 0.0325693488121033 \n",
      "Epoch [79/5000] , Step [120/488] , Loss: 0.0317019037902355 \n",
      "Epoch [79/5000] , Step [130/488] , Loss: 0.0325224548578262 \n",
      "Epoch [79/5000] , Step [140/488] , Loss: 0.0321399420499802 \n",
      "Epoch [79/5000] , Step [150/488] , Loss: 0.0319752395153046 \n",
      "Epoch [79/5000] , Step [160/488] , Loss: 0.0325104668736458 \n",
      "Epoch [79/5000] , Step [170/488] , Loss: 0.0330081060528755 \n",
      "Epoch [79/5000] , Step [180/488] , Loss: 0.0328183546662331 \n",
      "Epoch [79/5000] , Step [190/488] , Loss: 0.0329967923462391 \n",
      "Epoch [79/5000] , Step [200/488] , Loss: 0.0326527170836926 \n",
      "Epoch [79/5000] , Step [210/488] , Loss: 0.0329497419297695 \n",
      "Epoch [79/5000] , Step [220/488] , Loss: 0.0327209867537022 \n",
      "Epoch [79/5000] , Step [230/488] , Loss: 0.0325393602252007 \n",
      "Epoch [79/5000] , Step [240/488] , Loss: 0.0323402769863605 \n",
      "Epoch [79/5000] , Step [250/488] , Loss: 0.0328041017055511 \n",
      "Epoch [79/5000] , Step [260/488] , Loss: 0.0324706472456455 \n",
      "Epoch [79/5000] , Step [270/488] , Loss: 0.0324058644473553 \n",
      "Epoch [79/5000] , Step [280/488] , Loss: 0.0334645658731461 \n",
      "Epoch [79/5000] , Step [290/488] , Loss: 0.0324031300842762 \n",
      "Epoch [79/5000] , Step [300/488] , Loss: 0.0326858982443810 \n",
      "Epoch [79/5000] , Step [310/488] , Loss: 0.0326309539377689 \n",
      "Epoch [79/5000] , Step [320/488] , Loss: 0.0327772200107574 \n",
      "Epoch [79/5000] , Step [330/488] , Loss: 0.0325051397085190 \n",
      "Epoch [79/5000] , Step [340/488] , Loss: 0.0326257571578026 \n",
      "Epoch [79/5000] , Step [350/488] , Loss: 0.0321460328996181 \n",
      "Epoch [79/5000] , Step [360/488] , Loss: 0.0323442034423351 \n",
      "Epoch [79/5000] , Step [370/488] , Loss: 0.0320165827870369 \n",
      "Epoch [79/5000] , Step [380/488] , Loss: 0.0321909449994564 \n",
      "Epoch [79/5000] , Step [390/488] , Loss: 0.0319483764469624 \n",
      "Epoch [79/5000] , Step [400/488] , Loss: 0.0323764495551586 \n",
      "Epoch [79/5000] , Step [410/488] , Loss: 0.0320593640208244 \n",
      "Epoch [79/5000] , Step [420/488] , Loss: 0.0325541123747826 \n",
      "Epoch [79/5000] , Step [430/488] , Loss: 0.0321721099317074 \n",
      "Epoch [79/5000] , Step [440/488] , Loss: 0.0331305526196957 \n",
      "Epoch [79/5000] , Step [450/488] , Loss: 0.0326343290507793 \n",
      "Epoch [79/5000] , Step [460/488] , Loss: 0.0324074551463127 \n",
      "Epoch [79/5000] , Step [470/488] , Loss: 0.0325301587581635 \n",
      "Epoch [79/5000] , Step [480/488] , Loss: 0.0329866446554661 \n",
      "Epoch [80/5000] , Step [10/488] , Loss: 0.0317657887935638 \n",
      "Epoch [80/5000] , Step [20/488] , Loss: 0.0325043685734272 \n",
      "Epoch [80/5000] , Step [30/488] , Loss: 0.0323056057095528 \n",
      "Epoch [80/5000] , Step [40/488] , Loss: 0.0322525016963482 \n",
      "Epoch [80/5000] , Step [50/488] , Loss: 0.0324198827147484 \n",
      "Epoch [80/5000] , Step [60/488] , Loss: 0.0323128029704094 \n",
      "Epoch [80/5000] , Step [70/488] , Loss: 0.0322003178298473 \n",
      "Epoch [80/5000] , Step [80/488] , Loss: 0.0324306041002274 \n",
      "Epoch [80/5000] , Step [90/488] , Loss: 0.0326940082013607 \n",
      "Epoch [80/5000] , Step [100/488] , Loss: 0.0328782722353935 \n",
      "Epoch [80/5000] , Step [110/488] , Loss: 0.0321505926549435 \n",
      "Epoch [80/5000] , Step [120/488] , Loss: 0.0329679958522320 \n",
      "Epoch [80/5000] , Step [130/488] , Loss: 0.0322754867374897 \n",
      "Epoch [80/5000] , Step [140/488] , Loss: 0.0331698246300220 \n",
      "Epoch [80/5000] , Step [150/488] , Loss: 0.0333265326917171 \n",
      "Epoch [80/5000] , Step [160/488] , Loss: 0.0321589969098568 \n",
      "Epoch [80/5000] , Step [170/488] , Loss: 0.0320521220564842 \n",
      "Epoch [80/5000] , Step [180/488] , Loss: 0.0329308547079563 \n",
      "Epoch [80/5000] , Step [190/488] , Loss: 0.0314672142267227 \n",
      "Epoch [80/5000] , Step [200/488] , Loss: 0.0317898616194725 \n",
      "Epoch [80/5000] , Step [210/488] , Loss: 0.0329231433570385 \n",
      "Epoch [80/5000] , Step [220/488] , Loss: 0.0330078750848770 \n",
      "Epoch [80/5000] , Step [230/488] , Loss: 0.0326005034148693 \n",
      "Epoch [80/5000] , Step [240/488] , Loss: 0.0322786383330822 \n",
      "Epoch [80/5000] , Step [250/488] , Loss: 0.0324298441410065 \n",
      "Epoch [80/5000] , Step [260/488] , Loss: 0.0317128896713257 \n",
      "Epoch [80/5000] , Step [270/488] , Loss: 0.0319888256490231 \n",
      "Epoch [80/5000] , Step [280/488] , Loss: 0.0325423069298267 \n",
      "Epoch [80/5000] , Step [290/488] , Loss: 0.0326625779271126 \n",
      "Epoch [80/5000] , Step [300/488] , Loss: 0.0327531062066555 \n",
      "Epoch [80/5000] , Step [310/488] , Loss: 0.0331740975379944 \n",
      "Epoch [80/5000] , Step [320/488] , Loss: 0.0325236022472382 \n",
      "Epoch [80/5000] , Step [330/488] , Loss: 0.0328058004379272 \n",
      "Epoch [80/5000] , Step [340/488] , Loss: 0.0322182923555374 \n",
      "Epoch [80/5000] , Step [350/488] , Loss: 0.0328304842114449 \n",
      "Epoch [80/5000] , Step [360/488] , Loss: 0.0320782028138638 \n",
      "Epoch [80/5000] , Step [370/488] , Loss: 0.0329434759914875 \n",
      "Epoch [80/5000] , Step [380/488] , Loss: 0.0318312868475914 \n",
      "Epoch [80/5000] , Step [390/488] , Loss: 0.0324662737548351 \n",
      "Epoch [80/5000] , Step [400/488] , Loss: 0.0322541594505310 \n",
      "Epoch [80/5000] , Step [410/488] , Loss: 0.0323709845542908 \n",
      "Epoch [80/5000] , Step [420/488] , Loss: 0.0323597788810730 \n",
      "Epoch [80/5000] , Step [430/488] , Loss: 0.0328732356429100 \n",
      "Epoch [80/5000] , Step [440/488] , Loss: 0.0325903259217739 \n",
      "Epoch [80/5000] , Step [450/488] , Loss: 0.0323258936405182 \n",
      "Epoch [80/5000] , Step [460/488] , Loss: 0.0328936763107777 \n",
      "Epoch [80/5000] , Step [470/488] , Loss: 0.0331112183630466 \n",
      "Epoch [80/5000] , Step [480/488] , Loss: 0.0324604324996471 \n",
      "Epoch [81/5000] , Step [10/488] , Loss: 0.0326922833919525 \n",
      "Epoch [81/5000] , Step [20/488] , Loss: 0.0325481332838535 \n",
      "Epoch [81/5000] , Step [30/488] , Loss: 0.0321964919567108 \n",
      "Epoch [81/5000] , Step [40/488] , Loss: 0.0326747782528400 \n",
      "Epoch [81/5000] , Step [50/488] , Loss: 0.0329668931663036 \n",
      "Epoch [81/5000] , Step [60/488] , Loss: 0.0325373671948910 \n",
      "Epoch [81/5000] , Step [70/488] , Loss: 0.0336766242980957 \n",
      "Epoch [81/5000] , Step [80/488] , Loss: 0.0322790816426277 \n",
      "Epoch [81/5000] , Step [90/488] , Loss: 0.0325272530317307 \n",
      "Epoch [81/5000] , Step [100/488] , Loss: 0.0328639857470989 \n",
      "Epoch [81/5000] , Step [110/488] , Loss: 0.0326791778206825 \n",
      "Epoch [81/5000] , Step [120/488] , Loss: 0.0323522537946701 \n",
      "Epoch [81/5000] , Step [130/488] , Loss: 0.0328057035803795 \n",
      "Epoch [81/5000] , Step [140/488] , Loss: 0.0322627946734428 \n",
      "Epoch [81/5000] , Step [150/488] , Loss: 0.0325192920863628 \n",
      "Epoch [81/5000] , Step [160/488] , Loss: 0.0325747653841972 \n",
      "Epoch [81/5000] , Step [170/488] , Loss: 0.0326576344668865 \n",
      "Epoch [81/5000] , Step [180/488] , Loss: 0.0326131395995617 \n",
      "Epoch [81/5000] , Step [190/488] , Loss: 0.0328915268182755 \n",
      "Epoch [81/5000] , Step [200/488] , Loss: 0.0328728444874287 \n",
      "Epoch [81/5000] , Step [210/488] , Loss: 0.0323950238525867 \n",
      "Epoch [81/5000] , Step [220/488] , Loss: 0.0326346382498741 \n",
      "Epoch [81/5000] , Step [230/488] , Loss: 0.0328246802091599 \n",
      "Epoch [81/5000] , Step [240/488] , Loss: 0.0329504832625389 \n",
      "Epoch [81/5000] , Step [250/488] , Loss: 0.0330754853785038 \n",
      "Epoch [81/5000] , Step [260/488] , Loss: 0.0322991833090782 \n",
      "Epoch [81/5000] , Step [270/488] , Loss: 0.0319282151758671 \n",
      "Epoch [81/5000] , Step [280/488] , Loss: 0.0329683907330036 \n",
      "Epoch [81/5000] , Step [290/488] , Loss: 0.0328243970870972 \n",
      "Epoch [81/5000] , Step [300/488] , Loss: 0.0328833833336830 \n",
      "Epoch [81/5000] , Step [310/488] , Loss: 0.0322274975478649 \n",
      "Epoch [81/5000] , Step [320/488] , Loss: 0.0327944718301296 \n",
      "Epoch [81/5000] , Step [330/488] , Loss: 0.0328176878392696 \n",
      "Epoch [81/5000] , Step [340/488] , Loss: 0.0328827500343323 \n",
      "Epoch [81/5000] , Step [350/488] , Loss: 0.0331847593188286 \n",
      "Epoch [81/5000] , Step [360/488] , Loss: 0.0323527716100216 \n",
      "Epoch [81/5000] , Step [370/488] , Loss: 0.0325328521430492 \n",
      "Epoch [81/5000] , Step [380/488] , Loss: 0.0320351980626583 \n",
      "Epoch [81/5000] , Step [390/488] , Loss: 0.0321881100535393 \n",
      "Epoch [81/5000] , Step [400/488] , Loss: 0.0323600210249424 \n",
      "Epoch [81/5000] , Step [410/488] , Loss: 0.0329765193164349 \n",
      "Epoch [81/5000] , Step [420/488] , Loss: 0.0320477373898029 \n",
      "Epoch [81/5000] , Step [430/488] , Loss: 0.0329561606049538 \n",
      "Epoch [81/5000] , Step [440/488] , Loss: 0.0324330553412437 \n",
      "Epoch [81/5000] , Step [450/488] , Loss: 0.0323591046035290 \n",
      "Epoch [81/5000] , Step [460/488] , Loss: 0.0331867709755898 \n",
      "Epoch [81/5000] , Step [470/488] , Loss: 0.0324814096093178 \n",
      "Epoch [81/5000] , Step [480/488] , Loss: 0.0324911549687386 \n",
      "Epoch [82/5000] , Step [10/488] , Loss: 0.0329228602349758 \n",
      "Epoch [82/5000] , Step [20/488] , Loss: 0.0318966247141361 \n",
      "Epoch [82/5000] , Step [30/488] , Loss: 0.0319231897592545 \n",
      "Epoch [82/5000] , Step [40/488] , Loss: 0.0327486246824265 \n",
      "Epoch [82/5000] , Step [50/488] , Loss: 0.0322007946670055 \n",
      "Epoch [82/5000] , Step [60/488] , Loss: 0.0327716469764709 \n",
      "Epoch [82/5000] , Step [70/488] , Loss: 0.0329523421823978 \n",
      "Epoch [82/5000] , Step [80/488] , Loss: 0.0328924469649792 \n",
      "Epoch [82/5000] , Step [90/488] , Loss: 0.0323040075600147 \n",
      "Epoch [82/5000] , Step [100/488] , Loss: 0.0321540236473083 \n",
      "Epoch [82/5000] , Step [110/488] , Loss: 0.0323310680687428 \n",
      "Epoch [82/5000] , Step [120/488] , Loss: 0.0325254052877426 \n",
      "Epoch [82/5000] , Step [130/488] , Loss: 0.0333620011806488 \n",
      "Epoch [82/5000] , Step [140/488] , Loss: 0.0327748879790306 \n",
      "Epoch [82/5000] , Step [150/488] , Loss: 0.0325380116701126 \n",
      "Epoch [82/5000] , Step [160/488] , Loss: 0.0323317050933838 \n",
      "Epoch [82/5000] , Step [170/488] , Loss: 0.0326816365122795 \n",
      "Epoch [82/5000] , Step [180/488] , Loss: 0.0323989354074001 \n",
      "Epoch [82/5000] , Step [190/488] , Loss: 0.0326655134558678 \n",
      "Epoch [82/5000] , Step [200/488] , Loss: 0.0328106842935085 \n",
      "Epoch [82/5000] , Step [210/488] , Loss: 0.0322093740105629 \n",
      "Epoch [82/5000] , Step [220/488] , Loss: 0.0331156626343727 \n",
      "Epoch [82/5000] , Step [230/488] , Loss: 0.0323706045746803 \n",
      "Epoch [82/5000] , Step [240/488] , Loss: 0.0318541042506695 \n",
      "Epoch [82/5000] , Step [250/488] , Loss: 0.0323792099952698 \n",
      "Epoch [82/5000] , Step [260/488] , Loss: 0.0321996025741100 \n",
      "Epoch [82/5000] , Step [270/488] , Loss: 0.0326815769076347 \n",
      "Epoch [82/5000] , Step [280/488] , Loss: 0.0323017947375774 \n",
      "Epoch [82/5000] , Step [290/488] , Loss: 0.0324794389307499 \n",
      "Epoch [82/5000] , Step [300/488] , Loss: 0.0328385382890701 \n",
      "Epoch [82/5000] , Step [310/488] , Loss: 0.0330948680639267 \n",
      "Epoch [82/5000] , Step [320/488] , Loss: 0.0323839038610458 \n",
      "Epoch [82/5000] , Step [330/488] , Loss: 0.0330131724476814 \n",
      "Epoch [82/5000] , Step [340/488] , Loss: 0.0328446738421917 \n",
      "Epoch [82/5000] , Step [350/488] , Loss: 0.0329681858420372 \n",
      "Epoch [82/5000] , Step [360/488] , Loss: 0.0322960093617439 \n",
      "Epoch [82/5000] , Step [370/488] , Loss: 0.0329631492495537 \n",
      "Epoch [82/5000] , Step [380/488] , Loss: 0.0321923159062862 \n",
      "Epoch [82/5000] , Step [390/488] , Loss: 0.0323236100375652 \n",
      "Epoch [82/5000] , Step [400/488] , Loss: 0.0323165357112885 \n",
      "Epoch [82/5000] , Step [410/488] , Loss: 0.0327806286513805 \n",
      "Epoch [82/5000] , Step [420/488] , Loss: 0.0329362824559212 \n",
      "Epoch [82/5000] , Step [430/488] , Loss: 0.0325962156057358 \n",
      "Epoch [82/5000] , Step [440/488] , Loss: 0.0329160727560520 \n",
      "Epoch [82/5000] , Step [450/488] , Loss: 0.0326205790042877 \n",
      "Epoch [82/5000] , Step [460/488] , Loss: 0.0328382626175880 \n",
      "Epoch [82/5000] , Step [470/488] , Loss: 0.0326651781797409 \n",
      "Epoch [82/5000] , Step [480/488] , Loss: 0.0325025245547295 \n",
      "Epoch [83/5000] , Step [10/488] , Loss: 0.0318947024643421 \n",
      "Epoch [83/5000] , Step [20/488] , Loss: 0.0326312258839607 \n",
      "Epoch [83/5000] , Step [30/488] , Loss: 0.0327854827046394 \n",
      "Epoch [83/5000] , Step [40/488] , Loss: 0.0324848219752312 \n",
      "Epoch [83/5000] , Step [50/488] , Loss: 0.0321934036910534 \n",
      "Epoch [83/5000] , Step [60/488] , Loss: 0.0326241143047810 \n",
      "Epoch [83/5000] , Step [70/488] , Loss: 0.0319737754762173 \n",
      "Epoch [83/5000] , Step [80/488] , Loss: 0.0324080064892769 \n",
      "Epoch [83/5000] , Step [90/488] , Loss: 0.0322497524321079 \n",
      "Epoch [83/5000] , Step [100/488] , Loss: 0.0327423438429832 \n",
      "Epoch [83/5000] , Step [110/488] , Loss: 0.0325091704726219 \n",
      "Epoch [83/5000] , Step [120/488] , Loss: 0.0323404930531979 \n",
      "Epoch [83/5000] , Step [130/488] , Loss: 0.0323402620851994 \n",
      "Epoch [83/5000] , Step [140/488] , Loss: 0.0322531536221504 \n",
      "Epoch [83/5000] , Step [150/488] , Loss: 0.0320964828133583 \n",
      "Epoch [83/5000] , Step [160/488] , Loss: 0.0321539677679539 \n",
      "Epoch [83/5000] , Step [170/488] , Loss: 0.0330871529877186 \n",
      "Epoch [83/5000] , Step [180/488] , Loss: 0.0325464755296707 \n",
      "Epoch [83/5000] , Step [190/488] , Loss: 0.0328225009143353 \n",
      "Epoch [83/5000] , Step [200/488] , Loss: 0.0325546637177467 \n",
      "Epoch [83/5000] , Step [210/488] , Loss: 0.0325216539204121 \n",
      "Epoch [83/5000] , Step [220/488] , Loss: 0.0322326570749283 \n",
      "Epoch [83/5000] , Step [230/488] , Loss: 0.0326191522181034 \n",
      "Epoch [83/5000] , Step [240/488] , Loss: 0.0326737947762012 \n",
      "Epoch [83/5000] , Step [250/488] , Loss: 0.0319305472075939 \n",
      "Epoch [83/5000] , Step [260/488] , Loss: 0.0325233936309814 \n",
      "Epoch [83/5000] , Step [270/488] , Loss: 0.0325449444353580 \n",
      "Epoch [83/5000] , Step [280/488] , Loss: 0.0328139737248421 \n",
      "Epoch [83/5000] , Step [290/488] , Loss: 0.0324463210999966 \n",
      "Epoch [83/5000] , Step [300/488] , Loss: 0.0324313603341579 \n",
      "Epoch [83/5000] , Step [310/488] , Loss: 0.0321200862526894 \n",
      "Epoch [83/5000] , Step [320/488] , Loss: 0.0335064455866814 \n",
      "Epoch [83/5000] , Step [330/488] , Loss: 0.0329582057893276 \n",
      "Epoch [83/5000] , Step [340/488] , Loss: 0.0327761545777321 \n",
      "Epoch [83/5000] , Step [350/488] , Loss: 0.0326624512672424 \n",
      "Epoch [83/5000] , Step [360/488] , Loss: 0.0323903448879719 \n",
      "Epoch [83/5000] , Step [370/488] , Loss: 0.0323283076286316 \n",
      "Epoch [83/5000] , Step [380/488] , Loss: 0.0327040255069733 \n",
      "Epoch [83/5000] , Step [390/488] , Loss: 0.0328326746821404 \n",
      "Epoch [83/5000] , Step [400/488] , Loss: 0.0318856127560139 \n",
      "Epoch [83/5000] , Step [410/488] , Loss: 0.0322577320039272 \n",
      "Epoch [83/5000] , Step [420/488] , Loss: 0.0325765721499920 \n",
      "Epoch [83/5000] , Step [430/488] , Loss: 0.0322964526712894 \n",
      "Epoch [83/5000] , Step [440/488] , Loss: 0.0324244424700737 \n",
      "Epoch [83/5000] , Step [450/488] , Loss: 0.0330518297851086 \n",
      "Epoch [83/5000] , Step [460/488] , Loss: 0.0327188596129417 \n",
      "Epoch [83/5000] , Step [470/488] , Loss: 0.0330911800265312 \n",
      "Epoch [83/5000] , Step [480/488] , Loss: 0.0328691042959690 \n",
      "Epoch [84/5000] , Step [10/488] , Loss: 0.0324713066220284 \n",
      "Epoch [84/5000] , Step [20/488] , Loss: 0.0325841940939426 \n",
      "Epoch [84/5000] , Step [30/488] , Loss: 0.0329831130802631 \n",
      "Epoch [84/5000] , Step [40/488] , Loss: 0.0319413766264915 \n",
      "Epoch [84/5000] , Step [50/488] , Loss: 0.0325200855731964 \n",
      "Epoch [84/5000] , Step [60/488] , Loss: 0.0321323350071907 \n",
      "Epoch [84/5000] , Step [70/488] , Loss: 0.0321630425751209 \n",
      "Epoch [84/5000] , Step [80/488] , Loss: 0.0330064371228218 \n",
      "Epoch [84/5000] , Step [90/488] , Loss: 0.0325152948498726 \n",
      "Epoch [84/5000] , Step [100/488] , Loss: 0.0313301682472229 \n",
      "Epoch [84/5000] , Step [110/488] , Loss: 0.0330057218670845 \n",
      "Epoch [84/5000] , Step [120/488] , Loss: 0.0326086580753326 \n",
      "Epoch [84/5000] , Step [130/488] , Loss: 0.0325582511723042 \n",
      "Epoch [84/5000] , Step [140/488] , Loss: 0.0325067192316055 \n",
      "Epoch [84/5000] , Step [150/488] , Loss: 0.0319089703261852 \n",
      "Epoch [84/5000] , Step [160/488] , Loss: 0.0328611657023430 \n",
      "Epoch [84/5000] , Step [170/488] , Loss: 0.0323643833398819 \n",
      "Epoch [84/5000] , Step [180/488] , Loss: 0.0322877801954746 \n",
      "Epoch [84/5000] , Step [190/488] , Loss: 0.0322466008365154 \n",
      "Epoch [84/5000] , Step [200/488] , Loss: 0.0326730124652386 \n",
      "Epoch [84/5000] , Step [210/488] , Loss: 0.0323333255946636 \n",
      "Epoch [84/5000] , Step [220/488] , Loss: 0.0326363481581211 \n",
      "Epoch [84/5000] , Step [230/488] , Loss: 0.0327061563730240 \n",
      "Epoch [84/5000] , Step [240/488] , Loss: 0.0324194133281708 \n",
      "Epoch [84/5000] , Step [250/488] , Loss: 0.0323941707611084 \n",
      "Epoch [84/5000] , Step [260/488] , Loss: 0.0329233929514885 \n",
      "Epoch [84/5000] , Step [270/488] , Loss: 0.0327232293784618 \n",
      "Epoch [84/5000] , Step [280/488] , Loss: 0.0325815118849277 \n",
      "Epoch [84/5000] , Step [290/488] , Loss: 0.0326348245143890 \n",
      "Epoch [84/5000] , Step [300/488] , Loss: 0.0325934775173664 \n",
      "Epoch [84/5000] , Step [310/488] , Loss: 0.0319746397435665 \n",
      "Epoch [84/5000] , Step [320/488] , Loss: 0.0325250960886478 \n",
      "Epoch [84/5000] , Step [330/488] , Loss: 0.0317862108349800 \n",
      "Epoch [84/5000] , Step [340/488] , Loss: 0.0331059917807579 \n",
      "Epoch [84/5000] , Step [350/488] , Loss: 0.0320676788687706 \n",
      "Epoch [84/5000] , Step [360/488] , Loss: 0.0323077477514744 \n",
      "Epoch [84/5000] , Step [370/488] , Loss: 0.0322925001382828 \n",
      "Epoch [84/5000] , Step [380/488] , Loss: 0.0322689674794674 \n",
      "Epoch [84/5000] , Step [390/488] , Loss: 0.0331927835941315 \n",
      "Epoch [84/5000] , Step [400/488] , Loss: 0.0326051302254200 \n",
      "Epoch [84/5000] , Step [410/488] , Loss: 0.0328460000455379 \n",
      "Epoch [84/5000] , Step [420/488] , Loss: 0.0328154228627682 \n",
      "Epoch [84/5000] , Step [430/488] , Loss: 0.0325363874435425 \n",
      "Epoch [84/5000] , Step [440/488] , Loss: 0.0332554057240486 \n",
      "Epoch [84/5000] , Step [450/488] , Loss: 0.0333437919616699 \n",
      "Epoch [84/5000] , Step [460/488] , Loss: 0.0330848023295403 \n",
      "Epoch [84/5000] , Step [470/488] , Loss: 0.0324640236794949 \n",
      "Epoch [84/5000] , Step [480/488] , Loss: 0.0321751646697521 \n",
      "Epoch [85/5000] , Step [10/488] , Loss: 0.0323443487286568 \n",
      "Epoch [85/5000] , Step [20/488] , Loss: 0.0322102233767509 \n",
      "Epoch [85/5000] , Step [30/488] , Loss: 0.0325292721390724 \n",
      "Epoch [85/5000] , Step [40/488] , Loss: 0.0322344042360783 \n",
      "Epoch [85/5000] , Step [50/488] , Loss: 0.0321869142353535 \n",
      "Epoch [85/5000] , Step [60/488] , Loss: 0.0323319993913174 \n",
      "Epoch [85/5000] , Step [70/488] , Loss: 0.0321801602840424 \n",
      "Epoch [85/5000] , Step [80/488] , Loss: 0.0327445976436138 \n",
      "Epoch [85/5000] , Step [90/488] , Loss: 0.0325879603624344 \n",
      "Epoch [85/5000] , Step [100/488] , Loss: 0.0324681363999844 \n",
      "Epoch [85/5000] , Step [110/488] , Loss: 0.0324339456856251 \n",
      "Epoch [85/5000] , Step [120/488] , Loss: 0.0324406102299690 \n",
      "Epoch [85/5000] , Step [130/488] , Loss: 0.0327972136437893 \n",
      "Epoch [85/5000] , Step [140/488] , Loss: 0.0321097560226917 \n",
      "Epoch [85/5000] , Step [150/488] , Loss: 0.0325922258198261 \n",
      "Epoch [85/5000] , Step [160/488] , Loss: 0.0324441380798817 \n",
      "Epoch [85/5000] , Step [170/488] , Loss: 0.0323934443295002 \n",
      "Epoch [85/5000] , Step [180/488] , Loss: 0.0326516069471836 \n",
      "Epoch [85/5000] , Step [190/488] , Loss: 0.0327091887593269 \n",
      "Epoch [85/5000] , Step [200/488] , Loss: 0.0331967063248158 \n",
      "Epoch [85/5000] , Step [210/488] , Loss: 0.0324580557644367 \n",
      "Epoch [85/5000] , Step [220/488] , Loss: 0.0326243191957474 \n",
      "Epoch [85/5000] , Step [230/488] , Loss: 0.0328643992543221 \n",
      "Epoch [85/5000] , Step [240/488] , Loss: 0.0321751795709133 \n",
      "Epoch [85/5000] , Step [250/488] , Loss: 0.0320599786937237 \n",
      "Epoch [85/5000] , Step [260/488] , Loss: 0.0321202240884304 \n",
      "Epoch [85/5000] , Step [270/488] , Loss: 0.0323096215724945 \n",
      "Epoch [85/5000] , Step [280/488] , Loss: 0.0327095873653889 \n",
      "Epoch [85/5000] , Step [290/488] , Loss: 0.0326139293611050 \n",
      "Epoch [85/5000] , Step [300/488] , Loss: 0.0330594852566719 \n",
      "Epoch [85/5000] , Step [310/488] , Loss: 0.0327630862593651 \n",
      "Epoch [85/5000] , Step [320/488] , Loss: 0.0328262485563755 \n",
      "Epoch [85/5000] , Step [330/488] , Loss: 0.0327705033123493 \n",
      "Epoch [85/5000] , Step [340/488] , Loss: 0.0322887971997261 \n",
      "Epoch [85/5000] , Step [350/488] , Loss: 0.0317640826106071 \n",
      "Epoch [85/5000] , Step [360/488] , Loss: 0.0325227715075016 \n",
      "Epoch [85/5000] , Step [370/488] , Loss: 0.0328720510005951 \n",
      "Epoch [85/5000] , Step [380/488] , Loss: 0.0326064601540565 \n",
      "Epoch [85/5000] , Step [390/488] , Loss: 0.0327866151928902 \n",
      "Epoch [85/5000] , Step [400/488] , Loss: 0.0325105562806129 \n",
      "Epoch [85/5000] , Step [410/488] , Loss: 0.0331857614219189 \n",
      "Epoch [85/5000] , Step [420/488] , Loss: 0.0324341878294945 \n",
      "Epoch [85/5000] , Step [430/488] , Loss: 0.0327136069536209 \n",
      "Epoch [85/5000] , Step [440/488] , Loss: 0.0328016355633736 \n",
      "Epoch [85/5000] , Step [450/488] , Loss: 0.0324606932699680 \n",
      "Epoch [85/5000] , Step [460/488] , Loss: 0.0331075675785542 \n",
      "Epoch [85/5000] , Step [470/488] , Loss: 0.0330061279237270 \n",
      "Epoch [85/5000] , Step [480/488] , Loss: 0.0320755913853645 \n",
      "Epoch [86/5000] , Step [10/488] , Loss: 0.0316555798053741 \n",
      "Epoch [86/5000] , Step [20/488] , Loss: 0.0327581614255905 \n",
      "Epoch [86/5000] , Step [30/488] , Loss: 0.0331878289580345 \n",
      "Epoch [86/5000] , Step [40/488] , Loss: 0.0323967412114143 \n",
      "Epoch [86/5000] , Step [50/488] , Loss: 0.0323682650923729 \n",
      "Epoch [86/5000] , Step [60/488] , Loss: 0.0321451053023338 \n",
      "Epoch [86/5000] , Step [70/488] , Loss: 0.0327432081103325 \n",
      "Epoch [86/5000] , Step [80/488] , Loss: 0.0326001308858395 \n",
      "Epoch [86/5000] , Step [90/488] , Loss: 0.0325062088668346 \n",
      "Epoch [86/5000] , Step [100/488] , Loss: 0.0324477702379227 \n",
      "Epoch [86/5000] , Step [110/488] , Loss: 0.0326405316591263 \n",
      "Epoch [86/5000] , Step [120/488] , Loss: 0.0319829583168030 \n",
      "Epoch [86/5000] , Step [130/488] , Loss: 0.0328690707683563 \n",
      "Epoch [86/5000] , Step [140/488] , Loss: 0.0328172035515308 \n",
      "Epoch [86/5000] , Step [150/488] , Loss: 0.0324638672173023 \n",
      "Epoch [86/5000] , Step [160/488] , Loss: 0.0326245799660683 \n",
      "Epoch [86/5000] , Step [170/488] , Loss: 0.0328074656426907 \n",
      "Epoch [86/5000] , Step [180/488] , Loss: 0.0325002856552601 \n",
      "Epoch [86/5000] , Step [190/488] , Loss: 0.0327340960502625 \n",
      "Epoch [86/5000] , Step [200/488] , Loss: 0.0322279781103134 \n",
      "Epoch [86/5000] , Step [210/488] , Loss: 0.0323817357420921 \n",
      "Epoch [86/5000] , Step [220/488] , Loss: 0.0324519947171211 \n",
      "Epoch [86/5000] , Step [230/488] , Loss: 0.0321746021509171 \n",
      "Epoch [86/5000] , Step [240/488] , Loss: 0.0325618796050549 \n",
      "Epoch [86/5000] , Step [250/488] , Loss: 0.0330386385321617 \n",
      "Epoch [86/5000] , Step [260/488] , Loss: 0.0326162949204445 \n",
      "Epoch [86/5000] , Step [270/488] , Loss: 0.0321653634309769 \n",
      "Epoch [86/5000] , Step [280/488] , Loss: 0.0325253941118717 \n",
      "Epoch [86/5000] , Step [290/488] , Loss: 0.0325696095824242 \n",
      "Epoch [86/5000] , Step [300/488] , Loss: 0.0322073362767696 \n",
      "Epoch [86/5000] , Step [310/488] , Loss: 0.0329118333756924 \n",
      "Epoch [86/5000] , Step [320/488] , Loss: 0.0324353463947773 \n",
      "Epoch [86/5000] , Step [330/488] , Loss: 0.0324434861540794 \n",
      "Epoch [86/5000] , Step [340/488] , Loss: 0.0324289388954639 \n",
      "Epoch [86/5000] , Step [350/488] , Loss: 0.0325062163174152 \n",
      "Epoch [86/5000] , Step [360/488] , Loss: 0.0330232195556164 \n",
      "Epoch [86/5000] , Step [370/488] , Loss: 0.0315377824008465 \n",
      "Epoch [86/5000] , Step [380/488] , Loss: 0.0318868979811668 \n",
      "Epoch [86/5000] , Step [390/488] , Loss: 0.0321331135928631 \n",
      "Epoch [86/5000] , Step [400/488] , Loss: 0.0325041189789772 \n",
      "Epoch [86/5000] , Step [410/488] , Loss: 0.0318376198410988 \n",
      "Epoch [86/5000] , Step [420/488] , Loss: 0.0329436622560024 \n",
      "Epoch [86/5000] , Step [430/488] , Loss: 0.0327670983970165 \n",
      "Epoch [86/5000] , Step [440/488] , Loss: 0.0329753085970879 \n",
      "Epoch [86/5000] , Step [450/488] , Loss: 0.0325406864285469 \n",
      "Epoch [86/5000] , Step [460/488] , Loss: 0.0325189940631390 \n",
      "Epoch [86/5000] , Step [470/488] , Loss: 0.0324814096093178 \n",
      "Epoch [86/5000] , Step [480/488] , Loss: 0.0320700779557228 \n",
      "Epoch [87/5000] , Step [10/488] , Loss: 0.0321911424398422 \n",
      "Epoch [87/5000] , Step [20/488] , Loss: 0.0324656590819359 \n",
      "Epoch [87/5000] , Step [30/488] , Loss: 0.0326898247003555 \n",
      "Epoch [87/5000] , Step [40/488] , Loss: 0.0321610681712627 \n",
      "Epoch [87/5000] , Step [50/488] , Loss: 0.0326359570026398 \n",
      "Epoch [87/5000] , Step [60/488] , Loss: 0.0322845391929150 \n",
      "Epoch [87/5000] , Step [70/488] , Loss: 0.0331251956522465 \n",
      "Epoch [87/5000] , Step [80/488] , Loss: 0.0324406698346138 \n",
      "Epoch [87/5000] , Step [90/488] , Loss: 0.0323884300887585 \n",
      "Epoch [87/5000] , Step [100/488] , Loss: 0.0321139767765999 \n",
      "Epoch [87/5000] , Step [110/488] , Loss: 0.0326637737452984 \n",
      "Epoch [87/5000] , Step [120/488] , Loss: 0.0325159505009651 \n",
      "Epoch [87/5000] , Step [130/488] , Loss: 0.0328884944319725 \n",
      "Epoch [87/5000] , Step [140/488] , Loss: 0.0326910801231861 \n",
      "Epoch [87/5000] , Step [150/488] , Loss: 0.0325557552278042 \n",
      "Epoch [87/5000] , Step [160/488] , Loss: 0.0331502109766006 \n",
      "Epoch [87/5000] , Step [170/488] , Loss: 0.0334360152482986 \n",
      "Epoch [87/5000] , Step [180/488] , Loss: 0.0322147309780121 \n",
      "Epoch [87/5000] , Step [190/488] , Loss: 0.0322132706642151 \n",
      "Epoch [87/5000] , Step [200/488] , Loss: 0.0324525162577629 \n",
      "Epoch [87/5000] , Step [210/488] , Loss: 0.0329360477626324 \n",
      "Epoch [87/5000] , Step [220/488] , Loss: 0.0333490706980228 \n",
      "Epoch [87/5000] , Step [230/488] , Loss: 0.0329990610480309 \n",
      "Epoch [87/5000] , Step [240/488] , Loss: 0.0327092409133911 \n",
      "Epoch [87/5000] , Step [250/488] , Loss: 0.0325818359851837 \n",
      "Epoch [87/5000] , Step [260/488] , Loss: 0.0324518457055092 \n",
      "Epoch [87/5000] , Step [270/488] , Loss: 0.0319691151380539 \n",
      "Epoch [87/5000] , Step [280/488] , Loss: 0.0323150567710400 \n",
      "Epoch [87/5000] , Step [290/488] , Loss: 0.0331834293901920 \n",
      "Epoch [87/5000] , Step [300/488] , Loss: 0.0325942002236843 \n",
      "Epoch [87/5000] , Step [310/488] , Loss: 0.0326718986034393 \n",
      "Epoch [87/5000] , Step [320/488] , Loss: 0.0325448922812939 \n",
      "Epoch [87/5000] , Step [330/488] , Loss: 0.0324293747544289 \n",
      "Epoch [87/5000] , Step [340/488] , Loss: 0.0328122042119503 \n",
      "Epoch [87/5000] , Step [350/488] , Loss: 0.0331192128360271 \n",
      "Epoch [87/5000] , Step [360/488] , Loss: 0.0323586389422417 \n",
      "Epoch [87/5000] , Step [370/488] , Loss: 0.0330132171511650 \n",
      "Epoch [87/5000] , Step [380/488] , Loss: 0.0321396663784981 \n",
      "Epoch [87/5000] , Step [390/488] , Loss: 0.0322538875043392 \n",
      "Epoch [87/5000] , Step [400/488] , Loss: 0.0328136347234249 \n",
      "Epoch [87/5000] , Step [410/488] , Loss: 0.0327964872121811 \n",
      "Epoch [87/5000] , Step [420/488] , Loss: 0.0323051661252975 \n",
      "Epoch [87/5000] , Step [430/488] , Loss: 0.0322125367820263 \n",
      "Epoch [87/5000] , Step [440/488] , Loss: 0.0321432948112488 \n",
      "Epoch [87/5000] , Step [450/488] , Loss: 0.0324548557400703 \n",
      "Epoch [87/5000] , Step [460/488] , Loss: 0.0327928476035595 \n",
      "Epoch [87/5000] , Step [470/488] , Loss: 0.0326793529093266 \n",
      "Epoch [87/5000] , Step [480/488] , Loss: 0.0330198481678963 \n",
      "Epoch [88/5000] , Step [10/488] , Loss: 0.0319599509239197 \n",
      "Epoch [88/5000] , Step [20/488] , Loss: 0.0325703397393227 \n",
      "Epoch [88/5000] , Step [30/488] , Loss: 0.0324008576571941 \n",
      "Epoch [88/5000] , Step [40/488] , Loss: 0.0329646021127701 \n",
      "Epoch [88/5000] , Step [50/488] , Loss: 0.0324292927980423 \n",
      "Epoch [88/5000] , Step [60/488] , Loss: 0.0319623164832592 \n",
      "Epoch [88/5000] , Step [70/488] , Loss: 0.0326370149850845 \n",
      "Epoch [88/5000] , Step [80/488] , Loss: 0.0323363579809666 \n",
      "Epoch [88/5000] , Step [90/488] , Loss: 0.0326068215072155 \n",
      "Epoch [88/5000] , Step [100/488] , Loss: 0.0327119380235672 \n",
      "Epoch [88/5000] , Step [110/488] , Loss: 0.0320944078266621 \n",
      "Epoch [88/5000] , Step [120/488] , Loss: 0.0332499071955681 \n",
      "Epoch [88/5000] , Step [130/488] , Loss: 0.0320145972073078 \n",
      "Epoch [88/5000] , Step [140/488] , Loss: 0.0324537679553032 \n",
      "Epoch [88/5000] , Step [150/488] , Loss: 0.0331199355423450 \n",
      "Epoch [88/5000] , Step [160/488] , Loss: 0.0326283089816570 \n",
      "Epoch [88/5000] , Step [170/488] , Loss: 0.0327124372124672 \n",
      "Epoch [88/5000] , Step [180/488] , Loss: 0.0330119095742702 \n",
      "Epoch [88/5000] , Step [190/488] , Loss: 0.0323284529149532 \n",
      "Epoch [88/5000] , Step [200/488] , Loss: 0.0325905010104179 \n",
      "Epoch [88/5000] , Step [210/488] , Loss: 0.0329038612544537 \n",
      "Epoch [88/5000] , Step [220/488] , Loss: 0.0321544185280800 \n",
      "Epoch [88/5000] , Step [230/488] , Loss: 0.0331980995833874 \n",
      "Epoch [88/5000] , Step [240/488] , Loss: 0.0332825519144535 \n",
      "Epoch [88/5000] , Step [250/488] , Loss: 0.0325952693820000 \n",
      "Epoch [88/5000] , Step [260/488] , Loss: 0.0325560718774796 \n",
      "Epoch [88/5000] , Step [270/488] , Loss: 0.0318038873374462 \n",
      "Epoch [88/5000] , Step [280/488] , Loss: 0.0326428450644016 \n",
      "Epoch [88/5000] , Step [290/488] , Loss: 0.0329861715435982 \n",
      "Epoch [88/5000] , Step [300/488] , Loss: 0.0324058420956135 \n",
      "Epoch [88/5000] , Step [310/488] , Loss: 0.0328553803265095 \n",
      "Epoch [88/5000] , Step [320/488] , Loss: 0.0319368466734886 \n",
      "Epoch [88/5000] , Step [330/488] , Loss: 0.0333164595067501 \n",
      "Epoch [88/5000] , Step [340/488] , Loss: 0.0323894321918488 \n",
      "Epoch [88/5000] , Step [350/488] , Loss: 0.0322469361126423 \n",
      "Epoch [88/5000] , Step [360/488] , Loss: 0.0329569503664970 \n",
      "Epoch [88/5000] , Step [370/488] , Loss: 0.0327778272330761 \n",
      "Epoch [88/5000] , Step [380/488] , Loss: 0.0326489657163620 \n",
      "Epoch [88/5000] , Step [390/488] , Loss: 0.0328957065939903 \n",
      "Epoch [88/5000] , Step [400/488] , Loss: 0.0321341119706631 \n",
      "Epoch [88/5000] , Step [410/488] , Loss: 0.0330357886850834 \n",
      "Epoch [88/5000] , Step [420/488] , Loss: 0.0323937535285950 \n",
      "Epoch [88/5000] , Step [430/488] , Loss: 0.0320310257375240 \n",
      "Epoch [88/5000] , Step [440/488] , Loss: 0.0324356518685818 \n",
      "Epoch [88/5000] , Step [450/488] , Loss: 0.0330545417964458 \n",
      "Epoch [88/5000] , Step [460/488] , Loss: 0.0321362428367138 \n",
      "Epoch [88/5000] , Step [470/488] , Loss: 0.0326242782175541 \n",
      "Epoch [88/5000] , Step [480/488] , Loss: 0.0329741090536118 \n",
      "Epoch [89/5000] , Step [10/488] , Loss: 0.0320687070488930 \n",
      "Epoch [89/5000] , Step [20/488] , Loss: 0.0332345105707645 \n",
      "Epoch [89/5000] , Step [30/488] , Loss: 0.0326310694217682 \n",
      "Epoch [89/5000] , Step [40/488] , Loss: 0.0327431522309780 \n",
      "Epoch [89/5000] , Step [50/488] , Loss: 0.0325230956077576 \n",
      "Epoch [89/5000] , Step [60/488] , Loss: 0.0319225527346134 \n",
      "Epoch [89/5000] , Step [70/488] , Loss: 0.0323375612497330 \n",
      "Epoch [89/5000] , Step [80/488] , Loss: 0.0326377637684345 \n",
      "Epoch [89/5000] , Step [90/488] , Loss: 0.0322939343750477 \n",
      "Epoch [89/5000] , Step [100/488] , Loss: 0.0335617996752262 \n",
      "Epoch [89/5000] , Step [110/488] , Loss: 0.0323744341731071 \n",
      "Epoch [89/5000] , Step [120/488] , Loss: 0.0326808989048004 \n",
      "Epoch [89/5000] , Step [130/488] , Loss: 0.0328785404562950 \n",
      "Epoch [89/5000] , Step [140/488] , Loss: 0.0322756879031658 \n",
      "Epoch [89/5000] , Step [150/488] , Loss: 0.0322228446602821 \n",
      "Epoch [89/5000] , Step [160/488] , Loss: 0.0330341309309006 \n",
      "Epoch [89/5000] , Step [170/488] , Loss: 0.0324381329119205 \n",
      "Epoch [89/5000] , Step [180/488] , Loss: 0.0320797264575958 \n",
      "Epoch [89/5000] , Step [190/488] , Loss: 0.0320287048816681 \n",
      "Epoch [89/5000] , Step [200/488] , Loss: 0.0327525846660137 \n",
      "Epoch [89/5000] , Step [210/488] , Loss: 0.0321802645921707 \n",
      "Epoch [89/5000] , Step [220/488] , Loss: 0.0328878201544285 \n",
      "Epoch [89/5000] , Step [230/488] , Loss: 0.0333018973469734 \n",
      "Epoch [89/5000] , Step [240/488] , Loss: 0.0329508967697620 \n",
      "Epoch [89/5000] , Step [250/488] , Loss: 0.0317144505679607 \n",
      "Epoch [89/5000] , Step [260/488] , Loss: 0.0325427874922752 \n",
      "Epoch [89/5000] , Step [270/488] , Loss: 0.0325274877250195 \n",
      "Epoch [89/5000] , Step [280/488] , Loss: 0.0328782983124256 \n",
      "Epoch [89/5000] , Step [290/488] , Loss: 0.0327432081103325 \n",
      "Epoch [89/5000] , Step [300/488] , Loss: 0.0326062738895416 \n",
      "Epoch [89/5000] , Step [310/488] , Loss: 0.0321787409484386 \n",
      "Epoch [89/5000] , Step [320/488] , Loss: 0.0322308279573917 \n",
      "Epoch [89/5000] , Step [330/488] , Loss: 0.0327183678746223 \n",
      "Epoch [89/5000] , Step [340/488] , Loss: 0.0326189361512661 \n",
      "Epoch [89/5000] , Step [350/488] , Loss: 0.0324026159942150 \n",
      "Epoch [89/5000] , Step [360/488] , Loss: 0.0330629236996174 \n",
      "Epoch [89/5000] , Step [370/488] , Loss: 0.0323514975607395 \n",
      "Epoch [89/5000] , Step [380/488] , Loss: 0.0325103960931301 \n",
      "Epoch [89/5000] , Step [390/488] , Loss: 0.0323777124285698 \n",
      "Epoch [89/5000] , Step [400/488] , Loss: 0.0328257866203785 \n",
      "Epoch [89/5000] , Step [410/488] , Loss: 0.0331999659538269 \n",
      "Epoch [89/5000] , Step [420/488] , Loss: 0.0320504382252693 \n",
      "Epoch [89/5000] , Step [430/488] , Loss: 0.0321808122098446 \n",
      "Epoch [89/5000] , Step [440/488] , Loss: 0.0324964635074139 \n",
      "Epoch [89/5000] , Step [450/488] , Loss: 0.0321452021598816 \n",
      "Epoch [89/5000] , Step [460/488] , Loss: 0.0327605009078979 \n",
      "Epoch [89/5000] , Step [470/488] , Loss: 0.0325766913592815 \n",
      "Epoch [89/5000] , Step [480/488] , Loss: 0.0327755697071552 \n",
      "Epoch [90/5000] , Step [10/488] , Loss: 0.0321477986872196 \n",
      "Epoch [90/5000] , Step [20/488] , Loss: 0.0327990874648094 \n",
      "Epoch [90/5000] , Step [30/488] , Loss: 0.0329118259251118 \n",
      "Epoch [90/5000] , Step [40/488] , Loss: 0.0324067249894142 \n",
      "Epoch [90/5000] , Step [50/488] , Loss: 0.0324924886226654 \n",
      "Epoch [90/5000] , Step [60/488] , Loss: 0.0330262891948223 \n",
      "Epoch [90/5000] , Step [70/488] , Loss: 0.0325960405170918 \n",
      "Epoch [90/5000] , Step [80/488] , Loss: 0.0328592844307423 \n",
      "Epoch [90/5000] , Step [90/488] , Loss: 0.0329572074115276 \n",
      "Epoch [90/5000] , Step [100/488] , Loss: 0.0325339771807194 \n",
      "Epoch [90/5000] , Step [110/488] , Loss: 0.0325237140059471 \n",
      "Epoch [90/5000] , Step [120/488] , Loss: 0.0329549834132195 \n",
      "Epoch [90/5000] , Step [130/488] , Loss: 0.0327921733260155 \n",
      "Epoch [90/5000] , Step [140/488] , Loss: 0.0320543870329857 \n",
      "Epoch [90/5000] , Step [150/488] , Loss: 0.0329079963266850 \n",
      "Epoch [90/5000] , Step [160/488] , Loss: 0.0325846672058105 \n",
      "Epoch [90/5000] , Step [170/488] , Loss: 0.0326212309300900 \n",
      "Epoch [90/5000] , Step [180/488] , Loss: 0.0316952764987946 \n",
      "Epoch [90/5000] , Step [190/488] , Loss: 0.0328352227807045 \n",
      "Epoch [90/5000] , Step [200/488] , Loss: 0.0328708924353123 \n",
      "Epoch [90/5000] , Step [210/488] , Loss: 0.0325372517108917 \n",
      "Epoch [90/5000] , Step [220/488] , Loss: 0.0318331718444824 \n",
      "Epoch [90/5000] , Step [230/488] , Loss: 0.0326375924050808 \n",
      "Epoch [90/5000] , Step [240/488] , Loss: 0.0328235700726509 \n",
      "Epoch [90/5000] , Step [250/488] , Loss: 0.0327111817896366 \n",
      "Epoch [90/5000] , Step [260/488] , Loss: 0.0321075841784477 \n",
      "Epoch [90/5000] , Step [270/488] , Loss: 0.0327666141092777 \n",
      "Epoch [90/5000] , Step [280/488] , Loss: 0.0331301242113113 \n",
      "Epoch [90/5000] , Step [290/488] , Loss: 0.0334612280130386 \n",
      "Epoch [90/5000] , Step [300/488] , Loss: 0.0324418283998966 \n",
      "Epoch [90/5000] , Step [310/488] , Loss: 0.0327703915536404 \n",
      "Epoch [90/5000] , Step [320/488] , Loss: 0.0322516560554504 \n",
      "Epoch [90/5000] , Step [330/488] , Loss: 0.0329758822917938 \n",
      "Epoch [90/5000] , Step [340/488] , Loss: 0.0324939452111721 \n",
      "Epoch [90/5000] , Step [350/488] , Loss: 0.0329011864960194 \n",
      "Epoch [90/5000] , Step [360/488] , Loss: 0.0327031351625919 \n",
      "Epoch [90/5000] , Step [370/488] , Loss: 0.0321465097367764 \n",
      "Epoch [90/5000] , Step [380/488] , Loss: 0.0328605622053146 \n",
      "Epoch [90/5000] , Step [390/488] , Loss: 0.0324536412954330 \n",
      "Epoch [90/5000] , Step [400/488] , Loss: 0.0318258926272392 \n",
      "Epoch [90/5000] , Step [410/488] , Loss: 0.0326890610158443 \n",
      "Epoch [90/5000] , Step [420/488] , Loss: 0.0326953865587711 \n",
      "Epoch [90/5000] , Step [430/488] , Loss: 0.0328531153500080 \n",
      "Epoch [90/5000] , Step [440/488] , Loss: 0.0317850299179554 \n",
      "Epoch [90/5000] , Step [450/488] , Loss: 0.0323047451674938 \n",
      "Epoch [90/5000] , Step [460/488] , Loss: 0.0322533659636974 \n",
      "Epoch [90/5000] , Step [470/488] , Loss: 0.0324718952178955 \n",
      "Epoch [90/5000] , Step [480/488] , Loss: 0.0330469794571400 \n",
      "Epoch [91/5000] , Step [10/488] , Loss: 0.0329174511134624 \n",
      "Epoch [91/5000] , Step [20/488] , Loss: 0.0326995365321636 \n",
      "Epoch [91/5000] , Step [30/488] , Loss: 0.0325738377869129 \n",
      "Epoch [91/5000] , Step [40/488] , Loss: 0.0322414748370647 \n",
      "Epoch [91/5000] , Step [50/488] , Loss: 0.0333448760211468 \n",
      "Epoch [91/5000] , Step [60/488] , Loss: 0.0323237255215645 \n",
      "Epoch [91/5000] , Step [70/488] , Loss: 0.0325049124658108 \n",
      "Epoch [91/5000] , Step [80/488] , Loss: 0.0325929746031761 \n",
      "Epoch [91/5000] , Step [90/488] , Loss: 0.0325261093676090 \n",
      "Epoch [91/5000] , Step [100/488] , Loss: 0.0329890139400959 \n",
      "Epoch [91/5000] , Step [110/488] , Loss: 0.0331303700804710 \n",
      "Epoch [91/5000] , Step [120/488] , Loss: 0.0329600386321545 \n",
      "Epoch [91/5000] , Step [130/488] , Loss: 0.0324774682521820 \n",
      "Epoch [91/5000] , Step [140/488] , Loss: 0.0320296771824360 \n",
      "Epoch [91/5000] , Step [150/488] , Loss: 0.0321094840764999 \n",
      "Epoch [91/5000] , Step [160/488] , Loss: 0.0331051759421825 \n",
      "Epoch [91/5000] , Step [170/488] , Loss: 0.0332905165851116 \n",
      "Epoch [91/5000] , Step [180/488] , Loss: 0.0326895564794540 \n",
      "Epoch [91/5000] , Step [190/488] , Loss: 0.0319511704146862 \n",
      "Epoch [91/5000] , Step [200/488] , Loss: 0.0320803672075272 \n",
      "Epoch [91/5000] , Step [210/488] , Loss: 0.0331334210932255 \n",
      "Epoch [91/5000] , Step [220/488] , Loss: 0.0326846390962601 \n",
      "Epoch [91/5000] , Step [230/488] , Loss: 0.0332249328494072 \n",
      "Epoch [91/5000] , Step [240/488] , Loss: 0.0328416228294373 \n",
      "Epoch [91/5000] , Step [250/488] , Loss: 0.0324598103761673 \n",
      "Epoch [91/5000] , Step [260/488] , Loss: 0.0320623032748699 \n",
      "Epoch [91/5000] , Step [270/488] , Loss: 0.0321045629680157 \n",
      "Epoch [91/5000] , Step [280/488] , Loss: 0.0325948372483253 \n",
      "Epoch [91/5000] , Step [290/488] , Loss: 0.0322484113276005 \n",
      "Epoch [91/5000] , Step [300/488] , Loss: 0.0322371535003185 \n",
      "Epoch [91/5000] , Step [310/488] , Loss: 0.0325995199382305 \n",
      "Epoch [91/5000] , Step [320/488] , Loss: 0.0324690602719784 \n",
      "Epoch [91/5000] , Step [330/488] , Loss: 0.0324235185980797 \n",
      "Epoch [91/5000] , Step [340/488] , Loss: 0.0325353592634201 \n",
      "Epoch [91/5000] , Step [350/488] , Loss: 0.0327401347458363 \n",
      "Epoch [91/5000] , Step [360/488] , Loss: 0.0321116596460342 \n",
      "Epoch [91/5000] , Step [370/488] , Loss: 0.0328059606254101 \n",
      "Epoch [91/5000] , Step [380/488] , Loss: 0.0324966497719288 \n",
      "Epoch [91/5000] , Step [390/488] , Loss: 0.0322570390999317 \n",
      "Epoch [91/5000] , Step [400/488] , Loss: 0.0324884541332722 \n",
      "Epoch [91/5000] , Step [410/488] , Loss: 0.0324591360986233 \n",
      "Epoch [91/5000] , Step [420/488] , Loss: 0.0328270979225636 \n",
      "Epoch [91/5000] , Step [430/488] , Loss: 0.0324138328433037 \n",
      "Epoch [91/5000] , Step [440/488] , Loss: 0.0317594520747662 \n",
      "Epoch [91/5000] , Step [450/488] , Loss: 0.0323513746261597 \n",
      "Epoch [91/5000] , Step [460/488] , Loss: 0.0324548855423927 \n",
      "Epoch [91/5000] , Step [470/488] , Loss: 0.0323243848979473 \n",
      "Epoch [91/5000] , Step [480/488] , Loss: 0.0316113866865635 \n",
      "Epoch [92/5000] , Step [10/488] , Loss: 0.0323650836944580 \n",
      "Epoch [92/5000] , Step [20/488] , Loss: 0.0323595553636551 \n",
      "Epoch [92/5000] , Step [30/488] , Loss: 0.0329452864825726 \n",
      "Epoch [92/5000] , Step [40/488] , Loss: 0.0328302942216396 \n",
      "Epoch [92/5000] , Step [50/488] , Loss: 0.0323498286306858 \n",
      "Epoch [92/5000] , Step [60/488] , Loss: 0.0325395129621029 \n",
      "Epoch [92/5000] , Step [70/488] , Loss: 0.0322017855942249 \n",
      "Epoch [92/5000] , Step [80/488] , Loss: 0.0323470942676067 \n",
      "Epoch [92/5000] , Step [90/488] , Loss: 0.0331345535814762 \n",
      "Epoch [92/5000] , Step [100/488] , Loss: 0.0324495024979115 \n",
      "Epoch [92/5000] , Step [110/488] , Loss: 0.0327930673956871 \n",
      "Epoch [92/5000] , Step [120/488] , Loss: 0.0327928476035595 \n",
      "Epoch [92/5000] , Step [130/488] , Loss: 0.0330736525356770 \n",
      "Epoch [92/5000] , Step [140/488] , Loss: 0.0331778451800346 \n",
      "Epoch [92/5000] , Step [150/488] , Loss: 0.0322906188666821 \n",
      "Epoch [92/5000] , Step [160/488] , Loss: 0.0330653563141823 \n",
      "Epoch [92/5000] , Step [170/488] , Loss: 0.0323709622025490 \n",
      "Epoch [92/5000] , Step [180/488] , Loss: 0.0328408516943455 \n",
      "Epoch [92/5000] , Step [190/488] , Loss: 0.0324217677116394 \n",
      "Epoch [92/5000] , Step [200/488] , Loss: 0.0332156345248222 \n",
      "Epoch [92/5000] , Step [210/488] , Loss: 0.0323963873088360 \n",
      "Epoch [92/5000] , Step [220/488] , Loss: 0.0322975814342499 \n",
      "Epoch [92/5000] , Step [230/488] , Loss: 0.0325445979833603 \n",
      "Epoch [92/5000] , Step [240/488] , Loss: 0.0324419438838959 \n",
      "Epoch [92/5000] , Step [250/488] , Loss: 0.0322795026004314 \n",
      "Epoch [92/5000] , Step [260/488] , Loss: 0.0327378697693348 \n",
      "Epoch [92/5000] , Step [270/488] , Loss: 0.0328727103769779 \n",
      "Epoch [92/5000] , Step [280/488] , Loss: 0.0324868746101856 \n",
      "Epoch [92/5000] , Step [290/488] , Loss: 0.0333328209817410 \n",
      "Epoch [92/5000] , Step [300/488] , Loss: 0.0324484817683697 \n",
      "Epoch [92/5000] , Step [310/488] , Loss: 0.0326864942908287 \n",
      "Epoch [92/5000] , Step [320/488] , Loss: 0.0328450053930283 \n",
      "Epoch [92/5000] , Step [330/488] , Loss: 0.0319497026503086 \n",
      "Epoch [92/5000] , Step [340/488] , Loss: 0.0325484275817871 \n",
      "Epoch [92/5000] , Step [350/488] , Loss: 0.0320661626756191 \n",
      "Epoch [92/5000] , Step [360/488] , Loss: 0.0320410020649433 \n",
      "Epoch [92/5000] , Step [370/488] , Loss: 0.0326873399317265 \n",
      "Epoch [92/5000] , Step [380/488] , Loss: 0.0324484035372734 \n",
      "Epoch [92/5000] , Step [390/488] , Loss: 0.0331180617213249 \n",
      "Epoch [92/5000] , Step [400/488] , Loss: 0.0328846126794815 \n",
      "Epoch [92/5000] , Step [410/488] , Loss: 0.0324623584747314 \n",
      "Epoch [92/5000] , Step [420/488] , Loss: 0.0320585668087006 \n",
      "Epoch [92/5000] , Step [430/488] , Loss: 0.0323029682040215 \n",
      "Epoch [92/5000] , Step [440/488] , Loss: 0.0323425419628620 \n",
      "Epoch [92/5000] , Step [450/488] , Loss: 0.0325425490736961 \n",
      "Epoch [92/5000] , Step [460/488] , Loss: 0.0326376147568226 \n",
      "Epoch [92/5000] , Step [470/488] , Loss: 0.0318238884210587 \n",
      "Epoch [92/5000] , Step [480/488] , Loss: 0.0324090756475925 \n",
      "Epoch [93/5000] , Step [10/488] , Loss: 0.0325332172214985 \n",
      "Epoch [93/5000] , Step [20/488] , Loss: 0.0316491685807705 \n",
      "Epoch [93/5000] , Step [30/488] , Loss: 0.0321017391979694 \n",
      "Epoch [93/5000] , Step [40/488] , Loss: 0.0323119498789310 \n",
      "Epoch [93/5000] , Step [50/488] , Loss: 0.0317404083907604 \n",
      "Epoch [93/5000] , Step [60/488] , Loss: 0.0324614606797695 \n",
      "Epoch [93/5000] , Step [70/488] , Loss: 0.0325770340859890 \n",
      "Epoch [93/5000] , Step [80/488] , Loss: 0.0323811024427414 \n",
      "Epoch [93/5000] , Step [90/488] , Loss: 0.0319768674671650 \n",
      "Epoch [93/5000] , Step [100/488] , Loss: 0.0324496962130070 \n",
      "Epoch [93/5000] , Step [110/488] , Loss: 0.0324287191033363 \n",
      "Epoch [93/5000] , Step [120/488] , Loss: 0.0322043709456921 \n",
      "Epoch [93/5000] , Step [130/488] , Loss: 0.0327384322881699 \n",
      "Epoch [93/5000] , Step [140/488] , Loss: 0.0325001403689384 \n",
      "Epoch [93/5000] , Step [150/488] , Loss: 0.0323912985622883 \n",
      "Epoch [93/5000] , Step [160/488] , Loss: 0.0331838428974152 \n",
      "Epoch [93/5000] , Step [170/488] , Loss: 0.0331184193491936 \n",
      "Epoch [93/5000] , Step [180/488] , Loss: 0.0319997072219849 \n",
      "Epoch [93/5000] , Step [190/488] , Loss: 0.0325705632567406 \n",
      "Epoch [93/5000] , Step [200/488] , Loss: 0.0328422114253044 \n",
      "Epoch [93/5000] , Step [210/488] , Loss: 0.0331894271075726 \n",
      "Epoch [93/5000] , Step [220/488] , Loss: 0.0326377227902412 \n",
      "Epoch [93/5000] , Step [230/488] , Loss: 0.0323045514523983 \n",
      "Epoch [93/5000] , Step [240/488] , Loss: 0.0323172435164452 \n",
      "Epoch [93/5000] , Step [250/488] , Loss: 0.0323194712400436 \n",
      "Epoch [93/5000] , Step [260/488] , Loss: 0.0323498807847500 \n",
      "Epoch [93/5000] , Step [270/488] , Loss: 0.0325723439455032 \n",
      "Epoch [93/5000] , Step [280/488] , Loss: 0.0325829833745956 \n",
      "Epoch [93/5000] , Step [290/488] , Loss: 0.0327115394175053 \n",
      "Epoch [93/5000] , Step [300/488] , Loss: 0.0323321409523487 \n",
      "Epoch [93/5000] , Step [310/488] , Loss: 0.0323344357311726 \n",
      "Epoch [93/5000] , Step [320/488] , Loss: 0.0326361507177353 \n",
      "Epoch [93/5000] , Step [330/488] , Loss: 0.0325927585363388 \n",
      "Epoch [93/5000] , Step [340/488] , Loss: 0.0329487696290016 \n",
      "Epoch [93/5000] , Step [350/488] , Loss: 0.0324558094143867 \n",
      "Epoch [93/5000] , Step [360/488] , Loss: 0.0326253846287727 \n",
      "Epoch [93/5000] , Step [370/488] , Loss: 0.0321354679763317 \n",
      "Epoch [93/5000] , Step [380/488] , Loss: 0.0319982022047043 \n",
      "Epoch [93/5000] , Step [390/488] , Loss: 0.0324003547430038 \n",
      "Epoch [93/5000] , Step [400/488] , Loss: 0.0316348373889923 \n",
      "Epoch [93/5000] , Step [410/488] , Loss: 0.0323904380202293 \n",
      "Epoch [93/5000] , Step [420/488] , Loss: 0.0328504778444767 \n",
      "Epoch [93/5000] , Step [430/488] , Loss: 0.0317643173038960 \n",
      "Epoch [93/5000] , Step [440/488] , Loss: 0.0325804613530636 \n",
      "Epoch [93/5000] , Step [450/488] , Loss: 0.0321963727474213 \n",
      "Epoch [93/5000] , Step [460/488] , Loss: 0.0318896807730198 \n",
      "Epoch [93/5000] , Step [470/488] , Loss: 0.0321661382913589 \n",
      "Epoch [93/5000] , Step [480/488] , Loss: 0.0328136123716831 \n",
      "Epoch [94/5000] , Step [10/488] , Loss: 0.0321528278291225 \n",
      "Epoch [94/5000] , Step [20/488] , Loss: 0.0328928418457508 \n",
      "Epoch [94/5000] , Step [30/488] , Loss: 0.0325761847198009 \n",
      "Epoch [94/5000] , Step [40/488] , Loss: 0.0319965146481991 \n",
      "Epoch [94/5000] , Step [50/488] , Loss: 0.0326764881610870 \n",
      "Epoch [94/5000] , Step [60/488] , Loss: 0.0320979766547680 \n",
      "Epoch [94/5000] , Step [70/488] , Loss: 0.0325899347662926 \n",
      "Epoch [94/5000] , Step [80/488] , Loss: 0.0328551903367043 \n",
      "Epoch [94/5000] , Step [90/488] , Loss: 0.0331184677779675 \n",
      "Epoch [94/5000] , Step [100/488] , Loss: 0.0325955003499985 \n",
      "Epoch [94/5000] , Step [110/488] , Loss: 0.0320348031818867 \n",
      "Epoch [94/5000] , Step [120/488] , Loss: 0.0320710688829422 \n",
      "Epoch [94/5000] , Step [130/488] , Loss: 0.0329142920672894 \n",
      "Epoch [94/5000] , Step [140/488] , Loss: 0.0333715416491032 \n",
      "Epoch [94/5000] , Step [150/488] , Loss: 0.0328438729047775 \n",
      "Epoch [94/5000] , Step [160/488] , Loss: 0.0330975130200386 \n",
      "Epoch [94/5000] , Step [170/488] , Loss: 0.0324445888400078 \n",
      "Epoch [94/5000] , Step [180/488] , Loss: 0.0327071771025658 \n",
      "Epoch [94/5000] , Step [190/488] , Loss: 0.0323237702250481 \n",
      "Epoch [94/5000] , Step [200/488] , Loss: 0.0319321565330029 \n",
      "Epoch [94/5000] , Step [210/488] , Loss: 0.0323849879205227 \n",
      "Epoch [94/5000] , Step [220/488] , Loss: 0.0322704203426838 \n",
      "Epoch [94/5000] , Step [230/488] , Loss: 0.0322689972817898 \n",
      "Epoch [94/5000] , Step [240/488] , Loss: 0.0326194390654564 \n",
      "Epoch [94/5000] , Step [250/488] , Loss: 0.0326736941933632 \n",
      "Epoch [94/5000] , Step [260/488] , Loss: 0.0326569341123104 \n",
      "Epoch [94/5000] , Step [270/488] , Loss: 0.0325043164193630 \n",
      "Epoch [94/5000] , Step [280/488] , Loss: 0.0331648103892803 \n",
      "Epoch [94/5000] , Step [290/488] , Loss: 0.0320858918130398 \n",
      "Epoch [94/5000] , Step [300/488] , Loss: 0.0325229465961456 \n",
      "Epoch [94/5000] , Step [310/488] , Loss: 0.0329791717231274 \n",
      "Epoch [94/5000] , Step [320/488] , Loss: 0.0314112231135368 \n",
      "Epoch [94/5000] , Step [330/488] , Loss: 0.0322639420628548 \n",
      "Epoch [94/5000] , Step [340/488] , Loss: 0.0331377238035202 \n",
      "Epoch [94/5000] , Step [350/488] , Loss: 0.0321962162852287 \n",
      "Epoch [94/5000] , Step [360/488] , Loss: 0.0329195037484169 \n",
      "Epoch [94/5000] , Step [370/488] , Loss: 0.0319093801081181 \n",
      "Epoch [94/5000] , Step [380/488] , Loss: 0.0325526259839535 \n",
      "Epoch [94/5000] , Step [390/488] , Loss: 0.0321554355323315 \n",
      "Epoch [94/5000] , Step [400/488] , Loss: 0.0325404033064842 \n",
      "Epoch [94/5000] , Step [410/488] , Loss: 0.0329133793711662 \n",
      "Epoch [94/5000] , Step [420/488] , Loss: 0.0320030339062214 \n",
      "Epoch [94/5000] , Step [430/488] , Loss: 0.0329785943031311 \n",
      "Epoch [94/5000] , Step [440/488] , Loss: 0.0328073054552078 \n",
      "Epoch [94/5000] , Step [450/488] , Loss: 0.0321913957595825 \n",
      "Epoch [94/5000] , Step [460/488] , Loss: 0.0322469919919968 \n",
      "Epoch [94/5000] , Step [470/488] , Loss: 0.0324113778769970 \n",
      "Epoch [94/5000] , Step [480/488] , Loss: 0.0323132090270519 \n",
      "Epoch [95/5000] , Step [10/488] , Loss: 0.0320808887481689 \n",
      "Epoch [95/5000] , Step [20/488] , Loss: 0.0332959964871407 \n",
      "Epoch [95/5000] , Step [30/488] , Loss: 0.0323833711445332 \n",
      "Epoch [95/5000] , Step [40/488] , Loss: 0.0323125682771206 \n",
      "Epoch [95/5000] , Step [50/488] , Loss: 0.0330382212996483 \n",
      "Epoch [95/5000] , Step [60/488] , Loss: 0.0326691903173923 \n",
      "Epoch [95/5000] , Step [70/488] , Loss: 0.0324288010597229 \n",
      "Epoch [95/5000] , Step [80/488] , Loss: 0.0321108326315880 \n",
      "Epoch [95/5000] , Step [90/488] , Loss: 0.0319019518792629 \n",
      "Epoch [95/5000] , Step [100/488] , Loss: 0.0321800634264946 \n",
      "Epoch [95/5000] , Step [110/488] , Loss: 0.0326316282153130 \n",
      "Epoch [95/5000] , Step [120/488] , Loss: 0.0323535278439522 \n",
      "Epoch [95/5000] , Step [130/488] , Loss: 0.0322372391819954 \n",
      "Epoch [95/5000] , Step [140/488] , Loss: 0.0331241562962532 \n",
      "Epoch [95/5000] , Step [150/488] , Loss: 0.0324008427560329 \n",
      "Epoch [95/5000] , Step [160/488] , Loss: 0.0330072976648808 \n",
      "Epoch [95/5000] , Step [170/488] , Loss: 0.0322451703250408 \n",
      "Epoch [95/5000] , Step [180/488] , Loss: 0.0328295491635799 \n",
      "Epoch [95/5000] , Step [190/488] , Loss: 0.0327804796397686 \n",
      "Epoch [95/5000] , Step [200/488] , Loss: 0.0324300937354565 \n",
      "Epoch [95/5000] , Step [210/488] , Loss: 0.0326506271958351 \n",
      "Epoch [95/5000] , Step [220/488] , Loss: 0.0332755185663700 \n",
      "Epoch [95/5000] , Step [230/488] , Loss: 0.0323182307183743 \n",
      "Epoch [95/5000] , Step [240/488] , Loss: 0.0320774987339973 \n",
      "Epoch [95/5000] , Step [250/488] , Loss: 0.0329190194606781 \n",
      "Epoch [95/5000] , Step [260/488] , Loss: 0.0328280180692673 \n",
      "Epoch [95/5000] , Step [270/488] , Loss: 0.0324472412467003 \n",
      "Epoch [95/5000] , Step [280/488] , Loss: 0.0326787531375885 \n",
      "Epoch [95/5000] , Step [290/488] , Loss: 0.0328543186187744 \n",
      "Epoch [95/5000] , Step [300/488] , Loss: 0.0324130132794380 \n",
      "Epoch [95/5000] , Step [310/488] , Loss: 0.0326890870928764 \n",
      "Epoch [95/5000] , Step [320/488] , Loss: 0.0318949259817600 \n",
      "Epoch [95/5000] , Step [330/488] , Loss: 0.0322977565228939 \n",
      "Epoch [95/5000] , Step [340/488] , Loss: 0.0320640131831169 \n",
      "Epoch [95/5000] , Step [350/488] , Loss: 0.0329785719513893 \n",
      "Epoch [95/5000] , Step [360/488] , Loss: 0.0329263694584370 \n",
      "Epoch [95/5000] , Step [370/488] , Loss: 0.0322777926921844 \n",
      "Epoch [95/5000] , Step [380/488] , Loss: 0.0324030891060829 \n",
      "Epoch [95/5000] , Step [390/488] , Loss: 0.0318859405815601 \n",
      "Epoch [95/5000] , Step [400/488] , Loss: 0.0325393900275230 \n",
      "Epoch [95/5000] , Step [410/488] , Loss: 0.0331090167164803 \n",
      "Epoch [95/5000] , Step [420/488] , Loss: 0.0334987938404083 \n",
      "Epoch [95/5000] , Step [430/488] , Loss: 0.0333962403237820 \n",
      "Epoch [95/5000] , Step [440/488] , Loss: 0.0323474891483784 \n",
      "Epoch [95/5000] , Step [450/488] , Loss: 0.0324497036635876 \n",
      "Epoch [95/5000] , Step [460/488] , Loss: 0.0324917994439602 \n",
      "Epoch [95/5000] , Step [470/488] , Loss: 0.0328000485897064 \n",
      "Epoch [95/5000] , Step [480/488] , Loss: 0.0329420864582062 \n",
      "Epoch [96/5000] , Step [10/488] , Loss: 0.0328165180981159 \n",
      "Epoch [96/5000] , Step [20/488] , Loss: 0.0325028449296951 \n",
      "Epoch [96/5000] , Step [30/488] , Loss: 0.0326756499707699 \n",
      "Epoch [96/5000] , Step [40/488] , Loss: 0.0322554446756840 \n",
      "Epoch [96/5000] , Step [50/488] , Loss: 0.0323083065450191 \n",
      "Epoch [96/5000] , Step [60/488] , Loss: 0.0317133590579033 \n",
      "Epoch [96/5000] , Step [70/488] , Loss: 0.0332671813666821 \n",
      "Epoch [96/5000] , Step [80/488] , Loss: 0.0321290679275990 \n",
      "Epoch [96/5000] , Step [90/488] , Loss: 0.0322821401059628 \n",
      "Epoch [96/5000] , Step [100/488] , Loss: 0.0329526886343956 \n",
      "Epoch [96/5000] , Step [110/488] , Loss: 0.0328472070395947 \n",
      "Epoch [96/5000] , Step [120/488] , Loss: 0.0323981940746307 \n",
      "Epoch [96/5000] , Step [130/488] , Loss: 0.0323141478002071 \n",
      "Epoch [96/5000] , Step [140/488] , Loss: 0.0324666015803814 \n",
      "Epoch [96/5000] , Step [150/488] , Loss: 0.0322970189154148 \n",
      "Epoch [96/5000] , Step [160/488] , Loss: 0.0330888368189335 \n",
      "Epoch [96/5000] , Step [170/488] , Loss: 0.0324974544346333 \n",
      "Epoch [96/5000] , Step [180/488] , Loss: 0.0325029157102108 \n",
      "Epoch [96/5000] , Step [190/488] , Loss: 0.0328087769448757 \n",
      "Epoch [96/5000] , Step [200/488] , Loss: 0.0321848094463348 \n",
      "Epoch [96/5000] , Step [210/488] , Loss: 0.0317386463284492 \n",
      "Epoch [96/5000] , Step [220/488] , Loss: 0.0322326980531216 \n",
      "Epoch [96/5000] , Step [230/488] , Loss: 0.0320547632873058 \n",
      "Epoch [96/5000] , Step [240/488] , Loss: 0.0321856290102005 \n",
      "Epoch [96/5000] , Step [250/488] , Loss: 0.0328741259872913 \n",
      "Epoch [96/5000] , Step [260/488] , Loss: 0.0322496481239796 \n",
      "Epoch [96/5000] , Step [270/488] , Loss: 0.0323455184698105 \n",
      "Epoch [96/5000] , Step [280/488] , Loss: 0.0323166586458683 \n",
      "Epoch [96/5000] , Step [290/488] , Loss: 0.0323668718338013 \n",
      "Epoch [96/5000] , Step [300/488] , Loss: 0.0327293239533901 \n",
      "Epoch [96/5000] , Step [310/488] , Loss: 0.0334937013685703 \n",
      "Epoch [96/5000] , Step [320/488] , Loss: 0.0325496569275856 \n",
      "Epoch [96/5000] , Step [330/488] , Loss: 0.0319445692002773 \n",
      "Epoch [96/5000] , Step [340/488] , Loss: 0.0323005802929401 \n",
      "Epoch [96/5000] , Step [350/488] , Loss: 0.0327041484415531 \n",
      "Epoch [96/5000] , Step [360/488] , Loss: 0.0331770628690720 \n",
      "Epoch [96/5000] , Step [370/488] , Loss: 0.0323962308466434 \n",
      "Epoch [96/5000] , Step [380/488] , Loss: 0.0329144783318043 \n",
      "Epoch [96/5000] , Step [390/488] , Loss: 0.0326190143823624 \n",
      "Epoch [96/5000] , Step [400/488] , Loss: 0.0328642018139362 \n",
      "Epoch [96/5000] , Step [410/488] , Loss: 0.0320622734725475 \n",
      "Epoch [96/5000] , Step [420/488] , Loss: 0.0324670188128948 \n",
      "Epoch [96/5000] , Step [430/488] , Loss: 0.0331323333084583 \n",
      "Epoch [96/5000] , Step [440/488] , Loss: 0.0326716490089893 \n",
      "Epoch [96/5000] , Step [450/488] , Loss: 0.0323461554944515 \n",
      "Epoch [96/5000] , Step [460/488] , Loss: 0.0327172018587589 \n",
      "Epoch [96/5000] , Step [470/488] , Loss: 0.0329134725034237 \n",
      "Epoch [96/5000] , Step [480/488] , Loss: 0.0322121195495129 \n",
      "Epoch [97/5000] , Step [10/488] , Loss: 0.0326795615255833 \n",
      "Epoch [97/5000] , Step [20/488] , Loss: 0.0320651493966579 \n",
      "Epoch [97/5000] , Step [30/488] , Loss: 0.0326774716377258 \n",
      "Epoch [97/5000] , Step [40/488] , Loss: 0.0324073918163776 \n",
      "Epoch [97/5000] , Step [50/488] , Loss: 0.0327662341296673 \n",
      "Epoch [97/5000] , Step [60/488] , Loss: 0.0322690717875957 \n",
      "Epoch [97/5000] , Step [70/488] , Loss: 0.0329736545681953 \n",
      "Epoch [97/5000] , Step [80/488] , Loss: 0.0328134074807167 \n",
      "Epoch [97/5000] , Step [90/488] , Loss: 0.0325491093099117 \n",
      "Epoch [97/5000] , Step [100/488] , Loss: 0.0323282852768898 \n",
      "Epoch [97/5000] , Step [110/488] , Loss: 0.0332516990602016 \n",
      "Epoch [97/5000] , Step [120/488] , Loss: 0.0326871015131474 \n",
      "Epoch [97/5000] , Step [130/488] , Loss: 0.0328005068004131 \n",
      "Epoch [97/5000] , Step [140/488] , Loss: 0.0329235754907131 \n",
      "Epoch [97/5000] , Step [150/488] , Loss: 0.0324433930218220 \n",
      "Epoch [97/5000] , Step [160/488] , Loss: 0.0323222391307354 \n",
      "Epoch [97/5000] , Step [170/488] , Loss: 0.0326586887240410 \n",
      "Epoch [97/5000] , Step [180/488] , Loss: 0.0331350229680538 \n",
      "Epoch [97/5000] , Step [190/488] , Loss: 0.0325598903000355 \n",
      "Epoch [97/5000] , Step [200/488] , Loss: 0.0324116982519627 \n",
      "Epoch [97/5000] , Step [210/488] , Loss: 0.0323785990476608 \n",
      "Epoch [97/5000] , Step [220/488] , Loss: 0.0328032597899437 \n",
      "Epoch [97/5000] , Step [230/488] , Loss: 0.0329672731459141 \n",
      "Epoch [97/5000] , Step [240/488] , Loss: 0.0327550470829010 \n",
      "Epoch [97/5000] , Step [250/488] , Loss: 0.0324855186045170 \n",
      "Epoch [97/5000] , Step [260/488] , Loss: 0.0320937372744083 \n",
      "Epoch [97/5000] , Step [270/488] , Loss: 0.0325037501752377 \n",
      "Epoch [97/5000] , Step [280/488] , Loss: 0.0322658084332943 \n",
      "Epoch [97/5000] , Step [290/488] , Loss: 0.0325128696858883 \n",
      "Epoch [97/5000] , Step [300/488] , Loss: 0.0325172655284405 \n",
      "Epoch [97/5000] , Step [310/488] , Loss: 0.0320427007973194 \n",
      "Epoch [97/5000] , Step [320/488] , Loss: 0.0326679423451424 \n",
      "Epoch [97/5000] , Step [330/488] , Loss: 0.0323946103453636 \n",
      "Epoch [97/5000] , Step [340/488] , Loss: 0.0317658931016922 \n",
      "Epoch [97/5000] , Step [350/488] , Loss: 0.0327142886817455 \n",
      "Epoch [97/5000] , Step [360/488] , Loss: 0.0329450815916061 \n",
      "Epoch [97/5000] , Step [370/488] , Loss: 0.0323781967163086 \n",
      "Epoch [97/5000] , Step [380/488] , Loss: 0.0327947884798050 \n",
      "Epoch [97/5000] , Step [390/488] , Loss: 0.0331279151141644 \n",
      "Epoch [97/5000] , Step [400/488] , Loss: 0.0320504121482372 \n",
      "Epoch [97/5000] , Step [410/488] , Loss: 0.0320401638746262 \n",
      "Epoch [97/5000] , Step [420/488] , Loss: 0.0322148315608501 \n",
      "Epoch [97/5000] , Step [430/488] , Loss: 0.0328350253403187 \n",
      "Epoch [97/5000] , Step [440/488] , Loss: 0.0323934517800808 \n",
      "Epoch [97/5000] , Step [450/488] , Loss: 0.0324065126478672 \n",
      "Epoch [97/5000] , Step [460/488] , Loss: 0.0323939658701420 \n",
      "Epoch [97/5000] , Step [470/488] , Loss: 0.0321329273283482 \n",
      "Epoch [97/5000] , Step [480/488] , Loss: 0.0324491411447525 \n",
      "Epoch [98/5000] , Step [10/488] , Loss: 0.0323536694049835 \n",
      "Epoch [98/5000] , Step [20/488] , Loss: 0.0322139561176300 \n",
      "Epoch [98/5000] , Step [30/488] , Loss: 0.0325103029608727 \n",
      "Epoch [98/5000] , Step [40/488] , Loss: 0.0323301702737808 \n",
      "Epoch [98/5000] , Step [50/488] , Loss: 0.0323027223348618 \n",
      "Epoch [98/5000] , Step [60/488] , Loss: 0.0324058867990971 \n",
      "Epoch [98/5000] , Step [70/488] , Loss: 0.0325441248714924 \n",
      "Epoch [98/5000] , Step [80/488] , Loss: 0.0319997519254684 \n",
      "Epoch [98/5000] , Step [90/488] , Loss: 0.0321601703763008 \n",
      "Epoch [98/5000] , Step [100/488] , Loss: 0.0319785214960575 \n",
      "Epoch [98/5000] , Step [110/488] , Loss: 0.0331807807087898 \n",
      "Epoch [98/5000] , Step [120/488] , Loss: 0.0325252562761307 \n",
      "Epoch [98/5000] , Step [130/488] , Loss: 0.0326416529715061 \n",
      "Epoch [98/5000] , Step [140/488] , Loss: 0.0318266712129116 \n",
      "Epoch [98/5000] , Step [150/488] , Loss: 0.0322227701544762 \n",
      "Epoch [98/5000] , Step [160/488] , Loss: 0.0326634459197521 \n",
      "Epoch [98/5000] , Step [170/488] , Loss: 0.0319972708821297 \n",
      "Epoch [98/5000] , Step [180/488] , Loss: 0.0324987806379795 \n",
      "Epoch [98/5000] , Step [190/488] , Loss: 0.0328420922160149 \n",
      "Epoch [98/5000] , Step [200/488] , Loss: 0.0328645817935467 \n",
      "Epoch [98/5000] , Step [210/488] , Loss: 0.0327622368931770 \n",
      "Epoch [98/5000] , Step [220/488] , Loss: 0.0326679348945618 \n",
      "Epoch [98/5000] , Step [230/488] , Loss: 0.0334315933287144 \n",
      "Epoch [98/5000] , Step [240/488] , Loss: 0.0325432941317558 \n",
      "Epoch [98/5000] , Step [250/488] , Loss: 0.0326685160398483 \n",
      "Epoch [98/5000] , Step [260/488] , Loss: 0.0324961617588997 \n",
      "Epoch [98/5000] , Step [270/488] , Loss: 0.0319930575788021 \n",
      "Epoch [98/5000] , Step [280/488] , Loss: 0.0326773636043072 \n",
      "Epoch [98/5000] , Step [290/488] , Loss: 0.0335824564099312 \n",
      "Epoch [98/5000] , Step [300/488] , Loss: 0.0317589454352856 \n",
      "Epoch [98/5000] , Step [310/488] , Loss: 0.0323380008339882 \n",
      "Epoch [98/5000] , Step [320/488] , Loss: 0.0322624221444130 \n",
      "Epoch [98/5000] , Step [330/488] , Loss: 0.0325581431388855 \n",
      "Epoch [98/5000] , Step [340/488] , Loss: 0.0324197076261044 \n",
      "Epoch [98/5000] , Step [350/488] , Loss: 0.0320242457091808 \n",
      "Epoch [98/5000] , Step [360/488] , Loss: 0.0324346385896206 \n",
      "Epoch [98/5000] , Step [370/488] , Loss: 0.0329885073006153 \n",
      "Epoch [98/5000] , Step [380/488] , Loss: 0.0321344099938869 \n",
      "Epoch [98/5000] , Step [390/488] , Loss: 0.0329176150262356 \n",
      "Epoch [98/5000] , Step [400/488] , Loss: 0.0326876752078533 \n",
      "Epoch [98/5000] , Step [410/488] , Loss: 0.0325085595250130 \n",
      "Epoch [98/5000] , Step [420/488] , Loss: 0.0320397838950157 \n",
      "Epoch [98/5000] , Step [430/488] , Loss: 0.0326033979654312 \n",
      "Epoch [98/5000] , Step [440/488] , Loss: 0.0325771905481815 \n",
      "Epoch [98/5000] , Step [450/488] , Loss: 0.0330311618745327 \n",
      "Epoch [98/5000] , Step [460/488] , Loss: 0.0328970588743687 \n",
      "Epoch [98/5000] , Step [470/488] , Loss: 0.0331322811543941 \n",
      "Epoch [98/5000] , Step [480/488] , Loss: 0.0324318297207355 \n",
      "Epoch [99/5000] , Step [10/488] , Loss: 0.0329637117683887 \n",
      "Epoch [99/5000] , Step [20/488] , Loss: 0.0330293774604797 \n",
      "Epoch [99/5000] , Step [30/488] , Loss: 0.0324752442538738 \n",
      "Epoch [99/5000] , Step [40/488] , Loss: 0.0324776731431484 \n",
      "Epoch [99/5000] , Step [50/488] , Loss: 0.0321563966572285 \n",
      "Epoch [99/5000] , Step [60/488] , Loss: 0.0326939895749092 \n",
      "Epoch [99/5000] , Step [70/488] , Loss: 0.0323364250361919 \n",
      "Epoch [99/5000] , Step [80/488] , Loss: 0.0327103175222874 \n",
      "Epoch [99/5000] , Step [90/488] , Loss: 0.0323170349001884 \n",
      "Epoch [99/5000] , Step [100/488] , Loss: 0.0324781574308872 \n",
      "Epoch [99/5000] , Step [110/488] , Loss: 0.0326527133584023 \n",
      "Epoch [99/5000] , Step [120/488] , Loss: 0.0323873758316040 \n",
      "Epoch [99/5000] , Step [130/488] , Loss: 0.0325652323663235 \n",
      "Epoch [99/5000] , Step [140/488] , Loss: 0.0325143486261368 \n",
      "Epoch [99/5000] , Step [150/488] , Loss: 0.0324761532247066 \n",
      "Epoch [99/5000] , Step [160/488] , Loss: 0.0327319018542767 \n",
      "Epoch [99/5000] , Step [170/488] , Loss: 0.0323356539011002 \n",
      "Epoch [99/5000] , Step [180/488] , Loss: 0.0322914831340313 \n",
      "Epoch [99/5000] , Step [190/488] , Loss: 0.0324299894273281 \n",
      "Epoch [99/5000] , Step [200/488] , Loss: 0.0322419665753841 \n",
      "Epoch [99/5000] , Step [210/488] , Loss: 0.0330055952072144 \n",
      "Epoch [99/5000] , Step [220/488] , Loss: 0.0315029695630074 \n",
      "Epoch [99/5000] , Step [230/488] , Loss: 0.0324438661336899 \n",
      "Epoch [99/5000] , Step [240/488] , Loss: 0.0324976108968258 \n",
      "Epoch [99/5000] , Step [250/488] , Loss: 0.0328548289835453 \n",
      "Epoch [99/5000] , Step [260/488] , Loss: 0.0330520197749138 \n",
      "Epoch [99/5000] , Step [270/488] , Loss: 0.0325443074107170 \n",
      "Epoch [99/5000] , Step [280/488] , Loss: 0.0326764546334743 \n",
      "Epoch [99/5000] , Step [290/488] , Loss: 0.0324444957077503 \n",
      "Epoch [99/5000] , Step [300/488] , Loss: 0.0325565040111542 \n",
      "Epoch [99/5000] , Step [310/488] , Loss: 0.0332675501704216 \n",
      "Epoch [99/5000] , Step [320/488] , Loss: 0.0324037820100784 \n",
      "Epoch [99/5000] , Step [330/488] , Loss: 0.0326408967375755 \n",
      "Epoch [99/5000] , Step [340/488] , Loss: 0.0326113067567348 \n",
      "Epoch [99/5000] , Step [350/488] , Loss: 0.0319423638284206 \n",
      "Epoch [99/5000] , Step [360/488] , Loss: 0.0318753607571125 \n",
      "Epoch [99/5000] , Step [370/488] , Loss: 0.0330846048891544 \n",
      "Epoch [99/5000] , Step [380/488] , Loss: 0.0318808183073997 \n",
      "Epoch [99/5000] , Step [390/488] , Loss: 0.0323945358395576 \n",
      "Epoch [99/5000] , Step [400/488] , Loss: 0.0317138843238354 \n",
      "Epoch [99/5000] , Step [410/488] , Loss: 0.0323347300291061 \n",
      "Epoch [99/5000] , Step [420/488] , Loss: 0.0326034091413021 \n",
      "Epoch [99/5000] , Step [430/488] , Loss: 0.0324445106089115 \n",
      "Epoch [99/5000] , Step [440/488] , Loss: 0.0317204631865025 \n",
      "Epoch [99/5000] , Step [450/488] , Loss: 0.0329351127147675 \n",
      "Epoch [99/5000] , Step [460/488] , Loss: 0.0321047119796276 \n",
      "Epoch [99/5000] , Step [470/488] , Loss: 0.0321787521243095 \n",
      "Epoch [99/5000] , Step [480/488] , Loss: 0.0332060195505619 \n",
      "Epoch [100/5000] , Step [10/488] , Loss: 0.0327541120350361 \n",
      "Epoch [100/5000] , Step [20/488] , Loss: 0.0324573442339897 \n",
      "Epoch [100/5000] , Step [30/488] , Loss: 0.0324982590973377 \n",
      "Epoch [100/5000] , Step [40/488] , Loss: 0.0327484719455242 \n",
      "Epoch [100/5000] , Step [50/488] , Loss: 0.0323382578790188 \n",
      "Epoch [100/5000] , Step [60/488] , Loss: 0.0325670987367630 \n",
      "Epoch [100/5000] , Step [70/488] , Loss: 0.0323723368346691 \n",
      "Epoch [100/5000] , Step [80/488] , Loss: 0.0329402647912502 \n",
      "Epoch [100/5000] , Step [90/488] , Loss: 0.0327243171632290 \n",
      "Epoch [100/5000] , Step [100/488] , Loss: 0.0319714769721031 \n",
      "Epoch [100/5000] , Step [110/488] , Loss: 0.0324754081666470 \n",
      "Epoch [100/5000] , Step [120/488] , Loss: 0.0324046760797501 \n",
      "Epoch [100/5000] , Step [130/488] , Loss: 0.0326444953680038 \n",
      "Epoch [100/5000] , Step [140/488] , Loss: 0.0333527103066444 \n",
      "Epoch [100/5000] , Step [150/488] , Loss: 0.0325330272316933 \n",
      "Epoch [100/5000] , Step [160/488] , Loss: 0.0321589112281799 \n",
      "Epoch [100/5000] , Step [170/488] , Loss: 0.0323314666748047 \n",
      "Epoch [100/5000] , Step [180/488] , Loss: 0.0326387770473957 \n",
      "Epoch [100/5000] , Step [190/488] , Loss: 0.0322365872561932 \n",
      "Epoch [100/5000] , Step [200/488] , Loss: 0.0326339043676853 \n",
      "Epoch [100/5000] , Step [210/488] , Loss: 0.0328000299632549 \n",
      "Epoch [100/5000] , Step [220/488] , Loss: 0.0328166261315346 \n",
      "Epoch [100/5000] , Step [230/488] , Loss: 0.0326936282217503 \n",
      "Epoch [100/5000] , Step [240/488] , Loss: 0.0323614850640297 \n",
      "Epoch [100/5000] , Step [250/488] , Loss: 0.0324397198855877 \n",
      "Epoch [100/5000] , Step [260/488] , Loss: 0.0321148112416267 \n",
      "Epoch [100/5000] , Step [270/488] , Loss: 0.0327871777117252 \n",
      "Epoch [100/5000] , Step [280/488] , Loss: 0.0319365113973618 \n",
      "Epoch [100/5000] , Step [290/488] , Loss: 0.0322745069861412 \n",
      "Epoch [100/5000] , Step [300/488] , Loss: 0.0331925600767136 \n",
      "Epoch [100/5000] , Step [310/488] , Loss: 0.0321325473487377 \n",
      "Epoch [100/5000] , Step [320/488] , Loss: 0.0327637083828449 \n",
      "Epoch [100/5000] , Step [330/488] , Loss: 0.0325789935886860 \n",
      "Epoch [100/5000] , Step [340/488] , Loss: 0.0330476686358452 \n",
      "Epoch [100/5000] , Step [350/488] , Loss: 0.0323967598378658 \n",
      "Epoch [100/5000] , Step [360/488] , Loss: 0.0327845178544521 \n",
      "Epoch [100/5000] , Step [370/488] , Loss: 0.0329788550734520 \n",
      "Epoch [100/5000] , Step [380/488] , Loss: 0.0331548675894737 \n",
      "Epoch [100/5000] , Step [390/488] , Loss: 0.0322907939553261 \n",
      "Epoch [100/5000] , Step [400/488] , Loss: 0.0326925516128540 \n",
      "Epoch [100/5000] , Step [410/488] , Loss: 0.0325910598039627 \n",
      "Epoch [100/5000] , Step [420/488] , Loss: 0.0321556441485882 \n",
      "Epoch [100/5000] , Step [430/488] , Loss: 0.0322145931422710 \n",
      "Epoch [100/5000] , Step [440/488] , Loss: 0.0327689647674561 \n",
      "Epoch [100/5000] , Step [450/488] , Loss: 0.0331586748361588 \n",
      "Epoch [100/5000] , Step [460/488] , Loss: 0.0324835777282715 \n",
      "Epoch [100/5000] , Step [470/488] , Loss: 0.0322007983922958 \n",
      "Epoch [100/5000] , Step [480/488] , Loss: 0.0322937332093716 \n",
      "Epoch [101/5000] , Step [10/488] , Loss: 0.0321382693946362 \n",
      "Epoch [101/5000] , Step [20/488] , Loss: 0.0324378460645676 \n",
      "Epoch [101/5000] , Step [30/488] , Loss: 0.0324191264808178 \n",
      "Epoch [101/5000] , Step [40/488] , Loss: 0.0322027467191219 \n",
      "Epoch [101/5000] , Step [50/488] , Loss: 0.0322379209101200 \n",
      "Epoch [101/5000] , Step [60/488] , Loss: 0.0323047488927841 \n",
      "Epoch [101/5000] , Step [70/488] , Loss: 0.0322401486337185 \n",
      "Epoch [101/5000] , Step [80/488] , Loss: 0.0327868126332760 \n",
      "Epoch [101/5000] , Step [90/488] , Loss: 0.0322605706751347 \n",
      "Epoch [101/5000] , Step [100/488] , Loss: 0.0324234664440155 \n",
      "Epoch [101/5000] , Step [110/488] , Loss: 0.0322432406246662 \n",
      "Epoch [101/5000] , Step [120/488] , Loss: 0.0323267579078674 \n",
      "Epoch [101/5000] , Step [130/488] , Loss: 0.0324660800397396 \n",
      "Epoch [101/5000] , Step [140/488] , Loss: 0.0325182341039181 \n",
      "Epoch [101/5000] , Step [150/488] , Loss: 0.0327332317829132 \n",
      "Epoch [101/5000] , Step [160/488] , Loss: 0.0325523093342781 \n",
      "Epoch [101/5000] , Step [170/488] , Loss: 0.0324048511683941 \n",
      "Epoch [101/5000] , Step [180/488] , Loss: 0.0327298268675804 \n",
      "Epoch [101/5000] , Step [190/488] , Loss: 0.0328929834067822 \n",
      "Epoch [101/5000] , Step [200/488] , Loss: 0.0321302451193333 \n",
      "Epoch [101/5000] , Step [210/488] , Loss: 0.0327318124473095 \n",
      "Epoch [101/5000] , Step [220/488] , Loss: 0.0327946729958057 \n",
      "Epoch [101/5000] , Step [230/488] , Loss: 0.0330069847404957 \n",
      "Epoch [101/5000] , Step [240/488] , Loss: 0.0325842127203941 \n",
      "Epoch [101/5000] , Step [250/488] , Loss: 0.0321593508124352 \n",
      "Epoch [101/5000] , Step [260/488] , Loss: 0.0324923545122147 \n",
      "Epoch [101/5000] , Step [270/488] , Loss: 0.0323455855250359 \n",
      "Epoch [101/5000] , Step [280/488] , Loss: 0.0323645807802677 \n",
      "Epoch [101/5000] , Step [290/488] , Loss: 0.0325648412108421 \n",
      "Epoch [101/5000] , Step [300/488] , Loss: 0.0325805768370628 \n",
      "Epoch [101/5000] , Step [310/488] , Loss: 0.0321975387632847 \n",
      "Epoch [101/5000] , Step [320/488] , Loss: 0.0325076617300510 \n",
      "Epoch [101/5000] , Step [330/488] , Loss: 0.0331368446350098 \n",
      "Epoch [101/5000] , Step [340/488] , Loss: 0.0327989682555199 \n",
      "Epoch [101/5000] , Step [350/488] , Loss: 0.0324315316975117 \n",
      "Epoch [101/5000] , Step [360/488] , Loss: 0.0326458141207695 \n",
      "Epoch [101/5000] , Step [370/488] , Loss: 0.0327030532062054 \n",
      "Epoch [101/5000] , Step [380/488] , Loss: 0.0329090468585491 \n",
      "Epoch [101/5000] , Step [390/488] , Loss: 0.0331532135605812 \n",
      "Epoch [101/5000] , Step [400/488] , Loss: 0.0324151590466499 \n",
      "Epoch [101/5000] , Step [410/488] , Loss: 0.0322317592799664 \n",
      "Epoch [101/5000] , Step [420/488] , Loss: 0.0328379794955254 \n",
      "Epoch [101/5000] , Step [430/488] , Loss: 0.0330764874815941 \n",
      "Epoch [101/5000] , Step [440/488] , Loss: 0.0331915020942688 \n",
      "Epoch [101/5000] , Step [450/488] , Loss: 0.0327142030000687 \n",
      "Epoch [101/5000] , Step [460/488] , Loss: 0.0324142612516880 \n",
      "Epoch [101/5000] , Step [470/488] , Loss: 0.0328339040279388 \n",
      "Epoch [101/5000] , Step [480/488] , Loss: 0.0321558639407158 \n",
      "Epoch [102/5000] , Step [10/488] , Loss: 0.0324983894824982 \n",
      "Epoch [102/5000] , Step [20/488] , Loss: 0.0325134359300137 \n",
      "Epoch [102/5000] , Step [30/488] , Loss: 0.0328099951148033 \n",
      "Epoch [102/5000] , Step [40/488] , Loss: 0.0319078750908375 \n",
      "Epoch [102/5000] , Step [50/488] , Loss: 0.0331613086163998 \n",
      "Epoch [102/5000] , Step [60/488] , Loss: 0.0327963940799236 \n",
      "Epoch [102/5000] , Step [70/488] , Loss: 0.0328210592269897 \n",
      "Epoch [102/5000] , Step [80/488] , Loss: 0.0325736366212368 \n",
      "Epoch [102/5000] , Step [90/488] , Loss: 0.0323235578835011 \n",
      "Epoch [102/5000] , Step [100/488] , Loss: 0.0326646752655506 \n",
      "Epoch [102/5000] , Step [110/488] , Loss: 0.0323279649019241 \n",
      "Epoch [102/5000] , Step [120/488] , Loss: 0.0328185968101025 \n",
      "Epoch [102/5000] , Step [130/488] , Loss: 0.0324083194136620 \n",
      "Epoch [102/5000] , Step [140/488] , Loss: 0.0323838330805302 \n",
      "Epoch [102/5000] , Step [150/488] , Loss: 0.0322959534823895 \n",
      "Epoch [102/5000] , Step [160/488] , Loss: 0.0323658883571625 \n",
      "Epoch [102/5000] , Step [170/488] , Loss: 0.0323167666792870 \n",
      "Epoch [102/5000] , Step [180/488] , Loss: 0.0328542664647102 \n",
      "Epoch [102/5000] , Step [190/488] , Loss: 0.0326364524662495 \n",
      "Epoch [102/5000] , Step [200/488] , Loss: 0.0327913761138916 \n",
      "Epoch [102/5000] , Step [210/488] , Loss: 0.0332404300570488 \n",
      "Epoch [102/5000] , Step [220/488] , Loss: 0.0322281643748283 \n",
      "Epoch [102/5000] , Step [230/488] , Loss: 0.0327397733926773 \n",
      "Epoch [102/5000] , Step [240/488] , Loss: 0.0327882133424282 \n",
      "Epoch [102/5000] , Step [250/488] , Loss: 0.0327147617936134 \n",
      "Epoch [102/5000] , Step [260/488] , Loss: 0.0331155657768250 \n",
      "Epoch [102/5000] , Step [270/488] , Loss: 0.0327993333339691 \n",
      "Epoch [102/5000] , Step [280/488] , Loss: 0.0323495864868164 \n",
      "Epoch [102/5000] , Step [290/488] , Loss: 0.0329300388693810 \n",
      "Epoch [102/5000] , Step [300/488] , Loss: 0.0330254770815372 \n",
      "Epoch [102/5000] , Step [310/488] , Loss: 0.0323138535022736 \n",
      "Epoch [102/5000] , Step [320/488] , Loss: 0.0329079292714596 \n",
      "Epoch [102/5000] , Step [330/488] , Loss: 0.0327270850539207 \n",
      "Epoch [102/5000] , Step [340/488] , Loss: 0.0329714007675648 \n",
      "Epoch [102/5000] , Step [350/488] , Loss: 0.0317942686378956 \n",
      "Epoch [102/5000] , Step [360/488] , Loss: 0.0333526879549026 \n",
      "Epoch [102/5000] , Step [370/488] , Loss: 0.0325826443731785 \n",
      "Epoch [102/5000] , Step [380/488] , Loss: 0.0325354747474194 \n",
      "Epoch [102/5000] , Step [390/488] , Loss: 0.0329601354897022 \n",
      "Epoch [102/5000] , Step [400/488] , Loss: 0.0327832624316216 \n",
      "Epoch [102/5000] , Step [410/488] , Loss: 0.0328689217567444 \n",
      "Epoch [102/5000] , Step [420/488] , Loss: 0.0326842851936817 \n",
      "Epoch [102/5000] , Step [430/488] , Loss: 0.0325403399765491 \n",
      "Epoch [102/5000] , Step [440/488] , Loss: 0.0322941318154335 \n",
      "Epoch [102/5000] , Step [450/488] , Loss: 0.0326150022447109 \n",
      "Epoch [102/5000] , Step [460/488] , Loss: 0.0328879989683628 \n",
      "Epoch [102/5000] , Step [470/488] , Loss: 0.0329598374664783 \n",
      "Epoch [102/5000] , Step [480/488] , Loss: 0.0320067703723907 \n",
      "Epoch [103/5000] , Step [10/488] , Loss: 0.0316225737333298 \n",
      "Epoch [103/5000] , Step [20/488] , Loss: 0.0327697992324829 \n",
      "Epoch [103/5000] , Step [30/488] , Loss: 0.0328053794801235 \n",
      "Epoch [103/5000] , Step [40/488] , Loss: 0.0324538275599480 \n",
      "Epoch [103/5000] , Step [50/488] , Loss: 0.0326027646660805 \n",
      "Epoch [103/5000] , Step [60/488] , Loss: 0.0328295417129993 \n",
      "Epoch [103/5000] , Step [70/488] , Loss: 0.0325920879840851 \n",
      "Epoch [103/5000] , Step [80/488] , Loss: 0.0325937978923321 \n",
      "Epoch [103/5000] , Step [90/488] , Loss: 0.0327842757105827 \n",
      "Epoch [103/5000] , Step [100/488] , Loss: 0.0329667367041111 \n",
      "Epoch [103/5000] , Step [110/488] , Loss: 0.0325785912573338 \n",
      "Epoch [103/5000] , Step [120/488] , Loss: 0.0320858806371689 \n",
      "Epoch [103/5000] , Step [130/488] , Loss: 0.0327195972204208 \n",
      "Epoch [103/5000] , Step [140/488] , Loss: 0.0325669236481190 \n",
      "Epoch [103/5000] , Step [150/488] , Loss: 0.0319407284259796 \n",
      "Epoch [103/5000] , Step [160/488] , Loss: 0.0328932739794254 \n",
      "Epoch [103/5000] , Step [170/488] , Loss: 0.0334015712141991 \n",
      "Epoch [103/5000] , Step [180/488] , Loss: 0.0327965356409550 \n",
      "Epoch [103/5000] , Step [190/488] , Loss: 0.0322296880185604 \n",
      "Epoch [103/5000] , Step [200/488] , Loss: 0.0324621722102165 \n",
      "Epoch [103/5000] , Step [210/488] , Loss: 0.0324711352586746 \n",
      "Epoch [103/5000] , Step [220/488] , Loss: 0.0323546379804611 \n",
      "Epoch [103/5000] , Step [230/488] , Loss: 0.0329531133174896 \n",
      "Epoch [103/5000] , Step [240/488] , Loss: 0.0329728350043297 \n",
      "Epoch [103/5000] , Step [250/488] , Loss: 0.0314158722758293 \n",
      "Epoch [103/5000] , Step [260/488] , Loss: 0.0324954539537430 \n",
      "Epoch [103/5000] , Step [270/488] , Loss: 0.0327655933797359 \n",
      "Epoch [103/5000] , Step [280/488] , Loss: 0.0323924981057644 \n",
      "Epoch [103/5000] , Step [290/488] , Loss: 0.0326643697917461 \n",
      "Epoch [103/5000] , Step [300/488] , Loss: 0.0328773446381092 \n",
      "Epoch [103/5000] , Step [310/488] , Loss: 0.0317501984536648 \n",
      "Epoch [103/5000] , Step [320/488] , Loss: 0.0326480716466904 \n",
      "Epoch [103/5000] , Step [330/488] , Loss: 0.0323439240455627 \n",
      "Epoch [103/5000] , Step [340/488] , Loss: 0.0324737615883350 \n",
      "Epoch [103/5000] , Step [350/488] , Loss: 0.0329281128942966 \n",
      "Epoch [103/5000] , Step [360/488] , Loss: 0.0323522128164768 \n",
      "Epoch [103/5000] , Step [370/488] , Loss: 0.0327001698315144 \n",
      "Epoch [103/5000] , Step [380/488] , Loss: 0.0326558724045753 \n",
      "Epoch [103/5000] , Step [390/488] , Loss: 0.0328201986849308 \n",
      "Epoch [103/5000] , Step [400/488] , Loss: 0.0317639335989952 \n",
      "Epoch [103/5000] , Step [410/488] , Loss: 0.0329290144145489 \n",
      "Epoch [103/5000] , Step [420/488] , Loss: 0.0322725921869278 \n",
      "Epoch [103/5000] , Step [430/488] , Loss: 0.0318920537829399 \n",
      "Epoch [103/5000] , Step [440/488] , Loss: 0.0323261767625809 \n",
      "Epoch [103/5000] , Step [450/488] , Loss: 0.0317577198147774 \n",
      "Epoch [103/5000] , Step [460/488] , Loss: 0.0323245301842690 \n",
      "Epoch [103/5000] , Step [470/488] , Loss: 0.0324525646865368 \n",
      "Epoch [103/5000] , Step [480/488] , Loss: 0.0326599963009357 \n",
      "Epoch [104/5000] , Step [10/488] , Loss: 0.0323276855051517 \n",
      "Epoch [104/5000] , Step [20/488] , Loss: 0.0323873721063137 \n",
      "Epoch [104/5000] , Step [30/488] , Loss: 0.0324405878782272 \n",
      "Epoch [104/5000] , Step [40/488] , Loss: 0.0328426212072372 \n",
      "Epoch [104/5000] , Step [50/488] , Loss: 0.0322932675480843 \n",
      "Epoch [104/5000] , Step [60/488] , Loss: 0.0324733965098858 \n",
      "Epoch [104/5000] , Step [70/488] , Loss: 0.0321214385330677 \n",
      "Epoch [104/5000] , Step [80/488] , Loss: 0.0326269976794720 \n",
      "Epoch [104/5000] , Step [90/488] , Loss: 0.0320975221693516 \n",
      "Epoch [104/5000] , Step [100/488] , Loss: 0.0320144705474377 \n",
      "Epoch [104/5000] , Step [110/488] , Loss: 0.0326105542480946 \n",
      "Epoch [104/5000] , Step [120/488] , Loss: 0.0328313559293747 \n",
      "Epoch [104/5000] , Step [130/488] , Loss: 0.0329636037349701 \n",
      "Epoch [104/5000] , Step [140/488] , Loss: 0.0327301621437073 \n",
      "Epoch [104/5000] , Step [150/488] , Loss: 0.0329794138669968 \n",
      "Epoch [104/5000] , Step [160/488] , Loss: 0.0321453399956226 \n",
      "Epoch [104/5000] , Step [170/488] , Loss: 0.0326222702860832 \n",
      "Epoch [104/5000] , Step [180/488] , Loss: 0.0321094170212746 \n",
      "Epoch [104/5000] , Step [190/488] , Loss: 0.0327392481267452 \n",
      "Epoch [104/5000] , Step [200/488] , Loss: 0.0326202958822250 \n",
      "Epoch [104/5000] , Step [210/488] , Loss: 0.0328829027712345 \n",
      "Epoch [104/5000] , Step [220/488] , Loss: 0.0318350270390511 \n",
      "Epoch [104/5000] , Step [230/488] , Loss: 0.0326870903372765 \n",
      "Epoch [104/5000] , Step [240/488] , Loss: 0.0324997119605541 \n",
      "Epoch [104/5000] , Step [250/488] , Loss: 0.0317068025469780 \n",
      "Epoch [104/5000] , Step [260/488] , Loss: 0.0321666263043880 \n",
      "Epoch [104/5000] , Step [270/488] , Loss: 0.0325608104467392 \n",
      "Epoch [104/5000] , Step [280/488] , Loss: 0.0332249216735363 \n",
      "Epoch [104/5000] , Step [290/488] , Loss: 0.0323051251471043 \n",
      "Epoch [104/5000] , Step [300/488] , Loss: 0.0324723236262798 \n",
      "Epoch [104/5000] , Step [310/488] , Loss: 0.0323947928845882 \n",
      "Epoch [104/5000] , Step [320/488] , Loss: 0.0324477218091488 \n",
      "Epoch [104/5000] , Step [330/488] , Loss: 0.0330769680440426 \n",
      "Epoch [104/5000] , Step [340/488] , Loss: 0.0328846201300621 \n",
      "Epoch [104/5000] , Step [350/488] , Loss: 0.0323917269706726 \n",
      "Epoch [104/5000] , Step [360/488] , Loss: 0.0324570387601852 \n",
      "Epoch [104/5000] , Step [370/488] , Loss: 0.0324421525001526 \n",
      "Epoch [104/5000] , Step [380/488] , Loss: 0.0329626761376858 \n",
      "Epoch [104/5000] , Step [390/488] , Loss: 0.0328351594507694 \n",
      "Epoch [104/5000] , Step [400/488] , Loss: 0.0321952179074287 \n",
      "Epoch [104/5000] , Step [410/488] , Loss: 0.0325370617210865 \n",
      "Epoch [104/5000] , Step [420/488] , Loss: 0.0329590886831284 \n",
      "Epoch [104/5000] , Step [430/488] , Loss: 0.0324015803635120 \n",
      "Epoch [104/5000] , Step [440/488] , Loss: 0.0323607847094536 \n",
      "Epoch [104/5000] , Step [450/488] , Loss: 0.0329364463686943 \n",
      "Epoch [104/5000] , Step [460/488] , Loss: 0.0326240472495556 \n",
      "Epoch [104/5000] , Step [470/488] , Loss: 0.0328409299254417 \n",
      "Epoch [104/5000] , Step [480/488] , Loss: 0.0322455987334251 \n",
      "Epoch [105/5000] , Step [10/488] , Loss: 0.0325461477041245 \n",
      "Epoch [105/5000] , Step [20/488] , Loss: 0.0328348949551582 \n",
      "Epoch [105/5000] , Step [30/488] , Loss: 0.0332378745079041 \n",
      "Epoch [105/5000] , Step [40/488] , Loss: 0.0327827073633671 \n",
      "Epoch [105/5000] , Step [50/488] , Loss: 0.0326757989823818 \n",
      "Epoch [105/5000] , Step [60/488] , Loss: 0.0326820090413094 \n",
      "Epoch [105/5000] , Step [70/488] , Loss: 0.0324801318347454 \n",
      "Epoch [105/5000] , Step [80/488] , Loss: 0.0323325097560883 \n",
      "Epoch [105/5000] , Step [90/488] , Loss: 0.0330394729971886 \n",
      "Epoch [105/5000] , Step [100/488] , Loss: 0.0325330719351768 \n",
      "Epoch [105/5000] , Step [110/488] , Loss: 0.0328312888741493 \n",
      "Epoch [105/5000] , Step [120/488] , Loss: 0.0331392288208008 \n",
      "Epoch [105/5000] , Step [130/488] , Loss: 0.0327795557677746 \n",
      "Epoch [105/5000] , Step [140/488] , Loss: 0.0318670682609081 \n",
      "Epoch [105/5000] , Step [150/488] , Loss: 0.0323353596031666 \n",
      "Epoch [105/5000] , Step [160/488] , Loss: 0.0322602912783623 \n",
      "Epoch [105/5000] , Step [170/488] , Loss: 0.0327136479318142 \n",
      "Epoch [105/5000] , Step [180/488] , Loss: 0.0326861776411533 \n",
      "Epoch [105/5000] , Step [190/488] , Loss: 0.0323088467121124 \n",
      "Epoch [105/5000] , Step [200/488] , Loss: 0.0320069380104542 \n",
      "Epoch [105/5000] , Step [210/488] , Loss: 0.0320182852447033 \n",
      "Epoch [105/5000] , Step [220/488] , Loss: 0.0322147607803345 \n",
      "Epoch [105/5000] , Step [230/488] , Loss: 0.0321251340210438 \n",
      "Epoch [105/5000] , Step [240/488] , Loss: 0.0320010110735893 \n",
      "Epoch [105/5000] , Step [250/488] , Loss: 0.0324074588716030 \n",
      "Epoch [105/5000] , Step [260/488] , Loss: 0.0327593386173248 \n",
      "Epoch [105/5000] , Step [270/488] , Loss: 0.0331045612692833 \n",
      "Epoch [105/5000] , Step [280/488] , Loss: 0.0321731641888618 \n",
      "Epoch [105/5000] , Step [290/488] , Loss: 0.0330337546765804 \n",
      "Epoch [105/5000] , Step [300/488] , Loss: 0.0325823239982128 \n",
      "Epoch [105/5000] , Step [310/488] , Loss: 0.0328472964465618 \n",
      "Epoch [105/5000] , Step [320/488] , Loss: 0.0327091030776501 \n",
      "Epoch [105/5000] , Step [330/488] , Loss: 0.0324031375348568 \n",
      "Epoch [105/5000] , Step [340/488] , Loss: 0.0322050489485264 \n",
      "Epoch [105/5000] , Step [350/488] , Loss: 0.0323908105492592 \n",
      "Epoch [105/5000] , Step [360/488] , Loss: 0.0320682451128960 \n",
      "Epoch [105/5000] , Step [370/488] , Loss: 0.0323660746216774 \n",
      "Epoch [105/5000] , Step [380/488] , Loss: 0.0320677272975445 \n",
      "Epoch [105/5000] , Step [390/488] , Loss: 0.0323804058134556 \n",
      "Epoch [105/5000] , Step [400/488] , Loss: 0.0322771780192852 \n",
      "Epoch [105/5000] , Step [410/488] , Loss: 0.0327829346060753 \n",
      "Epoch [105/5000] , Step [420/488] , Loss: 0.0321672149002552 \n",
      "Epoch [105/5000] , Step [430/488] , Loss: 0.0324584841728210 \n",
      "Epoch [105/5000] , Step [440/488] , Loss: 0.0332544408738613 \n",
      "Epoch [105/5000] , Step [450/488] , Loss: 0.0329716503620148 \n",
      "Epoch [105/5000] , Step [460/488] , Loss: 0.0320926569402218 \n",
      "Epoch [105/5000] , Step [470/488] , Loss: 0.0322387851774693 \n",
      "Epoch [105/5000] , Step [480/488] , Loss: 0.0330911539494991 \n",
      "Epoch [106/5000] , Step [10/488] , Loss: 0.0320920124650002 \n",
      "Epoch [106/5000] , Step [20/488] , Loss: 0.0323366299271584 \n",
      "Epoch [106/5000] , Step [30/488] , Loss: 0.0328887663781643 \n",
      "Epoch [106/5000] , Step [40/488] , Loss: 0.0326229818165302 \n",
      "Epoch [106/5000] , Step [50/488] , Loss: 0.0331863090395927 \n",
      "Epoch [106/5000] , Step [60/488] , Loss: 0.0320339649915695 \n",
      "Epoch [106/5000] , Step [70/488] , Loss: 0.0327135697007179 \n",
      "Epoch [106/5000] , Step [80/488] , Loss: 0.0318404547870159 \n",
      "Epoch [106/5000] , Step [90/488] , Loss: 0.0320357196033001 \n",
      "Epoch [106/5000] , Step [100/488] , Loss: 0.0328347012400627 \n",
      "Epoch [106/5000] , Step [110/488] , Loss: 0.0324806571006775 \n",
      "Epoch [106/5000] , Step [120/488] , Loss: 0.0322740115225315 \n",
      "Epoch [106/5000] , Step [130/488] , Loss: 0.0322332568466663 \n",
      "Epoch [106/5000] , Step [140/488] , Loss: 0.0326890647411346 \n",
      "Epoch [106/5000] , Step [150/488] , Loss: 0.0325529091060162 \n",
      "Epoch [106/5000] , Step [160/488] , Loss: 0.0324847213923931 \n",
      "Epoch [106/5000] , Step [170/488] , Loss: 0.0326662138104439 \n",
      "Epoch [106/5000] , Step [180/488] , Loss: 0.0325712189078331 \n",
      "Epoch [106/5000] , Step [190/488] , Loss: 0.0327972844243050 \n",
      "Epoch [106/5000] , Step [200/488] , Loss: 0.0321907363831997 \n",
      "Epoch [106/5000] , Step [210/488] , Loss: 0.0326193049550056 \n",
      "Epoch [106/5000] , Step [220/488] , Loss: 0.0327881872653961 \n",
      "Epoch [106/5000] , Step [230/488] , Loss: 0.0320114940404892 \n",
      "Epoch [106/5000] , Step [240/488] , Loss: 0.0326450839638710 \n",
      "Epoch [106/5000] , Step [250/488] , Loss: 0.0322700589895248 \n",
      "Epoch [106/5000] , Step [260/488] , Loss: 0.0325360260903835 \n",
      "Epoch [106/5000] , Step [270/488] , Loss: 0.0328846573829651 \n",
      "Epoch [106/5000] , Step [280/488] , Loss: 0.0329919122159481 \n",
      "Epoch [106/5000] , Step [290/488] , Loss: 0.0326248817145824 \n",
      "Epoch [106/5000] , Step [300/488] , Loss: 0.0329501889646053 \n",
      "Epoch [106/5000] , Step [310/488] , Loss: 0.0328294076025486 \n",
      "Epoch [106/5000] , Step [320/488] , Loss: 0.0318618714809418 \n",
      "Epoch [106/5000] , Step [330/488] , Loss: 0.0325522348284721 \n",
      "Epoch [106/5000] , Step [340/488] , Loss: 0.0329367481172085 \n",
      "Epoch [106/5000] , Step [350/488] , Loss: 0.0328059718012810 \n",
      "Epoch [106/5000] , Step [360/488] , Loss: 0.0324922762811184 \n",
      "Epoch [106/5000] , Step [370/488] , Loss: 0.0330811329185963 \n",
      "Epoch [106/5000] , Step [380/488] , Loss: 0.0319809466600418 \n",
      "Epoch [106/5000] , Step [390/488] , Loss: 0.0321024358272552 \n",
      "Epoch [106/5000] , Step [400/488] , Loss: 0.0332990847527981 \n",
      "Epoch [106/5000] , Step [410/488] , Loss: 0.0325397141277790 \n",
      "Epoch [106/5000] , Step [420/488] , Loss: 0.0325038544833660 \n",
      "Epoch [106/5000] , Step [430/488] , Loss: 0.0329895503818989 \n",
      "Epoch [106/5000] , Step [440/488] , Loss: 0.0327509902417660 \n",
      "Epoch [106/5000] , Step [450/488] , Loss: 0.0324011743068695 \n",
      "Epoch [106/5000] , Step [460/488] , Loss: 0.0325869061052799 \n",
      "Epoch [106/5000] , Step [470/488] , Loss: 0.0322987437248230 \n",
      "Epoch [106/5000] , Step [480/488] , Loss: 0.0320663936436176 \n",
      "Epoch [107/5000] , Step [10/488] , Loss: 0.0319252386689186 \n",
      "Epoch [107/5000] , Step [20/488] , Loss: 0.0318158082664013 \n",
      "Epoch [107/5000] , Step [30/488] , Loss: 0.0323098301887512 \n",
      "Epoch [107/5000] , Step [40/488] , Loss: 0.0328618660569191 \n",
      "Epoch [107/5000] , Step [50/488] , Loss: 0.0323070250451565 \n",
      "Epoch [107/5000] , Step [60/488] , Loss: 0.0326633863151073 \n",
      "Epoch [107/5000] , Step [70/488] , Loss: 0.0322000049054623 \n",
      "Epoch [107/5000] , Step [80/488] , Loss: 0.0321651846170425 \n",
      "Epoch [107/5000] , Step [90/488] , Loss: 0.0323188118636608 \n",
      "Epoch [107/5000] , Step [100/488] , Loss: 0.0319020040333271 \n",
      "Epoch [107/5000] , Step [110/488] , Loss: 0.0323523953557014 \n",
      "Epoch [107/5000] , Step [120/488] , Loss: 0.0324977412819862 \n",
      "Epoch [107/5000] , Step [130/488] , Loss: 0.0321898572146893 \n",
      "Epoch [107/5000] , Step [140/488] , Loss: 0.0319629162549973 \n",
      "Epoch [107/5000] , Step [150/488] , Loss: 0.0329082459211349 \n",
      "Epoch [107/5000] , Step [160/488] , Loss: 0.0326206721365452 \n",
      "Epoch [107/5000] , Step [170/488] , Loss: 0.0330294594168663 \n",
      "Epoch [107/5000] , Step [180/488] , Loss: 0.0326371639966965 \n",
      "Epoch [107/5000] , Step [190/488] , Loss: 0.0321969538927078 \n",
      "Epoch [107/5000] , Step [200/488] , Loss: 0.0326471440494061 \n",
      "Epoch [107/5000] , Step [210/488] , Loss: 0.0333703160285950 \n",
      "Epoch [107/5000] , Step [220/488] , Loss: 0.0325560159981251 \n",
      "Epoch [107/5000] , Step [230/488] , Loss: 0.0324625857174397 \n",
      "Epoch [107/5000] , Step [240/488] , Loss: 0.0327529124915600 \n",
      "Epoch [107/5000] , Step [250/488] , Loss: 0.0324071682989597 \n",
      "Epoch [107/5000] , Step [260/488] , Loss: 0.0324051976203918 \n",
      "Epoch [107/5000] , Step [270/488] , Loss: 0.0321604087948799 \n",
      "Epoch [107/5000] , Step [280/488] , Loss: 0.0317479036748409 \n",
      "Epoch [107/5000] , Step [290/488] , Loss: 0.0326022468507290 \n",
      "Epoch [107/5000] , Step [300/488] , Loss: 0.0328023768961430 \n",
      "Epoch [107/5000] , Step [310/488] , Loss: 0.0327364020049572 \n",
      "Epoch [107/5000] , Step [320/488] , Loss: 0.0324947908520699 \n",
      "Epoch [107/5000] , Step [330/488] , Loss: 0.0321798883378506 \n",
      "Epoch [107/5000] , Step [340/488] , Loss: 0.0319869033992290 \n",
      "Epoch [107/5000] , Step [350/488] , Loss: 0.0325914435088634 \n",
      "Epoch [107/5000] , Step [360/488] , Loss: 0.0326979346573353 \n",
      "Epoch [107/5000] , Step [370/488] , Loss: 0.0331371277570724 \n",
      "Epoch [107/5000] , Step [380/488] , Loss: 0.0319141075015068 \n",
      "Epoch [107/5000] , Step [390/488] , Loss: 0.0322212576866150 \n",
      "Epoch [107/5000] , Step [400/488] , Loss: 0.0324532426893711 \n",
      "Epoch [107/5000] , Step [410/488] , Loss: 0.0330921933054924 \n",
      "Epoch [107/5000] , Step [420/488] , Loss: 0.0330149307847023 \n",
      "Epoch [107/5000] , Step [430/488] , Loss: 0.0317395105957985 \n",
      "Epoch [107/5000] , Step [440/488] , Loss: 0.0325128398835659 \n",
      "Epoch [107/5000] , Step [450/488] , Loss: 0.0329940021038055 \n",
      "Epoch [107/5000] , Step [460/488] , Loss: 0.0322477146983147 \n",
      "Epoch [107/5000] , Step [470/488] , Loss: 0.0327210202813148 \n",
      "Epoch [107/5000] , Step [480/488] , Loss: 0.0325328893959522 \n",
      "Epoch [108/5000] , Step [10/488] , Loss: 0.0321103557944298 \n",
      "Epoch [108/5000] , Step [20/488] , Loss: 0.0331788361072540 \n",
      "Epoch [108/5000] , Step [30/488] , Loss: 0.0325492881238461 \n",
      "Epoch [108/5000] , Step [40/488] , Loss: 0.0329011753201485 \n",
      "Epoch [108/5000] , Step [50/488] , Loss: 0.0325623899698257 \n",
      "Epoch [108/5000] , Step [60/488] , Loss: 0.0320307612419128 \n",
      "Epoch [108/5000] , Step [70/488] , Loss: 0.0326647758483887 \n",
      "Epoch [108/5000] , Step [80/488] , Loss: 0.0323193557560444 \n",
      "Epoch [108/5000] , Step [90/488] , Loss: 0.0320031382143497 \n",
      "Epoch [108/5000] , Step [100/488] , Loss: 0.0318503342568874 \n",
      "Epoch [108/5000] , Step [110/488] , Loss: 0.0324611403048038 \n",
      "Epoch [108/5000] , Step [120/488] , Loss: 0.0324982218444347 \n",
      "Epoch [108/5000] , Step [130/488] , Loss: 0.0330564342439175 \n",
      "Epoch [108/5000] , Step [140/488] , Loss: 0.0320920795202255 \n",
      "Epoch [108/5000] , Step [150/488] , Loss: 0.0333529710769653 \n",
      "Epoch [108/5000] , Step [160/488] , Loss: 0.0323532447218895 \n",
      "Epoch [108/5000] , Step [170/488] , Loss: 0.0319509953260422 \n",
      "Epoch [108/5000] , Step [180/488] , Loss: 0.0321610048413277 \n",
      "Epoch [108/5000] , Step [190/488] , Loss: 0.0321599729359150 \n",
      "Epoch [108/5000] , Step [200/488] , Loss: 0.0323769114911556 \n",
      "Epoch [108/5000] , Step [210/488] , Loss: 0.0320512168109417 \n",
      "Epoch [108/5000] , Step [220/488] , Loss: 0.0326919741928577 \n",
      "Epoch [108/5000] , Step [230/488] , Loss: 0.0327219776809216 \n",
      "Epoch [108/5000] , Step [240/488] , Loss: 0.0325292199850082 \n",
      "Epoch [108/5000] , Step [250/488] , Loss: 0.0322922393679619 \n",
      "Epoch [108/5000] , Step [260/488] , Loss: 0.0334120504558086 \n",
      "Epoch [108/5000] , Step [270/488] , Loss: 0.0331790484488010 \n",
      "Epoch [108/5000] , Step [280/488] , Loss: 0.0327872484922409 \n",
      "Epoch [108/5000] , Step [290/488] , Loss: 0.0320132039487362 \n",
      "Epoch [108/5000] , Step [300/488] , Loss: 0.0322486795485020 \n",
      "Epoch [108/5000] , Step [310/488] , Loss: 0.0323286280035973 \n",
      "Epoch [108/5000] , Step [320/488] , Loss: 0.0323961973190308 \n",
      "Epoch [108/5000] , Step [330/488] , Loss: 0.0323599688708782 \n",
      "Epoch [108/5000] , Step [340/488] , Loss: 0.0329192876815796 \n",
      "Epoch [108/5000] , Step [350/488] , Loss: 0.0325130447745323 \n",
      "Epoch [108/5000] , Step [360/488] , Loss: 0.0326189063489437 \n",
      "Epoch [108/5000] , Step [370/488] , Loss: 0.0325262323021889 \n",
      "Epoch [108/5000] , Step [380/488] , Loss: 0.0329477228224277 \n",
      "Epoch [108/5000] , Step [390/488] , Loss: 0.0318808965384960 \n",
      "Epoch [108/5000] , Step [400/488] , Loss: 0.0327951312065125 \n",
      "Epoch [108/5000] , Step [410/488] , Loss: 0.0327031835913658 \n",
      "Epoch [108/5000] , Step [420/488] , Loss: 0.0326285846531391 \n",
      "Epoch [108/5000] , Step [430/488] , Loss: 0.0319478400051594 \n",
      "Epoch [108/5000] , Step [440/488] , Loss: 0.0329292453825474 \n",
      "Epoch [108/5000] , Step [450/488] , Loss: 0.0328499302268028 \n",
      "Epoch [108/5000] , Step [460/488] , Loss: 0.0322851724922657 \n",
      "Epoch [108/5000] , Step [470/488] , Loss: 0.0326220020651817 \n",
      "Epoch [108/5000] , Step [480/488] , Loss: 0.0316333882510662 \n",
      "Epoch [109/5000] , Step [10/488] , Loss: 0.0323138423264027 \n",
      "Epoch [109/5000] , Step [20/488] , Loss: 0.0321974828839302 \n",
      "Epoch [109/5000] , Step [30/488] , Loss: 0.0324459858238697 \n",
      "Epoch [109/5000] , Step [40/488] , Loss: 0.0329109020531178 \n",
      "Epoch [109/5000] , Step [50/488] , Loss: 0.0320814214646816 \n",
      "Epoch [109/5000] , Step [60/488] , Loss: 0.0328932590782642 \n",
      "Epoch [109/5000] , Step [70/488] , Loss: 0.0328348129987717 \n",
      "Epoch [109/5000] , Step [80/488] , Loss: 0.0326047651469707 \n",
      "Epoch [109/5000] , Step [90/488] , Loss: 0.0321873947978020 \n",
      "Epoch [109/5000] , Step [100/488] , Loss: 0.0323109962046146 \n",
      "Epoch [109/5000] , Step [110/488] , Loss: 0.0327093563973904 \n",
      "Epoch [109/5000] , Step [120/488] , Loss: 0.0326345004141331 \n",
      "Epoch [109/5000] , Step [130/488] , Loss: 0.0322582982480526 \n",
      "Epoch [109/5000] , Step [140/488] , Loss: 0.0320549197494984 \n",
      "Epoch [109/5000] , Step [150/488] , Loss: 0.0328208133578300 \n",
      "Epoch [109/5000] , Step [160/488] , Loss: 0.0320678986608982 \n",
      "Epoch [109/5000] , Step [170/488] , Loss: 0.0315238684415817 \n",
      "Epoch [109/5000] , Step [180/488] , Loss: 0.0322493165731430 \n",
      "Epoch [109/5000] , Step [190/488] , Loss: 0.0323232710361481 \n",
      "Epoch [109/5000] , Step [200/488] , Loss: 0.0329565480351448 \n",
      "Epoch [109/5000] , Step [210/488] , Loss: 0.0327445603907108 \n",
      "Epoch [109/5000] , Step [220/488] , Loss: 0.0325615257024765 \n",
      "Epoch [109/5000] , Step [230/488] , Loss: 0.0331171564757824 \n",
      "Epoch [109/5000] , Step [240/488] , Loss: 0.0324774868786335 \n",
      "Epoch [109/5000] , Step [250/488] , Loss: 0.0327924154698849 \n",
      "Epoch [109/5000] , Step [260/488] , Loss: 0.0327885113656521 \n",
      "Epoch [109/5000] , Step [270/488] , Loss: 0.0321495085954666 \n",
      "Epoch [109/5000] , Step [280/488] , Loss: 0.0323959216475487 \n",
      "Epoch [109/5000] , Step [290/488] , Loss: 0.0325095094740391 \n",
      "Epoch [109/5000] , Step [300/488] , Loss: 0.0325630418956280 \n",
      "Epoch [109/5000] , Step [310/488] , Loss: 0.0322458185255527 \n",
      "Epoch [109/5000] , Step [320/488] , Loss: 0.0323189496994019 \n",
      "Epoch [109/5000] , Step [330/488] , Loss: 0.0325369760394096 \n",
      "Epoch [109/5000] , Step [340/488] , Loss: 0.0329257920384407 \n",
      "Epoch [109/5000] , Step [350/488] , Loss: 0.0326906330883503 \n",
      "Epoch [109/5000] , Step [360/488] , Loss: 0.0326615162193775 \n",
      "Epoch [109/5000] , Step [370/488] , Loss: 0.0323984548449516 \n",
      "Epoch [109/5000] , Step [380/488] , Loss: 0.0328097492456436 \n",
      "Epoch [109/5000] , Step [390/488] , Loss: 0.0325593985617161 \n",
      "Epoch [109/5000] , Step [400/488] , Loss: 0.0323562435805798 \n",
      "Epoch [109/5000] , Step [410/488] , Loss: 0.0328958742320538 \n",
      "Epoch [109/5000] , Step [420/488] , Loss: 0.0331199392676353 \n",
      "Epoch [109/5000] , Step [430/488] , Loss: 0.0322286114096642 \n",
      "Epoch [109/5000] , Step [440/488] , Loss: 0.0324555598199368 \n",
      "Epoch [109/5000] , Step [450/488] , Loss: 0.0318907871842384 \n",
      "Epoch [109/5000] , Step [460/488] , Loss: 0.0326271168887615 \n",
      "Epoch [109/5000] , Step [470/488] , Loss: 0.0325335673987865 \n",
      "Epoch [109/5000] , Step [480/488] , Loss: 0.0327608101069927 \n",
      "Epoch [110/5000] , Step [10/488] , Loss: 0.0323133841156960 \n",
      "Epoch [110/5000] , Step [20/488] , Loss: 0.0318174958229065 \n",
      "Epoch [110/5000] , Step [30/488] , Loss: 0.0330955125391483 \n",
      "Epoch [110/5000] , Step [40/488] , Loss: 0.0322470515966415 \n",
      "Epoch [110/5000] , Step [50/488] , Loss: 0.0321190766990185 \n",
      "Epoch [110/5000] , Step [60/488] , Loss: 0.0323524586856365 \n",
      "Epoch [110/5000] , Step [70/488] , Loss: 0.0329617150127888 \n",
      "Epoch [110/5000] , Step [80/488] , Loss: 0.0323249548673630 \n",
      "Epoch [110/5000] , Step [90/488] , Loss: 0.0320492275059223 \n",
      "Epoch [110/5000] , Step [100/488] , Loss: 0.0326104201376438 \n",
      "Epoch [110/5000] , Step [110/488] , Loss: 0.0322199426591396 \n",
      "Epoch [110/5000] , Step [120/488] , Loss: 0.0329576879739761 \n",
      "Epoch [110/5000] , Step [130/488] , Loss: 0.0323513336479664 \n",
      "Epoch [110/5000] , Step [140/488] , Loss: 0.0324296429753304 \n",
      "Epoch [110/5000] , Step [150/488] , Loss: 0.0324808657169342 \n",
      "Epoch [110/5000] , Step [160/488] , Loss: 0.0320953503251076 \n",
      "Epoch [110/5000] , Step [170/488] , Loss: 0.0325576364994049 \n",
      "Epoch [110/5000] , Step [180/488] , Loss: 0.0321168340742588 \n",
      "Epoch [110/5000] , Step [190/488] , Loss: 0.0330523811280727 \n",
      "Epoch [110/5000] , Step [200/488] , Loss: 0.0325081385672092 \n",
      "Epoch [110/5000] , Step [210/488] , Loss: 0.0321946665644646 \n",
      "Epoch [110/5000] , Step [220/488] , Loss: 0.0330019965767860 \n",
      "Epoch [110/5000] , Step [230/488] , Loss: 0.0327667705714703 \n",
      "Epoch [110/5000] , Step [240/488] , Loss: 0.0320635251700878 \n",
      "Epoch [110/5000] , Step [250/488] , Loss: 0.0330706983804703 \n",
      "Epoch [110/5000] , Step [260/488] , Loss: 0.0318294130265713 \n",
      "Epoch [110/5000] , Step [270/488] , Loss: 0.0321934595704079 \n",
      "Epoch [110/5000] , Step [280/488] , Loss: 0.0328505299985409 \n",
      "Epoch [110/5000] , Step [290/488] , Loss: 0.0320930965244770 \n",
      "Epoch [110/5000] , Step [300/488] , Loss: 0.0330186672508717 \n",
      "Epoch [110/5000] , Step [310/488] , Loss: 0.0326845608651638 \n",
      "Epoch [110/5000] , Step [320/488] , Loss: 0.0322751589119434 \n",
      "Epoch [110/5000] , Step [330/488] , Loss: 0.0322363339364529 \n",
      "Epoch [110/5000] , Step [340/488] , Loss: 0.0323052741587162 \n",
      "Epoch [110/5000] , Step [350/488] , Loss: 0.0328773669898510 \n",
      "Epoch [110/5000] , Step [360/488] , Loss: 0.0322350636124611 \n",
      "Epoch [110/5000] , Step [370/488] , Loss: 0.0318665802478790 \n",
      "Epoch [110/5000] , Step [380/488] , Loss: 0.0327419973909855 \n",
      "Epoch [110/5000] , Step [390/488] , Loss: 0.0326611846685410 \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i , (input_init_conditions,input_x_loc,input_time,Actual_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      5\u001b[0m     input1 \u001b[38;5;241m=\u001b[39m input_init_conditions\n\u001b[1;32m----> 6\u001b[0m     input1 \u001b[38;5;241m=\u001b[39m \u001b[43minput1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     input2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((input_x_loc,input_time),\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m     input2 \u001b[38;5;241m=\u001b[39m input2\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i , (input_init_conditions,input_x_loc,input_time,Actual_y) in enumerate(train_loader):\n",
    "        input1 = input_init_conditions\n",
    "        input1 = input1.to(device)\n",
    "\n",
    "        input2 = torch.cat((input_x_loc,input_time),-1)\n",
    "        input2 = input2.to(device)\n",
    "\n",
    "        Actual_y = Actual_y.to(device)\n",
    "        input_time.to(device)\n",
    "\n",
    "        Outputs = model(input1,input2)\n",
    "\n",
    "        #input2_BC1 = torch.cat((torch.zeros(input_time.size(0),1),input_time),-1).to(device)\n",
    "        #target_BC1 = torch.zeros(input_time.size(0),device=device)#.to(device)\n",
    "        #predicted_BC1 = model(input1,input2_BC1)\n",
    "        #loss_BC1 = torch.mean((predicted_BC1-target_BC1)**2)\n",
    "\n",
    "        #input2_BC2 = torch.cat((torch.ones(input_time.size(0),1),input_time),-1).to(device)\n",
    "        #target_BC2 = torch.zeros(input_time.size(0),device=device) #.to(device)\n",
    "        #predicted_BC2 = model(input1,input2_BC2)\n",
    "        #loss_BC2 = torch.mean((predicted_BC2-target_BC2)**2)\n",
    "\n",
    "        #Physics_loss = Physics_loss_Burgers(input1,input_time,x_locations_for_computation)\n",
    "        \n",
    "        loss = criterion(Outputs.unsqueeze(-1),Actual_y) # + (loss_BC1 + loss_BC2) + # 0.01*Physics_loss.abs()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimiser.step()    \n",
    "        optimiser.zero_grad()\n",
    "        loss_rec.append(loss.item())\n",
    "\n",
    "        if (i+1) % 10 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoch}] , Step [{i+1}/{total_samples}] , Loss: {loss.item():.16f} ')#, Physics loss : {Physics_loss.item():.16f}')\n",
    "            #y_locations_test = model(input1[1],input2_physics)\n",
    "            #plt.plot(x_locations.detach().numpy(),y_locations_test.detach().numpy())\n",
    "\n",
    "        if i == 10:\n",
    "            torch.save(model.state_dict(),\"model_burgers_5.pt\")\n",
    "            #plt.plot(loss_rec)#[1000:])\n",
    "            #plt.grid()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outputs.size()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model_burgers_5.pt\") #this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2246e-16,  3.1416e-03,  6.2831e-03,  ..., -6.2831e-03,\n",
       "         -3.1416e-03, -1.2246e-16],\n",
       "        [ 1.2246e-16,  3.1416e-03,  6.2831e-03,  ..., -6.2831e-03,\n",
       "         -3.1416e-03, -1.2246e-16],\n",
       "        [ 1.2246e-16,  3.1416e-03,  6.2831e-03,  ..., -6.2831e-03,\n",
       "         -3.1416e-03, -1.2246e-16],\n",
       "        ...,\n",
       "        [ 1.2246e-16,  3.1416e-03,  6.2831e-03,  ..., -6.2831e-03,\n",
       "         -3.1416e-03, -1.2246e-16],\n",
       "        [ 1.2246e-16,  3.1416e-03,  6.2831e-03,  ..., -6.2831e-03,\n",
       "         -3.1416e-03, -1.2246e-16],\n",
       "        [ 1.2246e-16,  3.1416e-03,  6.2831e-03,  ..., -6.2831e-03,\n",
       "         -3.1416e-03, -1.2246e-16]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[1].expand(100,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_input_physics = torch.tensor(0.1)\n",
    "time_input = time_input_physics*torch.ones_like(x_locations,dtype=torch.float32).requires_grad_(True)\n",
    "x_locations = torch.linspace(-1,1,300,dtype=torch.float32).requires_grad_(True)\n",
    "input2_physics = torch.cat((x_locations.unsqueeze(-1),time_input.unsqueeze(-1)),-1)\n",
    "#print(input2_physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28295d87ef0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_x_loc = torch.linspace(-1,1,201)\n",
    "test_output_loc = torch.linspace(-1,1,201)\n",
    "test_model_input = -1*torch.sin(np.pi*test_x_loc)\n",
    "plt.plot(test_x_loc,test_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_locations_test = model((input1[1].to(device)).expand(len(input2_physics),-1),input2_physics.to(device))\n",
    "time_asked = 0.9\n",
    "test_input_2 = torch.concat([test_output_loc.unsqueeze(-1) ,time_asked*torch.ones_like(test_output_loc).unsqueeze(-1)],dim=1)\n",
    "y_locations_test = model((test_model_input.to(device)),test_input_2.to(device))\n",
    "plt.plot(test_output_loc.cpu().detach().numpy(),y_locations_test.cpu().detach().numpy()) \n",
    "plt.grid()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_time.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2_BC1 = torch.cat((torch.zeros(input_time.size(0),1),input_time),-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_BC1 = torch.zeros(input_time.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABe+ElEQVR4nO3deVxU5f4H8M+wIwKKC4gLghsmKgqpWKhpYmBmyy21MjPzZmYu1L253DLNX9itvOY1NcsstavW1bYbKbhrYibirriLKIig7AoDnN8fxDjDbGdmzmyHz/v18vWSM8+c8zxzzpz5nmdVCIIggIiIiMjJudg7A0RERERSYFBDREREssCghoiIiGSBQQ0RERHJAoMaIiIikgUGNURERCQLDGqIiIhIFhjUEBERkSy42TsDtlRTU4Pr16/D19cXCoXC3tkhIiIiEQRBQElJCYKDg+Hior8+pkEFNdevX0fbtm3tnQ0iIiIyw9WrV9GmTRu9rzeooMbX1xdA7Yfi5+cn2X6VSiVSUlIQFxcHd3d3yfbr6FjuhlPuhlhmgOVuSOVuiGUGnKfcxcXFaNu2rep3XJ8GFdTUNTn5+flJHtQ0atQIfn5+Dn1RSI3lbjjlbohlBljuhlTuhlhmwPnKbazrCDsKExERkSwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0RERHJAoMaIiIikgWzgpply5YhNDQUXl5eiIqKwt69ew2m3717N6KiouDl5YWwsDCsWLFC4/XNmzcjOjoaTZo0gY+PDyIjI7F27VqNNO+++y4UCoXGv6CgIHOyT0RERDJkclCzceNGTJ8+HXPmzEFGRgZiY2MRHx+PrKwsnekvXbqEhIQExMbGIiMjA7Nnz8bUqVOxadMmVZqAgADMmTMHaWlpOHbsGMaPH4/x48dj69atGvvq1q0bcnJyVP+OHz9uavaJiIhIpkyefG/RokWYMGECXn75ZQDA4sWLsXXrVixfvhxJSUla6VesWIF27dph8eLFAICuXbvi0KFD+Oijj/DUU08BAAYNGqTxnmnTpuHrr7/Gvn37MGzYsHuZdXNj7QwRERHpZFJQU1lZifT0dMycOVNje1xcHPbv36/zPWlpaYiLi9PYNmzYMKxatQpKpVJrBkNBELBjxw5kZmbigw8+0Hjt3LlzCA4OhqenJ/r27Yv3338fYWFhevNbUVGBiooK1d/FxcUAamdQVCqVxgssUt2+pNynM2C5G065G2KZAZa7IZW7IZYZcJ5yi82fSUFNfn4+qqurERgYqLE9MDAQubm5Ot+Tm5urM31VVRXy8/PRqlUrAEBRURFat26NiooKuLq6YtmyZRg6dKjqPX379sWaNWvQuXNn3LhxAwsWLED//v1x8uRJNGvWTOexk5KSMG/ePK3tKSkpaNSokSlFFyU1NVXyfToDlrvhaIhlBljuhqQhlhlw/HKXl5eLSmfW2k/1114QBMHgegy60tff7uvriyNHjqC0tBTbt29HYmIiwsLCVE1T8fHxqrTdu3dHTEwMOnTogK+//hqJiYk6jztr1iyN1+oWxIqLi5N87afU1FQMHTrUKdbOkArL3XDK3RDLDLDcDancDbHMgPOUu66lxRiTgprmzZvD1dVVq1YmLy9PqzamTlBQkM70bm5uGjUsLi4u6NixIwAgMjISp0+fRlJSklZ/mzo+Pj7o3r07zp07pze/np6e8PT01Nru7u5ulZNnrf06Opa74WiIZQZY7oZErmX+8cg1+Hm746EuLXW+7ujlFps3k0Y/eXh4ICoqSquaKjU1Ff3799f5npiYGK30KSkpiI6ONphJQRA0+sPUV1FRgdOnT6uar4iIiEjbtcI7mLbhCMav/sPeWbE6k5ufEhMTMXbsWERHRyMmJgYrV65EVlYWJk2aBKC2yefatWtYs2YNAGDSpElYunQpEhMTMXHiRKSlpWHVqlVYv369ap9JSUmIjo5Ghw4dUFlZieTkZKxZswbLly9XpXnzzTcxYsQItGvXDnl5eViwYAGKi4sxbtw4Sz8DIiIi2Soo1V9BIDcmBzWjRo1CQUEB5s+fj5ycHERERCA5ORkhISEAgJycHI05a0JDQ5GcnIwZM2bg008/RXBwMJYsWaIazg0AZWVlmDx5MrKzs+Ht7Y3w8HCsW7cOo0aNUqXJzs7GmDFjkJ+fjxYtWqBfv344cOCA6rhERETUsJnVUXjy5MmYPHmyzte++uorrW0DBw7E4cOH9e5vwYIFWLBggcFjbtiwwaQ8EhERUcPCtZ+IiIhIFhjUEBERkSwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0REZGM/bkyUYPAoIaIiIhkgUENERERyQKDGiIiIpIFBjVEREQkCwxqiIiISBYY1BAREZEsMKghIiIiWWBQQ0REJGMNaJoaBjVEREQkDwxqiIiISBYY1BAREZEsMKghIiIiWWBQQ0RERLLAoIaIiIhkgUENERERyQKDGiIiIpIFBjVEREQyJggNZ/o9BjVEREQkCwxqiIiISBYY1BAREZEsMKghIiIiWWBQQ0RERLLAoIaIiIhkgUENERERyQKDGpK98sqqBjVPAxFRQ8WghmTt7I0S3PfOVkzdcMTeWSEisouG9EjHoIZk7fM9FwEAPx+9buecEBGRtTGoISIiIllgUENERESywKCGiIiIZIFBDREREckCgxoiIiKSBQY1JGsNaSgjEVFDx6CGiIhIxhrS3KMMaoiIiEgWGNSQKIIg4LkvDuC1bw7bOysNjiAIXOaBiEgEBjUkyoWbZfjtfAF+OZ6Dmhr+wNqKsroG8Z/sxStr0+2dFSIih8egRuZqagRMWpuOf6WetXBP9wIZhcLCXZFoGVmFOJNbgpRTN+ydFSIih8egRub2XyjAlpO5+GT7OXtnxS6cvdWGzU5EROIxqJG5u8pqe2fBrgQO6iYiajAY1BAREZEsMKghIiIiWWBQQ0REJGsNpxmeQQ0REREZVFpRhYRP9kowkta6GNSQXufzSnCt8I69s2EzJ64VYfDHu7D1ZK69s0JE5FDW/56FUznFDj+SlkEN6VRQWoGHF+3BAwt32DsrNvPK2nRcvFnGie6IiOqprK6xdxZEYVBDOl0uKLN3FqRhQlNyeWWV9fJBRERWx6CGdOKcb0RE5GwY1JBOf2UTDBERORkGNaTTrbJKe2eBiIjIJAxqSNbYikZEZDpBEHC98I7TrT/HoIaIiEjGzIlLlu++gP4Ldzj8vDT1MaghkzlZ4K5SU+OkGSfZ+z4jGymcH4kcyD+3ZAIAluw4b+ecmIZBDcmaetVp93e3Yu+5m3bMDZG23KK7mLHxKDvnE0mAQY3MKRSS7UmqHdlNWWU1Xlz9h72zQaSh8A475RNJhUENEcnaf9OzcfDSLXtng4hswM3eGSAispYjVwvx5ndHAQCXFw63c26IyNpYU0NEsnVFLst92MnpnBIcuFhg72wQicaghuhPCuk6IBGpHLlaiMeW7rN7E9jl/DJkFZSb9J7HlqVh9MoDyCm6Y6VcEUmLQQ3JGgdxk72NXpmGY9lFeOazNLvl4U5lNQZ9tAsDPtwJpRmrLV+77dhBjSAIuHrLtICtIWlI90Gzgpply5YhNDQUXl5eiIqKwt69ew2m3717N6KiouDl5YWwsDCsWLFC4/XNmzcjOjoaTZo0gY+PDyIjI7F27Vq9+0tKSoJCocD06dPNyT4Rkc3cVWoGEfaYoVV9hNVdZbXNj29t//jhBGL/uRNrD1yxd1bIzkwOajZu3Ijp06djzpw5yMjIQGxsLOLj45GVlaUz/aVLl5CQkIDY2FhkZGRg9uzZmDp1KjZt2qRKExAQgDlz5iAtLQ3Hjh3D+PHjMX78eGzdulVrf3/88QdWrlyJHj16mJp1skhDivVtx9mmICfLpJzMxf3/tx37z+ertilkMF2CLtcK72Dq+gwcyy60+rG++b329+fjlEyrH4scm8lBzaJFizBhwgS8/PLL6Nq1KxYvXoy2bdti+fLlOtOvWLEC7dq1w+LFi9G1a1e8/PLLeOmll/DRRx+p0gwaNAhPPPEEunbtig4dOmDatGno0aMH9u3bp7Gv0tJSPPfcc/j888/RtGlTU7NOVrLr7E3sOctJ7Ux1o/guHvxgJz7d6VwzdpL5/ro2HfmlFXj2i9/tnRWzFJRWYGdmnqjZuV//z2H8dPQ6Hlv6mw1yJp2iO0r8fPS6LGu0GgKTgprKykqkp6cjLi5OY3tcXBz279+v8z1paWla6YcNG4ZDhw5BqVRqpRcEAdu3b0dmZiYGDBig8dprr72G4cOH4+GHHzYl22RFd6qAiWsz8MKXB1FR5Xg3gfoVIWKfiZftsn6gsXjbWVwrvIMPt/LpkpzDI5/sxfjVf2DjoatG017Md86RZy+vPYzX12dg/v9O2TsrZAaT5qnJz89HdXU1AgMDNbYHBgYiN1f3uiW5ubk601dVVSE/Px+tWrUCABQVFaF169aoqKiAq6srli1bhqFDh6res2HDBhw+fBh//CF+RtiKigpUVFSo/i4uLgYAKJVKnQGVuer2JeU+pVJVfS/QMDd/tZ9XlcbfLi4KKJVKVKjFMWV3KuHi5VhTH9XUaHeK1Pc5qDcF/XNLJiY+EKIznVTnW1l1L2/69lVVXWU0jS3UL7MgCCitqIavnc/3wi2ZSLt4Cxsn9oGXu6vW69UWXv/W/G7X7bOqSqm1TfpjaV5HSu2PSmfe6lRVVUGpVOJmSe39dMuJHPylVyvDO1F7oLDZtStYdp8DgCNXiwAAP2Zcw7xHwyXLmj1VVem/j4i5xpVKpcXfJUuJPaZZd6T6Q18FQTA4HFZX+vrbfX19ceTIEZSWlmL79u1ITExEWFgYBg0ahKtXr2LatGlISUmBl5eX6HwmJSVh3rx5WttTUlLQqFEj0fsRKzU11eJ9CAJQXgX4uEuQIQAnbisA1N7BkpOTAQC55UBZFdDBz9A7710aycnJyC2/ty3511/houN0p6akwMFiGly/7gL1CskaoUb1OdRXWekK9bocfenqWHq+r169lzd9xzpfDKg+dyP5sYW6Mm+44IK0PBe83q0KHfVcR/tyFfg9zwWvdK1GY4mu5/pWpdV+Nu9/k4J+LbWbRI7ka1//5rDsXOv+UtTl57r6d8tK57iw4t4xUlJS4W3i9zQtLQ03Tt7bx828PKN5rVTe+z5Z/9p1+/OYlZIdq6qqym7fuVsVgI8b4Gkk+BTrgoj7iPY1rvkbkJktzXfJXOXl4ka3mXRpN2/eHK6urlq1Mnl5eVq1MXWCgoJ0pndzc0OzZs1U21xcXNCxY0cAQGRkJE6fPo2kpCQMGjQI6enpyMvLQ1RUlCp9dXU19uzZg6VLl6pqd+qbNWsWEhMTVX8XFxejbdu2iIuLg5+fwV90kyiVSqSmpmLo0KFwd7fs7r1wSyZWHbiCJaN6ID4iyOK8eWXexOdnMgAACQkJAIBOb6cAAHYmxqJNU2+d75uWlqL6f0JCAs7nlSLpaG0TY0J8vKqm5rv/3fsiDI2Ls/uTe30ppceAgnvXn4vCBQkJw3SmfffoTpSpPTXXfV71SXW+935/Er/fvAYAuNm0G8bFaNcMHbx8C/8+echgfmyhfpmn/XkNHbrTElNHR+t8T12aM66heCehq1XyVXed3tetOxLub6P1evWxHKw5dxyAeZ+fFOda/bukri4/Z2+U4IOjaWbnUYzc4ruYe3gPAGDo0KHw8zZclrpy14mJiUFUSFNVWVq0bImEhN4G9zH3yE6U//l9sva1W5cvD3cPJCQ8ZNY+6pfZzc1N773Cmq7cKsfD/9oHHw9XHHl7iCT7PHTlNpacrG3lqH8u9F3j9X8Druy+iF+unte5D1uoa2kxxqRfIA8PD0RFRSE1NRVPPPGEantqaipGjhyp8z0xMTH4+eefNbalpKQgOjra4E1CEARV09GQIUNw/PhxjdfHjx+P8PBwvPXWWzoDGgDw9PSEp6en1nZ3d3eLgw9dpNjvqt9qhyTO/fk0bpVXYUjXQLQNML9WyU3ts6mft+yiCoS2NB7c1ZbLTeNvFx1VNe7ublb5XC3h4qLdbUxfHuvXKBori6XnW/0zXJCciZcHdNRK4+aq+bnbW/0yKxQKo/mqqBasnndXV1edx3A1cP2bwhr3jLr9ubnd26+bm5tVJoH0cL/XdOBmRlnc3DS/2y4izrt6BzabXbsKaY9lj+/cgUuFAGoX4FU/vrK6Bu6u5k0t5+Zm/D5i6Bp3d3eX7LtkLrHHNPmxOjExEWPHjkV0dDRiYmKwcuVKZGVlYdKkSQBqa0euXbuGNWvWAAAmTZqEpUuXIjExERMnTkRaWhpWrVqF9evXq/aZlJSE6OhodOjQAZWVtdWHa9asUY2o8vX1RUREhEY+fHx80KxZM63tcnG7XIl3fz6FD7Zk4vR7j5j8/pyiO/j94i2d/QwsxUHIttPQPuvqGgGuuto2yWFl5pbgSkEZ4rpZXrNMup27UYKh/9qDlx4IxTsj7jP5/Q1p5giTg5pRo0ahoKAA8+fPR05ODiIiIpCcnIyQkNqq85ycHI05a0JDQ5GcnIwZM2bg008/RXBwMJYsWYKnnnpKlaasrAyTJ09GdnY2vL29ER4ejnXr1mHUqFESFNG53TFzWOHgj3bjjrIafdoHSJwjspdfj+cgvruRzplO7FrhHQxdtBuj729n1o1bF2dY+sLmWZT4B27Y4tpmrc2T+6N3O9tOtXE46zb+/t9jqr8d/2wbduFmKU5eL9LavnjbOQDAl79dkuy7IVdmdYCYPHkyJk+erPO1r776SmvbwIEDcfjwYb37W7BgARYsWGBSHnbt2mVS+oamLhg6eNl26804+8OAzX9bTPzAXv3msKxXmv5053mUV1bzxu2kMnNLbB7UPP/F7yivdLypJMw15OPd9s6C0+PaTxI5UqDA+bxSe2fDipz9GaiWEzy4y86es/lWX5dHcPqQ2rrketnLKaAhaTCokcDe8/lYfdYV8f+uHR2UkXUbOzPzJD/Ot4eu4u//PYpqEbN56sKZa83niBMLOovc4ruI/edOuxyby1CQuZyh6ZK0MaiRwIlrmkPNnli2H+NX/4Hs29I+nf79v8fw7aFs/O/YdbPeb+2Zax3x96P+j5o56+wcvHQLXf6xBYvU1pXZmq3AI0t+Q2F5pYF3EklDEATkFt2VZl82qtVylpBg26kbWH9Q99qFjoI1keIxqLGiG8XS3ITqK7rjeDMXy9m7P50EACzZca+mK/mqKy7cLMPney/aK1vk5E7nFENZXX8Fb91p39p0DP2StuPHI9cM7rOoXIlxXx7UTqcWYUjx8CGnn9iX1xzCrM3HceGmtMs6lFVUIfXUDa4hZWMMahzA7rM3sWzXeaesKnf0Glprf6JVZjYFOqqKqmq89s1hbLDDk6sjXv5Hs4twxUpd5eI/2YvXvtE/gELdt4eyAdwbBaPPkh3nsPvsTUzbcASlFVVYsv0czueVWJzXhqCgrMJ4Ij2u3irHtcI7Gtte/eYwJq45hCn/ycCWE7lmdxsg0zCocQDjvjyIf27JxK7MhrfSdXllldbTKtnPd4ey8cvxHMzcfNx4YjhmIKKu2IJazfLKKvzls9+x6LgbKqz0tJ1y6oak+7ut1hy68NfTWJR6Fg8v2mNWs6s6Bz/NKvboB3Onshqx/9yJBxbuQJXavWzP2dr7+bbTNzBpXTrWHbgi6XEFQRC1WnpDw6DGgVwvumM8kYRO5xTjkNqQ7+zb5RpfSmsrrajCfe9sxaAPd+HqrfIG9yTjiKXdckJ7YdpN6dl4ec1h3K3S8QYHoS+4evvHk2bvs0StwBVV1vteWPoznH27HBsOZml1Zj98pVD1/8sFtlsxWxAEXC+845DXtzXkl96r4SkzMBpr+5l7g0eqawSM+iwNs0Q+POgy/qs/MPCjnaIGMThjK4C5GNQ4AWvVZLyffAZ/WZGG/NIK7Dl7Ew9+sBPPffG7+Ts08Xtz9GohgNpJ12L/uVN0VbwzqK4RMHV9Blb/dknrtcqqGnyfkS1pn6trhXew/0K+RfsoKldi33ntfbzx3VHsPpePFWdc8cLqQ7hwU7s95mZJBd767zHVOTWk+K4SS7afw5lccWu5mKOiqhpbT2oHaHI05OPdmLn5OJbtvKA3zdMr0qyej39vPwdBELB0x3n0X7gDheWO3fdPEARk5krbNNdzXgr2nTP+PTx0+RZ+v3RLdAdlXTHJrsybuHrrDtKv3Db6/qu3tR+Yyytrg3a51fYwqLGTtAsFWJSSqVEzMuf7EzrTxn+yV7Lj6qoNyS26q6oa/f2S7Sbrq2+LM/4ICdDZETDlZC5+Onod834+pfXa8l0XMGPjUewVcfMT64GFO/Ds579r1LyZqvCO4ZFcl0oUSLt4C6+sTdd6bdbmY9h46CpGfvqbwX1UVtWgx7spWJR6Fo8sNu26FgQBBaW6+z3UD5A+2pqplc/Kqhocyy40+ybuqB3062qRftMRkNrS9aK72H+hAB+nnrVrPsRaueeiajZkKU1Zb/zhrLpelHIpvwzJx3Mkz0udN787qvH3z0ev4753tmL6hgxEvb8TO687eOdIEzCosZMxnx/Akh3nVR0ADZFyUr8DFwsk25dTqP/7ZeC7W1Bm+vDsz/ZcRPjbW3CxXu1FaYX+thp9cxi1n/mL1s3HVIdEPLVZKk+thqmuC8O20+LmZcoyOAmf4WDj7/89hqgF27D9tHY/lHUHNJ94v8/QHiU0+Zt0PLb0N3y+9yK+z8jWOR29Pv9MOYee81Lw6/EcHLhYgOPZ4t8rJUM/PWLPff1PubC8EiV3pQnY8kqsM+LTGpYambfLlj/zD320C5NtWFP9xp/3mR+OXEdpRRV+uCL9GoH2wqDGDm6W3HvavHLLdm3dgPlNWXlWGp6uzxd7L2L6hgyznqoLSiuw4WAWygwEFnX+vf0chi7ajSIdVeXFJtzoV/922WgaMe3a/003HuRai67sXbFhXwxjvvvzs1my3fAIIH3qAq+kX89gxsajGL5kn1YaQRCw/3y+Vo3Qxj8fPl5fn4HRKw9gxNJ9qvRvfncUK/fob/oxx4GLBZj380ncMXHG3LQLxh9a1K/DO5XViJyfiu7vphh8z2e7L5qcF0dXYmInsZoawaK5xxpSvxZ7MmvtJzLfiWtFePTf2jdTU9ijonDhljOq//9zyxmM6BmMLi0bWe14C345DQB4LDIYg8MDAdR2Ym3h64moEMPryzy/6iBO5xTjoIimtLqq8lX7tOebefenk1j0TKSo/Bqbi6KqugZPLNuP9s19RO3PEfzn9yzM/t78joz1Xb1V7vA39v8dy8Hr6zPg7+2OlBkDtF6vP4Q/7WKBKhD964AOFh+/bu+jVx4AAPh6uiExrovo9+eInKAv/cotvLruMJ7t205U+m2nb2DxdudoVhJDTPBX3xvfHcX3Gdew6JmeeLJ3GyvkSj8H/9o4FNbU2Jg9n8QtoV7r8dmeiyYFZhVV1dh3Lt+sSajKKmrfcz6vFJPWpeOp5fu10nx36Co2H773uZ7Oqe1f8auOkTz6KHXUCOnqgJejZ4Tad0bO6+GsQhy/VoSfj5o3G7RYUt789AU05g6bfe0/h/Huz+JGI20/fQO3zWgOBGqDJ3M7qW77s2lLbP+Z8grD17S+60WdoVN2xciaWYbW1DI0KubF1X8gr6TC6Lw36jLURlPpc6XAumt8GSP2ylx74LLJ+65r0ly6w/bLzRicUZgBjwYGNRLQ/0NinToVAcDfvjuKD9RqTxyBvi/enO9P4PlVv1v01H9VT7VvUbkSf/vvMSR+e1SrevyOshqX8rWbT/ady8eQj3fhDzM61cYk7cCus7rnE9I3JP1WWSX+L/m0yceSm2PZRfjtvLgn5AlfH9IZwAK1E+Lpc+PPdabETorY7/3taD/zF50BgBQBYraOUSf1TfnPvb4Uz35+wHATR71biqE1tfTNkFtVI5jc9CKWKUGSNZjTL84YQRCwJu2y5Pt1ZLpGODoLBjVOQr3N/nxeKb5Lz8byXdK245tD/R5b9yNw4GKBauIp4F7t1ObDhqd4N0e58t7Nefb3x7X6wZzK0R42/Pyq33HhZhme+czwMFd9P2qr9+ueREvf8Mzxqw+KGupcR6pOm0Btnl5dly5uLguJjllp5pwu9T/vizoCUmNOXDOtA2/un33FfjwifQ1aaUUVLojo5H/2xr00v1+6hbc2HVP9/eOR63jjW8s6j9cn9r5Rbsd5iWr+nBLBERbh/fVELt4xYb6jwnKl1fuiqTfjGvrevrouHa+sPWTy/nV1xncWDGokZqxDrbl9Ct5Pvlcr48gz8FbXCBi98gBe+PKg2c0H5vo+4xo+NmHRTqnbqfXNE2OoZkEXKYfwz9p8HL+eyMW3f1wFUPujvyk926K+LeqtT1dvl6vWxqrzze/SzpxqC+YGYvrsPnsTEXO3qvqGmaKgVPN7s+mwtE3Wu/SMvqtTUyPgwMVb2HBB/8+DVN8dfQMBfruQj5+OXrdoEd7SiipJRo6evWH6XDbPfm7BfF9q9H0+t9WaV2/puc8Wllfi1xO52HpSO0DR1Yaw/0IB/r39nN5jOnp/uDrsKCyxy6a2KTvHdSI6m+pNMLfLK9HUx0P/PkXs1NSZXI093dtqxmRD/U6OGKm1EdNkoY++JsDiP5sb6vpCNWvsgUFdWgKorRn66rfL6Nbaz+TjXb11B1/tv6yxTWxnVTEEQcC7P51Em6bandItGYlS38FLt/B8vxCT3jPn++Man/aatMtYf/Aq1rzUBwv+Vzs/kaGh/frUWPnHw9jev067/Of8StZ95l174Ao+2pqJdRP6onsbf43XykWMtDI2MnLQhzuRX1qJ7yf3R692hgcXSK3+OlCA5v1O7LIVF26WolOgr9a9UkyAYeplNO6r2nmdQluIG8wgCIJdlqUwhjU1Tui4iVXs6qT8wTHG2HfqFxGTTemakdcSpowQz7pVrvMJfv8F3X1xko/n4pdjOZIMfa2pEfDh1jNItWBtIEM/qOpPn+8nn8bHqWfx0lemV1PrsnKPdCuXH80uwtdpV3T2SXroo11a2/Q9tRrzkxkduL/5PQv/+f1ek+M7P57E6ZxiLLJw8jn15qj6Lt4sw9oDV6z61Kxrjh/ASGdVI3Tl9+0fTqDojhJvfHfErH0au3/k/1njpes7VKajg3dmbr3PXc/v9cX8Mo05jqwZhOra8+2ySo1m9fppLL02rt4y/lB1V1mNYYv3YNbmY0bT2hqDGid04pr508vrW2vE2NdA1/f7WuEdZJVpvmJK4C5minBDQdieszclq+bV59cTps3y+dp/DkvyRU85lYtPd17Aqn2aQV36lduipkUHgKnrM0Sl++OyaRP22fLZrNxAYKas1r5q//Zf+99kxfRfssTbP5zA/45Zb/ZZa4j/ZK/BWtLs2+X46eh1g+u/7TuXrzEtgNjOrLsyb2L86oPIVbuX7NbR2X/+L+IHXkxQewCwdGZwU7sT9HovFWNXHVT9nas2wu58Xgn6JW3H2rTLKKu0Xqeo1FM3cPZGKdYfvGq1Y5iLzU82Zq2Y/nrhHfh7u8PH07xTas5qxoM+3gvA9jNRPrZ0H8b2C7HJD5jYAELdD0eu48FOLSw6bq6eYK5uRNCchK5wcVFgwoOhGq8XlSuxbNd5PB7ZGjvUFtAz9PQm5YzV5qqsqsGGPyy7QTrKGjbKagHnrPyZmtPPo46+S8HU5gRldQ3cXcU9F5/JLcHR7EL0atsUF/PL0EGtiePsjVI8+EHtKK7Su1U6585Jv3ILz6+qfYBp2sgdiUM7i87nqZxinMoB/vHDCXwxLlr0+wyNEFMfkPD5XnE1kzWCgBPXitApsLHG9ro5icz1fvIZ1RxJDy+qXfbh7R9PYrgVl7yxdhOpJVhTIwPZt8vRf+EORC/YZvY+1Nd8ErMgmy4X88u0RkOZ01m4fu1Efceyi2z2RL4mzTE7vf5f8mm8979TWp/vZ3su4p9bMvEXPcOhpXBbxBwwuvoUGKJvyKwpt84cC2e9Lr6r1BgFZW5zi7XnIrIWU36nrhSUIfztLZj7o+716nRT4P+ST+PhRbvxLz1NdPo622dkFar+f7tcaXD19QMXC3QG8dvMGNGTJaKPpNi5efZfKMCj/96Hl7/WbOY158FJDENrgVlz1Xl7Y1BjI4IgYMn2c5KvCgvcmx3zjrIaszYft3gYZN0TkToxw2t1zSvytkk3vdrP6b3/3VsE0hG6oTnyaLNKPXm7Xq+mRxCAxdvu/ZCI7ahorgcW7jApva75hAyxpK+RPjM2HNH4+/eL9lvc1R7Gf/WH6LSXC8pRXSPgaxOD/roHliV6JrCrW1ndkoqA0SsPqBborc/YdXa53u15wIc7sStT97xU5jKluerYnyMnzfk4LFkl3YErYoxi85MVqdfkjvn8AA7ouEkezpI2She7lL2pzLvIBZy6blr/n4Ef7jLnQBYz9BNv7aYEW0i7WID9ZkwN76gmrpGmU7O67Wc0hzp/e8jx+gtYk65+Jups8UOnq58UAJw08T6irybH2APKxRLtO4Gh0YpSjsDT5c3vjuIvUbZdkqFGEOBSrxmy/kLI+0VOomkPrKmRgL7v+q/Hc/DcFwdws6RCZ0ADmN5J0x5MmTjO0iF+hldxth6p5ykRs5imLeWVVBhPRBocOQgsuqNEgpnzGZlb82iLFeD10Tciy1TDFu8x2B9J7G2g7i4ntjO+IzG2BMhmHfMijV55QKOLwkYHDvhZUyMx9XbMz/fWVrUmWXGK/PzSCqv3L5m0Ll102utqfSkMPdkZGuVgCXNHInxhpB+Pqeb+JH4GUl1MCXbN+SwVCmDZrvNwdcB5JtQ5czW4NVnS18vYtA7HTJws0pkIguFApKzKtO+Dqc2mjsDQemFA7fIauloQLB3lZSsMaiT2yXbttU9ul1tvZt0Pt5g/46ZYpjzZqa9Fo+v36KWv/tAYlSNaA/txEzOHD1B7kx7y8S6T9//toasG50NxFB+mWP/6pnv6J223dxa0HNQzisfcdabETOxnbaY+S9g6uNc1C7EhNTUCfr90CxGt/eDr5W6lXInD5icJGJvsyNwJwcQoqZBunSCp6fpYzAlonGV6bnsQIIiaxbr+Z+goAc0eI/04TGn65HViufodzO1l1b57w6SNrdFmqoJSZ2yKle7arptVXEpfp13GmM8PWDw8XQoMamzA1LV/6J6Csko8+MFOq9Z2ObMl2+2/4J8lXvjyoPFEJAtiayeu3iq3al/DMgM1NWJDh7LKapzOKbZJBbKxwB8AjmUX6h0Obwtr/xxtZmqHbmtg85OTEzOltTFbTuRKkBNtt8oqJRmTfa3wDr6UeLkEuRA72s2R6zB+OZaDKj2jXkg+CkU+mKg3YTsySxaeNWUpFTFDyh9b+pvZeZHCxZuO07eIQY2Ts2QdqDpLLZzXRp8xnx9AmMjF0ajheu0/hyXZzzsGJmQj+5v8jTTn2Zpu26hlypSV7Msrq7DttBn9EG1EirXupMTmJ3IKlqx3RY71JGUtZnVAJ5u5q3TcSSzrHLtlm5/EO0rxgYCly4dYm7kLkloLgxoiIiIyS/Jx63RfMBeDGjIqv5SddImIyPExqCGrcpSVk4mIHIWySr73RdMWOZUegxqyKjFzqBARNSQHL8t3sVRTFzmVGoMaIiIikgUGNURERCQLDGqIiIhIFhjUSEC+Xb6IiIicB4MaIiIikgUGNURERCQLDGqIiIhIFhjUEBERkSwwqCEiIiJZYFBDREREssCgRgJXuBQAERGR3TGokcDN0gp7Z4GIiKjBY1BDREREssCgRgL7L8h3xVUiIiJnwaCGiIiIZIFBDREREckCgxoiIiKSBQY1REREJAsMaoiIiEgWGNQQERGRLDCoISIiIllgUENERESywKCGiIiIZIFBDREREckCgxoiIiKSBQY1REREJAsMaoiIiEgWGNQQERGRLDCoISIiIllgUENERESywKCGiIiIZIFBDREREcmCWUHNsmXLEBoaCi8vL0RFRWHv3r0G0+/evRtRUVHw8vJCWFgYVqxYofH65s2bER0djSZNmsDHxweRkZFYu3atRprly5ejR48e8PPzg5+fH2JiYvDrr7+ak30iIiKykuzb5XY7tslBzcaNGzF9+nTMmTMHGRkZiI2NRXx8PLKysnSmv3TpEhISEhAbG4uMjAzMnj0bU6dOxaZNm1RpAgICMGfOHKSlpeHYsWMYP348xo8fj61bt6rStGnTBgsXLsShQ4dw6NAhDB48GCNHjsTJkyfNKDYRERFZw11ltd2OrRAEQTDlDX379kXv3r2xfPly1bauXbvi8ccfR1JSklb6t956Cz/99BNOnz6t2jZp0iQcPXoUaWlpeo/Tu3dvDB8+HO+9957eNAEBAfjwww8xYcIEUXkvLi6Gv78/ioqK4OfnJ+o9YrSf+Ytk+yIiInJm2xIHoGNLX0n3Kfb3282UnVZWViI9PR0zZ87U2B4XF4f9+/frfE9aWhri4uI0tg0bNgyrVq2CUqmEu7u7xmuCIGDHjh3IzMzEBx98oHOf1dXV+O6771BWVoaYmBi9+a2oqEBFRYXq7+LiYgCAUqmEUqnUX1AiIiIyi1JZJflvrNj9mRTU5Ofno7q6GoGBgRrbAwMDkZubq/M9ubm5OtNXVVUhPz8frVq1AgAUFRWhdevWqKiogKurK5YtW4ahQ4dqvO/48eOIiYnB3bt30bhxY3z//fe477779OY3KSkJ8+bN09qekpKCRo0aiSqzOCZ9jERERLK1Z88enJXyJxZAebm4fjpm/RorFAqNvwVB0NpmLH397b6+vjhy5AhKS0uxfft2JCYmIiwsDIMGDVKl6dKlC44cOYLCwkJs2rQJ48aNw+7du/UGNrNmzUJiYqLq7+LiYrRt2xZxcXGSNj9NS0uRbF9ERETObMCAAejYsrGk+6xraTHGpKCmefPmcHV11aqVycvL06qNqRMUFKQzvZubG5o1a6ba5uLigo4dOwIAIiMjcfr0aSQlJWkENR4eHqo00dHR+OOPP/DJJ5/gs88+03lsT09PeHp6am13d3fXavYiIiIiy7m7u0n+Gyt2fyaNfvLw8EBUVBRSU1M1tqempqJ///463xMTE6OVPiUlBdHR0QYzKQiCRn8Yc9MQERGR7Zg2/EhaJjc/JSYmYuzYsYiOjkZMTAxWrlyJrKwsTJo0CUBtk8+1a9ewZs0aALUjnZYuXYrExERMnDgRaWlpWLVqFdavX6/aZ1JSEqKjo9GhQwdUVlYiOTkZa9as0RhhNXv2bMTHx6Nt27YoKSnBhg0bsGvXLmzZssXSz4CIiIhkwOSgZtSoUSgoKMD8+fORk5ODiIgIJCcnIyQkBACQk5OjMWdNaGgokpOTMWPGDHz66acIDg7GkiVL8NRTT6nSlJWVYfLkycjOzoa3tzfCw8Oxbt06jBo1SpXmxo0bGDt2LHJycuDv748ePXpgy5YtWp2JiYiIqGEyeZ4aZ8Z5aoiIiKwrdcYAdAq0zzw1XPuJiIiIZIFBDREREckCgxoiIiKSjD37tDCoISIiIsnYs6cugxoiIiKSBQY1REREJAsMaoiIiEgyBpaCtDoGNURERCQLDGqIiIhIFhjUEBERkWQ4+omIiIjIQgxqiIiISBYY1BAREZEsMKghIiIiWWBQQ0RERLLAoIaIiIgkI9hxSUsGNURERCQZDukmIiIishCDGiIiIpIFBjVEREQkCwxqiIiISBYY1BAREZEsMKghIiIiWWBQQ0RERLLAoIaIiIhkgUENERERyQKDGiIiIpIFBjVEREQkCwxqiIiISDLNfDzsdmwGNURERCQdhf0OzaCGiIiIZIFBDREREckCgxoiIiKSBQY1REREJAsMaoiIiEgWGNQQERGRLDCoISIiIukI9js0gxoiIiKSBQY1REREJAsMaoiIiEg6nFGYiIiIyDIMaoiIiEgWGNQQERGRdDj6iYiIiMgyDGqIiIhIFhjUEBERkSwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0RERFJxo4juhnUEBERkTwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0RERHJAoMaIiIikgUGNURERCQLDGqIiIhIFhjUEBERkSwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0RERFJRrDjipYMaoiIiEgWGNQQERGRLDCoISIiIlkwK6hZtmwZQkND4eXlhaioKOzdu9dg+t27dyMqKgpeXl4ICwvDihUrNF7fvHkzoqOj0aRJE/j4+CAyMhJr167VSJOUlIT7778fvr6+aNmyJR5//HFkZmaak30iIiKSIZODmo0bN2L69OmYM2cOMjIyEBsbi/j4eGRlZelMf+nSJSQkJCA2NhYZGRmYPXs2pk6dik2bNqnSBAQEYM6cOUhLS8OxY8cwfvx4jB8/Hlu3blWl2b17N1577TUcOHAAqampqKqqQlxcHMrKyswoNhEREcmNQhBM66fct29f9O7dG8uXL1dt69q1Kx5//HEkJSVppX/rrbfw008/4fTp06ptkyZNwtGjR5GWlqb3OL1798bw4cPx3nvv6Xz95s2baNmyJXbv3o0BAwaIyntxcTH8/f1RVFQEPz8/Ue8Ro/3MXyTbFxERkTNLmzUYrfy9Jd2n2N9vN1N2WllZifT0dMycOVNje1xcHPbv36/zPWlpaYiLi9PYNmzYMKxatQpKpRLu7u4arwmCgB07diAzMxMffPCB3rwUFRUBqK3l0aeiogIVFRWqv4uLiwEASqUSSqVS7/uIiIjIPEplleS/sWL3Z1JQk5+fj+rqagQGBmpsDwwMRG5urs735Obm6kxfVVWF/Px8tGrVCkBtkNK6dWtUVFTA1dUVy5Ytw9ChQ3XuUxAEJCYm4sEHH0RERITe/CYlJWHevHla21NSUtCoUSODZTWNSR8jERGRbO3csQNNPKXdZ3l5uah0Zv0aKxQKjb8FQdDaZix9/e2+vr44cuQISktLsX37diQmJiIsLAyDBg3S2t+UKVNw7Ngx7Nu3z2A+Z82ahcTERNXfxcXFaNu2LeLi4iRtfpqWliLZvoiIiJzZQ4MHo5W/l6T7rGtpMcakoKZ58+ZwdXXVqpXJy8vTqo2pExQUpDO9m5sbmjVrptrm4uKCjh07AgAiIyNx+vRpJCUlaQU1r7/+On766Sfs2bMHbdq0MZhfT09PeHpqh4vu7u5azV5ERERkOQ8r/MaK3Z9Jo588PDwQFRWF1NRUje2pqano37+/zvfExMRopU9JSUF0dLTBTAqCoNEfRhAETJkyBZs3b8aOHTsQGhpqStaJiIhI5kxufkpMTMTYsWMRHR2NmJgYrFy5EllZWZg0aRKA2iafa9euYc2aNQBqRzotXboUiYmJmDhxItLS0rBq1SqsX79etc+kpCRER0ejQ4cOqKysRHJyMtasWaMxwuq1117Df/7zH/z444/w9fVV1f74+/vD21vaXtZERETkfEwOakaNGoWCggLMnz8fOTk5iIiIQHJyMkJCQgAAOTk5GnPWhIaGIjk5GTNmzMCnn36K4OBgLFmyBE899ZQqTVlZGSZPnozs7Gx4e3sjPDwc69atw6hRo1Rp6gKc+s1Rq1evxosvvmhqMYiIiMgKBNhvRUuT56lxZpynhoiIyLrsOU8N134iIiIiWWBQQ0RERLLAoIaIiIhkgUENERERyQKDGiIiIpKMPYcfMaghIiIiWWBQQ0RERLLAoIaIiIhkgUENERERyQKDGiIiIpIFBjVEREQkCwxqiIiISDItfD3tdmwGNURERCQZd1f7hRYMaoiIiEgWGNQQERGRLDCoISIiIllgUENERESywKCGiIiIZIFBDREREckCgxoiIiKSBQY1REREJAsMaoiIiEgWGNQQERGRLDCoISIiIllgUENERESywKCGyIjWTbztnQUiIhKBQY1Mebjx1ErF3VVh7ywQiRLSrJG9s0AO4sX+7bF1+gD079BMsn0+3LWlZPuyFv7yydChfzyMTZP62zsbsjH94c72zgKRlm9ficGbcZ3xeGSwaluQn5cdc0SOZEjXlugS5IvxD4RKts9n+7aTbF/WwqBGhtxcWLMgpcd7tbZ3Foi09AkNwJTBnfDh0z3tnRWH08LX095ZcBiuNv6Vjw5patsD1sOgRgIPdpSuek+fnm2bWP0YROR83G39q2UDq8ffb9H7/b3dTX5Pj9Z+Fh3TVKHNfWx6PFuJ797KrseX37fBwf3w2gNmvU/KdlF1Azu3sMp+qdYj3YJEp320h31vBo6IlY6m2/nmILRv4H1rzLlsXK10sT3fT3eTjbUvbR9PN8n3GdnWeC2Mvb+yDGpsLNLMGpdpQzpJmg8PVxdcXjgcX7/UR9L9OqoebfztnQWDxj/QHqPvt017dU+Rn4VCUdtvwxRLxvRC00amPyXr076ZD57szeY/Y/qEBgCo7fMQ2twHu/72kJ1zZF++XtL/oJsr0Fe6fk5/HRCGcTEhGH1/W6Npe1mhdj/Ax0PyfUqNQY2T8HJ3tXcWzGbpA1BjCZ44/j2ml8X7MNemV40HBh5uLohs18TiY42KNn6zM6UPhsLEc9e8sePf9MzV5M9gzRED5LUT+iBlxgA81jPYeGITDb0vUPJ91nkmuo1V9itYZa+anujVWlQAH9u5BV4ZEIakJ7vDx8Oy+3i3YD/MGxmBdkZq4qJCmkIh4ssr9gFH3cdG7h/hrXxN3qeUGNTYkENFuTasI7Skzf+lB0IR1sJw2/OUhzoa3Y+Lqb/OEooKCRCVzlOCYfixnZtbvA9H07ap/ZtSPh/bCwdnP4yT84ZJEmRLzdPNFZ0DfUX9kDmyYH8vbH9joL2zIYrY5ioFgFkJXTGmTztkvBOn+YKZBodLM7R6YBfT9/NUlO5AdNlzvbH02V7o38G+9yAGNTbUpqntJnFzpHvbyEjznh6fjmqDOcO7Gk3nSGXVJ0JEJ0R3VxdsSxyAp/XcNJxF/R/WL16IxpF3huL1wZrBp5j+RolxnTFpYAez82Lpk3EdTzcXeLi5wMfTzSmuN2chqFWpLHg8AvveGowOLRrbJy8mpveuV3ue9GR3o+9Rnz/MksuoS6B9a0PqqH8GCd1b4dEe0tcUmopBjY20buKNjxxp6KUt6mf/NO+xCLPe9+HTPUU9DTUTUQNmq8kIH+jYzKIauY4tfdElyLo3LFv/Jvs3ckeTRh54I66LxnYx5/bRHsHw1hOY/ENEwJv+9lCcmDdMXEZFUti9K6TtxISJq2WUQr+wALiwZ7goCoUC97e379BpR8WgxkZ+mzkYnf+Mrs2d9TM+QvxIGmNs2RSm70dJnSVt62P6tsOTvVtjTB/dHW1feiAUgTomJZudEK76f9/QAMR2sqza9JWBYfjm5X5mDSdt4wBNLPVFBPtb/PP96qAOVpu3wtikYl0CfeHl7uqQzUX2YKymuIWvJ755ua/Gd7F+s62vFT7LfwzvilcGhqFjS+mCecHEhzYxNanGmPowouueZIovxukf9m6r0NARay0Z1EhgoIX9GFY831trm/p01Mueq33902d7Y48Zoxpa+Wt/edwcbOr/hU/2MPu9nm6uWPRMpN5Oku+MuE/n9r8O6IDfZg7GpaQEbPhrP4v7I9SvjhZr0sAOGCNiNIMYUtYifDY2yuT31O8X9NYj4Xbp5zEnoSt+mfqgZPtTn6nXETsKS+Hg7CF4oGNzhDS714dt7qPhBt4hjZdjwzAr3nitm7X8PnsIfnzN9Gvl/lDNWqze7XQH7431jMR6rm+IycdUJ/bhqUebJhYdx9kwqJHA833aYnznarPmhpg/shseidCenySi9b0bZ8Kfkxm5uCjQrlkjrJ/Yz6RjvPWIeTem6Q9LO4xcXYcWPqL7SsTr+HzMEa7jSap1E28oFAqr//A+3FX3CJK2Ad6YGR8ONztNoKavCaddQCMEi1jI83+vP4iJsaEYFxOC4T1a6b2x6yJYsQ3U39td72eq3sJx6B8Pi9qf+kRpIyP1DzF/M855l9TQ9R0Ibe4j+8a2Zj4ecHVRmFy7M8LIvFJRIU3xaI9WevsIdQv2w4X3E0w7qBmaN/bEwdlDrH4cR8GgRgJuri6IbCaYNTW3l1vt070p7aOmrho9MjLY6AgiXXStI/PFC9Em70efmfHhmDviPnwyOtJgW/rE2FB88UI0hljY49/ciQ8BIHXGANX/e7Qxvap68iDdI7RMvZGaYsHjEdjw13743+uaT6Hqv139wgxP6mgs1oto7Y85w+/DvJER+PTZ3rUBooi8LR4VKSKV+cQGTM0bm/6dNdTtw9jTs6+nGz78i/m1kpYQW8Mk52H59R2cM8TsBwpjD0KbXu2Ppc9q18Lv/tsgbHq1P9o39zF5wj8/M5q2AaClnxfWTeiLofcFYs/fHsLQ+wLx/hPGOzYbc18r287CLAaDGjto2si2Nw2FQgFPN82mEX0/psYmB9RXlSpmfhRdxj8QqvPJV/3G6ubqgofvC0QTCz83L3dXg/1mxvdvr/e1TmaONqj7cfVwc9E5K7TYoMackXPP9wtBv7BmiGjtb3IgfI91ntObSDhBn6ksrZUL1NGcq7Zzg+89OjcOT0e3RZwV537R568DxNWMPtm7DUZFt8GLnaotOl7vdk3wf0+YN0jA3KZcU7WUcGI8dYbyH9LMB1Fm9DO7v31TDKo3A7y+75Guy/DBTs3x+QvRaNesET5/IVqSxSn7hTXD0md7Ycv0WIv3JRUGNXag6ynVlL4QTX0M/yC4uii0LmrBwK/nugl9Vf8PbnLvS25KJYK+uQvM9Xw/ce3NpnbKbd9Mf43VQ+EtsX/mYAzXs3ZJXaBV/8ZiiLG+AtYe6WSMOZ2aGzo/L3dsSxyg1XTXp73xkUJ1NZL/GhWJFc/3xgAj15JUwd/4B9obnGhNPdh3d3XBgpH3oVdz7TuAKfeEJWN6Ge03ou/6F/NZGmIon40kGOZv7CHO3MEghswd0U3yZnIp9vZoj2CEBzlOjQ2HBdhBexELmRl6gvf1csffhnXBh1szVds8XF3w2kMd4epS+7opHrRg1M/MnlVoe1+Uapr2+mY8bF4fg1cHiXuqTFFrFhLjb490QVWNgMf1zJ0T3MRbb1NY8tRYpF0swMNdmmPJjgtarw/TMe+KsXP9cqzhETxSebxXMD7deQFd61UX66vBeap3bZDqiKMb6igADOjcAnvO3rT5sTu29EWHFo3holAgvJUvKpQ1uD80AN9nXBP1fh9PNzwS0Qo/ZFy3ck5rzR3RTe9rP095EJ2DzJ8bpkcbfxzLLjL5fX8b1gUvxLTX+Zo9hna/ObQTxq4+JCrt+yLmpJGaI38XHQmDGkdh4gXbU0eP9mlW7NirT6tG0FuV/ny/dmblKdjfS6u5TB9Th0X6ebmLmiRLl5Z+XhgZ2RpKpVLrtf0zB4vqWFufmFmEYzs1x6X8MpP3rW7akM7o2aYJ+oY2w83SCo3Xmjf2QH5ppca2KYONz9IspaaN3HFg9hB0+ccWk9637LneiJi71Uq5MkyhUOClB20TlFpTdxNGc+mq8TX3t/Y1ETOBS8XHwxVllYab0/qFBSA2qAZ7c9mA4cx49uzMS6IZT6UaSSLl/DUTHgyTbF+2ZKipTh9zAhp93KzwlOrh5oK4bkHwF9mcYcmKxWNjapscDDWt6OpXJiaQrd8Z39Q5aIb3aKWaN8caHWJ19X36S1QbuChgtINw4lDtWs2h9UbNmd83yvbqf40WSrD2kbm+FzlIwNMOv4irxkk3+KLO7AT7DZG3N9bU2MnfhnXBocu39E6o1721febCaN7YE1+Nvx+NPNxw4WapwbQbJ/ZB7on9WtuD/b2w481BTr0IpyV8PMWXW1f89Mz9bfHtoWycyik2+v7wIF+cyS0xJXui8lDHnNDm9cGd0L9Dc52jbRY90xNXb91BTzNXEB7RIxhf/nbJrPcCQBNvd8wdcR++3HcZY/pIMzeQukGdW2BOQlfcF+yH/NIKZGQV4p1H78PCJ7sbHWUzdUgnLEo9CwD4+yNd0LSRBx7rGYzv0rNVaVr4euKH1x6Ap7vtfn2lavZwcVHAW0SNialOzhuGbkZq6zpbsKxAIw9XlNfLs5SPHUO6BmJweEvsOJOn9VqXQF9k3ij585jijpo8NRb3BZvfx8XX0w0lFVVmv9/eWFMjIVOe8F97qCNWj++jWuxR/XJNmTEAQ7q2xLBugRgXo7ujXS8JVnTWZ1CXlnr7yKjrrScPCoXCKgGNs7QpLx4VifAgX9WkiaZq5OGG5GniRhOoj8p60cDoLX2sMaLc1UWBPqEBOq+BJ3u3UTVJqn9dpMiHh8ihuS19vTAzPlxjkjl1q8ZFm32tKRQKTBwQhgc6NsfIyNZ497FucHFRmDxsuHljT4zp0w4+9WqiXh/cES18PeFnYr85qeg8Tzb6YqpPSKqu/mcEALEdLV9Use7+NlfP5J261NX+mbrg5L+eicQTvTRHgbbw9TR6H/jnU7W1f+o1lpYENHLAoMYB1a22+9nYaMwbqXtIpI+nG86894jefVjrpifVvCpSTainzlGCno4tfbFl+gDVpIm28u5j+juDqnOUz8lS9cuh3j/Jkut0SNdAh5xw7tVBHTBEzySOzsKS8/LFuPu1OrrrM2VwR71rwhmam0k9extficHW6QPwjIGRTnXTUdSNLPtlaiw+frqnyX0J/Ru54yW1ZT/eGNoZP772gEYzsK4a4LhuQTg9/xFMGuicTf3WwOYnJ6b+JFz/ZtE2oBH+Mbyr2ZM11derXROM1LMMgSmWPdcbggAMtcM8Heb4beZge2cBQO1Q9Ozbd7S2W+PHV71fla4hpGP7heDE9SL8RcJh/LYKImy4jqvkzJko0BZsce4GdWlh0rG83F0xpk87LN15Xuu1sTEhGN69ldHaaHdXF9WQ8y9fjMbq3y5j77l8jTQz48PRJzQAD3SorRkK9POSZHqL14fcC4reezwCReWVemsWxayt15AwqJGxl2P1R+/1OwRHtm2CI1cL9a6f9P3k2o52aRcKLMpTgI+H0Vls7W1A5xb437EceLi6OEzHzI+e7olnvziAizdrR0FNHdIJ/cICsOHgVUmPMyehK+K7G144tamPh+p6sDWxtUyWBi/OHPzIjaebCz4Z1Uuy/bm5KEwOPAaHB6JdgA8eXrRbY7uXu6vVa2THipiza3iPYHyUclbnUjCmcvZrn0GNlbRv1giXC8oB1I48MaZjy8b4/dIta2cLQO3EVh/UG4mx6dX+KLmrtHjWXjn4S+82aNrIwyYLF4q5gUS2bYIgfy989nwUhv5rD4B7I2UsDWrq9wObOEAzEG6qa7SUFdZ2cPYbqS2YMypPDp7vF6IatffBUz0wamWaVsfdhi60uQ/S//GwZDXz9bUN8MY3E0xbc9BeGNRYya6/PYSsgnL8a9tZvCKivfOt+HC4uSgwspf+xfKk8u2kGK1tri4KqwY0Q+8LxMWbpaIWPHQXEQRak4uLwmbNY4Z+p1JnDMCOM3kY92cH4I4tG2NMn3YaQ5HN+ZkzpbkgpJkP3ns8An4eLpj27TEzjiathvi7PrZfCLafvoFnJFrJ3VRSrvxuqe5t/HHi3WFIWLLX6Kg/6WfrduyLr5kVmyfH9GmHdlaYJdkaGNRYUbtmjfAvkQv3+Xm56+0U7Cwe6xmMn45e1zlx28qxURAEwzOF/ntML3yw5Qw+1bEInLlMHYVgTaZ20O0U6KsxukmhUBidONCS+WX0GdsvBEql0iGCGmt0cp6dEI73k8/ofb2Lf430BzXBe49HYP5I6afIN4euoPK9kREYsXSfqLRSEDvb8KM9WqHwjhK9zJw+oCEa1i0Qv50X38XAAS5JLRz9JBPWuH8M/HPyNF2rdevyr1GR2PXmIIzpo71QmkKhMHozGtEzGPveGowIieboibsvEJ+MjpRkX85icHhLRIc01RhJ4QzE/gCqX0FS/cj/dUAHBPppPuWum9AXfl5umPBACCaGWy+oEdvJU+qAxlfPwrTm6N7GH6fmD5Nsf3Xqhik/1MW8BxOFQoGx/UIku59o7lvyXdolQHg6urZvUTsfAR8+FYGPn4m0fSYkxpoa0iu4iTfS//Gw3pW563N1UYha18pcE2PD8N/0bPh6uaHkrvHJoZ7s3drkdbCcnYebC/77an+DadzV5kyxZ4W6IzUlNW3kgRvF95aPeKBjcxydG4eqqiokJ2uv8yWVmfHhyMwtUS3gWndt61rRXUpNG3mI+g6JZaiGcPT9bZF2sQCP9miFD37VXyNW3763HsKl/DL0EtFkLRV7XpL3tfJDdEhTk5d+sUSbpo1w5B+DsWtbCoZHBsPd3flDAucvAVmVNdtpTdUlyBen5g9D2oUCTPha3MJzpK1tQCM8E90GjT3dNQIcsRwoFtHg4eYCVBhOoy+QWvpsb/z9v0cxVW0orS2aewL9vDQmWPt99hAU36lCkL/tfthMob4cS1hzHzzao3bkj4erC/qEBuBWWSXO52nORL7wqR4QBMHkz7NJIw/0aieun9+EB0Oxap/5M007AhcXhdEHEmvw8XTTqCVy9g7pDGpkwlYXolRrTJmrkYebQ7bjmsteN5B//qWnXY5rKV3nfsXzvbHgl9NY+mxvPP7pbwBMrwXq2LIxNttpmLq6Rh5uaOThWLflED0dRHe8OUj1f4VCgY1/7YeKqhqEv127KKn6vcLaAeI/hndFdY2Ar/ZftupxyPE51reHSELWjBe6Na3Bydum1XI4+QOQVYkN7nQleySiFR6xwgzVctbC1xNZt8pFpZ06pBPKKquQ0L0Vxq/+Q286hUJhtwcOhUKBln4S1CrzO+r02FFYJvhdtK3xnWsk7WxpLhlVWmkZ/0B7e2dBtvp3aIZpQzphuYj1yXw83bDg8e7o38Hy9ZSkUjfNwYNqazz5OFgNF9kHg5oGwl6rfttSx5aNbXYsdxdg/oiuACDJLJ7mkiKYteXnJlaAjwfmjtBey0rs2j/2biZ1dI093TBjaGfE23h9sjeHdQEAPNtXe4SkKUbf3xbJU2Ox6sVo1bZR97dFbKfmePtR8QtQkmV6tGli7yxoYWgroSZWms1RCm+PuA8t/TzxWE/rT+5nL80be2LXm4Mw6KNdNjne8O5B6BTkjw4tHC8oMMUno3vh45RM1dOvMdZoRqu/S7d6o2l2vDEQ1wvvolljzngtVpdAX2TeKNFYM2r+yG5IPXUDL8S0t/rxdV0nY/q0w4DOLRBsYUdohUKhtRq1l7sr1k7oa9F+DWkX4AMvd5cGN6JSl+1vDMSp68V6V063JwY1Enrn0a4orqjGeJE/Drbk5+WOvw0Lt3c2rM6aQ8rrUygUFs+BIWYJDWsL8vfCh087dsfhsBaNEdaiMU7nFFu0n542WPrCUax6MRordl/AhAfvzWj+Qkx7qwY0YmYftvd6auoLAdf3YFANduS4YLiOGiwPNxcceScOri4Kh5gI0VrEPLN0aNHYYR/mGNRIqJW/F759RXsJArIPR26AmDakE67eKkdkA57t1JwmInNriVJnDMDBy7fwdLR9lhqwhzZNG2HB44ZnoDaVI3+njPnbsC64eLMM0SH6571p5gWceGcIfLx1dzo2FBDJmSMtlWEMgxqZ4Mga5zLjzwUpSdMrA8Lw2Z6LeGeEtP0i6i85QQ3Paw9pL9+ii6e7q6xrYuSOQQ0RmcQqo77+DMpnJXTFq4M6cLV4J6U+s7C/A/cxJNM4U8d7BjVkkmB/+7aHk/2MDqtGnnuQ1TuZShHQsObSPlxdFPj2lRhUVFWjqQ8DU7I9BjVkkvbNfbDsud5oZscblrcM1idxRjGBAhISesG9gfYrIHH6hAbYOwvUgJk19GLZsmUIDQ2Fl5cXoqKisHfvXoPpd+/ejaioKHh5eSEsLAwrVqzQeH3z5s2Ijo5GkyZN4OPjg8jISKxdu1YjzZ49ezBixAgEBwdDoVDghx9+MCfrJIGE7q3QN8y6C+4Z0i8sAE9HtcGsePmP5moo2gbonoqfiMgUJgc1GzduxPTp0zFnzhxkZGQgNjYW8fHxyMrK0pn+0qVLSEhIQGxsLDIyMjB79mxMnToVmzZtUqUJCAjAnDlzkJaWhmPHjmH8+PEYP348tm7dqkpTVlaGnj17YunSpWYUk+REoVDgw6d74pWBHeydFZLI8ueNz2wLAB5u7MBpT68MqB0ePqJnsJ1zQtbyf09EAACmP9zJSErHZHI9/qJFizBhwgS8/PLLAIDFixdj69atWL58OZKSkrTSr1ixAu3atcPixYsBAF27dsWhQ4fw0Ucf4amnngIADBo0SOM906ZNw9dff419+/Zh2LBhAID4+HjEx8ebml0icgIhzcTNL9ShRWM80au10eZPdqmxjukPd8aQroG4T+TMzuR8nujVBoPDA+Hv7Y7F287ZOzsmMymoqaysRHp6OmbOnKmxPS4uDvv379f5nrS0NMTFxWlsGzZsGFatWgWlUgl3d80e8oIgYMeOHcjMzMQHH3xgSva0VFRUoKKiQvV3cXHtxF1KpRJKpdKifaur25eU+7QkH7Y+nr3LrU9VVZVV8mZuudUXbZQqXzU1NZLvUxdrnOuaGvM+j38+2c3oe6qrqyXJq6Nf49ZiqNzdgnwAoRpKZbWts2VVPNf3yt3ITfPvmuoau38uYo9vUlCTn5+P6upqBAYGamwPDAxEbm6uzvfk5ubqTF9VVYX8/Hy0alU7c2NRURFat26NiooKuLq6YtmyZRg6dKgp2dOSlJSEefPmaW1PSUlBo0bSt+GnpqZKvk/j7p3C5ORkOxzfXuU2pPYzycjIgJBlvWd2U8udn++CuhZfqc5VznXp92mIlOc6N9caea899ydPnEBy/nGJ9umI17htNMRyN8QyA/rKXft9OpN5Bsmlp22boXrKy8WtKm/WMJL6ExMJgmBwsiJd6etv9/X1xZEjR1BaWort27cjMTERYWFhWk1Tppg1axYSExNVfxcXF6Nt27aIi4uDn5901adKpRKpqakYOnSoVs2TtU1LS1H9PyEhwabHtme5Dan7THr16oX4iCDJ929uuTfcOIRzxbcASHeuUkqPAQW5ku5TF2uc6/8VHsHx23kApMt73bnvFhGBhD6Wzx7sqNe4tTXEcjfEMgOGy133fQrvEo6EAaH2yJ5KXUuLMSYFNc2bN4erq6tWrUxeXp5WbUydoKAgnend3NzQrNm9ETQuLi7o2LF2xsfIyEicPn0aSUlJFgU1np6e8PTUnu7a3d3dKhettfZryMTYUHy+9xJmJ4Tb7Ytoj3KL4ebmZtV8mVpu9SBeqny5uNzr62+LcyDlubbG51HH1dVV0n066jVubQ2x3A2xzIDhcru4utj9MxF7fJNGP3l4eCAqKkqrmio1NRX9+/fX+Z6YmBit9CkpKYiOjjaYSUEQNPrDkG6zE7pi798fwl8HcCQQkQpn3yNqkExufkpMTMTYsWMRHR2NmJgYrFy5EllZWZg0aRKA2iafa9euYc2aNQCASZMmYenSpUhMTMTEiRORlpaGVatWYf369ap9JiUlITo6Gh06dEBlZSWSk5OxZs0aLF++XJWmtLQU58+fV/196dIlHDlyBAEBAWjXrp3ZH4CzUygUnOODiIisRtYLWo4aNQoFBQWYP38+cnJyEBERgeTkZISEhAAAcnJyNOasCQ0NRXJyMmbMmIFPP/0UwcHBWLJkiWo4N1A7B83kyZORnZ0Nb29vhIeHY926dRg1apQqzaFDh/DQQw+p/q7rKzNu3Dh89dVXJhecSA6mDu6In49exwsxIfbOChGR3ZnVUXjy5MmYPHmyztd0BRgDBw7E4cOH9e5vwYIFWLBggcFjDho0SGNILJE+kW2b4Fh2IR7o2NzeWdHwYKfm2H+hAJ5uZk3krVOnQF+cXRAPDwn3SUTkrLiIDsnO5lf7o7K6Bl4OtkbRxNgwtPT1QkwHaZeYYEBDRFSLQQ3JjouLAl4ujhXQAIC7qwv+EtXG3tlwGKx3JSKp8RGPiGSHARNRw8SghoiIiGSBQQ0RyQ7HFBA1TAxqiIiISBYY1BAREZEsMKghIiIiWWBQQ0RERHqFt/K1dxZE4zw1RGQXj/ZohdRTN9A2wNveWSEiHX6dFoszucUY1LmFvbMiGoMaIrKLx3oGo03TRugU2NjeWSEiHbq28kPXVn72zoZJGNQQkV0oFApEhTS1dzaISEbYp4aIZIeL3xI1TAxqiEh2GNIQNUwMaoiIiEgWGNQQERGRLDCoISIiIllgUENERESywKCGiIiIZIFBDREREckCgxoiIiKSBQY1REREJAsMaohIdjq1dJ5VhYlIOlz7iYhk43+vP4jM3BI82Km5vbNCRHbAoIaIZCOitT8iWvvbOxtEZCdsfiIiIiJZYFBDREREssCghoiIiGSBQQ0RERHJAoMaIiIikgUGNURERCQLDGqIiIhIFhjUEBERkSwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0RERHJAoMaIiIikoUGtUq3IAgAgOLiYkn3q1QqUV5ejuLiYri7u0u6b0fGcjeccjfEMgMsd0Mqd0MsM+A85a773a77HdenQQU1JSUlAIC2bdvaOSdERERkqpKSEvj7++t9XSEYC3tkpKamBtevX4evry8UCoVk+y0uLkbbtm1x9epV+Pn5SbZfR8dyN5xyN8QyAyx3Qyp3Qywz4DzlFgQBJSUlCA4OhouL/p4zDaqmxsXFBW3atLHa/v38/Bz6orAWlrvhaIhlBljuhqQhlhlwjnIbqqGpw47CREREJAsMaoiIiEgWGNRIwNPTE3PnzoWnp6e9s2JTLHfDKXdDLDPAcjekcjfEMgPyK3eD6ihMRERE8sWaGiIiIpIFBjVEREQkCwxqiIiISBYY1BAREZEsMKiRwLJlyxAaGgovLy9ERUVh79699s6STklJSbj//vvh6+uLli1b4vHHH0dmZqZGmhdffBEKhULjX79+/TTSVFRU4PXXX0fz5s3h4+ODxx57DNnZ2Rppbt++jbFjx8Lf3x/+/v4YO3YsCgsLNdJkZWVhxIgR8PHxQfPmzTF16lRUVlZKWuZ3331XqzxBQUGq1wVBwLvvvovg4GB4e3tj0KBBOHnypNOWt0779u21yq1QKPDaa68BkM953rNnD0aMGIHg4GAoFAr88MMPGq872vk9fvw4Bg4cCG9vb7Ru3Rrz5883upaNqeVWKpV466230L17d/j4+CA4OBgvvPACrl+/rrGPQYMGaV0Do0ePdthyGzvXjnZN2+JcA9D5PVcoFPjwww9VaZztXFtEIIts2LBBcHd3Fz7//HPh1KlTwrRp0wQfHx/hypUr9s6almHDhgmrV68WTpw4IRw5ckQYPny40K5dO6G0tFSVZty4ccIjjzwi5OTkqP4VFBRo7GfSpElC69athdTUVOHw4cPCQw89JPTs2VOoqqpSpXnkkUeEiIgIYf/+/cL+/fuFiIgI4dFHH1W9XlVVJURERAgPPfSQcPjwYSE1NVUIDg4WpkyZImmZ586dK3Tr1k2jPHl5earXFy5cKPj6+gqbNm0Sjh8/LowaNUpo1aqVUFxc7JTlrZOXl6dR5tTUVAGAsHPnTkEQ5HOek5OThTlz5gibNm0SAAjff/+9xuuOdH6LioqEwMBAYfTo0cLx48eFTZs2Cb6+vsJHH30kabkLCwuFhx9+WNi4caNw5swZIS0tTejbt68QFRWlsY+BAwcKEydO1LgGCgsLNdI4UrmNnWtHuqZtda4FQdAob05OjvDll18KCoVCuHDhgiqNs51rSzCosVCfPn2ESZMmaWwLDw8XZs6caacciZeXlycAEHbv3q3aNm7cOGHkyJF631NYWCi4u7sLGzZsUG27du2a4OLiImzZskUQBEE4deqUAEA4cOCAKk1aWpoAQDhz5owgCLVfVBcXF+HatWuqNOvXrxc8PT2FoqIiqYoozJ07V+jZs6fO12pqaoSgoCBh4cKFqm13794V/P39hRUrVjhlefWZNm2a0KFDB6GmpkYQBPmdZ0EQtG74jnZ+ly1bJvj7+wt3795VpUlKShKCg4NV50WKcuty8OBBAYDGw9bAgQOFadOm6X2PI5dbX1DjKNe0Pc/1yJEjhcGDB2tsc+ZzbSo2P1mgsrIS6enpiIuL09geFxeH/fv32ylX4hUVFQEAAgICNLbv2rULLVu2ROfOnTFx4kTk5eWpXktPT4dSqdQoc3BwMCIiIlRlTktLg7+/P/r27atK069fP/j7+2ukiYiIQHBwsCrNsGHDUFFRgfT0dEnLee7cOQQHByM0NBSjR4/GxYsXAQCXLl1Cbm6uRlk8PT0xcOBAVT6dsbz1VVZWYt26dXjppZc0FnKV23muz9HOb1paGgYOHKgxydmwYcNw/fp1XL58WfoPQE1RUREUCgWaNGmisf2bb75B8+bN0a1bN7z55psoKSlRveaM5XaUa9pe5/rGjRv45ZdfMGHCBK3X5Hau9WlQC1pKLT8/H9XV1QgMDNTYHhgYiNzcXDvlShxBEJCYmIgHH3wQERERqu3x8fF4+umnERISgkuXLuHtt9/G4MGDkZ6eDk9PT+Tm5sLDwwNNmzbV2J96mXNzc9GyZUutY7Zs2VIjTf3PrWnTpvDw8JD0s+vbty/WrFmDzp0748aNG1iwYAH69++PkydPqo6j6/xduXJFlU9nKq8uP/zwAwoLC/Hiiy+qtsntPOviaOc3NzcX7du31zpO3WuhoaHmFNOou3fvYubMmXj22Wc1Fix87rnnEBoaiqCgIJw4cQKzZs3C0aNHkZqaqsqTM5Xbka5pe53rr7/+Gr6+vnjyySc1tsvtXBvCoEYC6k+/QG3AUH+bo5kyZQqOHTuGffv2aWwfNWqU6v8RERGIjo5GSEgIfvnlF60virr6ZdZVfnPSWCo+Pl71/+7duyMmJgYdOnTA119/repEaM75c9Ty6rJq1SrEx8drPGHJ7Twb4kjnV1de9L1XCkqlEqNHj0ZNTQ2WLVum8drEiRNV/4+IiECnTp0QHR2Nw4cPo3fv3nrz5ajldrRr2tbnGgC+/PJLPPfcc/Dy8tLYLrdzbQibnyzQvHlzuLq6aj1x5uXlaUW0juT111/HTz/9hJ07d6JNmzYG07Zq1QohISE4d+4cACAoKAiVlZW4ffu2Rjr1MgcFBeHGjRta+7p586ZGmvqf2+3bt6FUKq362fn4+KB79+44d+6cahSUofPn7OW9cuUKtm3bhpdfftlgOrmd57pjA45zfnWlqWsescZnoVQq8cwzz+DSpUtITU3VqKXRpXfv3nB3d9e4Bpyx3HXseU3bo8x79+5FZmam0e86IL9zrY5BjQU8PDwQFRWlqsKrk5qaiv79+9spV/oJgoApU6Zg8+bN2LFjh6iqwIKCAly9ehWtWrUCAERFRcHd3V2jzDk5OThx4oSqzDExMSgqKsLBgwdVaX7//XcUFRVppDlx4gRycnJUaVJSUuDp6YmoqChJyqtLRUUFTp8+jVatWqmqY9XLUllZid27d6vy6ezlXb16NVq2bInhw4cbTCe38wzA4c5vTEwM9uzZozEENiUlBcHBwVpV9paqC2jOnTuHbdu2oVmzZkbfc/LkSSiVStU14IzlVmfPa9oeZV61ahWioqLQs2dPo2nldq412KQ7sozVDeletWqVcOrUKWH69OmCj4+PcPnyZXtnTcurr74q+Pv7C7t27dIY2ldeXi4IgiCUlJQIb7zxhrB//37h0qVLws6dO4WYmBihdevWWkNg27RpI2zbtk04fPiwMHjwYJ3DInv06CGkpaUJaWlpQvfu3XUODxwyZIhw+PBhYdu2bUKbNm0kH+L8xhtvCLt27RIuXrwoHDhwQHj00UcFX19f1flZuHCh4O/vL2zevFk4fvy4MGbMGJ1Dfp2lvOqqq6uFdu3aCW+99ZbGdjmd55KSEiEjI0PIyMgQAAiLFi0SMjIyVKN8HOn8FhYWCoGBgcKYMWOE48ePC5s3bxb8/PzMGu5qqNxKpVJ47LHHhDZt2ghHjhzR+K5XVFQIgiAI58+fF+bNmyf88ccfwqVLl4RffvlFCA8PF3r16uWw5TZUZke7pm11rusUFRUJjRo1EpYvX671fmc815ZgUCOBTz/9VAgJCRE8PDyE3r17awyRdiQAdP5bvXq1IAiCUF5eLsTFxQktWrQQ3N3dhXbt2gnjxo0TsrKyNPZz584dYcqUKUJAQIDg7e0tPProo1ppCgoKhOeee07w9fUVfH19heeee064ffu2RporV64Iw4cPF7y9vYWAgABhypQpGkMBpVA3L4m7u7sQHBwsPPnkk8LJkydVr9fU1Ahz584VgoKCBE9PT2HAgAHC8ePHnba86rZu3SoAEDIzMzW2y+k879y5U+c1PW7cOEEQHO/8Hjt2TIiNjRU8PT2FoKAg4d133zVrqKuhcl+6dEnvd71unqKsrCxhwIABQkBAgODh4SF06NBBmDp1qta8Lo5UbkNldsRr2hbnus5nn30meHt7a809IwjOea4toRAEW071R0RERGQd7FNDREREssCghoiIiGSBQQ0RERHJAoMaIiIikgUGNURERCQLDGqIiIhIFhjUEBERkSwwqCEiIiJZYFBDREREssCghoiIiGSBQQ0RERHJAoMaIiIikoX/B5YDT1jCYSFAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_rec)#[1000:])\n",
    "plt.grid(which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(y,torch.tensor([0,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Khushi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
