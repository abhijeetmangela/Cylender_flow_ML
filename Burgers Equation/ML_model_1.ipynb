{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepONet,self).__init__()\n",
    "        self.Bralch_L1 = nn.Linear(100,20)\n",
    "        self.Bralch_L2 = nn.Linear(20,20)\n",
    "        self.Bralch_L3 = nn.Linear(20,20)\n",
    "        self.Bralch_L4 = nn.Linear(20,20)\n",
    "        self.Bralch_L5 = nn.Linear(20,100)\n",
    "\n",
    "        self.Trunk_L1 = nn.Linear(2,20)\n",
    "        self.Trunk_L2 = nn.Linear(20,20)\n",
    "        self.Trunk_L3 = nn.Linear(20,20)\n",
    "        self.Trunk_L4 = nn.Linear(20,20)\n",
    "        self.Trunk_L5 = nn.Linear(20,100)\n",
    "        \n",
    "    def forward(self,y_0,x_loc_and_time):\n",
    "        # Branch\n",
    "        b = F.relu(self.Bralch_L1(y_0))\n",
    "        b = F.relu(self.Bralch_L2(b))\n",
    "        b = F.relu(self.Bralch_L3(b))\n",
    "        b = F.relu(self.Bralch_L4(b))\n",
    "        b = self.Bralch_L5(b)\n",
    "\n",
    "        # Trunk \n",
    "        t = F.relu(self.Trunk_L1(x_loc_and_time))\n",
    "        t = F.relu(self.Trunk_L2(t))\n",
    "        t = F.relu(self.Trunk_L3(t))\n",
    "        t = F.relu(self.Trunk_L4(t))\n",
    "        t = self.Trunk_L5(t)\n",
    "\n",
    "        # dot product\n",
    "        output = torch.sum(b*torch.(t),dim=0) \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = pd.read_csv(\"Dataset_1.csv\").iloc[:,1:-3].dropna().to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141000, 103)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,transform=None):\n",
    "        data_full = df_trial\n",
    "        self.init_conditions = torch.from_numpy(data_full[:,:100])\n",
    "        self.x_loc = torch.from_numpy(data_full[:,[100]])\n",
    "        self.Time = torch.from_numpy(data_full[:,[101]])\n",
    "        self.Y_value = torch.from_numpy(data_full[:,[102]])\n",
    "        self.n_samples = data_full.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.init_conditions[index] , self.x_loc[index] , self.Time[index] , self.Y_value[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7*len(Data()))\n",
    "test_size = len(Data()) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burger_train , Burger_split = torch.utils.data.random_split(Data(), [train_size,test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Burger_train\n",
    "train_loader = DataLoader(dataset=data_train,batch_size=300,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 1])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "data = data_iter.__next__()\n",
    "Init_val , x_loc, time, y_value = data\n",
    "print(y_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329 2\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "total_samples = len(train_loader)\n",
    "n_iterations = math.ceil(total_samples/300)\n",
    "print(total_samples,n_iterations)\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m input2 \u001b[38;5;241m=\u001b[39m input2\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m Actual_y \u001b[38;5;241m=\u001b[39m Actual_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m Outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(Outputs,Actual_y)\n\u001b[0;32m     15\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[99], line 32\u001b[0m, in \u001b[0;36mDeepONet.forward\u001b[1;34m(self, y_0, x_loc_and_time)\u001b[0m\n\u001b[0;32m     29\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTrunk_L5(t)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# dot product\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(b\u001b[38;5;241m*\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for i , (input_init_conditions,input_x_loc,input_time,Actual_y) in enumerate(train_loader):\n",
    "        input1 = input_init_conditions\n",
    "        input1 = input1.to(device)\n",
    "\n",
    "        input2 = torch.cat((input_x_loc,input_time),-1)\n",
    "        input2 = input2.to(device)\n",
    "\n",
    "        Actual_y = Actual_y.to(device)\n",
    "\n",
    "        Outputs = model(input1,input2)\n",
    "        loss = criterion(Outputs,Actual_y)\n",
    "\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        if (i+1) % 100 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoch}] , Step [{i+1}/{total_samples}] , Loss: {loss.item():.16f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\envs\\abhi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[99], line 32\u001b[0m, in \u001b[0;36mDeepONet.forward\u001b[1;34m(self, y_0, x_loc_and_time)\u001b[0m\n\u001b[0;32m     29\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTrunk_L5(t)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# dot product\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(b\u001b[38;5;241m*\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim0, int dim1)\n * (Tensor input, name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "model(input1,input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(input1.device)        # Should output cuda:0 or cpu\n",
    "print(input2.device)        # Should output cuda:0 or cpu\n",
    "print(next(model.parameters()).device) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
